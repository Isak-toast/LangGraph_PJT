# Phase 0 Baseline 벤치마크 보고서

> 측정일: 2025-12-20
> 대상: Deep Research System (5-node architecture)

---

## 1. 테스트 환경

| 항목 | 값 |
|------|-----|
| **아키텍처** | Planner → Searcher → ContentReader → Analyzer → Writer |
| **LLM** | gemini-2.0-flash-exp |
| **검색 API** | Tavily (max 5 results) |
| **최대 반복** | 3회 |

---

## 2. 테스트 질문

| # | 유형 | 질문 |
|---|------|------|
| 1 | 비교형 | LangGraph와 CrewAI의 멀티 에이전트 아키텍처를 비교하고 장단점을 분석해줘 |
| 2 | 학술형 | 2024년 발표된 LLM 기반 에이전트 시스템 관련 논문들을 분석하고 주요 트렌드를 설명해줘 |
| 3 | 기술형 | RAG와 Agent 기반 접근법의 차이점과 각각 언제 사용하면 좋은지 설명해줘 |

---

## 3. 측정 결과

### 3.1 개별 결과

| 테스트 | 시간 | LLM 호출 | 검색 | URL 읽기 | 반복 | 토큰 | 응답 길이 | 인용 |
|--------|------|---------|------|---------|------|------|----------|------|
| 비교형 | 31.89s | 2 | 3 | 9 | 3 | 1,434 | 3,843자 | ❌ |
| 학술형 | 38.25s | 2 | 3 | 9 | 3 | 1,288 | 3,346자 | ❌ |
| 기술형 | 27.47s | 2 | 1 | 3 | 1 | 1,384 | 3,517자 | ❌ |

### 3.2 평균 지표

| 지표 | 값 |
|------|-----|
| **평균 소요 시간** | 32.54초 |
| **평균 토큰 사용량** | 1,369 |
| **인용 포함률** | 0% |
| **평균 응답 길이** | 3,569자 |

---

## 4. 분석

### 4.1 성능 평가

| 항목 | 평가 | 비고 |
|------|------|------|
| ⏱️ 소요 시간 | ⚠️ 느림 | 30초+ 대기 시간 |
| 🔍 검색 깊이 | ✅ 적절 | 평균 9개 URL 읽기 |
| 📝 응답 길이 | ✅ 충분 | 3,500자 상세 응답 |
| 📚 인용 | ❌ 없음 | Citation 미포함 |
| 🔄 반복 검색 | ✅ 작동 | Analyzer 판단 정상 |

### 4.2 발견된 문제점

1. **인용 미포함 (0%)**
   - Writer 프롬프트에 Citation Rules 부재
   - Phase 4에서 해결 예정

2. **느린 응답 시간 (평균 32초)**
   - 순차 처리로 인한 지연
   - Phase 6 병렬 처리로 개선 가능

3. **토큰 비효율**
   - 연구 결과 압축 없음
   - Phase 1 Compress로 개선 예정

---

## 5. Phase 1 개선 목표

| 지표 | Phase 0 (현재) | Phase 1 목표 | 예상 개선 |
|------|--------------|-------------|----------|
| 토큰 사용량 | 1,369 | ~1,100 | -20% |
| 인용 포함률 | 0% | 30%+ | +30% |
| 응답 품질 | 기준 | +0.5점 | 향상 |

---

## 6. 다음 단계

Phase 1 Compress 구현:
1. `compress_node` 추가
2. Graph 수정 (Analyzer → Compress → Writer)
3. 재측정 및 비교

---

## 부록: 원시 데이터

`benchmark_results/phase_0_20251220_002536.json` 참조
