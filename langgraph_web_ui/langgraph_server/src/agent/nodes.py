"""
nodes.py - Deep Research ë…¸ë“œ êµ¬í˜„
===================================

5ê°œ ë…¸ë“œë¡œ êµ¬ì„±ëœ Deep Research ì‹œìŠ¤í…œ:
1. Planner: ë¦¬ì„œì¹˜ ê³„íš ìˆ˜ë¦½
2. Searcher: ì›¹ ê²€ìƒ‰ (Tavily)
3. ContentReader: URL ë‚´ìš© ì½ê¸°
4. Analyzer: ì •ë³´ ë¶„ì„ + ì¶”ê°€ ê²€ìƒ‰ íŒë‹¨
5. Writer: ìµœì¢… ì‘ë‹µ ì‘ì„±

ê·¸ë˜í”„ êµ¬ì¡°:
  Planner â†’ Searcher â†’ ContentReader â†’ Analyzer â†’ Writer
                 â†‘                          â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      (ì¶”ê°€ ê²€ìƒ‰ í•„ìš”ì‹œ)
"""

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from src.agent.state import DeepResearchState
from src.agent.tools import tavily_tool, read_url_tool


# ================================================================
# LLM ì´ˆê¸°í™”
# ================================================================

llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    temperature=0.3
)


# ================================================================
# 1. Planner ë…¸ë“œ - ë¦¬ì„œì¹˜ ê³„íš ìˆ˜ë¦½
# ================================================================

PLANNER_PROMPT = """You are a RESEARCH PLANNER. Your job is to create a research strategy.

Analyze the user's question and create a research plan with:
1. Multiple search queries (in English for better results)
2. Focus areas to explore
3. Depth level (1=quick, 2=medium, 3=deep)

OUTPUT FORMAT (JSON):
{
    "search_queries": ["query1", "query2", "query3"],
    "focus_areas": ["area1", "area2"],
    "depth_level": 2
}

EXAMPLES:
- "LangGraph Vision AI papers" â†’ queries: ["LangGraph Vision AI paper", "LangGraph computer vision", "LangGraph image processing agent"]
- "AI trends 2024" â†’ queries: ["AI trends 2024", "machine learning trends 2024", "generative AI advances 2024"]

Create 2-4 diverse search queries to get comprehensive results.
"""

def planner_node(state: DeepResearchState) -> dict:
    """ë¦¬ì„œì¹˜ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” Planner ë…¸ë“œ"""
    
    messages = state["messages"]
    user_query = ""
    
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage) or (hasattr(msg, 'type') and msg.type == 'human'):
            user_query = msg.content
            break
    
    print(f"ğŸ“‹ Planner: Creating research plan for: {user_query[:50]}...")
    
    # LLMì—ê²Œ ê³„íš ìƒì„± ìš”ì²­
    structured_llm = llm.with_structured_output({
        "type": "object",
        "properties": {
            "search_queries": {"type": "array", "items": {"type": "string"}},
            "focus_areas": {"type": "array", "items": {"type": "string"}},
            "depth_level": {"type": "integer", "minimum": 1, "maximum": 3}
        },
        "required": ["search_queries", "focus_areas", "depth_level"]
    })
    
    try:
        plan = structured_llm.invoke(f"{PLANNER_PROMPT}\n\nUser Question: {user_query}")
        print(f"ğŸ“‹ Planner: Generated {len(plan.get('search_queries', []))} queries")
    except Exception as e:
        print(f"âŒ Planner error: {e}")
        plan = {
            "search_queries": [user_query],
            "focus_areas": ["general"],
            "depth_level": 2
        }
    
    return {
        "research_plan": plan,
        "current_query_index": 0,
        "research_iteration": 1,
        "search_results": [],
        "urls_to_read": [],
        "read_contents": [],
        "findings": []
    }


# ================================================================
# 2. Searcher ë…¸ë“œ - ì›¹ ê²€ìƒ‰
# ================================================================

def searcher_node(state: DeepResearchState) -> dict:
    """Tavily ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” Searcher ë…¸ë“œ"""
    
    plan = state.get("research_plan", {})
    queries = plan.get("search_queries", [])
    current_idx = state.get("current_query_index", 0)
    iteration = state.get("research_iteration", 1)
    
    # ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    next_query = state.get("next_search_query")
    if next_query:
        query = next_query
        print(f"ğŸ” Searcher [{iteration}]: Follow-up search for: {query}")
    elif current_idx < len(queries):
        query = queries[current_idx]
        print(f"ğŸ” Searcher [{iteration}]: Searching for: {query}")
    else:
        return {"search_results": [], "urls_to_read": []}
    
    try:
        results = tavily_tool.invoke(query)
        urls = [r.get("url", "") for r in results if r.get("url")]
        
        print(f"ğŸ” Searcher: Found {len(results)} results, {len(urls)} URLs")
        
        return {
            "search_results": results,
            "urls_to_read": urls[:5],  # ìƒìœ„ 5ê°œ URL
            "current_query_index": current_idx + 1,
            "next_search_query": None  # ì‚¬ìš© í›„ ë¦¬ì…‹
        }
    except Exception as e:
        print(f"âŒ Searcher error: {e}")
        return {"search_results": [], "urls_to_read": []}


# ================================================================
# 3. ContentReader ë…¸ë“œ - URL ë‚´ìš© ì½ê¸°
# ================================================================

def content_reader_node(state: DeepResearchState) -> dict:
    """URL ë‚´ìš©ì„ ì½ëŠ” ContentReader ë…¸ë“œ"""
    
    urls = state.get("urls_to_read", [])
    existing_contents = state.get("read_contents", [])
    
    if not urls:
        print("ğŸ“– ContentReader: No URLs to read")
        return {"read_contents": existing_contents}
    
    print(f"ğŸ“– ContentReader: Reading {len(urls)} URLs...")
    
    new_contents = []
    for url in urls[:3]:  # ìƒìœ„ 3ê°œë§Œ ì½ê¸° (í† í° ì ˆì•½)
        try:
            content = read_url_tool.invoke(url)
            new_contents.append({
                "url": url,
                "content": content[:4000],  # ê° URL 4000ì ì œí•œ
                "title": url.split("/")[-1]
            })
            print(f"  âœ“ Read: {url[:60]}...")
        except Exception as e:
            print(f"  âœ— Failed: {url[:40]}... ({e})")
    
    # ê¸°ì¡´ ë‚´ìš© + ìƒˆ ë‚´ìš©
    all_contents = existing_contents + new_contents
    
    return {"read_contents": all_contents, "urls_to_read": []}


# ================================================================
# 4. Analyzer ë…¸ë“œ - ì •ë³´ ë¶„ì„ + ì¶”ê°€ ê²€ìƒ‰ íŒë‹¨
# ================================================================

ANALYZER_PROMPT = """You are a RESEARCH ANALYZER. Analyze the collected information.

YOUR TASKS:
1. Extract key findings from the search results and read contents
2. Determine if the information is sufficient to answer the user's question
3. If more research is needed, suggest a specific search query

CONSIDER:
- Have we found specific papers/articles about the topic?
- Is the information detailed enough?
- Are there gaps in our knowledge?

OUTPUT FORMAT (JSON):
{
    "findings": ["finding1", "finding2", ...],
    "needs_more_research": true/false,
    "next_search_query": "specific query if more research needed"
}
"""

def analyzer_node(state: DeepResearchState) -> dict:
    """ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” Analyzer ë…¸ë“œ"""
    
    search_results = state.get("search_results", [])
    read_contents = state.get("read_contents", [])
    iteration = state.get("research_iteration", 1)
    existing_findings = state.get("findings", [])
    
    print(f"ğŸ”¬ Analyzer [{iteration}]: Analyzing {len(search_results)} results, {len(read_contents)} contents")
    
    # ë¶„ì„í•  ë‚´ìš© ì¤€ë¹„
    content_summary = ""
    for r in search_results[:5]:
        content_summary += f"- {r.get('content', '')[:500]}\n"
    for c in read_contents:
        content_summary += f"- [URL: {c.get('url', '')}] {c.get('content', '')[:800]}\n"
    
    # ì‚¬ìš©ì ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
    user_query = ""
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            user_query = msg.content
            break
    
    # LLM ë¶„ì„
    structured_llm = llm.with_structured_output({
        "type": "object",
        "properties": {
            "findings": {"type": "array", "items": {"type": "string"}},
            "needs_more_research": {"type": "boolean"},
            "next_search_query": {"type": "string"}
        },
        "required": ["findings", "needs_more_research"]
    })
    
    try:
        prompt = f"""{ANALYZER_PROMPT}

User Question: {user_query}
Research Iteration: {iteration}/3

Collected Information:
{content_summary[:6000]}

Existing Findings: {existing_findings}
"""
        analysis = structured_llm.invoke(prompt)
        
        new_findings = existing_findings + analysis.get("findings", [])
        needs_more = analysis.get("needs_more_research", False)
        next_query = analysis.get("next_search_query", "")
        
        # ìµœëŒ€ 3íšŒ ë°˜ë³µ ì œí•œ
        if iteration >= 3:
            needs_more = False
            print("ğŸ”¬ Analyzer: Max iterations reached, proceeding to Writer")
        
        if needs_more:
            print(f"ğŸ”¬ Analyzer: More research needed - {next_query}")
        else:
            print(f"ğŸ”¬ Analyzer: Research complete with {len(new_findings)} findings")
        
        return {
            "findings": new_findings,
            "needs_more_research": needs_more,
            "next_search_query": next_query if needs_more else None,
            "research_iteration": iteration + 1 if needs_more else iteration
        }
        
    except Exception as e:
        print(f"âŒ Analyzer error: {e}")
        return {
            "findings": existing_findings,
            "needs_more_research": False,
            "next_search_query": None
        }


# ================================================================
# 5. Writer ë…¸ë“œ - ìµœì¢… ì‘ë‹µ ì‘ì„±
# ================================================================

WRITER_PROMPT = """You are a PROFESSIONAL WRITER. Write the FINAL RESPONSE based on research.

INSTRUCTIONS:
1. Synthesize ALL findings into a comprehensive response
2. Write in Korean (í•œêµ­ì–´)
3. Use proper markdown formatting
4. Include analysis and insights
5. Reference key sources

STRUCTURE:
## í•µì‹¬ ìš”ì•½
(1-2 sentences overview)

## ì£¼ìš” ë°œê²¬ ì‚¬í•­
(Key findings from research)

## ìƒì„¸ ë¶„ì„
(Detailed analysis with structure)

## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜
(List of relevant sources)

## ê²°ë¡  ë° í‰ê°€
(Conclusion and your assessment)

IMPORTANT:
- Write clear, professional Korean
- DO NOT just copy findings - synthesize and analyze
- Provide valuable insights
"""

def writer_node(state: DeepResearchState) -> dict:
    """ìµœì¢… ì‘ë‹µì„ ì‘ì„±í•˜ëŠ” Writer ë…¸ë“œ"""
    
    findings = state.get("findings", [])
    read_contents = state.get("read_contents", [])
    search_results = state.get("search_results", [])
    
    print(f"âœï¸ Writer: Composing response from {len(findings)} findings")
    
    # ì‚¬ìš©ì ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
    user_query = ""
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            user_query = msg.content
            break
    
    # ì†ŒìŠ¤ URL ëª©ë¡
    source_urls = list(set([c.get("url", "") for c in read_contents if c.get("url")]))
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    content_details = ""
    for c in read_contents[:5]:
        content_details += f"\n### Source: {c.get('url', '')}\n{c.get('content', '')[:1500]}\n"
    
    prompt = f"""{WRITER_PROMPT}

USER QUESTION: {user_query}

RESEARCH FINDINGS:
{chr(10).join(f'- {f}' for f in findings)}

DETAILED CONTENT FROM SOURCES:
{content_details}

SOURCE URLs:
{chr(10).join(f'- {url}' for url in source_urls)}

Now write the final response in Korean:
"""
    
    try:
        response = llm.invoke([SystemMessage(content=prompt)])
        content = response.content
        
        if not content or len(content.strip()) < 50:
            content = f"""## ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½

{chr(10).join(f'- {f}' for f in findings)}

### ì¶œì²˜
{chr(10).join(f'- {url}' for url in source_urls)}
"""
        
        print(f"âœï¸ Writer: Generated {len(content)} chars")
        
    except Exception as e:
        print(f"âŒ Writer error: {e}")
        content = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"
    
    return {
        "messages": [AIMessage(content=content, name="Writer")]
    }


# ================================================================
# ë¼ìš°íŒ… í•¨ìˆ˜
# ================================================================

def should_continue_research(state: DeepResearchState) -> str:
    """Analyzer í›„ ì¶”ê°€ ê²€ìƒ‰ ì—¬ë¶€ íŒë‹¨"""
    if state.get("needs_more_research", False):
        return "continue"
    return "finish"


def route_after_planner(state: DeepResearchState) -> str:
    """Planner í›„ Searcherë¡œ ì´ë™"""
    return "Searcher"
