"""
tools.py - ì—ì´ì „íŠ¸ ë„êµ¬ ì •ì˜
==============================

ì´ íŒŒì¼ì€ ì—ì´ì „íŠ¸ë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬(Tools)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
ë„êµ¬ëŠ” ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ì„¸ê³„ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

í˜„ì¬ ë„êµ¬:
- Tavily Search: ì›¹ ê²€ìƒ‰ API (ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½)
- Read URL: íŠ¹ì • URLì˜ ì „ì²´ ë‚´ìš©ì„ ì½ì–´ì˜¤ê¸°

ë„êµ¬ë€?
- LLMì´ ì§ì ‘ í•  ìˆ˜ ì—†ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
- ì˜ˆ: ì›¹ ê²€ìƒ‰, ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ, API í˜¸ì¶œ, ê³„ì‚° ë“±
"""

import os
import httpx
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.tools import tool


# ================================================================
# Tavily Search Tool (ì›¹ ê²€ìƒ‰ ë„êµ¬)
# ================================================================
# 
# TavilyëŠ” AI ì—ì´ì „íŠ¸ë¥¼ ìœ„í•´ ìµœì í™”ëœ ê²€ìƒ‰ APIì…ë‹ˆë‹¤.
# ê²€ìƒ‰ ê²°ê³¼ì˜ ìš”ì•½ê³¼ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤.
#
# ì‚¬ìš© ë°©ë²•:
#   result = tavily_tool.invoke("ê²€ìƒ‰í•  ì¿¼ë¦¬")
#
# ë°˜í™˜ í˜•ì‹:
#   [{"content": "ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½...", "url": "https://..."}, ...]

tavily_tool = TavilySearchResults(
    max_results=5  # ë” ë§ì€ ê²€ìƒ‰ ê²°ê³¼ë¡œ ì¦ê°€
)


# ================================================================
# URL Reader Tool (ì›¹ í˜ì´ì§€ ë‚´ìš© ì½ê¸°)
# ================================================================
# 
# íŠ¹ì • URLì˜ ì‹¤ì œ ë‚´ìš©ì„ ì½ì–´ì™€ì„œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
# Tavilyê°€ ìš”ì•½ë§Œ ì œê³µí•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, ì „ì²´ í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#
# ì‚¬ìš© ë°©ë²•:
#   result = read_url_tool.invoke("https://arxiv.org/abs/...")
#
# ë°˜í™˜ í˜•ì‹:
#   "ì›¹ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ë‚´ìš© (ìµœëŒ€ 8000ì)"

@tool
def read_url_tool(url: str) -> str:
    """
    Read the full content of a web page URL.
    Use this tool to get detailed information from a specific URL found during search.
    
    Args:
        url: The URL to read (e.g., "https://arxiv.org/abs/2412.03801")
    
    Returns:
        The text content of the web page (max 8000 characters)
    
    Example:
        read_url_tool("https://arxiv.org/html/2412.03801v1")
    """
    try:
        # HTTP ìš”ì²­ìœ¼ë¡œ í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        headers = {
            "User-Agent": "Mozilla/5.0 (compatible; ResearchBot/1.0)"
        }
        
        with httpx.Client(timeout=15.0, follow_redirects=True) as client:
            response = client.get(url, headers=headers)
            response.raise_for_status()
        
        content = response.text
        
        # HTML íƒœê·¸ ê°„ë‹¨íˆ ì œê±° (BeautifulSoup ì—†ì´)
        import re
        # script, style íƒœê·¸ ì œê±°
        content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL | re.IGNORECASE)
        content = re.sub(r'<style[^>]*>.*?</style>', '', content, flags=re.DOTALL | re.IGNORECASE)
        # HTML íƒœê·¸ ì œê±°
        content = re.sub(r'<[^>]+>', ' ', content)
        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        content = re.sub(r'\s+', ' ', content).strip()
        
        # í† í° ì œí•œì„ ìœ„í•´ 8000ìë¡œ ìë¥´ê¸°
        if len(content) > 8000:
            content = content[:8000] + "... [truncated]"
        
        print(f"ğŸ“– Read URL: {url[:50]}... ({len(content)} chars)")
        return content
        
    except httpx.TimeoutException:
        return f"Error: Timeout while reading URL: {url}"
    except httpx.HTTPStatusError as e:
        return f"Error: HTTP {e.response.status_code} for URL: {url}"
    except Exception as e:
        return f"Error reading URL {url}: {str(e)}"


# ================================================================
# ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡
# ================================================================
# 
# ResearcherëŠ” ì´ ë‘ ë„êµ¬ë¥¼ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
# 1. tavily_tool: ë¨¼ì € ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ URL ì°¾ê¸°
# 2. read_url_tool: ì°¾ì€ URLì˜ ìƒì„¸ ë‚´ìš© ì½ê¸°

tools = [tavily_tool, read_url_tool]
