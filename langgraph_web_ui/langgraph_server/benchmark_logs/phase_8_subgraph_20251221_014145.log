/home/isak/LangGraph_PJT/langgraph_web_ui/langgraph_server/src/agent/tools.py:36: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.
  tavily_tool = TavilySearchResults(

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Deep Research Benchmark - Phase 8 Subgraph
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Test Queries: 3
â•‘  Verbose: ON (full response)
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸ“Š Running benchmark: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜...

ğŸ” Clarify: Analyzing query...
   â””â”€ Query: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜
   â””â”€ Status: ğŸŸ¡ Needs clarification
   â””â”€ Analysis: The query asks for a comparison of LangGraph and CrewAI's multi-agent architectures, including their pros and cons. While the request is clear in its intent (comparison and analysis), it lacks specific criteria for comparison. It would be helpful to know what aspects of the architectures the user is most interested in (e.g., scalability, cost, ease of use, specific capabilities).
   â””â”€ Topics: LangGraph, CrewAI, Multi-Agent Architecture
   â””â”€ Suggested question: What specific aspects or criteria are you most interested in when comparing the multi-agent architectures of LangGraph and CrewAI (e.g., scalability, cost, ease of use, specific capabilities)?
ğŸ“‹ Planner: Creating research plan for: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜

ğŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] LangGraph vs CrewAI multi-agent architecture
      [2] LangGraph multi-agent system advantages disadvantages
      [3] CrewAI multi-agent system advantages disadvantages
      [4] Comparing LangGraph and CrewAI for complex tasks
   â””â”€ Focus: Architectural differences, Performance comparison, Scalability, Ease of use, Cost analysis

ğŸ”¬ Research Subgraph: Starting research loop...
ğŸ” Searcher [1]: Searching for: LangGraph vs CrewAI multi-agent architecture

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [2] https://www.zenml.io/blog/langgraph-vs-crewai
      [3] https://www.zams.com/blog/crewai-vs-langgraph
      [4] https://blog.langchain.com/langgraph-multi-agent-workflows/
      [5] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/
   â””â”€ Snippets:
      â€¢ While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. [...] CrewAI and LangGraph both bring powerful capabilities to AI application development, but they excel in different areas. CrewAI is ideal for structured, role-based multi-agent collaboration, while LangGraph is built for adaptive, stateful workflows that can branch, loop, and respond to changing inputs. Your choice depends on your projectâ€™s nature. If you need a coordinated team of specialized agents, CrewAI is a natural fit. If your focus is on flexible execution with robust state management, [...] When you build with CrewAI or LangGraph, you are working with powerful frameworks for orchestrating AI agents. CrewAI excels in structuring multi-agent collaboration, while LangGraph shines in managing complex, adaptive workflows. But once these systems move from development to production, the challenges shift. You need to ensure they run securely, efficiently, and with complete operational visibility. Thatâ€™s where TrueFoundry AI Gateway becomes the perfect companion.
      â€¢ What's the learning curve difference between these frameworks? CrewAI offers faster initial setup with its role-based, YAML-configurable approachâ€”teams can build working multi-agent systems in hours. LangGraph requires deeper understanding of graph structures, state management, and functional composition, typically taking days to weeks to master. However, LangGraph's complexity pays dividends in complex workflows requiring precise control, conditional routing, and advanced debugging. [...] Complex stateful workflows with branching logic: Choose LangGraph for its graph-based architecture, conditional routing, and time-travel debugging capabilities that handle non-linear agent interactions.  Rapid prototyping and POC development: Choose CrewAI for its intuitive role-based model and YAML configuration that enables working multi-agent systems in hours rather than days. [...] ## LangGraph vs CrewAI: Key Takeaways  ğŸ§‘â€ğŸ’» LangGraph: Itâ€™s a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic.
      â€¢ ## Final verdict  To sum up, Crew and Langgraph are both powerful frameworks, each with its unique strengths and weaknesses. Choosing the right framework ultimately depends on your specific needs and expertise.  For beginners or those looking for a simple multi-agent orchestration framework Crew is the way to go. Its user friendly and modular design makes it easy to get started. [...] While Crewai offers a beginner-friendly and is easy-to-use, it is limited in flexibility. On the other hand, LangGraph offers great control and flexibility but is not easy to quickly set up and get going.  > Both these platforms are primarily for software development teams.  When engineering teams want to research and quickly prototype, they go for Crew. And during production, they prefer LangGraph to develop agents for complex and detailed workflows. [...] LangGraph is an agent framework that takes a state-centric approach, providing a graph-based architecture to enable creation of complex workflows and applications. This approach is ideal for applications requiring sophisticated state management, knowledge retrieval, and distributed systems.  ## How to choose between Crewai and LangGraph?  Both are multi agent frameworks and they provide plenty of resources to get you started including tutorials, documentation, pre-built agents and tools.
ğŸ’­ Think: Query: LangGraph vs CrewAI multi-agent architecture | Found 5 results, 5 URLs. Key snippets: While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and co | What's the learning curve difference between these frameworks? CrewAI offers faster initial setup wi | ## Final verdict

To sum up, Crew and Langgraph are both powerful frameworks, each with its un. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://www.zams.com/blog/crewai-vs-langgraph... (8015 chars)
ğŸ“– Read URL: https://www.truefoundry.com/blog/crewai-vs-langgra... (8015 chars)
ğŸ“– Read URL: https://www.zenml.io/blog/langgraph-vs-crewai... (8015 chars)
   âœ“ [https://www.zams.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs. LangGraph: Multi agent framework comparison | Zams Integrations Customers Pricing Blog Login Login Get Started Get Started Technology April 19, 2025 Crewai vs. LangGraph: Which multi agent framework should you use? Yaagneshwaran Ganesh Objective feature comparison to help you decide - based on features, benefits, and ideal use cases. While there are different ways to build an AI agent from scratch, itâ€™s great that you are taking the efficient approach of using multi agent frameworks. Youâ€™re probably here because youâ€™ve shortlisted Crew ai and LangGraph and want to decide which one is right for you. Youâ€™re in the right place. In this blog, we will compare the two in detail - on their features, benefits, and ideal use cases, including how agents connect to establish communication and interoperability. To get started, we need to have a basic understanding of multi agent systems. So, letâ€™s first get a few basics out of the way. Why do you need a multi-agent framework? As your AI systems scale and you add multiple agents with different capabilities, the complexity of these applications grow. As the complexity grows, you will need a structured environment that orchestrates the agent activities, including the technical steps and requirements involved in building agents. That is where agentic frameworks come in. Multi agent frameworks provide you with a foundational structure for developing autonomous systems, and define parameters and protocols to handle interactions between multiple specialized agents. These frameworks also incorporate agent actions, which are fundamental components within a node-based AI framework, facilitating the execution of complex tasks. An agentic application can significantly enhance user experience and system efficiency by streamlining user interaction through minimal input and adaptive responses. Single agent systems These systems are autonomous but rely on one agent to handle a wide range of tasks, like a jack of all trades. For example, hereâ€™s how it works when requested for a sales pipeline report: As you can see, one agent carries out a series of tasks to accomplish the requested outcome. Single agent systems are great for specialized tasks where the problem is well defined and the scope is limited. But as your environment and context evolves, they fall short. Multi agent systems Multi agent systems, on the contrary, consist of multiple AI agents working together to achieve common goals. Letâ€™s look at the same example of requesting to email the sales report, and see how the multi agent architecture manages specialized agents to execute it. Instead of one agent accomplishing all the tasks, the tasks are broken down into smaller components where each agent specializes in a specific task â€“ such as planning, integrating, analyzing, and more like a team of specialists working together, where each brings their unique expertise to the table. And because these AI agents can collaborate dynamically and run these tasks in parallel, they can tackle more complex problems where the environment is always changing and evolving. Multi agent interactions allow these AI agents to communicate within the system, monitor and debug in real-time, and handle handoffs efficiently, enabling dynamic workflows. The better you understand how these multi agents interact, the better you can optimize these systems and scale your operations, without worrying about bottlenecks or performance issues. And thatâ€™s exactly what multi agent frameworks help you with. Additionally, these frameworks give you a set of pre-packaged tools and features to help you quickly build any type of agent systems, be it knowledge oriented, process oriented or predictive. In short, agentic frameworks are the backbone of scalable, efficient and autonomous AI operations. With that said letâ€™s get to the comparison. What is Crewai? It is an open-source multi agent orchestration framework, that helps you build multi agent systems, and integrate them wit
   âœ“ [https://www.truefoundry.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs LangGraph: Know The Differences --> --> Join the AI Security Webinar with Palo Alto. Register here Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Open Source Resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities Insurance Retail Government Technology Oil and Gas BY FUNCTION For DS Leaders For IT Leaders Application Suites Customer Support and CRM Finance IT Operations Marketing Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Careers resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Trust Center Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities CUSTOMERS For DS Leaders For IT Leaders Insurance Retail Government Technology Oil and Gas BY FUNCTION Newsletter Application Suites Customer Support and CRM Finance IT Operations Marketing Trust Center Compare Newsletter Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Pricing Docs Blog Live Demo Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Login Book Demo Sign Up Login Sign Up Book Demo comparison Crewai vs LangGraph: Know The Differences August 21, 2025 | 9:30 min read TrueFoundry SHARE The rise of multi-agent AI systems has created a need for frameworks that go beyond simple prompt chaining. Developers now want tools that can orchestrate multiple agents, manage shared state, and support complex workflows with branching, looping, and retries. Two notable frameworks leading this space are CrewAI and LangGraph. While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. In this comparison, weâ€™ll break down their core philosophies, features, and use cases to help you decide which framework better fits your AI development needs. What Is CrewAI? CrewAI is an open-source, Python-based framework designed for orchestrating autonomous, collaborative AI agents, much like a digital team handling complex tasks. Each agent operates with a defined role, such as researcher, writer, or analyst, and works together within a structured crew to solve problems efficiently. CrewAI combines modularity with performance, offering both high-level simplicity and precise control over how agents interact. Through components like Crews and Flows, it supports dynamic collaboration while giving developers the ability to manage control flows, tasks, and environments with flexibility. Agents in CrewAI are set up with defined roles, goals, tools, and even personality through backstories. This is similar to how a human team organizes itself to divide work and minimize errors. The framework allows agents to work sequentially or in parallel, with coordination
   âœ“ [https://www.zenml.io/blog/langgraph-vs-crewai]
      Preview: LangGraph vs CrewAI: Letâ€™s Learn About the Differences - ZenML Blog Product DATA SCience Iterate at warp speed Accelerate your ML workflow seamlessly Auto-track everything Automatic logging and versioning Shared ML building blocks Boost team productivity with reusable components Infrastructure Backend flexibility, zero lock-in One framework for all your MLOps and LLMOps needs Limitless scaling Effortlessly deploy across clouds Streamline cloud expenses Gain clarity on resource usage and costs Organization ZenML Pro Our managed control plane for MLOps Open Source vs Pro Pick what works for your needs ZenML vs Other Tools Compare ZenML to other ML tools Solutions GENAI &amp; LLMS Finetuning LLMs Customize large language models for specific tasks Productionalizing a RAG application Deploy and scale RAG systems LLMOps Database A curated knowledge base of real-world implementations mlops Building Enterprise MLOps Platform architecture and best practices Abstract cloud compute Simplify management of cloud-based ML resources Track metrics and metadata Monitor and analyze ML model performance and data Success Stories JetBrains Software Adeo Leroy Merlin Retail Cross Screen Media Media View All Case Studies Learn more Developers Documentation Docs Comprehensive guides to use ZenML Deploying ZenML Understanding ZenML system architecture Tutorials Examples showing ZenML in action GUIDES Quickstart Quickly get your hands dirty Showcase Projects of ML use cases built with ZenML Starter Guide Get started with the basics COMMUNITY Slack Join our Slack Community Changelog Discover whatâ€™s new on ZenML Roadmap Join us on our MLOps journey Pricing Blog Case Studies Get Started Book a demo Software Engineering LangGraph vs CrewAI: Letâ€™s Learn About the Differences Hamza Tahir Jun 28, 2025 â€¢ 12 mins All posts LLMOps Contents Get started with ZenML today Begin with open source tools Works with any infrastructure Secure, metadata-only tracking Book a demo Related Posts Metaflow vs MLflow vs ZenML: Whatâ€™s the Difference? ZenML&#x27;s MCP Server Supports DXT: Making MLOps Conversations Frictionless This is also a heading This is a heading LangGraph and CrewAI are modern frameworks for orchestrating complex AI workflows with multiple LLM-driven agents. Both these intelligent systems are capable of sophisticated reasoning, planning, and autonomous action, and are becoming central to modern AI applications. However, they differ in abstraction, interfaces, and enterprise features. This LangGraph vs CrewAI article compares key attributes of these platforms, like: Workflow patterns Human-in-loop capabilities Parallelism and throttling Compliance and security Integration options Pricing We do this so you can exactly know when to use which one of these platforms. Recently Updated (November 2025) : This comparison has been refreshed with major 2025 developments including LangGraph 1.0&#x27;s stable release (October 2025), CrewAI&#x27;s multimodal support and agentic RAG capabilities, updated market adoption statistics showing 85% of organizations now using AI agents, and the emergence of new interoperability protocols like A2A and MCP. All framework comparisons and integration information reflect current capabilities as of November 2025. LangGraph vs CrewAI: Key Takeaways ğŸ§‘â€ğŸ’» LangGraph : Itâ€™s a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. ğŸ§‘â€ğŸ’» CrewAI : Itâ€™s a high-level framework for orchestrating autonomous AI agents working together as a crew. The platform abstracts away complexity by providing pre-built patterns for agent collaboration, role assignment, and task delegation. Framework Maturity &amp; Lineage The table below compared the framework maturity of LangGraph and CrewAI: Metric CrewAI LangGraph First public release v0.1.0 â€” 14 Nov 2023 v0.0.9 â€” 8 Jan 20
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.21s
ğŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ğŸ”¬ Analyzer [1]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] CrewAI focuses on collaborative agent teams with specific roles and communication strategies.
      [2] LangGraph is a graph-based workflow engine for structured, resilient LLM applications.
      [3] CrewAI offers faster initial setup due to its role-based, YAML-configurable approach.
      [4] LangGraph requires a deeper understanding of graph structures and state management.
      [5] CrewAI is more user-friendly for beginners, while LangGraph is more flexible for complex workflows.
   â””â”€ Decision: More research needed
   â””â”€ Next query: LangGraph vs CrewAI architecture detailed comparison
ğŸ” Searcher [2]: Follow-up search for: LangGraph vs CrewAI architecture detailed comparison

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [2] https://www.zenml.io/blog/langgraph-vs-crewai
      [3] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/
      [4] https://aaronyuqi.medium.com/first-hand-comparison-of-langgraph-crewai-and-autogen-30026e60b563
      [5] https://latenode.com/blog/ai-frameworks-technical-infrastructure/langgraph-multi-agent-orchestration/langgraph-multi-agent-orchestration-complete-framework-guide-architecture-analysis-2025
   â””â”€ Snippets:
      â€¢ While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. [...] ## FAQâ€™s  ### 1. What is the difference between CrewAI and LangGraph?  CrewAI focuses on orchestrating multiple AI agents with defined roles and goals, ideal for structured collaboration. LangGraph uses a graph-based workflow model, enabling adaptive, branching, and looping processes with explicit state management. Both are powerful but serve different types of AI application needs.  ### 2. Can CrewAI and LangGraph be used together? [...] CrewAI and LangGraph both bring powerful capabilities to AI application development, but they excel in different areas. CrewAI is ideal for structured, role-based multi-agent collaboration, while LangGraph is built for adaptive, stateful workflows that can branch, loop, and respond to changing inputs. Your choice depends on your projectâ€™s nature. If you need a coordinated team of specialized agents, CrewAI is a natural fit. If your focus is on flexible execution with robust state management,
      â€¢ CrewAI launched a few months earlier than LangGraph (Novâ€¯2023 vs Janâ€¯2024), and it quickly attracted a large fanbase on GitHub â€“ 33â€¯k stars vs LangGraphâ€™s 15â€¯k.  On the other hand, LangGraphâ€™s 5â€¯800+ commits show a much faster development velocity compared to CrewAIâ€™s 1â€¯520.  When looking at actual usage, LangGraph leads in monthly downloads (~â€¯6.17â€¯M) compared to CrewAI (~â€¯1.38â€¯M), indicating broader adoption in production deployments.  ## LangGraph vs CrewAI: Feature Comparison [...] For other integrations, CrewAI is fully open-source Python: you can call any SDK or API by importing it in an agentâ€™s code.  Many teams use CrewAI with Slack or other SaaS tools; CrewAI provides Zapier connectors and webhook support.  Bottom line: LangGraph gives you the full LangChain integration stack, whereas CrewAI offers a broader and more diverse integration landscape with a vast network of partners - LLMs, core infrastructure, and a wide array of business applications. [...] What's the learning curve difference between these frameworks? CrewAI offers faster initial setup with its role-based, YAML-configurable approachâ€”teams can build working multi-agent systems in hours. LangGraph requires deeper understanding of graph structures, state management, and functional composition, typically taking days to weeks to master. However, LangGraph's complexity pays dividends in complex workflows requiring precise control, conditional routing, and advanced debugging.
      â€¢ The architecture follows a modular design that separates the concerns of agent creation, task definition, and process orchestration. This separation allows for precise customization at every level while maintaining a clean abstraction layer that simplifies development. CrewAI's standalone nature provides developers with greater flexibility and control over agent behavior and interaction patterns. [...] ### CrewAI's collaborative intelligence approach  CrewAI adopts a comprehensive approach to agent collaboration, structuring its architecture around crews, agents, tasks, and execution processes. The framework is built from the ground up without dependencies on Langchain or other agent frameworks, giving developers complete control over system behavior. At its core, CrewAI enables agents to assume specific roles within a crew, share goals, and operate as a cohesive unit. [...] This article provides a comprehensive analysis of the capabilities, features, and implementation considerations of leading AI agent frameworks focused on multi-agent collaboration and orchestration. Based on official documentation and reliable sources, this article provides a detailed comparison of CrewAI, LangGraph, and IBM's BeeAI frameworks.
ğŸ’­ Think: Query: LangGraph vs CrewAI architecture detailed comparison | Found 5 results, 5 URLs. Key snippets: While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and co | CrewAI launched a few months earlier than LangGraph (Novâ€¯2023 vs Janâ€¯2024), and it quickly attracted | The architecture follows a modular design that separates the concerns of agent creation, task . Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://www.zenml.io/blog/langgraph-vs-crewai... (8015 chars)
ğŸ“– Read URL: https://www.truefoundry.com/blog/crewai-vs-langgra... (8015 chars)
ğŸ“– Read URL: https://developer.ibm.com/articles/awb-comparing-a... (13 chars)
   âœ“ [https://www.zenml.io/blog/langgraph-vs-crewai]
      Preview: LangGraph vs CrewAI: Letâ€™s Learn About the Differences - ZenML Blog Product DATA SCience Iterate at warp speed Accelerate your ML workflow seamlessly Auto-track everything Automatic logging and versioning Shared ML building blocks Boost team productivity with reusable components Infrastructure Backend flexibility, zero lock-in One framework for all your MLOps and LLMOps needs Limitless scaling Effortlessly deploy across clouds Streamline cloud expenses Gain clarity on resource usage and costs Organization ZenML Pro Our managed control plane for MLOps Open Source vs Pro Pick what works for your needs ZenML vs Other Tools Compare ZenML to other ML tools Solutions GENAI &amp; LLMS Finetuning LLMs Customize large language models for specific tasks Productionalizing a RAG application Deploy and scale RAG systems LLMOps Database A curated knowledge base of real-world implementations mlops Building Enterprise MLOps Platform architecture and best practices Abstract cloud compute Simplify management of cloud-based ML resources Track metrics and metadata Monitor and analyze ML model performance and data Success Stories JetBrains Software Adeo Leroy Merlin Retail Cross Screen Media Media View All Case Studies Learn more Developers Documentation Docs Comprehensive guides to use ZenML Deploying ZenML Understanding ZenML system architecture Tutorials Examples showing ZenML in action GUIDES Quickstart Quickly get your hands dirty Showcase Projects of ML use cases built with ZenML Starter Guide Get started with the basics COMMUNITY Slack Join our Slack Community Changelog Discover whatâ€™s new on ZenML Roadmap Join us on our MLOps journey Pricing Blog Case Studies Get Started Book a demo Software Engineering LangGraph vs CrewAI: Letâ€™s Learn About the Differences Hamza Tahir Jun 28, 2025 â€¢ 12 mins All posts LLMOps Contents Get started with ZenML today Begin with open source tools Works with any infrastructure Secure, metadata-only tracking Book a demo Related Posts Metaflow vs MLflow vs ZenML: Whatâ€™s the Difference? ZenML&#x27;s MCP Server Supports DXT: Making MLOps Conversations Frictionless This is also a heading This is a heading LangGraph and CrewAI are modern frameworks for orchestrating complex AI workflows with multiple LLM-driven agents. Both these intelligent systems are capable of sophisticated reasoning, planning, and autonomous action, and are becoming central to modern AI applications. However, they differ in abstraction, interfaces, and enterprise features. This LangGraph vs CrewAI article compares key attributes of these platforms, like: Workflow patterns Human-in-loop capabilities Parallelism and throttling Compliance and security Integration options Pricing We do this so you can exactly know when to use which one of these platforms. Recently Updated (November 2025) : This comparison has been refreshed with major 2025 developments including LangGraph 1.0&#x27;s stable release (October 2025), CrewAI&#x27;s multimodal support and agentic RAG capabilities, updated market adoption statistics showing 85% of organizations now using AI agents, and the emergence of new interoperability protocols like A2A and MCP. All framework comparisons and integration information reflect current capabilities as of November 2025. LangGraph vs CrewAI: Key Takeaways ğŸ§‘â€ğŸ’» LangGraph : Itâ€™s a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. ğŸ§‘â€ğŸ’» CrewAI : Itâ€™s a high-level framework for orchestrating autonomous AI agents working together as a crew. The platform abstracts away complexity by providing pre-built patterns for agent collaboration, role assignment, and task delegation. Framework Maturity &amp; Lineage The table below compared the framework maturity of LangGraph and CrewAI: Metric CrewAI LangGraph First public release v0.1.0 â€” 14 Nov 2023 v0.0.9 â€” 8 Jan 20
   âœ“ [https://www.truefoundry.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs LangGraph: Know The Differences --> --> Join the AI Security Webinar with Palo Alto. Register here Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Open Source Resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities Insurance Retail Government Technology Oil and Gas BY FUNCTION For DS Leaders For IT Leaders Application Suites Customer Support and CRM Finance IT Operations Marketing Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Careers resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Trust Center Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities CUSTOMERS For DS Leaders For IT Leaders Insurance Retail Government Technology Oil and Gas BY FUNCTION Newsletter Application Suites Customer Support and CRM Finance IT Operations Marketing Trust Center Compare Newsletter Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Pricing Docs Blog Live Demo Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Login Book Demo Sign Up Login Sign Up Book Demo comparison Crewai vs LangGraph: Know The Differences August 21, 2025 | 9:30 min read TrueFoundry SHARE The rise of multi-agent AI systems has created a need for frameworks that go beyond simple prompt chaining. Developers now want tools that can orchestrate multiple agents, manage shared state, and support complex workflows with branching, looping, and retries. Two notable frameworks leading this space are CrewAI and LangGraph. While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. In this comparison, weâ€™ll break down their core philosophies, features, and use cases to help you decide which framework better fits your AI development needs. What Is CrewAI? CrewAI is an open-source, Python-based framework designed for orchestrating autonomous, collaborative AI agents, much like a digital team handling complex tasks. Each agent operates with a defined role, such as researcher, writer, or analyst, and works together within a structured crew to solve problems efficiently. CrewAI combines modularity with performance, offering both high-level simplicity and precise control over how agents interact. Through components like Crews and Flows, it supports dynamic collaboration while giving developers the ability to manage control flows, tasks, and environments with flexibility. Agents in CrewAI are set up with defined roles, goals, tools, and even personality through backstories. This is similar to how a human team organizes itself to divide work and minimize errors. The framework allows agents to work sequentially or in parallel, with coordination
   âœ“ [https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/]
      Preview: IBM Developer
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.56s
ğŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ğŸ”¬ Analyzer [2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] CrewAI focuses on collaborative agent teams with specific roles and communication strategies.
      [2] LangGraph is a graph-based workflow engine for structured, resilient LLM applications.
      [3] CrewAI offers faster initial setup due to its role-based, YAML-configurable approach.
      [4] LangGraph requires a deeper understanding of graph structures and state management.
      [5] CrewAI is more user-friendly for beginners, while LangGraph is more flexible for complex workflows.
   â””â”€ Decision: Research complete (16 total findings)
   â””â”€ âœ… Research Subgraph completed (execution #1)
   â””â”€ Findings: 16 items
   â””â”€ Contents: 6 URLs read

ğŸ“¦ Compress: Compressing 16 findings, 6 contents
   â””â”€ Compressed to 1953 chars (from ~6108 raw chars)
   â””â”€ Sources cited: 4
   â””â”€ Preview:
      ## Key Findings
      - CrewAI focuses on collaborative agent teams with specific roles and communication strategies [1], [2], [3].
      - LangGraph is a graph-based workflow engine for structured, resilient LLM applications [1], [2], [3].
      - CrewAI offers faster initial setup due to its role-based, YAML-configurable approach [1], [3].
      - LangGraph requires a deeper understanding of graph structures and state management [1], [3].
      - CrewAI is more user-friendly for beginners, while LangGraph is more flexible for complex workflows [1], [3].
      - LangGraph is fully integrated into the LangChain ecosystem [2], [3].
      - CrewAI has a modular design that separates agent creation, task definition, and process orchestration [1], [3].
      - CrewAI is a higher-level framework, while LangGraph gives more lower-level controllability [1], [3].
      
      ## Detailed Information
      CrewAI and LangGraph are both multi-agent frameworks, but they cater to different needs and expertise levels [3].
      
      CrewAI is designed with a focus on collaborative agent teams, emphasizing specific roles and communication strategies [1], [2], [3]. Its role-based, YAML-configurable approach allows for a faster initial setup [1], [3]. CrewAI's modular design separates agent creation, task definition, and process orchestration [1], [3]. This makes CrewAI a higher-level framework that is more user-friendly for beginners [1], [3].
      
      LangGraph, on the other hand, is a graph-based workflow engine suited for structured and resilient LLM applications [1], [2], [3]. Using LangGraph requires a deeper understanding of graph structures and state management [1], [3]. LangGraph provides more lower-level controllability and greater flexibility for complex workflows [1], [3]. LangGraph is fully integrated into the LangChain ecosystem [2], [3].
      
      ## Sources
      [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [2] https://www.zenml.io/blog/langgraph-vs-crewai
      [3] https://www.zams.com/blog/crewai-vs-langgraph

âœï¸ Writer: Composing response from 16 findings
   â””â”€ Using compressed notes (1953 chars)

âœï¸ Writer: Generated response (2460 chars)
   â””â”€ Sources used:
      [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [2] https://www.zenml.io/blog/langgraph-vs-crewai
      [3] https://www.zams.com/blog/crewai-vs-langgraph
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      
      CrewAIì™€ LangGraphëŠ” ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, CrewAIëŠ” í˜‘ì—… ì—ì´ì „íŠ¸ íŒ€ êµ¬ì¶•ì— ì´ˆì ì„ ë§ì¶˜ ì‚¬ìš©ì ì¹œí™”ì ì¸ ê³ ìˆ˜ì¤€ í”„ë ˆì„ì›Œí¬ì´ê³ , LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì™€ ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°ì— ì í•©í•œ LangChain ìƒíƒœê³„ì— í†µí•©ëœ ê·¸ë˜í”„ ê¸°ë°˜ ì—”ì§„ì´ë‹¤ [1], [2], [3].
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   CrewAIëŠ” íŠ¹ì • ì—­í• ê³¼ ì†Œí†µ ì „ëµì„ ê°•ì¡°í•˜ëŠ” í˜‘ì—… ì—ì´ì „íŠ¸ íŒ€ êµ¬ì¶•ì— íŠ¹í™”ë˜ì–´ ìˆë‹¤ [1], [2], [3].
      *   LangGraphëŠ” êµ¬ì¡°í™”ë˜ê³  ë³µì›ë ¥ ìˆëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì—”ì§„ì´ë‹¤ [1], [2], [3].
      *   CrewAIëŠ” ì—­í•  ê¸°ë°˜ YAML êµ¬ì„± ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸° ì„¤ì •ì´ ë” ë¹ ë¥´ë‹¤ [1], [3].
      *   LangGraphëŠ” ê·¸ë˜í”„ êµ¬ì¡°ì™€ ìƒíƒœ ê´€ë¦¬ì— ëŒ€í•œ ë” ê¹Šì€ ì´í•´ê°€ í•„ìš”í•˜ë‹¤ [1], [3].
      *   CrewAIëŠ” ì´ˆë³´ìì—ê²Œ ë” ì‚¬ìš©ì ì¹œí™”ì ì´ë©°, LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ìœ ì—°í•˜ë‹¤ [1], [3].
      *   LangGraphëŠ” LangChain ìƒíƒœê³„ì— ì™„ì „íˆ í†µí•©ë˜ì–´ ìˆë‹¤ [2], [3].
      *   CrewAIëŠ” ì—ì´ì „íŠ¸ ìƒì„±, ì‘ì—… ì •ì˜ ë° í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ë¶„ë¦¬í•˜ëŠ” ëª¨ë“ˆì‹ ë””ìì¸ì„ ê°€ì§€ê³  ìˆë‹¤ [1], [3].
      *   CrewAIëŠ” ê³ ìˆ˜ì¤€ í”„ë ˆì„ì›Œí¬ì´ê³ , LangGraphëŠ” ë” ë‚®ì€ ìˆ˜ì¤€ì˜ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤ [1], [3].
      
      ## ìƒì„¸ ë¶„ì„
      
      CrewAIì™€ LangGraphëŠ” ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, ëŒ€ìƒ ì‚¬ìš©ìì™€ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ ë©´ì—ì„œ ëšœë ·í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤ [3].
      
      **CrewAI:** CrewAIëŠ” í˜‘ì—… ì—ì´ì „íŠ¸ íŒ€ êµ¬ì¶•ì— ì¤‘ì ì„ ë‘ê³ , ê° ì—ì´ì „íŠ¸ì˜ ì—­í• ê³¼ ì†Œí†µ ì „ëµì„ ëª…í™•í•˜ê²Œ ì •ì˜í•˜ëŠ” ë° ìš©ì´í•˜ë‹¤ [1], [2], [3].  YAML ê¸°ë°˜ ì„¤ì • íŒŒì¼ì€ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì´ì–´ì„œ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì…ì„ ì œì‘í•˜ê³  ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤ [1], [3].  ì—ì´ì „íŠ¸ ìƒì„±, ì‘ì—… ì •ì˜, í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì´ ëª¨ë“ˆí™”ë˜ì–´ ìˆì–´ ì½”ë“œì˜ ì¬ì‚¬ìš©ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ë†’ì¸ë‹¤ [1], [3].  ë”°ë¼ì„œ, ë³µì¡í•œ ë¡œì§ë³´ë‹¤ëŠ” ì—­í•  ë¶„ë‹´ê³¼ í˜‘ì—…ì´ ì¤‘ìš”í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ CrewAIëŠ” ê°•ë ¥í•œ ì„ íƒì§€ê°€ ë  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³ ê° ì§€ì› ì‹œìŠ¤í…œì—ì„œ ê° ì—ì´ì „íŠ¸ê°€ íŠ¹ì • ê¸°ìˆ  ë¶„ì•¼ë¥¼ ë‹´ë‹¹í•˜ê³ , ê³ ê°ì˜ ë¬¸ì˜ë¥¼ ì ì ˆí•œ ì—ì´ì „íŠ¸ì—ê²Œ ì „ë‹¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.  ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ì´ˆë³´ìê°€ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•˜ê³  ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ”ë‹¤ [1], [3].
      
      **LangGraph:** ë°˜ë©´ LangGraphëŠ” ë”ìš± ë³µì¡í•˜ê³  êµ¬ì¡°í™”ëœ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆë‹¤ [1], [2], [3]. ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ê°„ì˜ ìƒí˜¸ ì‘ìš©ê³¼ ìƒíƒœ ë³€í™”ë¥¼ ì •ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆë‹¤.  í•˜ì§€ë§Œ ì´ë¥¼ ìœ„í•´ì„œëŠ” ê·¸ë˜í”„ êµ¬ì¡°ì™€ ìƒíƒœ ê´€ë¦¬ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ì´í•´ê°€ í•„ìˆ˜ì ì´ë‹¤ [1], [3]. LangChain ìƒíƒœê³„ì™€ì˜ ì™„ë²½í•œ í†µí•©ì€ LangChainì˜ ë‹¤ì–‘í•œ ë„êµ¬ì™€ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë”ìš± ê°•ë ¥í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ í•´ì¤€ë‹¤ [2], [3].  LangGraphëŠ” ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ë‚˜ ë³µì¡í•œ ì˜ì‚¬ ê²°ì • ì‹œìŠ¤í…œê³¼ ê°™ì´ ì—ì´ì „íŠ¸ ê°„ì˜ ìƒí˜¸ ì˜ì¡´ì„±ì´ ë†’ê³ , ê° ë‹¨ê³„ë³„ë¡œ ì •ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•˜ë‹¤.  ì˜ˆë¥¼ ë“¤ì–´, LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ê²½ìš°, ê° ë…¸ë“œ(ì—ì´ì „íŠ¸)ê°€ íŠ¹ì • ë‹¨ê³„ë¥¼ ë‹´ë‹¹í•˜ê³ , ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ë„ë¡ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤.  ë”°ë¼ì„œ, LangGraphëŠ” ìˆ™ë ¨ëœ ê°œë°œìì—ê²Œ ë” ë§ì€ ìœ ì—°ì„±ê³¼ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ë§Œ, í•™ìŠµ ê³¡ì„ ì´ ê°€íŒŒë¥´ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤ [1], [3].
      
      ## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜
      
      *   [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      *   [2] https://www.zenml.io/blog/langgraph-vs-crewai
      *   [3] https://www.zams.com/blog/crewai-vs-langgraph
      
      ## ê²°ë¡  ë° í‰ê°€
      
      CrewAIì™€ LangGraphëŠ” ê°ê° ëšœë ·í•œ ì¥ë‹¨ì ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, í”„ë¡œì íŠ¸ì˜ ìš”êµ¬ ì‚¬í•­ê³¼ ê°œë°œìì˜ ìˆ™ë ¨ë„ì— ë”°ë¼ ì ì ˆí•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.  ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ì œì‘ê³¼ ì‰¬ìš´ ì‚¬ìš©ì„±ì„ ì¤‘ì‹œí•œë‹¤ë©´ CrewAIê°€ ì í•©í•˜ë©°, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì™€ ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•˜ë‹¤ë©´ LangGraphê°€ ë” ë‚˜ì€ ì„ íƒì´ ë  ìˆ˜ ìˆë‹¤.  ë‘ í”„ë ˆì„ì›Œí¬ ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ì§€ë§Œ, ì‹¤ì œ ì ìš© ì‹œì—ëŠ” ì„±ëŠ¥, í™•ì¥ì„±, ìœ ì§€ë³´ìˆ˜ì„± ë“± ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼ í•œë‹¤.  íŠ¹íˆ, LangGraphì˜ ê²½ìš° LangChainê³¼ì˜ í†µí•©ì´ ê°•ë ¥í•œ ì¥ì ì´ì§€ë§Œ, LangChain ìƒíƒœê³„ì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë†’ì•„ì§„ë‹¤ëŠ” ì ë„ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì´ë‹¤. ê¶ê·¹ì ìœ¼ë¡œ, ë‘ í”„ë ˆì„ì›Œí¬ë¥¼ ëª¨ë‘ ê²½í—˜í•´ë³´ê³ , ìì‹ ì˜ í”„ë¡œì íŠ¸ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.

ğŸ” Critique: CARC Quality Evaluation...
   â””â”€ CARC Scores: C=4.0 A=4.0 R=4.5 C=4.0
   â””â”€ Total: 16.5/20 âœ… Excellent
   â””â”€ Feedback: The response effectively compares LangGraph and CrewAI, highlighting their strengths and weaknesses. The explanation of each framework's use cases and target audience is helpful. The response could benefit from a more detailed comparison table for easier comparison. The accuracy appears good, but cross-referencing with the sources could enhance confidence.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 8 Subgraph Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜...
â”‚ Time: 24.44s
â”‚ LLM Calls: 2
â”‚ Search Calls: 0
â”‚ URLs Read: 6
â”‚ Iterations: 2
â”‚ Est. Tokens: 1011
â”‚ Response Length: 2460 chars
â”‚ Has Citations: âœ…
â”‚ CARC Quality: C=4.0 A=4.0 R=4.5 C=4.0 â†’ 16.5/20 ğŸ‘ Good
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ğŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½

CrewAIì™€ LangGraphëŠ” ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, CrewAIëŠ” í˜‘ì—… ì—ì´ì „íŠ¸ íŒ€ êµ¬ì¶•ì— ì´ˆì ì„ ë§ì¶˜ ì‚¬ìš©ì ì¹œí™”ì ì¸ ê³ ìˆ˜ì¤€ í”„ë ˆì„ì›Œí¬ì´ê³ , LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì™€ ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°ì— ì í•©í•œ LangChain ìƒíƒœê³„ì— í†µí•©ëœ ê·¸ë˜í”„ ê¸°ë°˜ ì—”ì§„ì´ë‹¤ [1], [2], [3].

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   CrewAIëŠ” íŠ¹ì • ì—­í• ê³¼ ì†Œí†µ ì „ëµì„ ê°•ì¡°í•˜ëŠ” í˜‘ì—… ì—ì´ì „íŠ¸ íŒ€ êµ¬ì¶•ì— íŠ¹í™”ë˜ì–´ ìˆë‹¤ [1], [2], [3].
*   LangGraphëŠ” êµ¬ì¡°í™”ë˜ê³  ë³µì›ë ¥ ìˆëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì—”ì§„ì´ë‹¤ [1], [2], [3].
*   CrewAIëŠ” ì—­í•  ê¸°ë°˜ YAML êµ¬ì„± ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸° ì„¤ì •ì´ ë” ë¹ ë¥´ë‹¤ [1], [3].
*   LangGraphëŠ” ê·¸ë˜í”„ êµ¬ì¡°ì™€ ìƒíƒœ ê´€ë¦¬ì— ëŒ€í•œ ë” ê¹Šì€ ì´í•´ê°€ í•„ìš”í•˜ë‹¤ [1], [3].
*   CrewAIëŠ” ì´ˆë³´ìì—ê²Œ ë” ì‚¬ìš©ì ì¹œí™”ì ì´ë©°, LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ìœ ì—°í•˜ë‹¤ [1], [3].
*   LangGraphëŠ” LangChain ìƒíƒœê³„ì— ì™„ì „íˆ í†µí•©ë˜ì–´ ìˆë‹¤ [2], [3].
*   CrewAIëŠ” ì—ì´ì „íŠ¸ ìƒì„±, ì‘ì—… ì •ì˜ ë° í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ë¶„ë¦¬í•˜ëŠ” ëª¨ë“ˆì‹ ë””ìì¸ì„ ê°€ì§€ê³  ìˆë‹¤ [1], [3].
*   CrewAIëŠ” ê³ ìˆ˜ì¤€ í”„ë ˆì„ì›Œí¬ì´ê³ , LangGraphëŠ” ë” ë‚®ì€ ìˆ˜ì¤€ì˜ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤ [1], [3].

## ìƒì„¸ ë¶„ì„

CrewAIì™€ LangGraphëŠ” ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, ëŒ€ìƒ ì‚¬ìš©ìì™€ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ ë©´ì—ì„œ ëšœë ·í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤ [3].

**CrewAI:** CrewAIëŠ” í˜‘ì—… ì—ì´ì „íŠ¸ íŒ€ êµ¬ì¶•ì— ì¤‘ì ì„ ë‘ê³ , ê° ì—ì´ì „íŠ¸ì˜ ì—­í• ê³¼ ì†Œí†µ ì „ëµì„ ëª…í™•í•˜ê²Œ ì •ì˜í•˜ëŠ” ë° ìš©ì´í•˜ë‹¤ [1], [2], [3].  YAML ê¸°ë°˜ ì„¤ì • íŒŒì¼ì€ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì´ì–´ì„œ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì…ì„ ì œì‘í•˜ê³  ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤ [1], [3].  ì—ì´ì „íŠ¸ ìƒì„±, ì‘ì—… ì •ì˜, í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì´ ëª¨ë“ˆí™”ë˜ì–´ ìˆì–´ ì½”ë“œì˜ ì¬ì‚¬ìš©ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ë†’ì¸ë‹¤ [1], [3].  ë”°ë¼ì„œ, ë³µì¡í•œ ë¡œì§ë³´ë‹¤ëŠ” ì—­í•  ë¶„ë‹´ê³¼ í˜‘ì—…ì´ ì¤‘ìš”í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ CrewAIëŠ” ê°•ë ¥í•œ ì„ íƒì§€ê°€ ë  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³ ê° ì§€ì› ì‹œìŠ¤í…œì—ì„œ ê° ì—ì´ì „íŠ¸ê°€ íŠ¹ì • ê¸°ìˆ  ë¶„ì•¼ë¥¼ ë‹´ë‹¹í•˜ê³ , ê³ ê°ì˜ ë¬¸ì˜ë¥¼ ì ì ˆí•œ ì—ì´ì „íŠ¸ì—ê²Œ ì „ë‹¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.  ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ì´ˆë³´ìê°€ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•˜ê³  ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ”ë‹¤ [1], [3].

**LangGraph:** ë°˜ë©´ LangGraphëŠ” ë”ìš± ë³µì¡í•˜ê³  êµ¬ì¡°í™”ëœ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆë‹¤ [1], [2], [3]. ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ê°„ì˜ ìƒí˜¸ ì‘ìš©ê³¼ ìƒíƒœ ë³€í™”ë¥¼ ì •ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆë‹¤.  í•˜ì§€ë§Œ ì´ë¥¼ ìœ„í•´ì„œëŠ” ê·¸ë˜í”„ êµ¬ì¡°ì™€ ìƒíƒœ ê´€ë¦¬ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ì´í•´ê°€ í•„ìˆ˜ì ì´ë‹¤ [1], [3]. LangChain ìƒíƒœê³„ì™€ì˜ ì™„ë²½í•œ í†µí•©ì€ LangChainì˜ ë‹¤ì–‘í•œ ë„êµ¬ì™€ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë”ìš± ê°•ë ¥í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ í•´ì¤€ë‹¤ [2], [3].  LangGraphëŠ” ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ë‚˜ ë³µì¡í•œ ì˜ì‚¬ ê²°ì • ì‹œìŠ¤í…œê³¼ ê°™ì´ ì—ì´ì „íŠ¸ ê°„ì˜ ìƒí˜¸ ì˜ì¡´ì„±ì´ ë†’ê³ , ê° ë‹¨ê³„ë³„ë¡œ ì •ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•˜ë‹¤.  ì˜ˆë¥¼ ë“¤ì–´, LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ê²½ìš°, ê° ë…¸ë“œ(ì—ì´ì „íŠ¸)ê°€ íŠ¹ì • ë‹¨ê³„ë¥¼ ë‹´ë‹¹í•˜ê³ , ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ë„ë¡ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤.  ë”°ë¼ì„œ, LangGraphëŠ” ìˆ™ë ¨ëœ ê°œë°œìì—ê²Œ ë” ë§ì€ ìœ ì—°ì„±ê³¼ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ë§Œ, í•™ìŠµ ê³¡ì„ ì´ ê°€íŒŒë¥´ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤ [1], [3].

## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜

*   [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
*   [2] https://www.zenml.io/blog/langgraph-vs-crewai
*   [3] https://www.zams.com/blog/crewai-vs-langgraph

## ê²°ë¡  ë° í‰ê°€

CrewAIì™€ LangGraphëŠ” ê°ê° ëšœë ·í•œ ì¥ë‹¨ì ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, í”„ë¡œì íŠ¸ì˜ ìš”êµ¬ ì‚¬í•­ê³¼ ê°œë°œìì˜ ìˆ™ë ¨ë„ì— ë”°ë¼ ì ì ˆí•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.  ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ì œì‘ê³¼ ì‰¬ìš´ ì‚¬ìš©ì„±ì„ ì¤‘ì‹œí•œë‹¤ë©´ CrewAIê°€ ì í•©í•˜ë©°, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì™€ ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•˜ë‹¤ë©´ LangGraphê°€ ë” ë‚˜ì€ ì„ íƒì´ ë  ìˆ˜ ìˆë‹¤.  ë‘ í”„ë ˆì„ì›Œí¬ ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ì§€ë§Œ, ì‹¤ì œ ì ìš© ì‹œì—ëŠ” ì„±ëŠ¥, í™•ì¥ì„±, ìœ ì§€ë³´ìˆ˜ì„± ë“± ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼ í•œë‹¤.  íŠ¹íˆ, LangGraphì˜ ê²½ìš° LangChainê³¼ì˜ í†µí•©ì´ ê°•ë ¥í•œ ì¥ì ì´ì§€ë§Œ, LangChain ìƒíƒœê³„ì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë†’ì•„ì§„ë‹¤ëŠ” ì ë„ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì´ë‹¤. ê¶ê·¹ì ìœ¼ë¡œ, ë‘ í”„ë ˆì„ì›Œí¬ë¥¼ ëª¨ë‘ ê²½í—˜í•´ë³´ê³ , ìì‹ ì˜ í”„ë¡œì íŠ¸ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.
======================================================================


ğŸ“Š Running benchmark: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´...

ğŸ” Clarify: Analyzing query...
   â””â”€ Query: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´ì¤˜
   â””â”€ Status: ğŸŸ¢ Clear
   â””â”€ Analysis: The user is asking for an analysis of research papers published in 2024 regarding LLM-based agent systems and a summary of the major trends identified in those papers. The query is specific about the year of publication (2024) and the type of system (LLM-based agent systems).
   â””â”€ Topics: LLM, Agent System, Research Paper Analysis, Trend Analysis
ğŸ“‹ Planner: Creating research plan for: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´

ğŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] LLM based agent systems research 2024
      [2] Large Language Model agent architecture 2024 papers
      [3] Trends in LLM agent development 2024
      [4] Autonomous agents using LLMs 2024
   â””â”€ Focus: Architectures of LLM-based agents, Applications of LLM agents, Limitations of current LLM agents, Advancements in LLM agent capabilities

ğŸ”¬ Research Subgraph: Starting research loop...
ğŸ” Searcher [1]: Searching for: LLM based agent systems research 2024

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.sciencedirect.com/science/article/pii/S1571064524001386
      [2] https://dl.acm.org/doi/10.1145/3712003
      [3] https://arxiv.org/abs/2402.01680
      [4] https://blog.promptlayer.com/types-of-llm-agent/
      [5] https://www.oaepublish.com/articles/aiagent.2025.06
   â””â”€ Snippets:
      â€¢ Skip to article  My account  Sign in   View PDF  ## Physics of Life Reviews  Volume 51, December 2024, Pages 283-293  # Review LLMs and generative agent-based models for complex systems research  Author links open overlay panel, , , ,   rights and content  Under a Creative Commons license  Open access  ## Highlights   â€¢    We review the recent literature on LLMs and how these tools could shape research in different areas of complexity science.  â€¢ [...] ## Cited by (0)  1 :   These authors contributed equally to this work.  Â© 2024 The Author(s). Published by Elsevier B.V.
      â€¢ November 2022, we limited our review to papers published after this date (exclusion criterion 6). Furthermore, we excluded papers unrelated to SE (exclusion criterion 7) and those that mention LMA systems only in discussions or as future work, without presenting experimental results (exclusion criterion 8). After the third phase, we identified 41 primary studies directly relevant to our research focus. The search process was conducted on November 14th, 2024. [...] ## 5 Research Agenda [...] could form the basis of future research projects.
      â€¢ also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository, dedicated to outlining the research on LLM-based multi-agent systems. [...] > Abstract:Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of [...] this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents' capacities? For those interested in delving into this field of study, we
ğŸ’­ Think: Query: LLM based agent systems research 2024 | Found 5 results, 5 URLs. Key snippets: Skip to article

My account

Sign in

 View PDF

## Physics of Life Reviews

Volume 51, December 202 | November 2022, we limited our review to papers published after this date (exclusion criterion 6). Fu | also summarize the commonly used datasets or benchmarks for them to have convenient access. To. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://arxiv.org/abs/2402.01680... (5331 chars)
   âœ“ [https://arxiv.org/abs/2402.01680]
      Preview: [2402.01680] Large Language Model based Multi-Agents: A Survey of Progress and Challenges Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2402.01680 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2402.01680 (cs) [Submitted on 21 Jan 2024 ( v1 ), last revised 19 Apr 2024 (this version, v2)] Title: Large Language Model based Multi-Agents: A Survey of Progress and Challenges Authors: Taicheng Guo , Xiuying Chen , Yaqi Wang , Ruidi Chang , Shichao Pei , Nitesh V. Chawla , Olaf Wiest , Xiangliang Zhang View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors View PDF HTML (experimental) Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents&#39; capacities? For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository, dedicated to outlining the research on LLM-based multi-agent systems. Comments: This work is ongoing and we welcome your contribution! Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) Cite as: arXiv:2402.01680 [cs.CL] &nbsp; (or arXiv:2402.01680v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2402.01680 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Taicheng Guo [ view email ] [v1] Sun, 21 Jan 2024 23:36:14 UTC (5,000 KB) [v2] Fri, 19 Apr 2024 01:15:16 UTC (5,001 KB) Full-text links: Access Paper: View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2024-02 Change to browse by: cs cs.AI cs.MA References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( Wh
   âœ“ [https://dl.acm.org/doi/10.1145/3712003]
      Preview: Error: HTTP 403 for URL: https://dl.acm.org/doi/10.1145/3712003
   âœ“ [https://www.sciencedirect.com/science/article/pii/S1571064524001386]
      Preview: Error: HTTP 403 for URL: https://www.sciencedirect.com/science/article/pii/S1571064524001386
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.42s
ğŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ğŸ”¬ Analyzer [1]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] LLMs are being used as autonomous agents for various tasks due to their planning and reasoning abilities.
      [2] LLM agents have diversified into specialized categories such as conversational agents and clinical decision support agents.
      [3] There's a growing trend towards multi-agent systems, moving from single-agent evaluations to dynamic interactions and full-process simulations.
      [4] A survey paper (arXiv:2402.01680) discusses the progress and challenges of LLM-based multi-agent systems.
      [5] An open-source GitHub repository is maintained to outline research on LLM-based multi-agent systems.
   â””â”€ Decision: More research needed
   â””â”€ Next query: recent advances in LLM based agent systems 2024
ğŸ” Searcher [2]: Follow-up search for: recent advances in LLM based agent systems 2024

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://medium.com/@yousra.aoudi/advancements-in-large-language-models-llms-transforming-ai-capabilities-in-2024-666f4d243012
      [2] https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1638227/full
      [3] https://arxiv.org/abs/2412.17481
      [4] https://arxiv.org/html/2508.17281v1
      [5] https://medium.com/@evolutionmlmail/unlocking-scalable-llm-agent-systems-with-asymptotic-analysis-b9244d85ca31
   â””â”€ Snippets:
      â€¢ Large Language Models (LLMs) have undergone significant advancements in 2024, enhancing their capabilities and expanding their applications
      â€¢ The concept of LLM-based Multi-Agent Systems (MASs) involves a collective of diverse LLM-based agents, each possessing unique strengths, collaborating to achieve a common objective efficiently. This approach has shown significant improvements by leveraging the collaborative and coordinated efforts of multiple agents and tackling tasks that exceed the capabilities of any single agent (Guo et al., 2024). The growing popularity of LLM-based MASs is based on the success in complex problem-solving [...] Merdan et al., 2013; Fortino and and, 2013). Several recent research endeavors have focused on the implementation of MAS based on LLM by combining the argumentative and reasoning power of LLMs with collaborative interactions among intelligent agents to enable complex problem-solving and dynamic simulations. These LLM agents in MAS such as MetaGPT (Hong et al., 2023), Camel (Li et al., 2024), AutoGen (Wu et al., 2023), and AGENTVERSE (Chen et al., 2023) are able to break down tasks, explore [...] Recently revolutionized LLMs, such as GPT-4 and BERT, have revealed remarkable performance in a wide spectrum of language tasks, setting novel standards in the field of Natural Language Processing (NLP) (Naveed et al., 2023; Llanes-Jurado et al., 2024; Eberhard et al., 2024; Baabdullah, 2024; Gao et al., 2024; Yan et al., 2024). Moreover, recent LLMs have emergent abilities to facilitate emergent language (EL), a field that investigates the form of communication that develops among artificial
      â€¢ Cornell University arxiv logo  Help | Advanced Search  arXiv logo Cornell University Logo  ## quick links  # Computer Science > Computation and Language  # Title:A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application [...] Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.  Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.  arXiv Operational Status [...] # Code, Data and Media Associated with this Article  # Demos  # Recommenders and Search Tools  # arXivLabs: experimental projects with community collaborators  arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
ğŸ’­ Think: Query: recent advances in LLM based agent systems 2024 | Found 5 results, 5 URLs. Key snippets: Large Language Models (LLMs) have undergone significant advancements in 2024, enhancing their capabi | The concept of LLM-based Multi-Agent Systems (MASs) involves a collective of diverse LLM-based agent | Cornell University
arxiv logo

Help | Advanced Search

arXiv logo
Cornell University Logo

## . Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://arxiv.org/abs/2412.17481... (4883 chars)
ğŸ“– Read URL: https://www.frontiersin.org/journals/artificial-in... (8015 chars)
   âœ“ [https://medium.com/@yousra.aoudi/advancements-in-large-language-models-llms-transforming-ai-capabilities-in-2024-666f4d243012]
      Preview: Error: HTTP 403 for URL: https://medium.com/@yousra.aoudi/advancements-in-large-language-models-llms-transforming-ai-capabilities-in-2024-666f4d243012
   âœ“ [https://arxiv.org/abs/2412.17481]
      Preview: [2412.17481] A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application Happy Open Access Week from arXiv! YOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all. Donate! Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2412.17481 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2412.17481 (cs) [Submitted on 23 Dec 2024 ( v1 ), last revised 7 Jan 2025 (this version, v2)] Title: A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application Authors: Shuaihang Chen , Yuanxing Liu , Wei Han , Weinan Zhang , Ting Liu View a PDF of the paper titled A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application, by Shuaihang Chen and 4 other authors View PDF HTML (experimental) Abstract: LLM-based Multi-Agent Systems ( LLM-MAS ) have become a research hotspot since the rise of large language models (LLMs). However, with the continuous influx of new related works, the existing reviews struggle to capture them comprehensively. This paper presents a comprehensive survey of these studies. We first discuss the definition of LLM-MAS, a framework encompassing much of previous work. We provide an overview of the various applications of LLM-MAS in (i) solving complex tasks, (ii) simulating specific scenarios, and (iii) evaluating generative agents. Building on previous studies, we also highlight several challenges and propose future directions for research in this field. Comments: 13 pages, 1 figure, 3 tables Subjects: Computation and Language (cs.CL) ; Multiagent Systems (cs.MA) Cite as: arXiv:2412.17481 [cs.CL] &nbsp; (or arXiv:2412.17481v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2412.17481 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Shuaihang Chen [ view email ] [v1] Mon, 23 Dec 2024 11:11:51 UTC (201 KB) [v2] Tue, 7 Jan 2025 12:48:22 UTC (233 KB) Full-text links: Access Paper: View a PDF of the paper titled A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application, by Shuaihang Chen and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2024-12 Change to browse by: cs cs.MA References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle C
   âœ“ [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1638227/full]
      Preview: Frontiers | Auto-scaling LLM-based multi-agent systems through dynamic integration of agents Frontiers in Artificial Intelligence About us About us Who we are Mission and values History Leadership Awards Impact and progress Frontiers&#39; impact Our annual reports Thought leadership Publishing model How we publish Open access Peer review Research integrity Research Topics FAIRÂ² Data Management Fee policy Services Societies National consortia Institutional partnerships Collaborators More from Frontiers Frontiers Forum Frontiers Planet Prize Press office Sustainability Career opportunities Contact us All journals All articles Submit your research Search Frontiers in Artificial Intelligence Sections Sections AI for Human Learning and Behavior Change AI in Business AI in Finance AI in Food, Agriculture and Water Big Data and AI in High Energy Physics Language and Computation Logic and Reasoning in AI Machine Learning and Artificial Intelligence Medicine and Public Health Natural Language Processing Organoid Intelligence Pattern Recognition Technology and Law Articles Research Topics Editorial board About journal About journal Scope Field chief editors Mission &amp; scope Facts Journal sections Open access statement Copyright statement Quality For authors Why submit? Article types Author guidelines Editor guidelines Publishing fees Submission checklist Contact editorial office About us About us Who we are Mission and values History Leadership Awards Impact and progress Frontiers&#39; impact Our annual reports Thought leadership Publishing model How we publish Open access Peer review Research integrity Research Topics FAIRÂ² Data Management Fee policy Services Societies National consortia Institutional partnerships Collaborators More from Frontiers Frontiers Forum Frontiers Planet Prize Press office Sustainability Career opportunities Contact us All journals All articles Submit your research Frontiers in Artificial Intelligence Sections Sections AI for Human Learning and Behavior Change AI in Business AI in Finance AI in Food, Agriculture and Water Big Data and AI in High Energy Physics Language and Computation Logic and Reasoning in AI Machine Learning and Artificial Intelligence Medicine and Public Health Natural Language Processing Organoid Intelligence Pattern Recognition Technology and Law Articles Research Topics Editorial board About journal About journal Scope Field chief editors Mission &amp; scope Facts Journal sections Open access statement Copyright statement Quality For authors Why submit? Article types Author guidelines Editor guidelines Publishing fees Submission checklist Contact editorial office Frontiers in Artificial Intelligence Sections Sections AI for Human Learning and Behavior Change AI in Business AI in Finance AI in Food, Agriculture and Water Big Data and AI in High Energy Physics Language and Computation Logic and Reasoning in AI Machine Learning and Artificial Intelligence Medicine and Public Health Natural Language Processing Organoid Intelligence Pattern Recognition Technology and Law Articles Research Topics Editorial board About journal About journal Scope Field chief editors Mission &amp; scope Facts Journal sections Open access statement Copyright statement Quality For authors Why submit? Article types Author guidelines Editor guidelines Publishing fees Submission checklist Contact editorial office Submit your research Search Your new experience awaits. Try the new design now and help us make it even better Switch to the new experience ORIGINAL RESEARCH article Front. Artif. Intell. , 12 September 2025 Sec. Machine Learning and Artificial Intelligence Volume 8 - 2025 | https://doi.org/10.3389/frai.2025.1638227 This article is part of the Research Topic Advanced Integration of Large Language Models for Autonomous Systems and Critical Decision Support View all 3 articles Auto-scaling LLM-based multi-agent systems through dynamic integration of agents Ravindu Perera 1,2 &#x0002A; &#x02020; Anuradha Bas
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 1.58s
ğŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ğŸ”¬ Analyzer [2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] LLMs are being used as autonomous agents for various tasks due to their planning and reasoning abilities.
      [2] LLM agents have diversified into specialized categories such as conversational agents and clinical decision support agents.
      [3] There's a growing trend towards multi-agent systems, moving from single-agent evaluations to dynamic interactions and full-process simulations.
      [4] A survey paper (arXiv:2402.01680) discusses the progress and challenges of LLM-based multi-agent systems.
      [5] LLM-based Multi-Agent Systems (MASs) involve a collective of diverse LLM-based agents, each possessing unique strengths, collaborating to achieve a common objective efficiently.
   â””â”€ Decision: More research needed
   â””â”€ Next query: key trends in LLM-based agent systems 2024
ğŸ” Searcher [3]: Follow-up search for: key trends in LLM-based agent systems 2024

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.teneo.ai/blog/what-are-the-10-key-trends-in-ai-for-2024
      [2] https://arxiv.org/html/2510.04023v1
      [3] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
      [4] https://blog.promptlayer.com/types-of-llm-agent/
      [5] https://medium.com/@de_val/2024-llm-evaluation-trends-major-advancements-and-hilarious-fails-in-ai-development-bfa29f79424b
   â””â”€ Snippets:
      â€¢ ### 4. How do proactive and predictive interactions work in LLM bots? [...] ### 2. How do multimodal capabilities enhance LLM bots? [...] In recent years, Large Language Models (LLMs) have rapidly evolved, becoming more sophisticated and integral to various applications across industries. With the most recent updates being Apple Intelligence, GPT-4o, and Gemini. As we navigate through 2024, several trends in LLM bots are emerging that are poised to shape the future of artificial intelligence and its interaction with humans. Letâ€™s dive into 10 key trends in AI for 2024 that are defining the landscape of LLM bots.
      â€¢ multi-agent systems, we refer readers to the work of Ke et al. (Ke et al., 2025). In the context of data science, LLM agents have been applied to tasks such as data exploration (Cheng et al., 2023), automated machine learning (Hassan et al., 2023), and visualization and reporting (Yu et al., 2024). The next section outlines how agent architectures have evolved from classical AI agents to modern LLM-based agents designed for complex reasoning and tool orchestration. [...] problems across text, code, and multimodal inputs (Achiam et al., 2023; Liu et al., 2024). Leveraging these advancements, recent work has shifted from static prompting to LLM-powered agents that perform planning, reasoning, tool use, and interactive decision-making (Shen et al., 2023; Yao et al., 2023). To improve factual grounding and reduce hallucinations, many LLM-based agents incorporate retrieval-augmented generation (RAG), which conditions outputs on dynamically retrieved external [...] These technical and responsible-AI gaps highlight the need for a systematic and comprehensive understanding of how DS agents are currently designed, what parts of the data science lifecycle they support, and where their capabilities remain incomplete. Several recent surveys have covered general-purpose LLM-based agents, focusing on design patterns, planning strategies, and evaluation methodologies (Plaat et al., 2025; Wang et al., 2024b; Guo et al., 2024a; Cheng et al., 2024b; Yehudai et al.,
      â€¢ >    Before: LLMs focused solely on language modeling. Capabilities like planning, tool use, and task decomposition/reasoning implemented external to the model. >  >    Trend: Models now designed from the ground up with built-in capabilities for multi-step task decomposition, planning, tool use, and multimodal interactions.  3. Interface Agents Take Center Stage  Image 8 [...] An important caveat here lies in _how_ the agents are implemented. Most deployments use an LLM as a thin wrapper/orchestrator that "calls" existing APIs as tools. In essence, this trend represents a shift from a less manual approach " clicking fetch data, upload to Salesforce, and generate report buttons" to a more streamlined approach "saying generate report" while an LLM-enabled pipeline handles the clicking. [...] This post is an attempt to catalog some of the key events into themes, and a reflection on where things might be headed. The content here is likely subjective (my viewpoint on what was interesting) and is based on a list agent/multi-agent news items I curated over the last year.  TLDR: Five key observations from building and studying AI agents in 2024:  1.   Enterprises are adopting agents, but with some caveats  2.   Teams are building "agent-native" foundation models from the ground up
ğŸ’­ Think: Query: key trends in LLM-based agent systems 2024 | Found 5 results, 5 URLs. Key snippets: ### 4. How do proactive and predictive interactions work in LLM bots? [...] ### 2. How do multimodal | multi-agent systems, we refer readers to the work of Ke et al. (Ke et al., 2025). In the context of  | >    Before: LLMs focused solely on language modeling. Capabilities like planning, tool use, a. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://arxiv.org/html/2510.04023v1... (8015 chars)
ğŸ“– Read URL: https://newsletter.victordibia.com/p/ai-agents-202... (8015 chars)
ğŸ“– Read URL: https://www.teneo.ai/blog/what-are-the-10-key-tren... (8015 chars)
   âœ“ [https://arxiv.org/html/2510.04023v1]
      Preview: LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions 1 Introduction 2 Background 2.1 The Data Science Process and Automation 2.2 Large Language Models and LLM Agents 2.3 Architectures of LLM Agents 2.3.1 Core Modules of LLM-Based Agents 2.3.2 Design Dimensions. 2.4 From General Agents to Data Science Agents 2.4.1 Distinctive Characteristics of Data Science Agents Structured data proficiency. End-to-end lifecycle coverage. Deep tool orchestration. Collaboration and reflection. Trust, safety, and governance. 2.4.2 Illustrative Example: Fraud Detection Agent 2.5 Responsible AI Foundations for LLM Agents Agentic robustness. 3 Methodology 4 Taxonomy of Agentic AI Systems for Data Science 4.1 Lifecycle Stages (S1â€“S6) 4.2 Cross-Cutting Design Attributes 5 Agentic Capabilities Across the Data Science Lifecycle 5.1 Business Understanding and Data Acquisition 5.2 Exploratory Data Analysis and Visualization 5.2.1 Domain Knowledge and Context-Aware Reasoning 5.2.2 Data Visualization 5.2.3 Multimodal Reasoning and Fusion in EDA 5.2.4 Interactive Analysis and Humanâ€“Agent Collaboration 5.2.5 Reporting and Insight Generation 5.2.6 Trust and Safety in EDA 5.3 Feature Engineering (FE) 5.4 Model Building and Selection 5.4.1 Conventional Supervised Training and Selection 5.4.2 Reinforcement Learning and Preference Optimization for Agent Training RL and Preference-Based Alignment RL for Planning and Sequential Tool Use Multi-Agent Reinforcement Learning (MARL) 5.5 Interpretation and Explanation 5.6 Deployment and Monitoring 6 Evaluation and Benchmarking 6.1 Core Evaluation Dimensions 6.2 Functional vs. Process-Centric Evaluation 6.3 Benchmark Datasets and Frameworks 6.4 Evaluation Metrics and Key Performance Indicators (KPIs) Task Correctness. Pipeline-Level Success. Robustness and Reliability. Output Quality (Data, Visualization, and Models). Efficiency and Usability. 6.5 Human-in-the-Loop and Subjective Evaluation 6.6 Current Gaps in Evaluation 7 Open Challenges and Future Directions 7.1 Ambiguous Task Instruction 7.2 Limited Context Window 7.3 Security, Privacy, and Compliance 7.4 Trustworthiness, Reliability, and Alignment Building Trust and Transparency. Ensuring Reliability and Mitigating Hallucination. Achieving Human Aligned Behavior. 7.5 Robustness and Generalizability, 7.6 Benchmarking and Evaluation 7.7 Scalability and Efficiency 7.8 Societal, Ethical, and Economic Challenges 7.9 Multimodal Understanding and Reasoning 8 Conclusion \DocumentMetadata LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions Mizanur Rahman York University Toronto Canada mizanurr@yorku.ca , Amran Bhuiyan York University Canada amran.apece@gmail.com , Mohammed Saidul Islam York University Canada Vector Institute for AI Canada saidulis@yorku.ca , Md Tahmid Rahman Laskar York University Canada Dialpad Inc. Canada tahmid20@yorku.ca , Ridwan Mahbub York University Canada rmahbub@yorku.ca , Ahmed Masry York University Canada masry20@yorku.ca , Shafiq Joty Nanyang Technological University Singapore Salesforce AI Research USA shafiqrayhan@gmail.com and Enamul Hoque York University Canada enamulh@yorku.ca (2025) Abstract. Recent advances in large language models (LLMs) have enabled a new class of AI agents that automate multiple stages of the data science workflow by integrating planning, tool use, and multimodal reasoning across text, code, tables, and visuals. This survey presents the first comprehensive, lifecycle-aligned taxonomy of data science agents, systematically analyzing and mapping forty-five systems onto the six stages of the end-to-end data science process: business understanding and data acquisition, exploratory analysis and visualization, feature engineering, model building and selection, interpretation and explanation, and deployment and monitoring. In addition to lifecycle coverage, we annotate each agent along five cross-cutting design dimensions: reasoning and planning style, 
   âœ“ [https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building]
      Preview: AI Agents 2024 Rewind - A Year of Building and Learning Designing with AI Subscribe Sign in Designing with AI Podcast AI Agents 2024 Rewind - A Year of Building and Learning 43 2 15 1Ã— 0:00 Current time: 0:00 / Total time: -13:30 -13:30 Audio playback is not supported on your browser. Please upgrade. AI Agents 2024 Rewind - A Year of Building and Learning Issue #26 | What were the top 5 trends in AI Multi-Agent Systems from 2024? What can we expect in 2025? Victor Dibia, PhD Jan 02, 2025 43 2 15 Share Transcript I spent a good chunk of 2024 focused on multi-agent system s - contributing to AutoGen - an OSS framework for building multi-agent apps, and working on a book on the topic . A lot has happened! This post is an attempt to catalog some of the key events into themes, and a reflection on where things might be headed. The content here is likely subjective (my viewpoint on what was interesting) and is based on a list agent/multi-agent news items I curated over the last year. TLDR: Five key observations from building and studying AI agents in 2024: Enterprises are adopting agents, but with some caveats Teams are building &quot;agent-native&quot; foundation models from the ground up Interface automation agents dominated early commercial applications A Shift to Complex Tasks and the Rise of Frameworks Benchmarks reveal both progress and limitations 1. Enterprise Adoption of Agents in Products .. with Caveats Many enterprises and startups have adopted the term â€œagentsâ€ in products, describing them broadly at systems that act on a userâ€™s behalf with the goal of saving the user time and avoiding tedious/busy work . Some examples below: Microsoft Copilot Agents : â€œThese AI-driven agents assist users in performing a variety of tasks, working alongside you to offer suggestions, automate repetitive tasks, and provide insights to help you make informed decisionâ€ Salesforce Agentforce : â€œAgentforce is a proactive, autonomous AI application that provides specialized, always-on support to employees or customers. You can equip Agentforce with any necessary business knowledge to execute tasks according to its specific roleâ€œ Sema4.ai agents. Sema4 goes a bit further than other offerings in their claims - â€œ&quot;RPA fall short when it comes to complex, knowledge-based work. They lack the ability to reason, make judgments, and adapt to real-world changes.â€ LinkedIn HR Assistant : â€œStarting today, recruiters can choose to delegate time-consuming tasks to Hiring Assistant including finding candidates and assisting in applicant review, so they can focus on the most strategic, people-centric parts of their jobâ€ An important caveat here lies in how the agents are implemented. Most deployments use an LLM as a thin wrapper/orchestrator that &quot;calls&quot; existing APIs as tools. In essence, this trend represents a shift from a less manual approach &quot; clicking fetch data, upload to Salesforce, and generate report buttons&quot; to a more streamlined approach &quot;saying generate report&quot; while an LLM-enabled pipeline handles the clicking. This is clearly the responsible approach - retaining the reliability of existing APIs while improving user experience by minimizing repetitive steps. It is also non-trivial, as ensuring reliable tool selection at production scale remains challenging. While this is still several steps removed from truly autonomous assistants (the holy grail of agents), it represents a first step toward that journey. Before - Separate apps and apis that users interact with to complete business tasks in products Trend : LLMs act as thin orchestration layers that translate natural language requests into multiple of API calls (minimizes clicks and intermediate tasks). 2. â€œAgent-Nativeâ€ Foundation Models An interesting development this year was seeing teams build foundation models specifically designed for agency . What does this mean? Well, a good agent must do a few things well - reason through multi-step plans for tasks, act 
   âœ“ [https://www.teneo.ai/blog/what-are-the-10-key-trends-in-ai-for-2024]
      Preview: What are the 10 key trends in AI for 2024? - Teneo.ai Teneo.AI Search Open menu Platform Solutions Learning Hub Partners About Us Search Contact What are the 10 key trends in AI for 2024? Home Home In recent years, Large Language Models (LLMs) have rapidly evolved, becoming more sophisticated and integral to various applications across industries. With the most recent updates being Apple Intelligence , GPT-4o , and Gemini . As we navigate through 2024, several trends in LLM bots are emerging that are poised to shape the future of artificial intelligence and its interaction with humans. Letâ€™s dive into 10 key trends in AI for 2024 that are defining the landscape of LLM bots. 1. Hyper-Personalization Personalization has always been a significant goal for AI-driven services, but with advancements in LLM Chat GPT technology, weâ€™re seeing unprecedented levels of customization. LLM bots are now capable of tailoring interactions to individual user preferences, behaviors, and needs with incredible accuracy. This trend is evident in customer service, where an LLM chatbot can recall past interactions and predict future needs, providing a seamless and highly personalized experience. Below is an example of personalization done in 2 steps with Teneo . 2. Multimodal Capabilities Traditionally, LLM bots have been primarily text-based. However, the latest models are now integrating multimodal capabilities, combining text, audio, visual data, and even sensory data to create a more comprehensive interaction experience. For instance, a customer service bot can now understand and respond to queries through voice, recognize emotions from facial expressions, and interpret images to assist users more effectively. This multimodal approach enhances the botâ€™s ability to interact in more human-like and intuitive ways, bridging the gap between digital and real-world interactions. 3. Ethical AI and Bias Mitigation As LLM bots become more ingrained in everyday applications, the importance of ethical AI practices has grown. There is a strong focus on developing models that are fair, transparent, and free from bias. Researchers and developers are investing in methods to identify and mitigate biases in training data, ensuring that LLM chat GPT systems make decisions that are equitable and just. 4. Enhanced Conversational Abilities The conversational abilities of LLM bots are becoming increasingly nuanced and sophisticated. Advanced models can now maintain context over long conversations, understand complex queries, and provide more natural and human-like responses. This trend is transforming industries such as mental health support, where an LLM chatbot can engage in meaningful dialogues and provide real-time assistance to users. 5. Integration with external APIs The integration of LLM bots with external APIs and other products is another emerging trend. By connecting to various smart devices, LLM chat systems can offer more holistic solutions. For instance, a smart home assistant powered by an LLM can control household appliances, provide weather updates, and even offer personalized recommendations based on user habits and preferences. Teneo has over 50 open sourced connectors with other software, and allows you to integrate your LLM with these. 6. Scalability and Deployment in Diverse Environments LLM bots are increasingly being designed for scalability and deployment across diverse environments, from small businesses to large enterprises. Advances in cloud computing and edge AI are enabling LLM bots to operate efficiently even in resource-constrained settings. This scalability ensures that businesses of all sizes can leverage the power of LLM chat systems to enhance their operations and customer engagement. 7. Improved Accessibility Accessibility is a key focus, with LLM bots being developed to cater to users with disabilities. Features such as voice-to-text, text-to-speech, and visual recognition are being enhanced to provide an inclusive experience. This
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.35s
ğŸ”¬ Analyzer [3]: Analyzing 5 results, 9 contents

ğŸ”¬ Analyzer: Max iterations reached, proceeding to Writer

ğŸ”¬ Analyzer [3]: Analyzed 5 results, 9 contents
   â””â”€ New findings:
      [1] LLMs are being used as autonomous agents for various tasks due to their planning and reasoning abilities.
      [2] LLM agents have diversified into specialized categories such as conversational agents and clinical decision support agents.
      [3] There's a growing trend towards multi-agent systems, moving from single-agent evaluations to dynamic interactions and full-process simulations.
      [4] A survey paper (arXiv:2402.01680) discusses the progress and challenges of LLM-based multi-agent systems.
      [5] An open-source GitHub repository is maintained to outline research on LLM-based multi-agent systems.
   â””â”€ Decision: Research complete (19 total findings)
   â””â”€ âœ… Research Subgraph completed (execution #1)
   â””â”€ Findings: 19 items
   â””â”€ Contents: 9 URLs read

ğŸ“¦ Compress: Compressing 19 findings, 9 contents
   â””â”€ Compressed to 1606 chars (from ~5393 raw chars)
   â””â”€ Sources cited: 9
   â””â”€ Preview:
      ## Key Findings
      - LLMs are utilized as autonomous agents due to their planning and reasoning capabilities [1].
      - LLM agents have diversified into specialized categories like conversational agents and clinical decision support agents [1].
      - There is a growing trend towards multi-agent systems (MASs) that involve dynamic interactions and full-process simulations [1].
      - LLM-based MASs consist of diverse LLM-based agents collaborating to achieve a common objective [1].
      - Recent advancements include models with built-in capabilities for multi-step task decomposition, planning, tool use, and multimodal interactions [1].
      
      ## Detailed Information
      Large Language Models (LLMs) are increasingly employed as autonomous agents, leveraging their inherent planning and reasoning abilities [1]. This has led to the diversification of LLM agents into specialized areas, including conversational AI and clinical decision support systems [1]. A significant trend is the development and deployment of LLM-based Multi-Agent Systems (MASs). These systems involve a collective of diverse LLM-based agents, each possessing unique capabilities, working together to achieve a shared goal [1]. Recent advancements in the field include models designed with integrated capabilities for multi-step task decomposition, planning, tool utilization, and multimodal interactions [1]. A survey paper (arXiv:2402.01680) discusses the progress and challenges of LLM-based multi-agent systems [1]. An open-source GitHub repository maintains research on LLM-based multi-agent systems [1].
      
      ## Sources
      [1] https://arxiv.org/abs/2402.01680

âœï¸ Writer: Composing response from 19 findings
   â””â”€ Using compressed notes (1606 chars)

âœï¸ Writer: Generated response (3634 chars)
   â””â”€ Sources used:
      [1] https://arxiv.org/abs/2402.01680
      [2] https://arxiv.org/abs/2412.17481
      [3] https://arxiv.org/html/2510.04023v1
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ ê³„íš ë° ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©í•œ ììœ¨ ì—ì´ì „íŠ¸ì˜ ë°œì „ê³¼, íŠ¹íˆ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ì˜ ì„±ì¥ì´ë¼ëŠ” ë‘ ê°€ì§€ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì¤€ë‹¤. ì´ëŸ¬í•œ ì‹œìŠ¤í…œì€ ë‹¤ì–‘í•œ LLM ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ì—…ì„ í†µí•´ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì¤‘ì ì„ ë‘”ë‹¤ [1].
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   LLMì€ ê³„íš ë° ì¶”ë¡  ëŠ¥ë ¥ ë•ë¶„ì— ììœ¨ ì—ì´ì „íŠ¸ë¡œ í™œìš©ë˜ê³  ìˆë‹¤ [1].
      *   LLM ì—ì´ì „íŠ¸ëŠ” ëŒ€í™”í˜• ì—ì´ì „íŠ¸, ì„ìƒ ì˜ì‚¬ ê²°ì • ì§€ì› ì—ì´ì „íŠ¸ ë“± ì „ë¬¸ ë¶„ì•¼ë¡œ ë‹¤ì–‘í™”ë˜ê³  ìˆë‹¤ [1].
      *   ì—­ë™ì ì¸ ìƒí˜¸ ì‘ìš© ë° ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ì„ í¬í•¨í•˜ëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ìœ¼ë¡œì˜ ê²½í–¥ì´ ì¦ê°€í•˜ê³  ìˆë‹¤ [1].
      *   LLM ê¸°ë°˜ MASëŠ” ê³µí†µ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ í˜‘ë ¥í•˜ëŠ” ë‹¤ì–‘í•œ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ë¡œ êµ¬ì„±ëœë‹¤ [1].
      *   ë‹¤ë‹¨ê³„ ì‘ì—… ë¶„í•´, ê³„íš, ë„êµ¬ ì‚¬ìš© ë° ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ ì‘ìš©ì„ ìœ„í•œ ë‚´ì¥ ê¸°ëŠ¥ì„ ê°–ì¶˜ ëª¨ë¸ì´ ìµœê·¼ì— ë°œì „í–ˆë‹¤ [1].
      
      ## ìƒì„¸ ë¶„ì„
      
      LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë°œì „ì€ ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì— ìƒë‹¹í•œ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆë‹¤. ì´ˆê¸°ì—ëŠ” ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ë¡œ ì‹œì‘í•œ LLMì´ ì´ì œëŠ” ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ í˜‘ë ¥í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¡œ ì§„í™”í•˜ê³  ìˆë‹¤.
      
      **ììœ¨ ì—ì´ì „íŠ¸ë¡œì„œì˜ LLM:** LLMì€ ë‹¨ìˆœíˆ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ì‘ë‹µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ìŠ¤ìŠ¤ë¡œ ëª©í‘œë¥¼ ì„¤ì •í•˜ê³ , ê³„íšì„ ìˆ˜ë¦½í•˜ê³ , í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª©í‘œë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” ììœ¨ì ì¸ ì—ì´ì „íŠ¸ë¡œì„œì˜ ì ì¬ë ¥ì„ ë³´ì—¬ì¤€ë‹¤ [1]. ì´ëŠ” LLMì˜ ê°•ë ¥í•œ ì¶”ë¡  ë° ê³„íš ëŠ¥ë ¥ ë•ë¶„ì´ë©°, ë‹¤ì–‘í•œ ì‹¤ì œ ë¬¸ì œ í•´ê²°ì— LLMì„ ì ìš©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì œì‹œí•œë‹¤.
      
      **ë‹¤ì–‘í•œ ì „ë¬¸ ë¶„ì•¼ë¡œì˜ í™•ì¥:** LLM ì—ì´ì „íŠ¸ëŠ” íŠ¹ì •í•œ ì „ë¬¸ ë¶„ì•¼ì— íŠ¹í™”ë˜ì–´ ë”ìš± ì •êµí•œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëŒ€í™”í˜• ì—ì´ì „íŠ¸ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì‚¬ìš©ìì˜ ìš”êµ¬ë¥¼ íŒŒì•…í•˜ê³  ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ì„ìƒ ì˜ì‚¬ ê²°ì • ì§€ì› ì—ì´ì „íŠ¸ëŠ” ì˜ë£Œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ì‚¬ì˜ ì§„ë‹¨ì„ ë•ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤ [1]. ì´ëŸ¬í•œ ì „ë¬¸í™”ëŠ” LLM ì—ì´ì „íŠ¸ì˜ ì‹¤ìš©ì„±ì„ ë†’ì´ê³ , íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ê°€ë¥¼ ë³´ì¡°í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•˜ë„ë¡ í•œë‹¤.
      
      **ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ì˜ ì¤‘ìš”ì„±:** ë‹¨ì¼ LLM ì—ì´ì „íŠ¸ë¡œëŠ” í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ LLM ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥í•˜ëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ì´ ì£¼ëª©ë°›ê³  ìˆë‹¤ [1]. MASëŠ” ê° ì—ì´ì „íŠ¸ê°€ íŠ¹ì • ì—­í• ê³¼ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§€ê³  í˜‘ë ¥í•˜ì—¬ ì „ì²´ ì‹œìŠ¤í…œì˜ íš¨ìœ¨ì„±ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³µê¸‰ë§ ê´€ë¦¬, êµí†µ ì œì–´, ë¡œë´‡ ê³µí•™ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ MASì˜ í™œìš© ê°€ëŠ¥ì„±ì´ ë†’ê²Œ í‰ê°€ë˜ê³  ìˆë‹¤. MAS í™˜ê²½ì—ì„œ ì—ì´ì „íŠ¸ë“¤ì€ ì„œë¡œ í†µì‹ í•˜ê³  ì •ë³´ë¥¼ êµí™˜í•˜ë©°, í˜‘ìƒ ë° ì¡°ì •ì„ í†µí•´ ê³µí†µ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•œë‹¤.
      
      **ìµœê·¼ ë°œì „ ì‚¬í•­:** ìµœê·¼ì—ëŠ” ë‹¤ë‹¨ê³„ ì‘ì—… ë¶„í•´, ê³„íš, ë„êµ¬ ì‚¬ìš©, ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ ì‘ìš©ê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ë‚´ì¥í•œ LLM ëª¨ë¸ì´ ë“±ì¥í•˜ì—¬ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ëŠ¥ë ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ê³  ìˆë‹¤ [1]. ë‹¤ë‹¨ê³„ ì‘ì—… ë¶„í•´ëŠ” ë³µì¡í•œ ì‘ì—…ì„ ë” ì‘ì€ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê° í•˜ìœ„ ì‘ì—…ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ ì „ì²´ ì‘ì—…ì˜ íš¨ìœ¨ì„±ì„ ë†’ì¸ë‹¤. ê³„íš ê¸°ëŠ¥ì€ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ìµœì ì˜ ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê³  ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ë° ë„ì›€ì„ ì¤€ë‹¤. ë„êµ¬ ì‚¬ìš© ê¸°ëŠ¥ì€ LLM ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ë„êµ¬ë‚˜ APIë¥¼ í™œìš©í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ê±°ë‚˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ ì‘ìš©ì€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„± ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³  ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ í™œìš© ë²”ìœ„ë¥¼ ë„“íŒë‹¤.
      
      ## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜
      
      *   [1] arXiv:2402.01680: [https://arxiv.org/abs/2402.01680](https://arxiv.org/abs/2402.01680)
      *   arXiv:2412.17481: [https://arxiv.org/abs/2412.17481](https://arxiv.org/abs/2412.17481)
      *   arXiv:2510.04023: [https://arxiv.org/html/2510.04023v1](https://arxiv.org/html/2510.04023v1)
      *   Frontiers in Artificial Intelligence: [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1638227/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1638227/full)
      *   ScienceDirect: [https://www.sciencedirect.com/science/article/pii/S1571064524001386](https://www.sciencedirect.com/science/article/pii/S1571064524001386)
      *   Medium Article: [https://medium.com/@yousra.aoudi/advancements-in-large-language-models-llms-transforming-ai-capabilities-in-2024-666f4d243012](https://medium.com/@yousra.aoudi/advancements-in-large-language-models-llms-transforming-ai-capabilities-in-2024-666f4d243012)
      *   Victor Dibia Newsletter: [https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building](https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building)
      *   Teneo AI Blog: [https://www.teneo.ai/blog/what-are-the-10-key-trends-in-ai-for-2024](https://www.teneo.ai/blog/what-are-the-10-key-trends-in-ai-for-2024)
      *   ACM Digital Library: [https://dl.acm.org/doi/10.1145/3712003](https://dl.acm.org/doi/10.1145/3712003)
      
      ## ê²°ë¡  ë° í‰ê°€
      
      2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ ë°œì „ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ì§€í‘œì´ë‹¤. íŠ¹íˆ, MASì˜ ë°œì „ì€ ë³µì¡í•œ í˜„ì‹¤ ì„¸ê³„ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° LLMì´ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤. í–¥í›„ ì—°êµ¬ëŠ” LLM ì—ì´ì „íŠ¸ ê°„ì˜ íš¨ìœ¨ì ì¸ í˜‘ë ¥ ë°©ë²•, MASì˜ í™•ì¥ì„± ë° ì•ˆì •ì„± í™•ë³´, ê·¸ë¦¬ê³  ìœ¤ë¦¬ì  ë¬¸ì œ í•´ê²°ì— ì§‘ì¤‘ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. íŠ¹íˆ, LLM ì—ì´ì „íŠ¸ì˜ ììœ¨ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ ìœ„í—˜ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì•ˆì „ ì¥ì¹˜ ë° ê·œì œ ë§ˆë ¨ì´ ì¤‘ìš”í•´ì§ˆ ê²ƒì´ë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ë“¤ê³¼ í˜‘ë ¥í•˜ì—¬ LLM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‹¤ì œ ë¬¸ì œì— ì ìš©í•˜ê³  ê·¸ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì—°êµ¬ê°€ í•„ìš”í•˜ë‹¤. LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì•ìœ¼ë¡œë„ ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ ìˆ˜í–‰í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.

ğŸ” Critique: CARC Quality Evaluation...
   â””â”€ CARC Scores: C=3.5 A=3.0 R=4.5 C=4.0
   â””â”€ Total: 15.0/20 ğŸ‘ Good
   â””â”€ Feedback: The response provides a good overview of the trends in LLM-based agent systems in 2024, focusing on autonomous agents and multi-agent systems. However, it could be more complete by providing specific examples of the advancements and challenges, and the accuracy of the sources needs to be verified further, since many of the dates in the provided URLs are either in the future or in the past.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 8 Subgraph Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´ì¤˜...
â”‚ Time: 35.37s
â”‚ LLM Calls: 2
â”‚ Search Calls: 0
â”‚ URLs Read: 9
â”‚ Iterations: 3
â”‚ Est. Tokens: 1352
â”‚ Response Length: 3634 chars
â”‚ Has Citations: âœ…
â”‚ CARC Quality: C=3.5 A=3.0 R=4.5 C=4.0 â†’ 15.0/20 ğŸ‘ Good
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ğŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½
2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ ê³„íš ë° ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©í•œ ììœ¨ ì—ì´ì „íŠ¸ì˜ ë°œì „ê³¼, íŠ¹íˆ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ì˜ ì„±ì¥ì´ë¼ëŠ” ë‘ ê°€ì§€ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì¤€ë‹¤. ì´ëŸ¬í•œ ì‹œìŠ¤í…œì€ ë‹¤ì–‘í•œ LLM ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ì—…ì„ í†µí•´ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì¤‘ì ì„ ë‘”ë‹¤ [1].

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   LLMì€ ê³„íš ë° ì¶”ë¡  ëŠ¥ë ¥ ë•ë¶„ì— ììœ¨ ì—ì´ì „íŠ¸ë¡œ í™œìš©ë˜ê³  ìˆë‹¤ [1].
*   LLM ì—ì´ì „íŠ¸ëŠ” ëŒ€í™”í˜• ì—ì´ì „íŠ¸, ì„ìƒ ì˜ì‚¬ ê²°ì • ì§€ì› ì—ì´ì „íŠ¸ ë“± ì „ë¬¸ ë¶„ì•¼ë¡œ ë‹¤ì–‘í™”ë˜ê³  ìˆë‹¤ [1].
*   ì—­ë™ì ì¸ ìƒí˜¸ ì‘ìš© ë° ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ì„ í¬í•¨í•˜ëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ìœ¼ë¡œì˜ ê²½í–¥ì´ ì¦ê°€í•˜ê³  ìˆë‹¤ [1].
*   LLM ê¸°ë°˜ MASëŠ” ê³µí†µ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ í˜‘ë ¥í•˜ëŠ” ë‹¤ì–‘í•œ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ë¡œ êµ¬ì„±ëœë‹¤ [1].
*   ë‹¤ë‹¨ê³„ ì‘ì—… ë¶„í•´, ê³„íš, ë„êµ¬ ì‚¬ìš© ë° ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ ì‘ìš©ì„ ìœ„í•œ ë‚´ì¥ ê¸°ëŠ¥ì„ ê°–ì¶˜ ëª¨ë¸ì´ ìµœê·¼ì— ë°œì „í–ˆë‹¤ [1].

## ìƒì„¸ ë¶„ì„

LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë°œì „ì€ ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì— ìƒë‹¹í•œ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆë‹¤. ì´ˆê¸°ì—ëŠ” ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ë¡œ ì‹œì‘í•œ LLMì´ ì´ì œëŠ” ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ í˜‘ë ¥í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¡œ ì§„í™”í•˜ê³  ìˆë‹¤.

**ììœ¨ ì—ì´ì „íŠ¸ë¡œì„œì˜ LLM:** LLMì€ ë‹¨ìˆœíˆ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ì‘ë‹µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ìŠ¤ìŠ¤ë¡œ ëª©í‘œë¥¼ ì„¤ì •í•˜ê³ , ê³„íšì„ ìˆ˜ë¦½í•˜ê³ , í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª©í‘œë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” ììœ¨ì ì¸ ì—ì´ì „íŠ¸ë¡œì„œì˜ ì ì¬ë ¥ì„ ë³´ì—¬ì¤€ë‹¤ [1]. ì´ëŠ” LLMì˜ ê°•ë ¥í•œ ì¶”ë¡  ë° ê³„íš ëŠ¥ë ¥ ë•ë¶„ì´ë©°, ë‹¤ì–‘í•œ ì‹¤ì œ ë¬¸ì œ í•´ê²°ì— LLMì„ ì ìš©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì œì‹œí•œë‹¤.

**ë‹¤ì–‘í•œ ì „ë¬¸ ë¶„ì•¼ë¡œì˜ í™•ì¥:** LLM ì—ì´ì „íŠ¸ëŠ” íŠ¹ì •í•œ ì „ë¬¸ ë¶„ì•¼ì— íŠ¹í™”ë˜ì–´ ë”ìš± ì •êµí•œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëŒ€í™”í˜• ì—ì´ì „íŠ¸ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì‚¬ìš©ìì˜ ìš”êµ¬ë¥¼ íŒŒì•…í•˜ê³  ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ì„ìƒ ì˜ì‚¬ ê²°ì • ì§€ì› ì—ì´ì „íŠ¸ëŠ” ì˜ë£Œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ì‚¬ì˜ ì§„ë‹¨ì„ ë•ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤ [1]. ì´ëŸ¬í•œ ì „ë¬¸í™”ëŠ” LLM ì—ì´ì „íŠ¸ì˜ ì‹¤ìš©ì„±ì„ ë†’ì´ê³ , íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ê°€ë¥¼ ë³´ì¡°í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•˜ë„ë¡ í•œë‹¤.

**ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ì˜ ì¤‘ìš”ì„±:** ë‹¨ì¼ LLM ì—ì´ì „íŠ¸ë¡œëŠ” í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ LLM ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥í•˜ëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(MAS)ì´ ì£¼ëª©ë°›ê³  ìˆë‹¤ [1]. MASëŠ” ê° ì—ì´ì „íŠ¸ê°€ íŠ¹ì • ì—­í• ê³¼ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§€ê³  í˜‘ë ¥í•˜ì—¬ ì „ì²´ ì‹œìŠ¤í…œì˜ íš¨ìœ¨ì„±ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³µê¸‰ë§ ê´€ë¦¬, êµí†µ ì œì–´, ë¡œë´‡ ê³µí•™ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ MASì˜ í™œìš© ê°€ëŠ¥ì„±ì´ ë†’ê²Œ í‰ê°€ë˜ê³  ìˆë‹¤. MAS í™˜ê²½ì—ì„œ ì—ì´ì „íŠ¸ë“¤ì€ ì„œë¡œ í†µì‹ í•˜ê³  ì •ë³´ë¥¼ êµí™˜í•˜ë©°, í˜‘ìƒ ë° ì¡°ì •ì„ í†µí•´ ê³µí†µ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•œë‹¤.

**ìµœê·¼ ë°œì „ ì‚¬í•­:** ìµœê·¼ì—ëŠ” ë‹¤ë‹¨ê³„ ì‘ì—… ë¶„í•´, ê³„íš, ë„êµ¬ ì‚¬ìš©, ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ ì‘ìš©ê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ë‚´ì¥í•œ LLM ëª¨ë¸ì´ ë“±ì¥í•˜ì—¬ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ëŠ¥ë ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ê³  ìˆë‹¤ [1]. ë‹¤ë‹¨ê³„ ì‘ì—… ë¶„í•´ëŠ” ë³µì¡í•œ ì‘ì—…ì„ ë” ì‘ì€ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê° í•˜ìœ„ ì‘ì—…ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ ì „ì²´ ì‘ì—…ì˜ íš¨ìœ¨ì„±ì„ ë†’ì¸ë‹¤. ê³„íš ê¸°ëŠ¥ì€ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ìµœì ì˜ ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê³  ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ë° ë„ì›€ì„ ì¤€ë‹¤. ë„êµ¬ ì‚¬ìš© ê¸°ëŠ¥ì€ LLM ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ë„êµ¬ë‚˜ APIë¥¼ í™œìš©í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ê±°ë‚˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ ì‘ìš©ì€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„± ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³  ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ í™œìš© ë²”ìœ„ë¥¼ ë„“íŒë‹¤.

## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜

*   [1] arXiv:2402.01680: [https://arxiv.org/abs/2402.01680](https://arxiv.org/abs/2402.01680)
*   arXiv:2412.17481: [https://arxiv.org/abs/2412.17481](https://arxiv.org/abs/2412.17481)
*   arXiv:2510.04023: [https://arxiv.org/html/2510.04023v1](https://arxiv.org/html/2510.04023v1)
*   Frontiers in Artificial Intelligence: [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1638227/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1638227/full)
*   ScienceDirect: [https://www.sciencedirect.com/science/article/pii/S1571064524001386](https://www.sciencedirect.com/science/article/pii/S1571064524001386)
*   Medium Article: [https://medium.com/@yousra.aoudi/advancements-in-large-language-models-llms-transforming-ai-capabilities-in-2024-666f4d243012](https://medium.com/@yousra.aoudi/advancements-in-large-language-models-llms-transforming-ai-capabilities-in-2024-666f4d243012)
*   Victor Dibia Newsletter: [https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building](https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building)
*   Teneo AI Blog: [https://www.teneo.ai/blog/what-are-the-10-key-trends-in-ai-for-2024](https://www.teneo.ai/blog/what-are-the-10-key-trends-in-ai-for-2024)
*   ACM Digital Library: [https://dl.acm.org/doi/10.1145/3712003](https://dl.acm.org/doi/10.1145/3712003)

## ê²°ë¡  ë° í‰ê°€

2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ ë°œì „ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ì§€í‘œì´ë‹¤. íŠ¹íˆ, MASì˜ ë°œì „ì€ ë³µì¡í•œ í˜„ì‹¤ ì„¸ê³„ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° LLMì´ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤. í–¥í›„ ì—°êµ¬ëŠ” LLM ì—ì´ì „íŠ¸ ê°„ì˜ íš¨ìœ¨ì ì¸ í˜‘ë ¥ ë°©ë²•, MASì˜ í™•ì¥ì„± ë° ì•ˆì •ì„± í™•ë³´, ê·¸ë¦¬ê³  ìœ¤ë¦¬ì  ë¬¸ì œ í•´ê²°ì— ì§‘ì¤‘ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. íŠ¹íˆ, LLM ì—ì´ì „íŠ¸ì˜ ììœ¨ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ ìœ„í—˜ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì•ˆì „ ì¥ì¹˜ ë° ê·œì œ ë§ˆë ¨ì´ ì¤‘ìš”í•´ì§ˆ ê²ƒì´ë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ë“¤ê³¼ í˜‘ë ¥í•˜ì—¬ LLM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‹¤ì œ ë¬¸ì œì— ì ìš©í•˜ê³  ê·¸ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì—°êµ¬ê°€ í•„ìš”í•˜ë‹¤. LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì•ìœ¼ë¡œë„ ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ ìˆ˜í–‰í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.
======================================================================


ğŸ“Š Running benchmark: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜...

ğŸ” Clarify: Analyzing query...
   â””â”€ Query: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ê³¼ ê°ê° ì–¸ì œ ì‚¬ìš©í•˜ë©´ ì¢‹ì€ì§€ ì„¤ëª…í•´ì¤˜
   â””â”€ Status: ğŸŸ¢ Clear
   â””â”€ Analysis: The query asks for a comparison between Retrieval-Augmented Generation (RAG) and Agent-based approaches, including when to use each. The user defines the acronym RAG, making the query clear.
   â””â”€ Topics: Retrieval-Augmented Generation, RAG, Agent-based approach
ğŸ“‹ Planner: Creating research plan for: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜

ğŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] RAG (Retrieval-Augmented Generation) vs Agent based approach
      [2] When to use RAG vs Agent
      [3] RAG advantages and disadvantages
      [4] Agent based approach advantages and disadvantages
   â””â”€ Focus: RAG architecture and use cases, Agent based approach architecture and use cases, Comparison of RAG and Agent based approach, Trade-offs between RAG and Agent based approach

ğŸ”¬ Research Subgraph: Starting research loop...
ğŸ” Searcher [1]: Searching for: RAG (Retrieval-Augmented Generation) vs Agent based approach

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [2] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
      [3] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
      [4] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [5] https://testrigor.com/blog/rag-vs-ai-agents/
   â””â”€ Snippets:
      â€¢ RAG vs Agentic RAG RAG (Retrieval Augmented Generation) is a method that combines information retrieval with large language models to generate answers. Hereâ€™s how RAG works on a high level: 1 - The model retrieves relevant data from data sources and then extracts it to a vector database from the pre-indexed model. 2 - Augment the prompts by retrieving information and merging it with the query prompt. 3 - A Large Language Model (like GPT, Claude, or Gemini) understands the combined query and [...] generates the final response. A traditional RAG has a simple retrieval, limited adaptability, and relies on static knowledge, making it less flexible for dynamic and real-time information. Agentic RAG improves on this by introducing AI agents that can make decisions, select tools, and even refine queries for more accurate and flexible responses. Hereâ€™s how Agentic RAG works on a high level: 1 - The user query is directed to an AI Agent for processing. 2 - The agent uses short-term and long-term [...] Agentic RAG? -- Subscribe to our weekly newsletter to get a Free System Design PDF (158 pages):  .
      â€¢ Agentic RAG innovates the retrieval augmentation concept by broadening it from static, single-turn interactions to the multi-step context of autonomous agents. While RAG focuses on factual grounding, AI Agents provide planning capabilities and adaptability within complex environments. By integrating these two models, agentic RAG seeks to develop autonomous systems that efficiently navigate iterative decision-making tasks without experiencing hallucinations. [...] The motivation behind agentic RAG development stems from use cases that require context-aware generation and real-time actions. Examples encompass advanced robotics, legal advisory services, healthcare diagnostics, and ongoing customer service engagements.    In these contexts, merely retrieving relevant information is insufficient. The agent must analyze the information, assess its importance, determine a response, and potentially execute an action in a continuous feedback loop. [...] The retriever module is central to both RAG and Agentic RAG techniques. Two primary methods are traditional sparse vector retrieval (TF-IDF or BM25) and neural dense vector retrieval (incorporating techniques like DPR, ColBERT, or Sentence-BERT). Sparse retrieval methods are well-recognized, straightforward to manage, and perform reliably with short queries. In contrast, neural retrieval often excels in handling more complex queries and synonyms; however, it requires GPU resources for training
      â€¢ Agentic RAG is more dynamic. Here, the AI agent actively manages how it gets information, integrating RAG into its reasoning process. Itâ€™s not just retrieving; itâ€™s refining its queries using reasoning, turning RAG into a sophisticated tool, and managing information over time. This intelligent approach allows AI agents to adapt much better to changing situations.  Key Differences: [...] RAG is a technique where an AI model retrieves information from a knowledge base before generating its response. This retrieval augments the generation process. Traditional RAG is like a quick lookup. The AI queries a knowledge base, retrieves information, and then generates a response. [...] From searching internal company documents to external databases, retrieval-augmented generation (RAG) allows an AI agent to find and use dynamic knowledgeãƒ¼data that is constantly changing. Using an AI query engine, you can give your agents access to constantly changing data, both internal and external, and use reasoning to enhance agent accuracy and decision-making, helping them perform complex tasks reliably.  ## Whatâ€™s the difference between RAG and agentic RAG?
ğŸ’­ Think: Query: RAG (Retrieval-Augmented Generation) vs Agent based approach | Found 5 results, 5 URLs. Key snippets: RAG vs Agentic RAG RAG (Retrieval Augmented Generation) is a method that combines information retrie | Agentic RAG innovates the retrieval augmentation concept by broadening it from static, single-turn i | Agentic RAG is more dynamic. Here, the AI agent actively manages how it gets information, inte. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://www.digitalocean.com/community/conceptual-... (8015 chars)
ğŸ“– Read URL: https://www.linkedin.com/posts/alexxubyte_systemde... (8015 chars)
ğŸ“– Read URL: https://developer.nvidia.com/blog/traditional-rag-... (8015 chars)
   âœ“ [https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis]
      Preview: RAG, AI Agents, and Agentic RAG: An In-Depth Review and Comparative Analysis | DigitalOcean Blog Docs Get Support Contact Sales DigitalOcean Products Featured Products Droplets Scalable virtual machines Kubernetes Scale more effectively Gradientâ„¢ AI Agentic Cloud Build and scale with AI Cloudways Managed cloud hosting App Platform Get apps to market faster Managed Databases Fully-managed database hosting Compute Droplets Kubernetes CPU-Optimized Droplets Functions App Platform Gradientâ„¢ AI Agentic Cloud GPU Droplets 1-Click Models Platform Bare Metal GPUs Backups &amp; Snapshots Backups Snapshots SnapShooter Networking Virtual Private Cloud (VPC) Partner Network Connect Cloud Firewalls Load Balancers DNS DDoS Protection Managed Databases MongoDB Kafka MySQL PostgreSQL Valkey OpenSearch Storage Spaces Object Storage Volume Block Storage Network File Storage Developer Tools API CLI Support Plans Monitoring Uptime Identity and Access Management Marketplace Droplet 1-Click Kubernetes 1-Click AI 1-Click Models Add-Ons Cloud Website Hosting Cloudways See all products Solutions AI and Machine Learning Develop, train, and deploy AI apps GPUs Platform 1-Click Models HR Knowledge Assistant Code Copilot Support Ticket Triage Recommendation Engine Blockchain Infrastructure for decentralized apps Blogs, Forums and Content Websites Lightning-fast, reliable CMS hosting Wordpress Ghost Mastodon Data Analytics Real-time data processing at scale Data Streaming AdTech &amp; Martech Kafka Developer Tools DevOps and CI/CD solutions CI/CD Prototyping Digital Marketing Agencies Power your clientsâ€™ websites and campaigns Freelancer IT Consulting Ecommerce Build beautiful online storefronts Dropshipping WooCommerce Magento Game Development Low-latency multiplayer servers Minecraft Hosting IoT Connect to the power of the cloud Kafka ISVs Streamlined ISV application development Secure Web Hosting Powerful protection from DDoS and more Private VPN Startup Cloud Hosting Scalable, cost-effective infrastructure Small Business Video Streaming High-bandwidth, low-latency delivery Kafka Web and Mobile Apps Simple cross-platform app hosting cPanel Docker Next.js Node.js Website Hosting Fast page loads and reliable site uptime VPS Hosting Virtual Machines Get help Migration Assistance Talk to an expert See all solutions Developers Our Community Community Home DevOps and development guides CSS-Tricks All things web design The Wave Content to level up your business. Resources Tutorials Questions and Answers Marketplace Tools Write for DOnations Cloud Chats Customer Stories DigitalOcean Blog Pricing Calculator Get Involved DigitalOcean Startups Open Source Sponsorships Hacktoberfest Deploy 2025 Wavemakers Program Documentation Quickstart Compute Gradientâ„¢ AI Platform Storage Managed Databases Containers Billing API Reference Partners DigitalOcean Partner Programs Become a Partner Partner Services Program DigitalOcean AI Partner Program Marketplace DigitalOcean Startups Connect with a Partner Partner Programs Resources Customer Stories DigitalOcean Onboarding Series Training for Agencies and Freelancers Price Estimate Calculator Featured Partner Articles Cloud cost optimization best practices Read more How to choose a cloud provider Read more DigitalOcean vs. AWS Lightsail: Which Cloud Platform is Right for You? Read more Questions? Talk to an expert Pricing Log in Log in to: Community DigitalOcean Sign up Sign up for: Community DigitalOcean Blog Docs Get Support Contact Sales Log in Log in to: Community DigitalOcean Sign up Sign up for: Community DigitalOcean Tutorials Questions Product Docs Cloud Chats Search Community Report this What is the reason for this report? This undefined is spam This undefined is offensive This undefined is off-topic This undefined is other Submit Table of contents Introduction Prerequisites Definition and Conceptual Overview of RAG Key Paradigms of RAG Modular RAG AI Agents Autonomy and Adaptability How ModelBased Reflex Agents Work Typ
   âœ“ [https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J]
      Preview: RAG vs Agentic RAG: How AI Agents Improve Answers | Alex Xu posted on the topic | LinkedIn Agree & Join LinkedIn By clicking Continue to join or sign in, you agree to LinkedInâ€™s User Agreement , Privacy Policy , and Cookie Policy . Skip to main content LinkedIn Top Content People Learning Jobs Games Get the app Sign in Register now RAG vs Agentic RAG: How AI Agents Improve Answers This title was summarized by AI from the post below. Alex Xu 5mo Report this post RAG vs Agentic RAG RAG (Retrieval Augmented Generation) is a method that combines information retrieval with large language models to generate answers. Hereâ€™s how RAG works on a high level: 1 - The model retrieves relevant data from data sources and then extracts it to a vector database from the pre-indexed model. 2 - Augment the prompts by retrieving information and merging it with the query prompt. 3 - A Large Language Model (like GPT, Claude, or Gemini) understands the combined query and generates the final response. A traditional RAG has a simple retrieval, limited adaptability, and relies on static knowledge, making it less flexible for dynamic and real-time information. Agentic RAG improves on this by introducing AI agents that can make decisions, select tools, and even refine queries for more accurate and flexible responses. Hereâ€™s how Agentic RAG works on a high level: 1 - The user query is directed to an AI Agent for processing. 2 - The agent uses short-term and long-term memory to track query context. It also formulates a retrieval strategy and selects appropriate tools for the job. 3 - The data fetching process can use tools such as vector search, multiple agents, and MCP servers to gather relevant data from the knowledge base. 4 - The agent then combines retrieved data with a query and system prompt. It passes this data to the LLM. 5 - LLM processes the optimized input to answer the userâ€™s query. Over to you: What else will you add to better understand RAG vs Agentic RAG? -- Subscribe to our weekly newsletter to get a Free System Design PDF (158 pages): https://bit.ly/bbg-social #systemdesign #coding #interviewtips . 9,249 377 Comments Like Comment Share Copy LinkedIn Facebook X Ritheesh T 5mo Report this comment Agentic RAG is going to be huge. Traditional RAG was already a game changer, but giving AI agents memory, decision-making, and tool orchestration takes it to the next level. It opens doors to dynamic multi-hop reasoning, real-time adaptability, and truly autonomous data workflows. Like Reply 31&nbsp;Reactions 32&nbsp;Reactions Aishwarya Srinivasan 5mo Report this comment Always great resources! CFBR Like Reply 9&nbsp;Reactions 10&nbsp;Reactions Mohit Anand 5mo Report this comment Fully agree but i think RAG is messy. Fine-tuning is expensive. And both are outdated â€” too slow, too complex, too resource-heavy. TOXO is the new hero. A smart behavior layer that sits on top of any LLM or API and converts them into C.A.L.M. (Context Augmented Language Model) No GPUs. No ML expertise. Just train it with plain English or your own data. It learns how you think â€” and feels fine-tuned without the pain. No infra. No code. Just alignment â€” in minutes. Like Reply 2&nbsp;Reactions 3&nbsp;Reactions Bajer Lin 5mo Report this comment Anyone know how these graphics are created. Its very impressive. Like Reply 1&nbsp;Reaction LEONARDO SANCHEZ NIÃ‘O 5mo Report this comment The approach you describe about RAG vs Agentic RAG is well structured and captures the key differences between both methods. Traditional RAG, while useful, has limitations in adaptability and handling dynamic information. Agentic RAG represents a natural evolution toward more intelligent systems. However, it's worth considering other modern alternatives like the Model Context Protocol (MCP). MCP offers a complementary approach. Instead of relying on static vector databases, MCP allows models to connect directly with applications and services in real-time - accessing APIs, databases, and tools more dyna
   âœ“ [https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/]
      Preview: Traditional RAG vs. Agentic RAGâ€”Why AI Agents Need Dynamic Knowledge to Get Smarter | NVIDIA Technical Blog DEVELOPER Home Blog Forums Docs Downloads Training Join Technical Blog Subscribe Related Resources Agentic AI / Generative AI English ä¸­æ–‡ Traditional RAG vs. Agentic RAGâ€”Why AI Agents Need Dynamic Knowledge to Get Smarter Jul 21, 2025 By Nicola Sessions Like Discuss (1) L T F R E AI-Generated Summary Like Dislike AI agents face challenges due to reliance on static training data, which can lead to hallucinations, stale information, knowledge gaps, and security issues. Retrieval-augmented generation (RAG) allows AI agents to access dynamic knowledge by retrieving information from constantly changing data sources, improving accuracy and decision-making. NVIDIA provides tools and infrastructure, including the NVIDIA AI-Q Blueprint, NeMo Retriever, and NeMo Agent Toolkit, to accelerate the development of RAG-powered AI agents and AI query engines. AI-generated content may summarize information incompletely. Verify important information. Learn more Ever relied on an old GPS that didnâ€™t know about the new highway bypass, or a sudden road closure? It might get you to your destination, but not in the most efficient or accurate way.&nbsp; AI agents face a similar challenge: they often rely on static training data. This data is fixed at a point in timeâ€”while it was current when created, it can quickly become outdated. This limitation can cause problems in real-world use: Hallucinations: Agents might generate incorrect facts that sound believable. Stale Information: They can&#8217;t access the newest data or real-time updates. Knowledge Gaps: They may lack specific, private, or emerging information. Security: Data permissions may change over time, or previously available data can become confidential. Now, imagine a GPS that updates in real time, instantly knowing about every new road, every traffic jam, and every shortcut. Thatâ€™s the power of dynamic knowledge for AI agents, and itâ€™s revolutionizing how AI can respond to our ever-changing world. AI agents need access to dynamic knowledge Beyond simple chatbots, AI agents are sophisticated AI systems designed to operate on their own. As NVIDIA CEO Jensen Huang described , AI agents are &#8220;information robots&#8221; that &#8220;perceive, reason, plan, and act.&#8221; They are built to understand problems, make plans, use various tools, and even understand different types of information, like text and images. An AI agentâ€™s core capabilities include: Perceiving: Understanding their surroundings and the context of a situation. Reasoning: Breaking down complex problems and strategizing solutions. Planning: Creating step-by-step actions to achieve their goals. Acting: Executing tasks, often by using various digital tools. From searching internal company documents to external databases, retrieval-augmented generation (RAG) allows an AI agent to find and use dynamic knowledgeãƒ¼data that is constantly changing. Using an AI query engine , you can give your agents access to constantly changing data, both internal and external, and use reasoning to enhance agent accuracy and decision-making, helping them perform complex tasks reliably. What&#8217;s the difference between RAG and agentic RAG? RAG is a technique where an AI model retrieves information from a knowledge base before generating its response. This retrieval augments the generation process. Traditional RAG is like a quick lookup. The AI queries a knowledge base, retrieves information, and then generates a response. Agentic RAG is more dynamic. Here, the AI agent actively manages how it gets information, integrating RAG into its reasoning process. Itâ€™s not just retrieving; itâ€™s refining its queries using reasoning, turning RAG into a sophisticated tool, and managing information over time. This intelligent approach allows AI agents to adapt much better to changing situations.&nbsp; Key Differences: Traditional RAG: Simple &#8211; query, 
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 1.45s
ğŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ğŸ”¬ Analyzer [1]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] RAG combines information retrieval with LLMs for answer generation.
      [2] Agentic RAG expands RAG to multi-step contexts with planning and adaptability.
      [3] Agentic RAG uses reasoning to refine queries and manage information dynamically.
      [4] RAG is suitable for fast, accurate answers from internal data.
      [5] Agentic RAG is goal-driven and can handle more complex tasks with dynamic knowledge updates.
   â””â”€ Decision: More research needed
   â””â”€ Next query: examples of RAG vs Agentic RAG use cases
ğŸ” Searcher [2]: Follow-up search for: examples of RAG vs Agentic RAG use cases

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.merge.dev/blog/agentic-rag
      [2] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
      [3] https://medium.com/@gaddam.rahul.kumar/agentic-rag-vs-traditional-rag-b1a156f72167
      [4] https://pureinsights.com/blog/2025/agentic-rag-vs-traditional-rag/
      [5] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
   â””â”€ Snippets:
      â€¢ For instance, a user can ask the AI agent to share all the tickets marked as â€œUrgentâ€ in a specific Slack channel. This requires the agent toâ€”using RAGâ€”identify these tickets in the project management system before going on to share them in the designated Slack channel.  ### Traditional RAG vs agentic RAG  In short, traditional RAG enables users to receive personalized answers to specific questions, while Agentic RAG lets users outsource certain tasks of varying complexity to an AI agent. [...] Your customersâ€™ use cases might require specific agentic RAG implementations.  For example, if an AI agent needs to access data from a 3rd-party system and that system doesnâ€™t support APIs (or at least the relevant endpoints), the AI agent would need to scrape the data from that application.  That said, this situation is likely few and far between. [...] Several 3rd-party solutions already let you implement internal or customer-facing agentic RAG use cases relatively easily.  Here are some examples.  ### Emaâ€™s Employee Assistant AI agent  Ema, a universal AI employee solution, offers an â€œEmployee Assistant AIâ€ agent that lets users make all kinds of requests, such as submitting a vacation request.
      â€¢ The motivation behind agentic RAG development stems from use cases that require context-aware generation and real-time actions. Examples encompass advanced robotics, legal advisory services, healthcare diagnostics, and ongoing customer service engagements.    In these contexts, merely retrieving relevant information is insufficient. The agent must analyze the information, assess its importance, determine a response, and potentially execute an action in a continuous feedback loop.
      â€¢ Of course, traditional RAG still shines in simpler use cases: a documentation Q&A bot, a single-turn FAQ answer, or anytime you have a well-defined static knowledge base and straightforward queries. The overhead of an agent might not be worth it for a question like â€œWhat are the store hours?â€ â€” a single retrieval from an FAQ vector index and answer generation is sufficient. As developers, the goal is to match the solution to the complexity of the problem. [...] user for clarification if needed, look up the userâ€™s account info via an API, and even proactively follow up. IBMâ€™s example highlights that a traditional RAG is like an employee waiting for instructions, whereas an agentic system is more like a proactive team that â€œtake initiative and solve challenges on their ownâ€. In a multi-turn workflow, the agent can decide at each turn what the best course of action is â€” whether thatâ€™s fetching more data or executing a step. This leads to more intelligent [...] Not every problem warrants the complexity of an agentic approach. However, certain scenarios and use cases see significant benefits from Agentic RAGâ€™s advanced capabilities:
ğŸ’­ Think: Query: examples of RAG vs Agentic RAG use cases | Found 5 results, 5 URLs. Key snippets: For instance, a user can ask the AI agent to share all the tickets marked as â€œUrgentâ€ in a specific  | The motivation behind agentic RAG development stems from use cases that require context-aware genera | Of course, traditional RAG still shines in simpler use cases: a documentation Q&A bot, a singl. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://www.digitalocean.com/community/conceptual-... (8015 chars)
ğŸ“– Read URL: https://www.merge.dev/blog/agentic-rag... (8015 chars)
   âœ“ [https://medium.com/@gaddam.rahul.kumar/agentic-rag-vs-traditional-rag-b1a156f72167]
      Preview: Error: HTTP 403 for URL: https://medium.com/@gaddam.rahul.kumar/agentic-rag-vs-traditional-rag-b1a156f72167
   âœ“ [https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis]
      Preview: RAG, AI Agents, and Agentic RAG: An In-Depth Review and Comparative Analysis | DigitalOcean Blog Docs Get Support Contact Sales DigitalOcean Products Featured Products Droplets Scalable virtual machines Kubernetes Scale more effectively Gradientâ„¢ AI Agentic Cloud Build and scale with AI Cloudways Managed cloud hosting App Platform Get apps to market faster Managed Databases Fully-managed database hosting Compute Droplets Kubernetes CPU-Optimized Droplets Functions App Platform Gradientâ„¢ AI Agentic Cloud GPU Droplets 1-Click Models Platform Bare Metal GPUs Backups &amp; Snapshots Backups Snapshots SnapShooter Networking Virtual Private Cloud (VPC) Partner Network Connect Cloud Firewalls Load Balancers DNS DDoS Protection Managed Databases MongoDB Kafka MySQL PostgreSQL Valkey OpenSearch Storage Spaces Object Storage Volume Block Storage Network File Storage Developer Tools API CLI Support Plans Monitoring Uptime Identity and Access Management Marketplace Droplet 1-Click Kubernetes 1-Click AI 1-Click Models Add-Ons Cloud Website Hosting Cloudways See all products Solutions AI and Machine Learning Develop, train, and deploy AI apps GPUs Platform 1-Click Models HR Knowledge Assistant Code Copilot Support Ticket Triage Recommendation Engine Blockchain Infrastructure for decentralized apps Blogs, Forums and Content Websites Lightning-fast, reliable CMS hosting Wordpress Ghost Mastodon Data Analytics Real-time data processing at scale Data Streaming AdTech &amp; Martech Kafka Developer Tools DevOps and CI/CD solutions CI/CD Prototyping Digital Marketing Agencies Power your clientsâ€™ websites and campaigns Freelancer IT Consulting Ecommerce Build beautiful online storefronts Dropshipping WooCommerce Magento Game Development Low-latency multiplayer servers Minecraft Hosting IoT Connect to the power of the cloud Kafka ISVs Streamlined ISV application development Secure Web Hosting Powerful protection from DDoS and more Private VPN Startup Cloud Hosting Scalable, cost-effective infrastructure Small Business Video Streaming High-bandwidth, low-latency delivery Kafka Web and Mobile Apps Simple cross-platform app hosting cPanel Docker Next.js Node.js Website Hosting Fast page loads and reliable site uptime VPS Hosting Virtual Machines Get help Migration Assistance Talk to an expert See all solutions Developers Our Community Community Home DevOps and development guides CSS-Tricks All things web design The Wave Content to level up your business. Resources Tutorials Questions and Answers Marketplace Tools Write for DOnations Cloud Chats Customer Stories DigitalOcean Blog Pricing Calculator Get Involved DigitalOcean Startups Open Source Sponsorships Hacktoberfest Deploy 2025 Wavemakers Program Documentation Quickstart Compute Gradientâ„¢ AI Platform Storage Managed Databases Containers Billing API Reference Partners DigitalOcean Partner Programs Become a Partner Partner Services Program DigitalOcean AI Partner Program Marketplace DigitalOcean Startups Connect with a Partner Partner Programs Resources Customer Stories DigitalOcean Onboarding Series Training for Agencies and Freelancers Price Estimate Calculator Featured Partner Articles Cloud cost optimization best practices Read more How to choose a cloud provider Read more DigitalOcean vs. AWS Lightsail: Which Cloud Platform is Right for You? Read more Questions? Talk to an expert Pricing Log in Log in to: Community DigitalOcean Sign up Sign up for: Community DigitalOcean Blog Docs Get Support Contact Sales Log in Log in to: Community DigitalOcean Sign up Sign up for: Community DigitalOcean Tutorials Questions Product Docs Cloud Chats Search Community Report this What is the reason for this report? This undefined is spam This undefined is offensive This undefined is off-topic This undefined is other Submit Table of contents Introduction Prerequisites Definition and Conceptual Overview of RAG Key Paradigms of RAG Modular RAG AI Agents Autonomy and Adaptability How ModelBased Reflex Agents Work Typ
   âœ“ [https://www.merge.dev/blog/agentic-rag]
      Preview: Agentic RAG: definition, benefits, and real-world examples Introducing Merge Agent Handler: Securely connect your AI agents to thousands of pre-built tools | Learn more Arrow Right Close Products Overview Why Merge Unified How Merge Unified works Security Observability Integrations Accounting ATS HRIS CRM File storage Ticketing Knowlege Base All integrations Merge Unified A single API. Hundreds of product integrations. Learn more Arrow Right Merge Agent Handler Connect your agents to thousands of third-party tools Learn more Arrow Right Solutions By use case Power AI products Auto-provision Candidate sourcing Knowledge base Project analysis Financial analysis Source leads Reconcile vendor payments Reconcile customer payments View all use cases Arrow Right By industry Financial services HR technology By function Product Developer GTM Customers Resources Resources Discover all of the resources Merge has to offer Visit resources Arrow Right Blog Data sheets eBooks Help center Events and webinars Careers Pricing Docs Merge Unified Merge Agent Handler Security Sign in Sign up Get a demo Mergeâ€™s Cookie Policy We use cookies to improve your experience on our site. By clicking â€œAcceptâ€, you are agreeing to the collection and use of data as described in our Privacy Policy . Accept all cookies Cookie settings Ã— We use cookies to improve your experience on our site. By using our site, you are agreeing to the collection and use of data as described in our Privacy Policy . Cookie Settings Ã— Table of contents toc link Add secure integrations to your products and AI agents with ease via Merge. Get a demo Just for you Building AI chatbots with RAG: a step-by-step guide AI agent observability: Hereâ€™s what you need to know Agentic RAG: definition, benefits, and real-world examples Jon Gitlin Senior Content Marketing Manager at Merge Retrieval-augmented generation (RAG) allows you to receive accurate answers to business-specific questions. You can ask an AI assistant about your teamâ€™s upcoming onsite, for example, and the AI assistant can leverage a document on the onsite in your file storage system to generate an accurate response. Guru&#x27;s enterprise AI search platform can use RAG to generate the output above But what if you also wanted to take an action, like declining or accepting the offsite invitation based on the office it takes place in? Thatâ€™s where agentic RAG comes in. Read on to learn how agentic RAG works, why itâ€™s becoming increasingly valuable, and how real-world platforms support it. {{this-blog-only-cta}} Agentic RAG overview Agentic RAG is when an AI agent uses a RAG pipeline to perform a specific action or set of actions on your behalf. For example, a traditional RAG pipeline works as follows: 1. A user asks a question (e.g., â€œGive me the marketing teamâ€™s first names and addresses?â€). 2. This question gets embedded (or converted into a vector representation) and a large language model (LLM) uses it to search for semantically-similar embeddings in a vector database. 3. The LLM can then use the embeddings it identified as context for generating an output. How a RAG pipeline can work when a user wants to find colleagues in the marketing team Agentic RAG will go a step further: Based on the userâ€™s role and department, the AI agent can offer to take specific actions, like asking marketing for an update on a project thatâ€™s relevant to the user or adding these marketing colleagues to an upcoming meeting that requires their support. Agentic RAG can also involve asking an AI agent to take specific actions directly. For instance, a user can ask the AI agent to share all the tickets marked as â€œUrgentâ€ in a specific Slack channel. This requires the agent toâ€”using RAGâ€”identify these tickets in the project management system before going on to share them in the designated Slack channel. Traditional RAG vs agentic RAG In short, traditional RAG enables users to receive personalized answers to specific questions, while Agentic RAG lets users
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.16s
ğŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ğŸ”¬ Analyzer [2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] RAG combines information retrieval with LLMs for answer generation.
      [2] Agentic RAG expands RAG to multi-step contexts with planning and adaptability.
      [3] Agentic RAG uses reasoning to refine queries and manage information dynamically.
      [4] RAG is suitable for simple, single-turn tasks and accessing information from a well-defined knowledge base.
      [5] Agentic RAG excels in complex, multi-step processes requiring context-aware generation and real-time actions.
   â””â”€ Decision: Research complete (12 total findings)
   â””â”€ âœ… Research Subgraph completed (execution #1)
   â””â”€ Findings: 12 items
   â””â”€ Contents: 6 URLs read

ğŸ“¦ Compress: Compressing 12 findings, 6 contents
   â””â”€ Compressed to 2003 chars (from ~5552 raw chars)
   â””â”€ Sources cited: 5
   â””â”€ Preview:
      ## Key Findings
      - RAG combines information retrieval with large language models (LLMs) for answer generation [1].
      - Agentic RAG expands RAG to multi-step contexts with planning and adaptability [5].
      - Agentic RAG uses reasoning to refine queries and manage information dynamically [5].
      - RAG is suited for fast, accurate answers from internal data and simple, single-turn tasks [1].
      - Agentic RAG is goal-driven and excels in complex, multi-step processes requiring context-aware generation and real-time actions [5].
      - Traditional RAG relies on static data, while Agentic RAG uses dynamic knowledge to improve accuracy and decision-making [3].
      
      ## Detailed Information
      
      **RAG (Retrieval Augmented Generation)**
      
      *   RAG combines information retrieval with LLMs to generate answers [1]. It is well-suited for fast, accurate answers derived from internal data [1]. Its capabilities are best utilized in simple, single-turn tasks involving accessing information from a well-defined knowledge base [1].
      
      **Agentic RAG**
      
      *   Agentic RAG expands the traditional RAG framework to handle multi-step contexts with planning and adaptability [5]. It leverages reasoning to refine queries and dynamically manage information [5]. This approach is goal-driven and excels in complex, multi-step processes that demand context-aware generation and real-time actions [5]. Furthermore, Agentic RAG employs dynamic knowledge to enhance accuracy and decision-making, contrasting with the static data dependency of traditional RAG [3].
      
      ## Sources
      [1] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [2] https://www.merge.dev/blog/agentic-rag
      [3] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
      [4] https://medium.com/@gaddam.rahul.kumar/agentic-rag-vs-traditional-rag-b1a156f72167
      [5] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis

âœï¸ Writer: Composing response from 12 findings
   â””â”€ Using compressed notes (2003 chars)

âœï¸ Writer: Generated response (3104 chars)
   â””â”€ Sources used:
      [1] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [2] https://www.merge.dev/blog/agentic-rag
      [3] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      
      RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ LLMì„ ê²°í•©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°˜ë©´ [1], Agent ê¸°ë°˜ RAGëŠ” ë‹¤ë‹¨ê³„ ìƒí™©ì—ì„œ ê³„íš ë° ì ì‘ì„±ì„ í†µí•´ RAGë¥¼ í™•ì¥í•©ë‹ˆë‹¤ [5]. RAGëŠ” ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ê³¼ ê°„ë‹¨í•œ ë‹¨ì¼ í„´ ì‘ì—…ì— ì í•©í•˜ë©°, Agent ê¸°ë°˜ RAGëŠ” ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ìœ ìš©í•©ë‹ˆë‹¤ [1, 5].
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ (LLM)ì„ ê²°í•©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ [1].
      *   Agent ê¸°ë°˜ RAGëŠ” ê³„íš ë° ì ì‘ì„±ì„ í†µí•´ ë‹¤ë‹¨ê³„ ì»¨í…ìŠ¤íŠ¸ë¡œ RAGë¥¼ í™•ì¥í•©ë‹ˆë‹¤ [5].
      *   Agent ê¸°ë°˜ RAGëŠ” ì¶”ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ê³  ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤ [5].
      *   RAGëŠ” ë‚´ë¶€ ë°ì´í„°ì—ì„œ ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì–»ê³  ê°„ë‹¨í•œ ë‹¨ì¼ í„´ ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤ [1].
      *   Agent ê¸°ë°˜ RAGëŠ” ëª©í‘œ ì§€í–¥ì ì´ë©° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— íƒì›”í•©ë‹ˆë‹¤ [5].
      *   ê¸°ì¡´ RAGëŠ” ì •ì  ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ” ë°˜ë©´, Agent ê¸°ë°˜ RAGëŠ” ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ì„±ê³¼ ì˜ì‚¬ ê²°ì •ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤ [3].
      
      ## ìƒì„¸ ë¶„ì„
      
      **RAG (Retrieval Augmented Generation)**
      
      RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±)ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  í•´ë‹¹ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. RAGëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ (LLM)ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ì„± ìˆê³  ê´€ë ¨ì„±ì´ ë†’ì€ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. RAGëŠ” ì˜ ì •ì˜ëœ ì§€ì‹ ê¸°ë°˜ì—ì„œ ì •ë³´ì— ì ‘ê·¼í•˜ëŠ” ê°„ë‹¨í•œ ë‹¨ì¼ í„´ ì‘ì—…ì— ê°€ì¥ ì í•©í•©ë‹ˆë‹¤ [1]. RAGëŠ” ë‚´ë¶€ ë°ì´í„°ì—ì„œ ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì–»ëŠ” ë° ìœ ìš©í•˜ë©°, íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ê¸° ìœ„í•´ ëŒ€ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë° ì í•©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡ì€ RAGë¥¼ ì‚¬ìš©í•˜ì—¬ FAQ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ê³ ê°ì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      
      **Agent ê¸°ë°˜ RAG**
      
      Agent ê¸°ë°˜ RAGëŠ” ê¸°ì¡´ RAG í”„ë ˆì„ì›Œí¬ë¥¼ í™•ì¥í•˜ì—¬ ê³„íš ë° ì ì‘ì„±ì„ í†µí•´ ë‹¤ë‹¨ê³„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤ [5]. ì¶”ë¡ ì„ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ê³  ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤ [5]. ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ëª©í‘œ ì§€í–¥ì ì´ë©° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤ [5]. Agent ê¸°ë°˜ RAGëŠ” ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ì„±ê³¼ ì˜ì‚¬ ê²°ì •ì„ í–¥ìƒì‹œí‚¤ë©°, ê¸°ì¡´ RAGì˜ ì •ì  ë°ì´í„° ì˜ì¡´ì„±ê³¼ ëŒ€ì¡°ë©ë‹ˆë‹¤ [3]. Agent ê¸°ë°˜ RAGëŠ” ì—ì´ì „íŠ¸ê°€ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•˜ëŠ” ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—ì´ì „íŠ¸ëŠ” ì—¬í–‰ ê³„íšì„ ì„¸ìš°ê¸° ìœ„í•´ í•­ê³µí¸, í˜¸í…”, ì•¡í‹°ë¹„í‹°ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ê° ì •ë³´ ì¡°ê°ì„ ê¸°ë°˜ìœ¼ë¡œ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Agent ê¸°ë°˜ RAGëŠ” ë°ì´í„°ê°€ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” í™˜ê²½ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—ì´ì „íŠ¸ëŠ” ì£¼ì‹ ì‹œì¥ ì •ë³´ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±°ë˜ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Agentic RAGëŠ” ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì‘ë‹µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì¶”ë¡ ê³¼ ê³„íšì„ í†µí•´ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
      
      **RAGì™€ Agent ê¸°ë°˜ RAGì˜ ì°¨ì´ì **
      
      ê°€ì¥ í° ì°¨ì´ì ì€ RAGëŠ” ì£¼ë¡œ ì •ë³´ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±ì— ì¤‘ì ì„ ë‘ëŠ” ë°˜ë©´, Agent ê¸°ë°˜ RAGëŠ” ì—ì´ì „íŠ¸ì˜ ì¶”ë¡  ë° ê³„íš ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ë”ìš± ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ê¸°ì¡´ RAGëŠ” ì •ì  ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ” ë°˜ë©´, Agent ê¸°ë°˜ RAGëŠ” ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ì„±ê³¼ ì˜ì‚¬ ê²°ì •ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤ [3]. Agent ê¸°ë°˜ RAGëŠ” ëª©í‘œ ì§€í–¥ì ì´ë©° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤ [5].
      
      **ì–¸ì œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê°€**
      
      *   **RAG**: ê°„ë‹¨í•˜ê³  ë‹¨ì¼ í„´ ì‘ì—…, ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì´ í•„ìš”í•œ ê²½ìš°, ì˜ ì •ì˜ëœ ì§€ì‹ ê¸°ë°˜ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ” ê²½ìš°ì— ì í•©í•©ë‹ˆë‹¤ [1]. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì œí’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê±°ë‚˜, ê°„ë‹¨í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      *   **Agent ê¸°ë°˜ RAG**: ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤, ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ê²½ìš°, ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•˜ëŠ” ê²½ìš°ì— ì í•©í•©ë‹ˆë‹¤ [5]. ì˜ˆë¥¼ ë“¤ì–´, ì—¬í–‰ ê³„íšì„ ì„¸ìš°ê±°ë‚˜, ì£¼ì‹ ì‹œì¥ ì •ë³´ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ê±°ë˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      
      ## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜
      
      *   [1] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      *   [2] https://www.merge.dev/blog/agentic-rag
      *   [3] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
      *   [4] https://medium.com/@gaddam.rahul.kumar/agentic-rag-vs-traditional-rag-b1a156f72167
      *   [5] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
      
      ## ê²°ë¡  ë° í‰ê°€
      
      RAGì™€ Agent ê¸°ë°˜ RAGëŠ” ëª¨ë‘ LLMì„ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ì§€ë§Œ, ë¬¸ì œ í•´ê²° ë°©ì‹ê³¼ ë³µì¡ì„±ì—ì„œ í° ì°¨ì´ë¥¼ ë³´ì…ë‹ˆë‹¤. RAGëŠ” ë¹ ë¥´ê³  ê°„ë‹¨í•œ ì •ë³´ ê²€ìƒ‰ì— ìœ ìš©í•˜ë©°, Agent ê¸°ë°˜ RAGëŠ” ë”ìš± ë³µì¡í•˜ê³  ë™ì ì¸ í™˜ê²½ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ì–´ë–¤ ì ‘ê·¼ ë°©ì‹ì„ ì„ íƒí• ì§€ëŠ” í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì˜ ë³µì¡ì„±ê³¼ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ, ì—ì´ì „íŠ¸ì˜ ê³„íš, ì¶”ë¡ , ê·¸ë¦¬ê³  ì™¸ë¶€ ë„êµ¬ì™€ì˜ ìƒí˜¸ ì‘ìš©ì´ í•„ìš”í•œ ê²½ìš° Agent ê¸°ë°˜ RAGê°€ ë” ì í•©í•©ë‹ˆë‹¤. RAGì˜ ì¥ì ì€ êµ¬í˜„ì´ ë¹„êµì  ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤ëŠ” ì ì´ì§€ë§Œ, Agent ê¸°ë°˜ RAGëŠ” ì´ˆê¸° ì„¤ì • ë° ê´€ë¦¬ê°€ ë” ë³µì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, í”„ë¡œì íŠ¸ì˜ ëª©í‘œì™€ ë¦¬ì†ŒìŠ¤ë¥¼ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ ë°©ë²•ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

ğŸ” Critique: CARC Quality Evaluation...
   â””â”€ CARC Scores: C=4.0 A=4.0 R=4.5 C=4.0
   â””â”€ Total: 16.5/20 âœ… Excellent
   â””â”€ Feedback: The response provides a good overview of the differences between RAG and Agent-based RAG, and when to use each. It covers the key aspects of each approach, provides examples, and includes a conclusion. However, the response could benefit from a more in-depth discussion of the limitations of each approach.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 8 Subgraph Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ê³¼ ê°ê° ì–¸...
â”‚ Time: 25.37s
â”‚ LLM Calls: 2
â”‚ Search Calls: 0
â”‚ URLs Read: 6
â”‚ Iterations: 2
â”‚ Est. Tokens: 1251
â”‚ Response Length: 3104 chars
â”‚ Has Citations: âœ…
â”‚ CARC Quality: C=4.0 A=4.0 R=4.5 C=4.0 â†’ 16.5/20 ğŸ‘ Good
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ğŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½

RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ LLMì„ ê²°í•©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°˜ë©´ [1], Agent ê¸°ë°˜ RAGëŠ” ë‹¤ë‹¨ê³„ ìƒí™©ì—ì„œ ê³„íš ë° ì ì‘ì„±ì„ í†µí•´ RAGë¥¼ í™•ì¥í•©ë‹ˆë‹¤ [5]. RAGëŠ” ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ê³¼ ê°„ë‹¨í•œ ë‹¨ì¼ í„´ ì‘ì—…ì— ì í•©í•˜ë©°, Agent ê¸°ë°˜ RAGëŠ” ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ìœ ìš©í•©ë‹ˆë‹¤ [1, 5].

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ (LLM)ì„ ê²°í•©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ [1].
*   Agent ê¸°ë°˜ RAGëŠ” ê³„íš ë° ì ì‘ì„±ì„ í†µí•´ ë‹¤ë‹¨ê³„ ì»¨í…ìŠ¤íŠ¸ë¡œ RAGë¥¼ í™•ì¥í•©ë‹ˆë‹¤ [5].
*   Agent ê¸°ë°˜ RAGëŠ” ì¶”ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ê³  ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤ [5].
*   RAGëŠ” ë‚´ë¶€ ë°ì´í„°ì—ì„œ ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì–»ê³  ê°„ë‹¨í•œ ë‹¨ì¼ í„´ ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤ [1].
*   Agent ê¸°ë°˜ RAGëŠ” ëª©í‘œ ì§€í–¥ì ì´ë©° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— íƒì›”í•©ë‹ˆë‹¤ [5].
*   ê¸°ì¡´ RAGëŠ” ì •ì  ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ” ë°˜ë©´, Agent ê¸°ë°˜ RAGëŠ” ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ì„±ê³¼ ì˜ì‚¬ ê²°ì •ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤ [3].

## ìƒì„¸ ë¶„ì„

**RAG (Retrieval Augmented Generation)**

RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±)ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  í•´ë‹¹ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. RAGëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ (LLM)ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ì„± ìˆê³  ê´€ë ¨ì„±ì´ ë†’ì€ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. RAGëŠ” ì˜ ì •ì˜ëœ ì§€ì‹ ê¸°ë°˜ì—ì„œ ì •ë³´ì— ì ‘ê·¼í•˜ëŠ” ê°„ë‹¨í•œ ë‹¨ì¼ í„´ ì‘ì—…ì— ê°€ì¥ ì í•©í•©ë‹ˆë‹¤ [1]. RAGëŠ” ë‚´ë¶€ ë°ì´í„°ì—ì„œ ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì–»ëŠ” ë° ìœ ìš©í•˜ë©°, íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ê¸° ìœ„í•´ ëŒ€ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë° ì í•©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡ì€ RAGë¥¼ ì‚¬ìš©í•˜ì—¬ FAQ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ê³ ê°ì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**Agent ê¸°ë°˜ RAG**

Agent ê¸°ë°˜ RAGëŠ” ê¸°ì¡´ RAG í”„ë ˆì„ì›Œí¬ë¥¼ í™•ì¥í•˜ì—¬ ê³„íš ë° ì ì‘ì„±ì„ í†µí•´ ë‹¤ë‹¨ê³„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤ [5]. ì¶”ë¡ ì„ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ê³  ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤ [5]. ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ëª©í‘œ ì§€í–¥ì ì´ë©° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤ [5]. Agent ê¸°ë°˜ RAGëŠ” ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ì„±ê³¼ ì˜ì‚¬ ê²°ì •ì„ í–¥ìƒì‹œí‚¤ë©°, ê¸°ì¡´ RAGì˜ ì •ì  ë°ì´í„° ì˜ì¡´ì„±ê³¼ ëŒ€ì¡°ë©ë‹ˆë‹¤ [3]. Agent ê¸°ë°˜ RAGëŠ” ì—ì´ì „íŠ¸ê°€ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•˜ëŠ” ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—ì´ì „íŠ¸ëŠ” ì—¬í–‰ ê³„íšì„ ì„¸ìš°ê¸° ìœ„í•´ í•­ê³µí¸, í˜¸í…”, ì•¡í‹°ë¹„í‹°ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ê° ì •ë³´ ì¡°ê°ì„ ê¸°ë°˜ìœ¼ë¡œ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Agent ê¸°ë°˜ RAGëŠ” ë°ì´í„°ê°€ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” í™˜ê²½ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—ì´ì „íŠ¸ëŠ” ì£¼ì‹ ì‹œì¥ ì •ë³´ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±°ë˜ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Agentic RAGëŠ” ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì‘ë‹µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì¶”ë¡ ê³¼ ê³„íšì„ í†µí•´ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

**RAGì™€ Agent ê¸°ë°˜ RAGì˜ ì°¨ì´ì **

ê°€ì¥ í° ì°¨ì´ì ì€ RAGëŠ” ì£¼ë¡œ ì •ë³´ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±ì— ì¤‘ì ì„ ë‘ëŠ” ë°˜ë©´, Agent ê¸°ë°˜ RAGëŠ” ì—ì´ì „íŠ¸ì˜ ì¶”ë¡  ë° ê³„íš ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ë”ìš± ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ê¸°ì¡´ RAGëŠ” ì •ì  ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ” ë°˜ë©´, Agent ê¸°ë°˜ RAGëŠ” ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ì„±ê³¼ ì˜ì‚¬ ê²°ì •ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤ [3]. Agent ê¸°ë°˜ RAGëŠ” ëª©í‘œ ì§€í–¥ì ì´ë©° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤ [5].

**ì–¸ì œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê°€**

*   **RAG**: ê°„ë‹¨í•˜ê³  ë‹¨ì¼ í„´ ì‘ì—…, ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì´ í•„ìš”í•œ ê²½ìš°, ì˜ ì •ì˜ëœ ì§€ì‹ ê¸°ë°˜ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ” ê²½ìš°ì— ì í•©í•©ë‹ˆë‹¤ [1]. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì œí’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê±°ë‚˜, ê°„ë‹¨í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
*   **Agent ê¸°ë°˜ RAG**: ë³µì¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤, ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„± ë° ì‹¤ì‹œê°„ ì‘ì—…ì´ í•„ìš”í•œ ê²½ìš°, ë™ì  ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•˜ëŠ” ê²½ìš°ì— ì í•©í•©ë‹ˆë‹¤ [5]. ì˜ˆë¥¼ ë“¤ì–´, ì—¬í–‰ ê³„íšì„ ì„¸ìš°ê±°ë‚˜, ì£¼ì‹ ì‹œì¥ ì •ë³´ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ê±°ë˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜

*   [1] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
*   [2] https://www.merge.dev/blog/agentic-rag
*   [3] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
*   [4] https://medium.com/@gaddam.rahul.kumar/agentic-rag-vs-traditional-rag-b1a156f72167
*   [5] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis

## ê²°ë¡  ë° í‰ê°€

RAGì™€ Agent ê¸°ë°˜ RAGëŠ” ëª¨ë‘ LLMì„ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ì§€ë§Œ, ë¬¸ì œ í•´ê²° ë°©ì‹ê³¼ ë³µì¡ì„±ì—ì„œ í° ì°¨ì´ë¥¼ ë³´ì…ë‹ˆë‹¤. RAGëŠ” ë¹ ë¥´ê³  ê°„ë‹¨í•œ ì •ë³´ ê²€ìƒ‰ì— ìœ ìš©í•˜ë©°, Agent ê¸°ë°˜ RAGëŠ” ë”ìš± ë³µì¡í•˜ê³  ë™ì ì¸ í™˜ê²½ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ì–´ë–¤ ì ‘ê·¼ ë°©ì‹ì„ ì„ íƒí• ì§€ëŠ” í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì˜ ë³µì¡ì„±ê³¼ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ, ì—ì´ì „íŠ¸ì˜ ê³„íš, ì¶”ë¡ , ê·¸ë¦¬ê³  ì™¸ë¶€ ë„êµ¬ì™€ì˜ ìƒí˜¸ ì‘ìš©ì´ í•„ìš”í•œ ê²½ìš° Agent ê¸°ë°˜ RAGê°€ ë” ì í•©í•©ë‹ˆë‹¤. RAGì˜ ì¥ì ì€ êµ¬í˜„ì´ ë¹„êµì  ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤ëŠ” ì ì´ì§€ë§Œ, Agent ê¸°ë°˜ RAGëŠ” ì´ˆê¸° ì„¤ì • ë° ê´€ë¦¬ê°€ ë” ë³µì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, í”„ë¡œì íŠ¸ì˜ ëª©í‘œì™€ ë¦¬ì†ŒìŠ¤ë¥¼ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ ë°©ë²•ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
======================================================================


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Phase 8 Subgraph Summary (3 tests)
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Average Time: 28.39s
â•‘  Average Tokens: 1205
â•‘  Citation Rate: 100%
â•‘  CARC Quality: C=3.8 A=3.7 R=4.5 C=4.0 â†’ 16.0/20
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Results saved to: benchmark_results/phase_8_subgraph_20251221_014312.json
