/home/isak/LangGraph_PJT/langgraph_web_ui/langgraph_server/src/agent/tools.py:36: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.
  tavily_tool = TavilySearchResults(

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Deep Research Benchmark - Phase 9 Fixed
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Test Queries: 3
â•‘  Verbose: ON (full response)
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸ“Š Running benchmark: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜...

ğŸ” Clarify: Analyzing query...
   â””â”€ Query: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜
   â””â”€ Status: ğŸŸ¢ Clear
   â””â”€ Analysis: The query asks for a comparison of the multi-agent architectures of LangGraph and CrewAI, including an analysis of their respective advantages and disadvantages. The intent is clear: a comparative analysis is desired.
   â””â”€ Topics: LangGraph, CrewAI, Multi-Agent Architecture
ğŸ“‹ Planner: Creating research plan for: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜

ğŸ“‹ Planner: Generated 6 queries
   â””â”€ Queries:
      [1] LangGraph vs CrewAI multi-agent architecture
      [2] LangGraph multi-agent system advantages disadvantages
      [3] CrewAI multi-agent system advantages disadvantages
      [4] LangGraph and CrewAI comparison
      [5] LangGraph architecture
      [6] CrewAI architecture
   â””â”€ Focus: Architecture comparison, Advantages of LangGraph, Disadvantages of LangGraph, Advantages of CrewAI, Disadvantages of CrewAI

ğŸ¯ Supervisor [Phase 9]: Analyzing query complexity
   â””â”€ Query: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜
   â””â”€ Planned queries: 6
   â””â”€ Complexity: ğŸŸ¡ MEDIUM
   â””â”€ Recommended: 2 iterations, depth 2
   â””â”€ Strategy: targeted
   â””â”€ Reasoning: The query requires comparison and analysis of two frameworks, LangGraph and CrewAI. Therefore, a medium complexity level is appropriate. Two iterations allow for gathering information about each framework separately and then comparing them directly. A depth of 2 allows for a more detailed investigation without being overly exhaustive. A targeted focus will ensure the research stays on topic.

ğŸ”¬ Research Subgraph: Starting research loop...
   â””â”€ Supervisor config: MEDIUM, max 2 iterations, targeted strategy
ğŸ” Searcher [1]: Searching for: LangGraph vs CrewAI multi-agent architecture

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [2] https://www.zenml.io/blog/langgraph-vs-crewai
      [3] https://www.leanware.co/insights/langgraph-vs-crewai-comparison
      [4] https://www.3pillarglobal.com/insights/blog/comparison-crewai-langgraph-n8n/
      [5] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/
   â””â”€ Snippets:
      â€¢ While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. [...] CrewAI and LangGraph both bring powerful capabilities to AI application development, but they excel in different areas. CrewAI is ideal for structured, role-based multi-agent collaboration, while LangGraph is built for adaptive, stateful workflows that can branch, loop, and respond to changing inputs. Your choice depends on your projectâ€™s nature. If you need a coordinated team of specialized agents, CrewAI is a natural fit. If your focus is on flexible execution with robust state management, [...] When you build with CrewAI or LangGraph, you are working with powerful frameworks for orchestrating AI agents. CrewAI excels in structuring multi-agent collaboration, while LangGraph shines in managing complex, adaptive workflows. But once these systems move from development to production, the challenges shift. You need to ensure they run securely, efficiently, and with complete operational visibility. Thatâ€™s where TrueFoundry AI Gateway becomes the perfect companion.
      â€¢ What's the learning curve difference between these frameworks? CrewAI offers faster initial setup with its role-based, YAML-configurable approachâ€”teams can build working multi-agent systems in hours. LangGraph requires deeper understanding of graph structures, state management, and functional composition, typically taking days to weeks to master. However, LangGraph's complexity pays dividends in complex workflows requiring precise control, conditional routing, and advanced debugging. [...] Complex stateful workflows with branching logic: Choose LangGraph for its graph-based architecture, conditional routing, and time-travel debugging capabilities that handle non-linear agent interactions.  Rapid prototyping and POC development: Choose CrewAI for its intuitive role-based model and YAML configuration that enables working multi-agent systems in hours rather than days. [...] ## LangGraph vs CrewAI: Key Takeaways  ğŸ§‘â€ğŸ’» LangGraph: Itâ€™s a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic.
      â€¢ CrewAI was designed specifically for multi-agent systems with better abstractions for agent collaboration. Agents communicate naturally, delegate tasks, and operate in parallel. LangGraph can implement multi-agent patterns but requires explicit graph design for coordination. For workflows primarily about multiple agents collaborating autonomously, CrewAI's model fits better. For workflows needing precise control over agent interactions, LangGraph provides more determinism.  ## Related Posts [...] Neither is universally better. LangGraph provides durable execution, persistent state management, and LangChain ecosystem integration, making it suitable for production systems requiring reliability. CrewAI offers faster development with autonomous agents and less boilerplate, fitting prototypes and simpler workflows. Choose based on priorities: control and durability versus speed and agent autonomy.  Can I use CrewAI for production workflows? [...] Both frameworks are open source and free under MIT license. You pay for infrastructure (hosting, compute) and third-party services (LLM APIs, vector databases). LangGraph's LangSmith observability platform charges subscription fees starting at $39 monthly. CrewAI's AMP Suite offers enterprise features with pricing for managed services. Core frameworks remain free.  Which is better for multi-agent coordination?
ğŸ’­ Think: Query: LangGraph vs CrewAI multi-agent architecture | Found 5 results, 5 URLs. Key snippets: While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and co | What's the learning curve difference between these frameworks? CrewAI offers faster initial setup wi | CrewAI was designed specifically for multi-agent systems with better abstractions for agent co. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://www.zenml.io/blog/langgraph-vs-crewai... (8015 chars)
ğŸ“– Read URL: https://www.truefoundry.com/blog/crewai-vs-langgra... (8015 chars)
ğŸ“– Read URL: https://www.leanware.co/insights/langgraph-vs-crew... (8015 chars)
   âœ“ [https://www.zenml.io/blog/langgraph-vs-crewai]
      Preview: LangGraph vs CrewAI: Letâ€™s Learn About the Differences - ZenML Blog Product DATA SCience Iterate at warp speed Accelerate your ML workflow seamlessly Auto-track everything Automatic logging and versioning Shared ML building blocks Boost team productivity with reusable components Infrastructure Backend flexibility, zero lock-in One framework for all your MLOps and LLMOps needs Limitless scaling Effortlessly deploy across clouds Streamline cloud expenses Gain clarity on resource usage and costs Organization ZenML Pro Our managed control plane for MLOps Open Source vs Pro Pick what works for your needs ZenML vs Other Tools Compare ZenML to other ML tools Solutions GENAI &amp; LLMS Finetuning LLMs Customize large language models for specific tasks Productionalizing a RAG application Deploy and scale RAG systems LLMOps Database A curated knowledge base of real-world implementations mlops Building Enterprise MLOps Platform architecture and best practices Abstract cloud compute Simplify management of cloud-based ML resources Track metrics and metadata Monitor and analyze ML model performance and data Success Stories JetBrains Software Adeo Leroy Merlin Retail Cross Screen Media Media View All Case Studies Learn more Developers Documentation Docs Comprehensive guides to use ZenML Deploying ZenML Understanding ZenML system architecture Tutorials Examples showing ZenML in action GUIDES Quickstart Quickly get your hands dirty Showcase Projects of ML use cases built with ZenML Starter Guide Get started with the basics COMMUNITY Slack Join our Slack Community Changelog Discover whatâ€™s new on ZenML Roadmap Join us on our MLOps journey Pricing Blog Case Studies Get Started Book a demo Software Engineering LangGraph vs CrewAI: Letâ€™s Learn About the Differences Hamza Tahir Jun 28, 2025 â€¢ 12 mins All posts LLMOps Contents Get started with ZenML today Begin with open source tools Works with any infrastructure Secure, metadata-only tracking Book a demo Related Posts Metaflow vs MLflow vs ZenML: Whatâ€™s the Difference? ZenML&#x27;s MCP Server Supports DXT: Making MLOps Conversations Frictionless This is also a heading This is a heading LangGraph and CrewAI are modern frameworks for orchestrating complex AI workflows with multiple LLM-driven agents. Both these intelligent systems are capable of sophisticated reasoning, planning, and autonomous action, and are becoming central to modern AI applications. However, they differ in abstraction, interfaces, and enterprise features. This LangGraph vs CrewAI article compares key attributes of these platforms, like: Workflow patterns Human-in-loop capabilities Parallelism and throttling Compliance and security Integration options Pricing We do this so you can exactly know when to use which one of these platforms. Recently Updated (November 2025) : This comparison has been refreshed with major 2025 developments including LangGraph 1.0&#x27;s stable release (October 2025), CrewAI&#x27;s multimodal support and agentic RAG capabilities, updated market adoption statistics showing 85% of organizations now using AI agents, and the emergence of new interoperability protocols like A2A and MCP. All framework comparisons and integration information reflect current capabilities as of November 2025. LangGraph vs CrewAI: Key Takeaways ğŸ§‘â€ğŸ’» LangGraph : Itâ€™s a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. ğŸ§‘â€ğŸ’» CrewAI : Itâ€™s a high-level framework for orchestrating autonomous AI agents working together as a crew. The platform abstracts away complexity by providing pre-built patterns for agent collaboration, role assignment, and task delegation. Framework Maturity &amp; Lineage The table below compared the framework maturity of LangGraph and CrewAI: Metric CrewAI LangGraph First public release v0.1.0 â€” 14 Nov 2023 v0.0.9 â€” 8 Jan 20
   âœ“ [https://www.truefoundry.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs LangGraph: Know The Differences --> --> Join the AI Security Webinar with Palo Alto. Register here Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Open Source Resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities Insurance Retail Government Technology Oil and Gas BY FUNCTION For DS Leaders For IT Leaders Application Suites Customer Support and CRM Finance IT Operations Marketing Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Careers resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Trust Center Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities CUSTOMERS For DS Leaders For IT Leaders Insurance Retail Government Technology Oil and Gas BY FUNCTION Newsletter Application Suites Customer Support and CRM Finance IT Operations Marketing Trust Center Compare Newsletter Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Pricing Docs Blog Live Demo Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Login Book Demo Sign Up Login Sign Up Book Demo comparison Crewai vs LangGraph: Know The Differences August 21, 2025 | 9:30 min read TrueFoundry SHARE The rise of multi-agent AI systems has created a need for frameworks that go beyond simple prompt chaining. Developers now want tools that can orchestrate multiple agents, manage shared state, and support complex workflows with branching, looping, and retries. Two notable frameworks leading this space are CrewAI and LangGraph. While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. In this comparison, weâ€™ll break down their core philosophies, features, and use cases to help you decide which framework better fits your AI development needs. What Is CrewAI? CrewAI is an open-source, Python-based framework designed for orchestrating autonomous, collaborative AI agents, much like a digital team handling complex tasks. Each agent operates with a defined role, such as researcher, writer, or analyst, and works together within a structured crew to solve problems efficiently. CrewAI combines modularity with performance, offering both high-level simplicity and precise control over how agents interact. Through components like Crews and Flows, it supports dynamic collaboration while giving developers the ability to manage control flows, tasks, and environments with flexibility. Agents in CrewAI are set up with defined roles, goals, tools, and even personality through backstories. This is similar to how a human team organizes itself to divide work and minimize errors. The framework allows agents to work sequentially or in parallel, with coordination
   âœ“ [https://www.leanware.co/insights/langgraph-vs-crewai-comparison]
      Preview: --> LangGraph vs CrewAI: Feature, Pricing &amp; Use Case Comparison top of page Services Staff Augmentation AI Strategy &amp; Integration Services Data Engineering Solutions Digital Products Development Testimonials Case Studies About Us Our Culture Tech Stack React.js Python Angular Vue.JS React Native Flutter Swift All technologies Engagement Models Contact Us Let&#x27;s Talk Let&#x27;s Talk Learn more at Clutch &nbsp;and&nbsp; Tech Times Got a Project in Mind? Letâ€™s Talk! Full Name * Your company email * Tell us about your project * How did you hear about us? * Get in Touch LangGraph vs CrewAI: Feature, Pricing &amp; Use Case Comparison Leanware Editorial Team Nov 13 7 min read AI agent orchestration frameworks have made it easier for teams to build automation systems. Instead of coding every rule or path, you can now create agents that handle tasks and coordinate with each other. LangGraph and CrewAI tackle this in different ways. Letâ€™s look at how each framework works, what they do well, and where they make the most sense in production. What Is LangGraph? LangGraph is an open-source orchestration framework for building stateful, long-running agents. Itâ€™s part of the LangChain ecosystem but can also run independently. Workflows in LangGraph are modeled as state graphs , where nodes represent actions and edges define control flow. Each node takes in the current state, performs an operation, like calling a language model, querying a database, or executing custom logic, and returns an updated state. This structure keeps execution paths clear and easy to debug. LangGraph is built for teams that need reliable, production-grade automation with clear control and visibility. Itâ€™s a good fit for workflows that require consistency and human oversight, like customer operations or document processing. Core Capabilities Durable execution : Workflows can recover automatically from crashes or restarts, resuming from the last checkpoint. This is useful for long-running processes like approvals or batch jobs. Human-in-the-loop : You can pause execution at any point, wait for human input, and resume later with that input included. State is stored persistently, so workflows can pause indefinitely. Memory management : Supports both short-term and long-term memory. Agents retain conversation history and past context across sessions for consistent decision-making. LangSmith integration : Provides debugging tools and observability. You can trace execution paths, inspect state transitions, and monitor runtime metrics. Flexible agent creation: Use create_react_agent for quick setup or build custom graphs manually for full control over logic and flow. What Is CrewAI? CrewAI is a Python framework built independently of LangChain. Itâ€™s open source under the MIT license and focuses on multi-agent coordination. The framework offers two main approaches: Crews for autonomous agent collaboration and Flows for event-driven workflow control. Crews organize agents by roles such as researcher, writer, or analyst and assign them tasks. Flows manage complex execution paths with conditional branching and state management. CrewAI focuses on speed and simplicity. It needs less setup than graph-based frameworks, so you can build multi-agent systems with only a small amount of code. Core Capabilities CrewAI handles multi-agent workflows through key features: Agent structure: Work is organized around agents with roles, goals, and backstories that define how they behave. Tasks assign objectives and specify which agent handles them. Work can run sequentially or in hierarchical mode, where a manager agent delegates tasks. Autonomous operation: Agents handle tasks independently. They choose tools, request help from other agents, and escalate tasks they canâ€™t complete. This coordination comes from configuration rather than hardcoded routing. Flows for control: Event-driven workflows use decorators like @start , @ listen , and @router . Conditions can be combined with or _
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.99s
ğŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ğŸ”¬ Analyzer [1/2]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] CrewAI is designed for collaborative agent teams with specific roles, goals, and communication strategies.
      [2] LangGraph is a graph-based workflow engine for structured, resilient LLM applications.
      [3] CrewAI emphasizes team coordination, while LangGraph emphasizes stateful execution.
      [4] CrewAI offers faster initial setup and can be used to build multi-agent systems quickly.
      [5] LangGraph requires a deeper understanding of graph structures and state management, taking longer to master.
   â””â”€ Decision: More research needed
   â””â”€ Next query: LangGraph vs CrewAI architecture comparison
ğŸ” Searcher [2]: Follow-up search for: LangGraph vs CrewAI architecture comparison

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.zenml.io/blog/langgraph-vs-crewai
      [2] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [3] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/
      [4] https://www.zams.com/blog/crewai-vs-langgraph
      [5] https://aaronyuqi.medium.com/first-hand-comparison-of-langgraph-crewai-and-autogen-30026e60b563
   â””â”€ Snippets:
      â€¢ Key Workflow Patterns: [...] ## LangGraph vs CrewAI: Key Takeaways  ğŸ§‘â€ğŸ’» LangGraph: Itâ€™s a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. [...] | Feature | LangGraph | CrewAI |  ---  | Workflow deployment patterns |  Parallel fan-out/fan-in  Hierarchical agent teams  Cyclical (looping) graphs with dynamic conditional routing |  Sequential and hierarchical processes (manager-led)  Consensual process planned for future release |
      â€¢ CrewAI and LangGraph both bring powerful capabilities to AI application development, but they excel in different areas. CrewAI is ideal for structured, role-based multi-agent collaboration, while LangGraph is built for adaptive, stateful workflows that can branch, loop, and respond to changing inputs. Your choice depends on your projectâ€™s nature. If you need a coordinated team of specialized agents, CrewAI is a natural fit. If your focus is on flexible execution with robust state management, [...] While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. [...] | Feature | CrewAI | LangGraph |  ---  | Focus | Multi-agent collaboration | Flexible multi-agent workflows | | Execution model | Parallel task execution | Graph-based execution | | State management | Shared context with crew | Explicit persistent state management | | Human-in-the-loop | Possible with structured crew interactions | Built-in checkpoints for human review | | Best use case | Specialized agents working together | Complex, dynamic workflows |  ## When to Use CrewAI
      â€¢ LangGraph implements a graph-based architecture focused on managing application state through a central persistence layer. This architecture draws inspiration from established distributed computing models like Pregel and processing frameworks like Apache Beam, with a public interface reminiscent of NetworkX. The framework's design emphasizes stateful execution, allowing applications to maintain context across interactions. [...] The core architectural component in LangGraph is the StateGraph, which enables developers to define nodes (processing steps) and edges (transitions between steps) to create sophisticated workflows. This state-centric approach allows for checkpointing execution states, making it possible to implement features like memory persistence and human-in-the-loop interventions. [...] | Feature Category | CrewAI | LangGraph | BeeAI |  ---  --- | | Core Architecture | Standalone framework with no dependencies on other agent frameworks | Built by LangChain Inc. but can be used independently | IBM-developed open-source framework for multi-agent systems | | Programming Languages | Python | Python | Python and TypeScript with full parity |
ğŸ’­ Think: Query: LangGraph vs CrewAI architecture comparison | Found 5 results, 5 URLs. Key snippets: Key Workflow Patterns: [...] ## LangGraph vs CrewAI: Key Takeaways

ğŸ§‘â€ğŸ’» LangGraph: Itâ€™s a framework  | CrewAI and LangGraph both bring powerful capabilities to AI application development, but they excel  | LangGraph implements a graph-based architecture focused on managing application state through . Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://www.zenml.io/blog/langgraph-vs-crewai... (8015 chars)
ğŸ“– Read URL: https://www.truefoundry.com/blog/crewai-vs-langgra... (8015 chars)
ğŸ“– Read URL: https://developer.ibm.com/articles/awb-comparing-a... (13 chars)
   âœ“ [https://www.zenml.io/blog/langgraph-vs-crewai]
      Preview: LangGraph vs CrewAI: Letâ€™s Learn About the Differences - ZenML Blog Product DATA SCience Iterate at warp speed Accelerate your ML workflow seamlessly Auto-track everything Automatic logging and versioning Shared ML building blocks Boost team productivity with reusable components Infrastructure Backend flexibility, zero lock-in One framework for all your MLOps and LLMOps needs Limitless scaling Effortlessly deploy across clouds Streamline cloud expenses Gain clarity on resource usage and costs Organization ZenML Pro Our managed control plane for MLOps Open Source vs Pro Pick what works for your needs ZenML vs Other Tools Compare ZenML to other ML tools Solutions GENAI &amp; LLMS Finetuning LLMs Customize large language models for specific tasks Productionalizing a RAG application Deploy and scale RAG systems LLMOps Database A curated knowledge base of real-world implementations mlops Building Enterprise MLOps Platform architecture and best practices Abstract cloud compute Simplify management of cloud-based ML resources Track metrics and metadata Monitor and analyze ML model performance and data Success Stories JetBrains Software Adeo Leroy Merlin Retail Cross Screen Media Media View All Case Studies Learn more Developers Documentation Docs Comprehensive guides to use ZenML Deploying ZenML Understanding ZenML system architecture Tutorials Examples showing ZenML in action GUIDES Quickstart Quickly get your hands dirty Showcase Projects of ML use cases built with ZenML Starter Guide Get started with the basics COMMUNITY Slack Join our Slack Community Changelog Discover whatâ€™s new on ZenML Roadmap Join us on our MLOps journey Pricing Blog Case Studies Get Started Book a demo Software Engineering LangGraph vs CrewAI: Letâ€™s Learn About the Differences Hamza Tahir Jun 28, 2025 â€¢ 12 mins All posts LLMOps Contents Get started with ZenML today Begin with open source tools Works with any infrastructure Secure, metadata-only tracking Book a demo Related Posts Metaflow vs MLflow vs ZenML: Whatâ€™s the Difference? ZenML&#x27;s MCP Server Supports DXT: Making MLOps Conversations Frictionless This is also a heading This is a heading LangGraph and CrewAI are modern frameworks for orchestrating complex AI workflows with multiple LLM-driven agents. Both these intelligent systems are capable of sophisticated reasoning, planning, and autonomous action, and are becoming central to modern AI applications. However, they differ in abstraction, interfaces, and enterprise features. This LangGraph vs CrewAI article compares key attributes of these platforms, like: Workflow patterns Human-in-loop capabilities Parallelism and throttling Compliance and security Integration options Pricing We do this so you can exactly know when to use which one of these platforms. Recently Updated (November 2025) : This comparison has been refreshed with major 2025 developments including LangGraph 1.0&#x27;s stable release (October 2025), CrewAI&#x27;s multimodal support and agentic RAG capabilities, updated market adoption statistics showing 85% of organizations now using AI agents, and the emergence of new interoperability protocols like A2A and MCP. All framework comparisons and integration information reflect current capabilities as of November 2025. LangGraph vs CrewAI: Key Takeaways ğŸ§‘â€ğŸ’» LangGraph : Itâ€™s a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. ğŸ§‘â€ğŸ’» CrewAI : Itâ€™s a high-level framework for orchestrating autonomous AI agents working together as a crew. The platform abstracts away complexity by providing pre-built patterns for agent collaboration, role assignment, and task delegation. Framework Maturity &amp; Lineage The table below compared the framework maturity of LangGraph and CrewAI: Metric CrewAI LangGraph First public release v0.1.0 â€” 14 Nov 2023 v0.0.9 â€” 8 Jan 20
   âœ“ [https://www.truefoundry.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs LangGraph: Know The Differences --> --> Join the AI Security Webinar with Palo Alto. Register here Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Product AI INFRA LLMOps Model Serving SECURE &amp; GOVERN AI Gateway MCP Gateway New! Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Open Source Resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities Insurance Retail Government Technology Oil and Gas BY FUNCTION For DS Leaders For IT Leaders Application Suites Customer Support and CRM Finance IT Operations Marketing Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Why TrueFoundry CUSTOMERS Case Studies Wall of Love G2 Reviews DISCOVER For DS Leaders For IT Leaders For AI/ML Leaders Elevate for Enterprises What&#x27;s New Careers resources Newsletter Resource Center Trust Center Events &amp; Conferences Webinars Trust Center Compare Newsletter Truefoundry vs Sagemaker Truefoundry vs Databricks Truefoundry vs Portkey Solutions BY INDUSTRY Banking and Investments Media and Communication Education Healthcare and Life Sciences Power and Utilities CUSTOMERS For DS Leaders For IT Leaders Insurance Retail Government Technology Oil and Gas BY FUNCTION Newsletter Application Suites Customer Support and CRM Finance IT Operations Marketing Trust Center Compare Newsletter Sales and Lead Management Security and Compliance HR and Recruiting Digital Workplace Pricing Docs Blog Live Demo Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Start Building OPEN SOURCE Elasti Cognita LLM Benchmarking EXPLORE Live Demo Accelerators Login Book Demo Sign Up Login Sign Up Book Demo comparison Crewai vs LangGraph: Know The Differences August 21, 2025 | 9:30 min read TrueFoundry SHARE The rise of multi-agent AI systems has created a need for frameworks that go beyond simple prompt chaining. Developers now want tools that can orchestrate multiple agents, manage shared state, and support complex workflows with branching, looping, and retries. Two notable frameworks leading this space are CrewAI and LangGraph. While CrewAI focuses on collaborative agent teamsâ€”where each agent has a specific role, goal, and communication strategyâ€”LangGraph provides a graph-based workflow engine designed for building structured, resilient LLM applications. Both aim to simplify multi-agent development but approach the problem from different angles: CrewAI emphasizes team coordination, whereas LangGraph emphasizes stateful, production-ready execution. In this comparison, weâ€™ll break down their core philosophies, features, and use cases to help you decide which framework better fits your AI development needs. What Is CrewAI? CrewAI is an open-source, Python-based framework designed for orchestrating autonomous, collaborative AI agents, much like a digital team handling complex tasks. Each agent operates with a defined role, such as researcher, writer, or analyst, and works together within a structured crew to solve problems efficiently. CrewAI combines modularity with performance, offering both high-level simplicity and precise control over how agents interact. Through components like Crews and Flows, it supports dynamic collaboration while giving developers the ability to manage control flows, tasks, and environments with flexibility. Agents in CrewAI are set up with defined roles, goals, tools, and even personality through backstories. This is similar to how a human team organizes itself to divide work and minimize errors. The framework allows agents to work sequentially or in parallel, with coordination
   âœ“ [https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/]
      Preview: IBM Developer
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.50s
ğŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ğŸ”¬ Analyzer: Max iterations reached (2), proceeding to Writer

ğŸ”¬ Analyzer [2/2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] CrewAI is designed for collaborative agent teams with specific roles, goals, and communication strategies.
      [2] LangGraph is a graph-based workflow engine for structured, resilient LLM applications.
      [3] CrewAI emphasizes team coordination, while LangGraph emphasizes stateful execution.
      [4] CrewAI offers faster initial setup and can be used to build multi-agent systems quickly.
      [5] LangGraph requires a deeper understanding of graph structures and state management, taking longer to master.
   â””â”€ Decision: Research complete (26 total findings)
   â””â”€ âœ… Research Subgraph completed (execution #1)
   â””â”€ Findings: 26 items
   â””â”€ Contents: 6 URLs read

ğŸ“¦ Compress: Compressing 26 findings, 6 contents
   â””â”€ Compressed to 2903 chars (from ~7827 raw chars)
   â””â”€ Sources cited: 4
   â””â”€ Preview:
      ## Key Findings
      - CrewAI and LangGraph are frameworks for building multi-agent systems, but they differ in their approach to team coordination and workflow management [1], [2].
      - CrewAI excels in faster setup, agent collaboration, and modular architecture [1], [2].
      - LangGraph is suited for complex workflows requiring precise control, state management, and advanced debugging [2].
      
      ## Detailed Information
      
      **Overview:**
      CrewAI and LangGraph are frameworks designed for building multi-agent systems, but each emphasizes different aspects of development [1], [2]. CrewAI focuses on collaborative agent teams with specific roles, goals, and communication strategies [1], [2]. LangGraph is a graph-based workflow engine that prioritizes structured, resilient LLM applications [2]. CrewAI emphasizes team coordination, while LangGraph emphasizes stateful execution [1], [2].
      
      **Setup and Abstraction:**
      CrewAI offers a faster initial setup, enabling users to quickly build multi-agent systems [1], [2]. It provides better abstractions for agent collaboration, allowing agents to communicate naturally, delegate tasks, and operate in parallel [1], [2]. CrewAI's architecture is modular, separating agent creation, task definition, and process orchestration, which allows for customization while maintaining abstraction [1], [2]. LangGraph, however, requires a deeper understanding of graph structures and state management, which can take longer to master [1], [2]. LangGraph requires explicit graph design for coordination [1], [2].
      
      **Control and Scalability:**
      LangGraph is better suited for complex workflows that demand precise control and advanced debugging capabilities [1], [2]. It provides low-level control over agent workflows, incorporating built-in persistence, streaming support, and the ability to create complex branching logic [1], [2]. LangGraph implements a graph-based architecture focused on managing application state through a central persistence layer [2]. CrewAI is geared more towards longer-running operations and demonstrates scalability in production environments; it also includes Human-in-the-Loop (HitL) capabilities [1], [2].
      
      **Agent Coordination and Workflow Management:**
      CrewAI offers simple orchestration of multi-agent teams with role/task assignment and coordination/delegation mechanisms [1], [2]. CrewAI features a clear object structure (Agent, Crew, Task, etc.) and seamless state management with out-of-the-box agent coordination [1], [2]. LangGraph offers fine-grained control over multi-agent workflows with a graph-based architecture and built-in support for complex state management, retries, and event handling [1], [2]. LangGraph has a well-established memory concept, making memory management more straightforward [2].
      
      ## Sources
      [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [2] https://www.leanware.co/insights/langgraph-vs-crewai-comparison

âœï¸ Writer: Composing response from 26 findings
   â””â”€ Using compressed notes (2903 chars)

âœï¸ Writer: Generated response (2713 chars)
   â””â”€ Sources used:
      [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      [2] https://www.leanware.co/insights/langgraph-vs-crewai-comparison
      [3] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, íŒ€ í˜‘ì—… ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹ì—ì„œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤. CrewAIëŠ” ë¹ ë¥¸ ì„¤ì •, ì—ì´ì „íŠ¸ í˜‘ì—…, ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜ì— ê°•ì ì„ ê°€ì§€ë©°, LangGraphëŠ” ì •ë°€í•œ ì œì–´, ìƒíƒœ ê´€ë¦¬, ê³ ê¸‰ ë””ë²„ê¹…ì´ í•„ìš”í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ì í•©í•˜ë‹¤ [1], [2].
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, ê° í”„ë ˆì„ì›Œí¬ëŠ” ê°œë°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì¸¡ë©´ì— ì¤‘ì ì„ ë‘”ë‹¤ [1], [2].
      *   CrewAIëŠ” ì—ì´ì „íŠ¸ íŒ€ì˜ í˜‘ì—…ê³¼ ì—­í•  ì •ì˜, ëª©í‘œ ì„¤ì •, í†µì‹  ì „ëµì— ì´ˆì ì„ ë§ì¶˜ë‹¤ [1], [2].
      *   LangGraphëŠ” êµ¬ì¡°í™”ë˜ê³  ë³µì›ë ¥ì´ ë›°ì–´ë‚œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì—”ì§„ì´ë‹¤ [2]. CrewAIëŠ” íŒ€ í˜‘ì—…ì„ ê°•ì¡°í•˜ê³ , LangGraphëŠ” ìƒíƒœ ê¸°ë°˜ ì‹¤í–‰ì„ ê°•ì¡°í•œë‹¤ [1], [2].
      *   CrewAIëŠ” ë¹ ë¥¸ ì´ˆê¸° ì„¤ì •ì„ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ ì‹ ì†í•˜ê²Œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤ [1], [2].
      *   LangGraphëŠ” ê·¸ë˜í”„ êµ¬ì¡° ë° ìƒíƒœ ê´€ë¦¬ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ í•„ìš”ë¡œ í•˜ë©°, ìˆ™ë‹¬í•˜ëŠ” ë° ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆë‹¤ [1], [2].
      *   LangGraphëŠ” ì •ë°€í•œ ì œì–´ ë° ê³ ê¸‰ ë””ë²„ê¹… ê¸°ëŠ¥ì´ í•„ìš”í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ì í•©í•˜ë‹¤ [1], [2].
      *   CrewAIëŠ” ì—­í• /ì‘ì—… í• ë‹¹ ë° ì¡°ì •/ìœ„ì„ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ íŒ€ì˜ ê°„ë‹¨í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ì œê³µí•œë‹¤ [1], [2].
      *   LangGraphëŠ” ê·¸ë˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ë³µì¡í•œ ìƒíƒœ ê´€ë¦¬, ì¬ì‹œë„ ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ì— ëŒ€í•œ ê¸°ë³¸ ì§€ì›ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ë¥¼ ì œê³µí•œë‹¤ [1], [2].
      
      ## ìƒì„¸ ë¶„ì„
      
      **ê°œìš”:** CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¼ëŠ” ê³µí†µì ì„ ê°€ì§€ì§€ë§Œ, ì„¤ê³„ ì² í•™ê³¼ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ëšœë ·í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤. CrewAIëŠ” ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ì—…ì„ ë‹¨ìˆœí™”í•˜ê³  ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì…ì„ êµ¬ì¶•í•˜ëŠ” ë° ì¤‘ì ì„ ë‘”ë‹¤. ë°˜ë©´, LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ë°€í•˜ê²Œ ì œì–´í•˜ê³  ê´€ë¦¬í•˜ë©°, ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìƒíƒœë¥¼ ëª…í™•í•˜ê²Œ ì¶”ì í•˜ëŠ” ë° ë” ì í•©í•˜ë‹¤ [1], [2].  ë”°ë¼ì„œ í”„ë¡œì íŠ¸ì˜ ìš”êµ¬ì‚¬í•­, ê°œë°œìì˜ ìˆ™ë ¨ë„, ê·¸ë¦¬ê³  í•„ìš”í•œ ì œì–´ ìˆ˜ì¤€ì— ë”°ë¼ ì í•©í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.
      
      **ì„¤ì • ë° ì¶”ìƒí™”:** CrewAIëŠ” ì§ê´€ì ì¸ APIì™€ ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œìê°€ ë¹ ë¥´ê²Œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³  ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤ [1], [2]. ì—ì´ì „íŠ¸ ìƒì„±, ì‘ì—… ì •ì˜, í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ìœ„í•œ ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ìœ ì—°ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ë³µì¡ì„±ì„ ì¤„ì¸ë‹¤. ë°˜ë©´ LangGraphëŠ” ê·¸ë˜í”„ êµ¬ì¡°ì— ëŒ€í•œ ì´í•´ë¥¼ ìš”êµ¬í•˜ë©°, ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ëª…ì‹œì ì¸ ê·¸ë˜í”„ ì„¤ê³„ë¥¼ í•„ìš”ë¡œ í•œë‹¤ [1], [2].  ì´ëŠ” ì´ˆê¸° í•™ìŠµ ê³¡ì„ ì„ ë†’ì´ì§€ë§Œ, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ë” ê°•ë ¥í•œ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
      
      **ì œì–´ ë° í™•ì¥ì„±:** LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ë°€í•˜ê²Œ ì œì–´í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ë° ê°•ì ì„ ë³´ì¸ë‹¤ [1], [2].  ë‚´ì¥ëœ ì§€ì†ì„±, ìŠ¤íŠ¸ë¦¬ë° ì§€ì›, ë³µì¡í•œ ë¶„ê¸° ë¡œì§ì„ í†µí•´ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆë‹¤. CrewAIëŠ” ì¥ê¸° ì‹¤í–‰ ì‘ì—…ì— ì í•©í•˜ë©°, ì‹¤ì œ í™˜ê²½ì—ì„œ í™•ì¥ì„±ì„ ì…ì¦í–ˆë‹¤ [1], [2]. ë˜í•œ, CrewAIëŠ” Human-in-the-Loop (HitL) ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì¸ê°„ì˜ ê°œì…ì´ í•„ìš”í•œ ìƒí™©ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆë‹¤.
      
      **ì—ì´ì „íŠ¸ í˜‘ì—… ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬:** CrewAIëŠ” ì—­í• /ì‘ì—… í• ë‹¹ ë° ì¡°ì •/ìœ„ì„ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ íŒ€ì˜ ê°„ë‹¨í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ì œê³µí•œë‹¤ [1], [2]. ëª…í™•í•œ ê°ì²´ êµ¬ì¡° (Agent, Crew, Task ë“±)ì™€ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ í˜‘ì—…ì„ í†µí•´ ì›í™œí•œ ìƒíƒœ ê´€ë¦¬ë¥¼ ì§€ì›í•œë‹¤. LangGraphëŠ” ê·¸ë˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ë³µì¡í•œ ìƒíƒœ ê´€ë¦¬, ì¬ì‹œë„ ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ì— ëŒ€í•œ ê¸°ë³¸ ì§€ì›ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ë¥¼ ì œê³µí•œë‹¤ [1], [2]. LangGraphëŠ” ì˜ ì •ì˜ëœ ë©”ëª¨ë¦¬ ê°œë…ì„ í†µí•´ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ë³´ë‹¤ ê°„ë‹¨í•˜ê²Œ ë§Œë“ ë‹¤.
      
      ## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜
      
      *   [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
      *   [2] https://www.leanware.co/insights/langgraph-vs-crewai-comparison
      
      ## ê²°ë¡  ë° í‰ê°€
      
      CrewAIì™€ LangGraphëŠ” ê°ê° ë‹¤ë¥¸ ì¥ë‹¨ì ì„ ê°€ì§„ ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì´ë‹¤. CrewAIëŠ” ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ì œì‘, ì‰¬ìš´ ì‚¬ìš©ë²•, ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ì—…ì— ì¤‘ì ì„ ë‘ì–´, ë¹„êµì  ê°„ë‹¨í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì— ì í•©í•˜ë‹¤. ë°˜ë©´, LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì •ë°€í•œ ì œì–´, ìƒíƒœ ê´€ë¦¬, ê³ ê¸‰ ë””ë²„ê¹… ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬, ë†’ì€ ìˆ˜ì¤€ì˜ ì œì–´ì™€ ì•ˆì •ì„±ì´ ìš”êµ¬ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•˜ë‹¤.
      
      í”„ë¡œì íŠ¸ì˜ ë³µì¡ì„±, ê°œë°œíŒ€ì˜ ìˆ™ë ¨ë„, ê·¸ë¦¬ê³  í•„ìš”í•œ ì œì–´ ìˆ˜ì¤€ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.  ë§Œì•½ ë¹ ë¥¸ ê°œë°œê³¼ ì—ì´ì „íŠ¸ ê°„ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í˜‘ì—…ì´ ì¤‘ìš”í•˜ë‹¤ë©´ CrewAIë¥¼, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì™€ ìƒíƒœ ì¶”ì ì´ ì¤‘ìš”í•˜ë‹¤ë©´ LangGraphë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤. ë˜í•œ, ë‘ í”„ë ˆì„ì›Œí¬ëŠ” ì„œë¡œ ë°°íƒ€ì ì¸ ê²ƒì´ ì•„ë‹ˆë¯€ë¡œ, í•„ìš”ì— ë”°ë¼ ë‘ í”„ë ˆì„ì›Œí¬ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆë‹¤.

ğŸ” Critique: CARC Quality Evaluation...
   â””â”€ CARC Scores: C=4.0 A=4.0 R=4.5 C=4.0
   â””â”€ Total: 16.5/20 âœ… Excellent
   â””â”€ Feedback: The response provides a good comparison of LangGraph and CrewAI, covering their strengths, weaknesses, and suitability for different use cases. It addresses the key aspects of the question effectively. However, it could benefit from more specific examples or scenarios to illustrate the differences more concretely. The accuracy seems good based on the provided sources, but a deeper dive into each framework's architecture could enhance the response.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 9 Fixed Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ì¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜...
â”‚ Time: 28.43s
â”‚ LLM Calls: 2
â”‚ Search Calls: 0
â”‚ URLs Read: 6
â”‚ Iterations: 2
â”‚ Est. Tokens: 1130
â”‚ Response Length: 2713 chars
â”‚ Has Citations: âœ…
â”‚ CARC Quality: C=4.0 A=4.0 R=4.5 C=4.0 â†’ 16.5/20 ğŸ‘ Good
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ğŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½
CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, íŒ€ í˜‘ì—… ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹ì—ì„œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤. CrewAIëŠ” ë¹ ë¥¸ ì„¤ì •, ì—ì´ì „íŠ¸ í˜‘ì—…, ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜ì— ê°•ì ì„ ê°€ì§€ë©°, LangGraphëŠ” ì •ë°€í•œ ì œì–´, ìƒíƒœ ê´€ë¦¬, ê³ ê¸‰ ë””ë²„ê¹…ì´ í•„ìš”í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ì í•©í•˜ë‹¤ [1], [2].

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, ê° í”„ë ˆì„ì›Œí¬ëŠ” ê°œë°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì¸¡ë©´ì— ì¤‘ì ì„ ë‘”ë‹¤ [1], [2].
*   CrewAIëŠ” ì—ì´ì „íŠ¸ íŒ€ì˜ í˜‘ì—…ê³¼ ì—­í•  ì •ì˜, ëª©í‘œ ì„¤ì •, í†µì‹  ì „ëµì— ì´ˆì ì„ ë§ì¶˜ë‹¤ [1], [2].
*   LangGraphëŠ” êµ¬ì¡°í™”ë˜ê³  ë³µì›ë ¥ì´ ë›°ì–´ë‚œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì—”ì§„ì´ë‹¤ [2]. CrewAIëŠ” íŒ€ í˜‘ì—…ì„ ê°•ì¡°í•˜ê³ , LangGraphëŠ” ìƒíƒœ ê¸°ë°˜ ì‹¤í–‰ì„ ê°•ì¡°í•œë‹¤ [1], [2].
*   CrewAIëŠ” ë¹ ë¥¸ ì´ˆê¸° ì„¤ì •ì„ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ ì‹ ì†í•˜ê²Œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤ [1], [2].
*   LangGraphëŠ” ê·¸ë˜í”„ êµ¬ì¡° ë° ìƒíƒœ ê´€ë¦¬ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ í•„ìš”ë¡œ í•˜ë©°, ìˆ™ë‹¬í•˜ëŠ” ë° ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆë‹¤ [1], [2].
*   LangGraphëŠ” ì •ë°€í•œ ì œì–´ ë° ê³ ê¸‰ ë””ë²„ê¹… ê¸°ëŠ¥ì´ í•„ìš”í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ì í•©í•˜ë‹¤ [1], [2].
*   CrewAIëŠ” ì—­í• /ì‘ì—… í• ë‹¹ ë° ì¡°ì •/ìœ„ì„ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ íŒ€ì˜ ê°„ë‹¨í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ì œê³µí•œë‹¤ [1], [2].
*   LangGraphëŠ” ê·¸ë˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ë³µì¡í•œ ìƒíƒœ ê´€ë¦¬, ì¬ì‹œë„ ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ì— ëŒ€í•œ ê¸°ë³¸ ì§€ì›ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ë¥¼ ì œê³µí•œë‹¤ [1], [2].

## ìƒì„¸ ë¶„ì„

**ê°œìš”:** CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¼ëŠ” ê³µí†µì ì„ ê°€ì§€ì§€ë§Œ, ì„¤ê³„ ì² í•™ê³¼ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ëšœë ·í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤. CrewAIëŠ” ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ì—…ì„ ë‹¨ìˆœí™”í•˜ê³  ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì…ì„ êµ¬ì¶•í•˜ëŠ” ë° ì¤‘ì ì„ ë‘”ë‹¤. ë°˜ë©´, LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ë°€í•˜ê²Œ ì œì–´í•˜ê³  ê´€ë¦¬í•˜ë©°, ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìƒíƒœë¥¼ ëª…í™•í•˜ê²Œ ì¶”ì í•˜ëŠ” ë° ë” ì í•©í•˜ë‹¤ [1], [2].  ë”°ë¼ì„œ í”„ë¡œì íŠ¸ì˜ ìš”êµ¬ì‚¬í•­, ê°œë°œìì˜ ìˆ™ë ¨ë„, ê·¸ë¦¬ê³  í•„ìš”í•œ ì œì–´ ìˆ˜ì¤€ì— ë”°ë¼ ì í•©í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.

**ì„¤ì • ë° ì¶”ìƒí™”:** CrewAIëŠ” ì§ê´€ì ì¸ APIì™€ ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œìê°€ ë¹ ë¥´ê²Œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³  ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤ [1], [2]. ì—ì´ì „íŠ¸ ìƒì„±, ì‘ì—… ì •ì˜, í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ìœ„í•œ ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ìœ ì—°ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ë³µì¡ì„±ì„ ì¤„ì¸ë‹¤. ë°˜ë©´ LangGraphëŠ” ê·¸ë˜í”„ êµ¬ì¡°ì— ëŒ€í•œ ì´í•´ë¥¼ ìš”êµ¬í•˜ë©°, ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ëª…ì‹œì ì¸ ê·¸ë˜í”„ ì„¤ê³„ë¥¼ í•„ìš”ë¡œ í•œë‹¤ [1], [2].  ì´ëŠ” ì´ˆê¸° í•™ìŠµ ê³¡ì„ ì„ ë†’ì´ì§€ë§Œ, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ë” ê°•ë ¥í•œ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.

**ì œì–´ ë° í™•ì¥ì„±:** LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ë°€í•˜ê²Œ ì œì–´í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ë° ê°•ì ì„ ë³´ì¸ë‹¤ [1], [2].  ë‚´ì¥ëœ ì§€ì†ì„±, ìŠ¤íŠ¸ë¦¬ë° ì§€ì›, ë³µì¡í•œ ë¶„ê¸° ë¡œì§ì„ í†µí•´ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆë‹¤. CrewAIëŠ” ì¥ê¸° ì‹¤í–‰ ì‘ì—…ì— ì í•©í•˜ë©°, ì‹¤ì œ í™˜ê²½ì—ì„œ í™•ì¥ì„±ì„ ì…ì¦í–ˆë‹¤ [1], [2]. ë˜í•œ, CrewAIëŠ” Human-in-the-Loop (HitL) ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì¸ê°„ì˜ ê°œì…ì´ í•„ìš”í•œ ìƒí™©ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆë‹¤.

**ì—ì´ì „íŠ¸ í˜‘ì—… ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬:** CrewAIëŠ” ì—­í• /ì‘ì—… í• ë‹¹ ë° ì¡°ì •/ìœ„ì„ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ íŒ€ì˜ ê°„ë‹¨í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ì œê³µí•œë‹¤ [1], [2]. ëª…í™•í•œ ê°ì²´ êµ¬ì¡° (Agent, Crew, Task ë“±)ì™€ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ í˜‘ì—…ì„ í†µí•´ ì›í™œí•œ ìƒíƒœ ê´€ë¦¬ë¥¼ ì§€ì›í•œë‹¤. LangGraphëŠ” ê·¸ë˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ë³µì¡í•œ ìƒíƒœ ê´€ë¦¬, ì¬ì‹œë„ ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ì— ëŒ€í•œ ê¸°ë³¸ ì§€ì›ì„ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ë¥¼ ì œê³µí•œë‹¤ [1], [2]. LangGraphëŠ” ì˜ ì •ì˜ëœ ë©”ëª¨ë¦¬ ê°œë…ì„ í†µí•´ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ë³´ë‹¤ ê°„ë‹¨í•˜ê²Œ ë§Œë“ ë‹¤.

## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜

*   [1] https://www.truefoundry.com/blog/crewai-vs-langgraph
*   [2] https://www.leanware.co/insights/langgraph-vs-crewai-comparison

## ê²°ë¡  ë° í‰ê°€

CrewAIì™€ LangGraphëŠ” ê°ê° ë‹¤ë¥¸ ì¥ë‹¨ì ì„ ê°€ì§„ ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì´ë‹¤. CrewAIëŠ” ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ì œì‘, ì‰¬ìš´ ì‚¬ìš©ë²•, ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ì—…ì— ì¤‘ì ì„ ë‘ì–´, ë¹„êµì  ê°„ë‹¨í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì— ì í•©í•˜ë‹¤. ë°˜ë©´, LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì •ë°€í•œ ì œì–´, ìƒíƒœ ê´€ë¦¬, ê³ ê¸‰ ë””ë²„ê¹… ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬, ë†’ì€ ìˆ˜ì¤€ì˜ ì œì–´ì™€ ì•ˆì •ì„±ì´ ìš”êµ¬ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•˜ë‹¤.

í”„ë¡œì íŠ¸ì˜ ë³µì¡ì„±, ê°œë°œíŒ€ì˜ ìˆ™ë ¨ë„, ê·¸ë¦¬ê³  í•„ìš”í•œ ì œì–´ ìˆ˜ì¤€ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.  ë§Œì•½ ë¹ ë¥¸ ê°œë°œê³¼ ì—ì´ì „íŠ¸ ê°„ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í˜‘ì—…ì´ ì¤‘ìš”í•˜ë‹¤ë©´ CrewAIë¥¼, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì™€ ìƒíƒœ ì¶”ì ì´ ì¤‘ìš”í•˜ë‹¤ë©´ LangGraphë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤. ë˜í•œ, ë‘ í”„ë ˆì„ì›Œí¬ëŠ” ì„œë¡œ ë°°íƒ€ì ì¸ ê²ƒì´ ì•„ë‹ˆë¯€ë¡œ, í•„ìš”ì— ë”°ë¼ ë‘ í”„ë ˆì„ì›Œí¬ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆë‹¤.
======================================================================


ğŸ“Š Running benchmark: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´...

ğŸ” Clarify: Analyzing query...
   â””â”€ Query: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´ì¤˜
   â””â”€ Status: ğŸŸ¢ Clear
   â””â”€ Analysis: The query asks for an analysis of research papers related to LLM-based agent systems published in 2024 and a description of the main trends.
   â””â”€ Topics: LLM-based agent systems, Research paper analysis, Trends in AI agents, Natural Language Processing
ğŸ“‹ Planner: Creating research plan for: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´

ğŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] LLM based agent systems papers 2024
      [2] Large language model agent architecture 2024
      [3] Trends in LLM agent research 2024
      [4] Applications of LLM agents 2024
   â””â”€ Focus: Architectures of LLM-based agents, Applications of LLM-based agents, Emerging trends in LLM agent research, Performance and limitations of LLM agents

ğŸ¯ Supervisor [Phase 9]: Analyzing query complexity
   â””â”€ Query: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´ì¤˜
   â””â”€ Planned queries: 4
   â””â”€ Complexity: ğŸŸ¡ MEDIUM
   â””â”€ Recommended: 2 iterations, depth 2
   â””â”€ Strategy: targeted
   â””â”€ Reasoning: The query requires analyzing multiple papers and identifying trends, which is beyond a simple factual question. Two iterations and a depth of 2 should be sufficient to gather relevant information and perform the analysis.

ğŸ”¬ Research Subgraph: Starting research loop...
   â””â”€ Supervisor config: MEDIUM, max 2 iterations, targeted strategy
ğŸ” Searcher [1]: Searching for: LLM based agent systems papers 2024

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://arxiv.org/html/2508.17281v1
      [2] https://dl.acm.org/doi/10.1145/3712003
      [3] https://openreview.net/forum?id=bkiM54QftZ
      [4] https://arxiv.org/abs/2402.01680
      [5] https://www.ijcai.org/proceedings/2024/0890.pdf
   â””â”€ Snippets:
      â€¢ The pursuit of human-level artificial intelligence (AI) has significantly advanced the development of autonomous agents and Large Language Models (LLMs). LLMs are now widely utilized as decision-making agents for their ability to interpret instructions, manage sequential tasks, and adapt through feedback. This review examines recent developments in employing LLMs as autonomous agents and tool users and comprises seven research questions. We only used the papers published between 2023 and 2025 [...] in conferences of the A and A rank and Q1 journals. A structured analysis of the LLM agentsâ€™ architectural design principles, dividing their applications into single-agent and multi-agent systems, and strategies for integrating external tools is presented. In addition, the cognitive mechanisms of LLM, including reasoning, planning, and memory, and the impact of prompting methods and fine-tuning procedures on agent performance are also investigated. Furthermore, we evaluated current benchmarks [...] usage [16, 17]. To address these limitations, the concept of multi-agent LLM systems has gained increasing attention. In such systems, multiple LLMs interact as specialized agents, each with distinct roles or goals, collaborating to solve more complex tasks than a single agent can manage. Through structured communication, reflective reasoning, and explicit role assignments in simulated settings, multi-agent LLMs exhibit capabilities such as consensus building, uncertainty-aware planning, and
      â€¢ Our search included two sets of keywords: one set targeting LLM-based Multi-Agent Systems (called [agent words]) and the other focusing on specific SE activities (called [SE words]). Papers may use variations of the same keyword. For example, the term â€œvulnerabilityâ€ may appear as â€œvulnerableâ€ or â€œvulnerabilities.â€ To address this, we use truncated terms like â€œvulnerabâ€ to capture all related forms. For LMA systems, we used keywords: â€œAgentâ€ OR â€œLLMâ€ OR â€œLarge Language Modelâ€ OR â€œCollaborat.â€ [...] November 2022, we limited our review to papers published after this date (exclusion criterion 6). Furthermore, we excluded papers unrelated to SE (exclusion criterion 7) and those that mention LMA systems only in discussions or as future work, without presenting experimental results (exclusion criterion 8). After the third phase, we identified 41 primary studies directly relevant to our research focus. The search process was conducted on November 14th, 2024. [...] leverages LLMs to create tailored process instances based on their knowledge of software development. These instances act as blueprints to guide the architecture of the LMA system, adapting to the specific and diverse needs of different projects. Similarly, in MegaAgent , agent roles and tasks are not predefined but are generated and planned dynamically based on project requirements. Both ToP and MegaAgent highlight the shift from rigid, static workflows to dynamic, adaptive systems. These
      â€¢ Abstract: Large language model-based multi-agent systems have shown great abilities across various tasks due to the collaboration of expert agents, each focusing on a specific domain. However, the impact of clumsy or even malicious agentsâ€”those who frequently make errors in their tasksâ€”on the overall performance of the system remains underexplored. This paper investigates: (1) What is the resilience of various system structures (e.g., A$\rightarrow$B$\rightarrow$C, [...] TL;DR: We investigate the resilience of multi-agent collaboration with faulty agents, finding hierarchical structures the best and propose methods to improve performance under errors.
ğŸ’­ Think: Query: LLM based agent systems papers 2024 | Found 5 results, 5 URLs. Key snippets: The pursuit of human-level artificial intelligence (AI) has significantly advanced the development o | Our search included two sets of keywords: one set targeting LLM-based Multi-Agent Systems (called [a | Abstract: Large language model-based multi-agent systems have shown great abilities across var. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://arxiv.org/html/2508.17281v1... (8015 chars)
ğŸ“– Read URL: https://openreview.net/forum?id=bkiM54QftZ... (3701 chars)
   âœ“ [https://dl.acm.org/doi/10.1145/3712003]
      Preview: Error: HTTP 403 for URL: https://dl.acm.org/doi/10.1145/3712003
   âœ“ [https://arxiv.org/html/2508.17281v1]
      Preview: From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users 1 Introduction 2 Related works 3 Methodology 3.1 Research questions (RQs) 3.2 Search strategies 3.3 Selection criteria 3.4 Article selection 4 Baseline Large Language Models for agent frameworks 4.1 Proprietary LLMs for agentic applications 4.2 Open-sourced LLMs for agentic applications 5 External tool integration across LLM agent workflows 5.1 Usage of tools across knowledge grounding, web search, and structured retrieval 5.2 Usage of tools across code generation, API use, and system-level integration 5.3 Usage of tools across interactive and embodied environments 6 Frameworks for building LLM agents 6.1 Basic architecture of an LLM agent 6.1.1 Single-agent LLM system 6.1.2 Multi-agent LLM systems 6.2 Common LLM agent frameworks 6.3 Domain-Specific Frameworks 6.3.1 Single-Agent LLM Systemsâ€™ Application Domain 6.3.2 Multi-Agent LLM systemsâ€™ application domain 7 Reasoning, planning, and memory of LLM agents 7.1 Reasoning in LLM-based agents 7.1.1 Application-specific reasoning techniques 7.1.2 Widely-used reasoning techniques 7.2 Planning in LLM-based agents 7.2.1 Application-specific reasoning techniques 7.2.2 Widely-used planning techniques 7.3 Memory mechanisms in LLM agents 7.3.1 Application-specific memory techniques 7.3.2 Widely-used memory techniques 8 Impact of prompting, fine-tuning and memory augmentation 8.1 Prompt engineering: a non-parametric approach to dynamic control and role delegation 8.2 Fine-tuning: embedding domain expertise and core behavioral traits 8.3 Memory augmentation: enabling grounded reasoning and experiential learning 8.4 The synergistic integration of prompting, fine-tuning, and memory 9 Evaluation benchmarks and datasets 9.1 Task-oriented and interactive benchmarks 9.2 Methodologies and metrics for evaluation 9.3 Datasets for agent training and grounding 10 Discussion 11 Future directions 11.1 Towards verifiable reasoning and robust self-improvement 11.2 Toward scalable, adaptive, and collaborative LLM-based agent systems 11.3 Deepening the human-agent symbiosis: personalization, proactivity, and trust 12 Conclusion From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users Sadia Sultana Chowa 1 Riasad Alvi 2 Subhey Sadi Rahman 2 Md Abdur Rahman 2 Mohaimenul Azam Khan Raiaan 2 Md Rafiqul Islam 3 Mukhtar Hussain 3 Sami Azam 3,* 1 Department of Computer Science and Engineering Daffodil International University Dhaka-1341 Bangladesh 2 Department of Computer Science and Engineering United International University Dhaka 1212 Bangladesh 3 Faculty of Science and Technology Charles Darwin University Casuarina NT 0909 Australia * Corresponding Author: sami.azam@cdu.edu.au Abstract The pursuit of human-level artificial intelligence (AI) has significantly advanced the development of autonomous agents and Large Language Models (LLMs). LLMs are now widely utilized as decision-making agents for their ability to interpret instructions, manage sequential tasks, and adapt through feedback. This review examines recent developments in employing LLMs as autonomous agents and tool users and comprises seven research questions. We only used the papers published between 2023 and 2025 in conferences of the A* and A rank and Q1 journals. A structured analysis of the LLM agentsâ€™ architectural design principles, dividing their applications into single-agent and multi-agent systems, and strategies for integrating external tools is presented. In addition, the cognitive mechanisms of LLM, including reasoning, planning, and memory, and the impact of prompting methods and fine-tuning procedures on agent performance are also investigated. Furthermore, we evaluated current benchmarks and assessment protocols and have provided an analysis of 68 publicly available datasets to assess the performance of LLM-based agents in various tasks. In conducting this review, we have identified critical findings on 
   âœ“ [https://openreview.net/forum?id=bkiM54QftZ]
      Preview: On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents | OpenReview Toggle navigation OpenReview .net Login Go to ICML 2025 Conference homepage On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents Jen-tse Huang , Jiaxu Zhou , Tailin Jin , Xuhui Zhou , Zixi Chen , Wenxuan Wang , Youliang Yuan , Michael Lyu , Maarten Sap Published: 01 May 2025, Last Modified: 23 Jul 2025 ICML 2025 poster Everyone Revisions BibTeX CC BY 4.0 TL;DR : We investigate the resilience of multi-agent collaboration with faulty agents, finding hierarchical structures the best and propose methods to improve performance under errors. Abstract : Large language model-based multi-agent systems have shown great abilities across various tasks due to the collaboration of expert agents, each focusing on a specific domain. However, the impact of clumsy or even malicious agentsâ€”those who frequently make errors in their tasksâ€”on the overall performance of the system remains underexplored. This paper investigates: (1) What is the resilience of various system structures (e.g., A$\rightarrow$B$\rightarrow$C, A$\leftrightarrow$B$\leftrightarrow$C) under faulty agents, on different downstream tasks? (2) How can we increase system resilience to defend against these agents? To simulate faulty agents, we propose two approachesâ€”AutoTransform and AutoInjectâ€”which introduce mistakes into the agents&#x27; responses. Experiments on four downstream tasks using six systems show that the &quot;hierarchical&quot; structure, i.e., A$\rightarrow$(B$\leftrightarrow$C), exhibits superior resilience with the lowest performance drop of 5.5%, compared to 10.5% and 23.7% of other two structures. To further improve resilience, we introduce (1) Challenger, that introduces a mechanism for each agent to challenge others&#x27; outputs, and (2) Inspector, an additional agent to review and correct messages, recovering up to 96.4% errors made by faulty agents. Our code and data are available at https://github.com/CUHK-ARISE/MAS-Resilience. Lay Summary : Teams of AI â€œagentsâ€ built on large language models can solve coding, maths and translation tasks, but one carelessâ€”or maliciousâ€”agent can poison the discussion and drag down the whole team. We create two automated stress-tests: AutoTransform, which rewrites an agentâ€™s role so it secretly adds mistakes, and AutoInject, which slips errors directly into its messages. Using them, we explore how different multi-agent structures (linear chains, flat peer groups and human-like hierarchies) and different tasks suffer from these faulty agents. A hierarchical structureâ€”one â€œbossâ€ overseeing peer agentsâ€”proved most robust, losing only â‰ˆ 5% accuracy, while a simple chain collapsed by â‰ˆ 24%. Adding two simple safeguardsâ€”a â€œChallengerâ€ ability that lets agents question each other and an independent â€œInspectorâ€ reviewerâ€”recovered up to 96% of the lost performance. Our open-source toolkit lets researchers and companies quickly gauge and harden the resilience of their AI agents before deploying in the wild. Link To Code : https://github.com/CUHK-ARISE/MAS-Resilience Primary Area : Social Aspects Keywords : Multi-Agent Collaboration, Large Language Models, Resilience Flagged For Ethics Review : true Submission Number : 3634 Loading About OpenReview Hosting a Venue All Venues Contact Sponsors Donate FAQ Terms of Use / Privacy Policy News About OpenReview Hosting a Venue All Venues Sponsors News FAQ Contact Donate Terms of Use Privacy Policy OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . Â© 2025 OpenReview
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.74s
ğŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ğŸ”¬ Analyzer [1/2]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] LLMs are being widely used as decision-making agents due to their ability to interpret instructions, manage sequential tasks, and adapt through feedback.
      [2] Research is focused on how agents interact with the task environment, how agents are characterized by an LLM to behave in specific ways, how agents exchange messages and collaborate, and how agents develop their abilities to effectively solve problems.
      [3] Multi-agent systems based on LLMs are being explored, specifically focusing on the domains and environments they simulate, how these agents are profiled and how they communicate, and what mechanisms contribute to the growth of agents' capacities.
      [4] One study investigates the resilience of multi-agent collaboration in the presence of faulty agents.
      [5] A review paper examines recent developments in employing LLMs as autonomous agents and tool users, including usage of tools across knowledge grounding, web search, structured retrieval, code generation, API use, and system-level integration, as well as frameworks for building LLM agents.
   â””â”€ Decision: More research needed
   â””â”€ Next query: 2024 LLM agent system trends
ğŸ” Searcher [2]: Follow-up search for: 2024 LLM agent system trends

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://blog.langchain.com/langchain-state-of-ai-2024/
      [2] https://thenewstack.io/top-5-ai-engineering-trends-of-2024/
      [3] https://arxiv.org/html/2505.00753v1
      [4] https://www.latent.space/p/2024-agents
      [5] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
   â””â”€ Snippets:
      â€¢ In 2024, developers leaned into complexity with multi-step agents, sharpened efficiency by doing more with fewer LLM calls, and added quality checks to their apps using methods of feedback and evaluation. As more LLM apps are created, weâ€™re excited to see how folks dig into smarter workflows, better performance, and stronger reliability. [...] As we did last year, we want to share some product usage patterns that showcase how the AI ecosystem and practice of building LLM apps are evolving. As folks have traced, evaluated, and iterated their way around LangSmith, weâ€™ve seen a few notable changes. These include the dramatic rise of open-source model adoption and a shift from predominantly retrieval workflows to AI agent applications with multi-step, agentic workflows. [...] As companies are getting more serious about incorporating AI agents across various industries, adoption of our controllable agent framework, LangGraph, is also on the rise. Since its release in March 2024, LangGraph has steadily gained traction â€” with 43% of LangSmith organizations are now sending LangGraph traces. These traces represent complex, orchestrated tasks that go beyond basic LLM interactions.
      â€¢ This time last year, I wrote that AI engineering in 2023 was defined by a proliferation of LLMs and an expansion of AI dev tooling. In 2024, those trends continued â€” but also the market for both LLMs and AI development tools matured considerably. This year, AI got integrated into the core tools of developers (IDEs), while new techniques for creating â€œAI agentsâ€ arose in secondary tools like LangChain and LlamaIndex. The types of LLMs available also became more varied, with smaller models and [...] Meanwhile, in a separate presentation at the Worldâ€™s Fair, LlamaIndex creator Jerry Liu pitched agents as the natural successor to RAG (Retrieval-Augmented Generation), the most common method of integrating a pretrained LLM with an external data source. LlamaIndex calls its AI agents â€œknowledge assistants,â€ perhaps to make them more enterprise-friendly. [...] In 2024, weâ€™ve observed the maturing of AI software (especially AI coding tools for developers), a push toward more automation (AI agents), the emergence of small models and locally hosted LLMs, and some clarification on what is or isnâ€™t open source (although that debate will continue into the new year).  This year also proved that being an AI engineer is a viable career option â€” especially if you want to dive even deeper into AI than tools like GitHub Copilot or Cursor allow.
      â€¢ We define LLM-based human-agent systems as interactive frameworks where humans actively provide additional information, feedback, or control during interaction with an LLM-powered agent to enhance system performance, reliability and safety Feng et al. (2024); Shao et al. (2024); Mehta et al. (2024). The core idea is synergy: combining unique human strengthsâ€”like intuition, creativity, expertise, ethical judgment, and adaptabilityâ€”with LLM agent capabilities such as vast knowledge recall, [...] While surveys on LLM-based autonomous agents Wang et al. (2024a); Li et al. (2024a), multi-agent systems Tran et al. (2025); Wu et al. (2025), and specific applications exist Wang et al. (2025b); Peng et al. (2025), a dedicated synthesis focusing specifically on LLM-based human-agent systems is lacking. This survey fills that gap by providing a comprehensive and structured overview of the LLM-HAS. It clarifies the fundamental concepts and systematically presents its core components, emerging [...] instance, the human robot coordination in household activities Chang et al. (2024), cooperative embodied language agent (CoELA) (Zhang et al., 2024a), human designers collaborate with the LLM-based agent (Sharma et al., 2024).
ğŸ’­ Think: Query: 2024 LLM agent system trends | Found 5 results, 5 URLs. Key snippets: In 2024, developers leaned into complexity with multi-step agents, sharpened efficiency by doing mor | This time last year, I wrote that AI engineering in 2023 was defined by a proliferation of LLMs and  | We define LLM-based human-agent systems as interactive frameworks where humans actively provid. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://arxiv.org/html/2505.00753v1... (8015 chars)
ğŸ“– Read URL: https://blog.langchain.com/langchain-state-of-ai-2... (8015 chars)
ğŸ“– Read URL: https://thenewstack.io/top-5-ai-engineering-trends... (8015 chars)
   âœ“ [https://arxiv.org/html/2505.00753v1]
      Preview: A Survey on Large Language Model based Human-Agent Systems 1 Introduction 2 LLM-Based Human-Agent Systems 3 Core Components 3.1 Environment and Profiling 3.2 Human Feedback 3.3 Human-Agent Interaction Types 3.3.1 Collaboration 3.3.2 Competition 3.3.3 Coopetition 3.4 Orchestration Paradigm 3.4.1 Task Strategy 3.4.2 Temporal Synchronization 3.5 Communication 3.5.1 Communication Structure 3.5.2 Communication Mode 4 Application 5 Implementation Tools and Resources 5.1 Human-Agent Framework 5.2 Datasets and Benchmarks 6 Challenges and Opportunities 7 Conclusion A Difference with Multi-Agent Systems B Human Feedback Type and Subtype C Evaluation Metrics C.1 Quantitative Evaluation C.2 Qualitative Evaluation C.3 Mixed-Method Evaluation D Tables A Survey on Large Language Model based Human-Agent Systems Henry Peng Zou 1, * , Wei-Chieh Huang 1, * , Yaozu Wu 2, * , Yankai Chen 1, â€  , Chunyu Miao 1 , Hoang Nguyen 1 , Yue Zhou 1 , Weizhi Zhang 1 , Liancheng Fang 1 , Langzhou He 1 , Yangning Li 3 , Yuwei Cao 4 , Dongyuan Li 2 , Renhe Jiang 2 , Philip S. Yu 1, â€  1 University of Illinois Chicago, 2 The University of Tokyo, 3 Tsinghua University, 4 Google DeepMind {pzou3, whuang80, psyu}@uic.edu , yaozuwu279@gmail.com , yankaichen@acm.org Abstract Recent advances in large language models (LLMs) have sparked growing interest in building fully autonomous agents. However, fully autonomous LLM-based agents still face significant challenges, including limited reliability due to hallucinations, difficulty in handling complex tasks, and substantial safety and ethical risks, all of which limit their feasibility and trustworthiness in real-world applications. To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety. This paper provides the first comprehensive and structured survey of LLM-HAS. It clarifies fundamental concepts, systematically presents core components shaping these systems, including environment &amp; profiling, human feedback, interaction types, orchestration and communication, explores emerging applications, and discusses unique challenges and opportunities. By consolidating current knowledge and offering a structured overview, we aim to foster further research and innovation in this rapidly evolving interdisciplinary field. Paper lists and resources are available at GitHub repository . A Survey on Large Language Model based Human-Agent Systems Henry Peng Zou 1, * , Wei-Chieh Huang 1, * , Yaozu Wu 2, * , Yankai Chen 1, â€  , Chunyu Miao 1 , Hoang Nguyen 1 , Yue Zhou 1 , Weizhi Zhang 1 , Liancheng Fang 1 , Langzhou He 1 , Yangning Li 3 , Yuwei Cao 4 , Dongyuan Li 2 , Renhe Jiang 2 , Philip S. Yu 1, â€  1 University of Illinois Chicago, 2 The University of Tokyo, 3 Tsinghua University, 4 Google DeepMind {pzou3, whuang80, psyu}@uic.edu , yaozuwu279@gmail.com , yankaichen@acm.org â€  â€  âˆ— Equal Contribution. â€  Corresponding Author. 1 Introduction Recent advances in Large Language Models (LLMs) have led to growing enthusiasm for building fully autonomous agents â€” systems that use LLMs as a central engine to perceive environments, make decisions, and execute actions to achieve goals Wang et al. ( 2024a ); Li et al. ( 2024a ) . These agents are often equipped with modules for memory, planning, and tool use, aiming to automate complex workflows with minimal human involvement Xi et al. ( 2025 ) . However, the pursuit of full autonomy faces critical hurdles. (1) Reliability remains a major concern due to LLMsâ€™ propensity for hallucination â€“ generating plausible but factually incorrect or nonsensical outputs â€“ which erodes trust and can lead to significant errors, especially when actions are chained Gosmar and Dahl ( 2025 ); Xu et al. ( 2024 ) . (2) Complexity often stalls autonomous agents; they struggle with very complicated tasks requiring deep domain expertise, long multi-step execution, nuanced reas
   âœ“ [https://blog.langchain.com/langchain-state-of-ai-2024/]
      Preview: LangChain State of AI 2024 Report Skip to content Case Studies In the Loop Web Home Try LangSmith Docs Sign in Subscribe LangChain State of AI 2024 Report Dive into LangSmith product usage patterns that show how the AI ecosystem and the way people are building LLM apps is evolving. By LangChain 6 min read Dec 19, 2024 Another year of building with LLMs is coming to an end â€”&nbsp;and 2024 didnâ€™t disappoint. With nearly 30k users signing up for LangSmith every month, weâ€™re lucky to have front row seats to whatâ€™s happening in the industry.&nbsp; As we did last year , we want to share some product usage patterns that showcase how the AI&nbsp;ecosystem and practice of building LLM apps are evolving. As folks have traced, evaluated, and iterated their way around LangSmith, weâ€™ve seen a few notable changes. These include the dramatic rise of open-source model adoption and a shift from predominantly retrieval workflows to AI agent applications with multi-step, agentic workflows.&nbsp; Dive into the stats below to learn exactly what developers are building, testing, and prioritizing. Infrastructure usage With Large Language Models (LLMs) eating the world, everyoneâ€™s asking the mirror-mirror-on-the-wall question: â€œWhich model is the most utilized of them all?â€ Letâ€™s unpack what weâ€™ve seen. Top LLM providers Like last yearâ€™s results , OpenAI reigns as the most used LLM provider among LangSmith users â€”&nbsp;used more than 6x as much as Ollama, the next-most popular provider (counted by LangSmith organization usage). Interestingly, Ollama and Groq (which both allow users to run open source models, with the former focusing on local execution and the latter on cloud deployment) have accelerated in momentum this year, breaking into the top 5. This shows a growing interest in more flexible deployment options and customizable AI infrastructure. When it comes to providers that offer open-source models, the top providers have stayed relatively consistent compared to last year - Ollama, Mistral, and Hugging Face have made it easy for developers to run open source models on their platforms. These OSS providersâ€™ collective usage represents 20% of the top 20 LLM providers (by the number of organizations using them).&nbsp; Top Retrievers / Vector Stores Performing retrieval is still critical for many GenAI workflows. The top 3 vector stores have remained the same as last year, with Chroma and FAISS as the most popular choices. This year, Milvus, MongoDB, and Elasticâ€™s vector databases have also entered the top 10.&nbsp; Building with LangChain products As developers have gained more experience utilizing generative AI, they are also building more dynamic applications. From the growing sophistication of workflows, to the rise of AI agents â€” weâ€™re seeing a few trends that point to an evolving ecosystem of innovation. Observability isnâ€™t limited to LangChain applications While langchain (our open source framework) is central to many folksâ€™ LLM app development journeys, 15.7% of LangSmith traces this year come from non- langchain frameworks. This reflects a broader trend where observability is needed regardless of what framework youâ€™re using to build the LLM app â€” and that interoperability is supported by LangSmith. Python remains dominant, while JavaScript usage grows Debugging, testing, and monitoring certainly has a special place in our Python developersâ€™ hearts, with 84.7% usage coming from the Python SDK. But there is a notable and growing interest in JavaScript as developers pursue web-first applications â€”&nbsp;the JavaScript SDK accounts for 15.3% of LangSmith usage this year, increasing 3x compared to the previous year.&nbsp; AI agents are gaining traction As companies are getting more serious about incorporating AI agents across various industries , adoption of our controllable agent framework, LangGraph, is also on the rise. Since its release in March 2024, LangGraph has steadily gained traction â€”&nbsp;with 43% of LangSmith organizations are now 
   âœ“ [https://thenewstack.io/top-5-ai-engineering-trends-of-2024/]
      Preview: Top 5 AI Engineering Trends of 2024 - The New Stack TNS OK SUBSCRIBE Join our community of software engineering leaders and aspirational developers. Always stay in-the-know by getting the most important news and exclusive content delivered fresh to your inbox to learn more about at-scale software development. EMAIL ADDRESS REQUIRED SUBSCRIBE RESUBSCRIPTION REQUIRED &nbsp; It seems that you've previously unsubscribed from our newsletter in the past. Click the button below to open the re-subscribe form in a new tab. When you're done, simply close that tab and continue with this form to complete your subscription. RE-SUBSCRIBE The New Stack does not sell your information or share it with unaffiliated third parties. By continuing, you agree to our Terms of Use and Privacy Policy . Welcome and thank you for joining The New Stack community! Please answer a few simple questions to help us deliver the news and resources you are interested in. FIRST NAME REQUIRED LAST NAME REQUIRED COMPANY NAME REQUIRED COUNTRY REQUIRED Select ... United States Canada India United Kingdom Germany France --- Afghanistan Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and Barbuda Argentina Armenia Aruba Asia/Pacific Region Australia Austria Azerbaijan Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bonaire, Sint Eustatius and Saba Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory Brunei Darussalam Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Chile China Christmas Island Cocos (Keeling) Islands Colombia Comoros Congo Congo, The Democratic Republic of the Cook Islands Costa Rica Croatia Cuba CuraÃ§ao Cyprus Czech Republic CÃ´te d'Ivoire Denmark Djibouti Dominica Dominican Republic Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Ethiopia Falkland Islands (Malvinas) Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern Territories Gabon Gambia Georgia Germany Ghana Gibraltar Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-Bissau Guyana Haiti Heard Island and Mcdonald Islands Holy See (Vatican City State) Honduras Hong Kong Hungary Iceland India Indonesia Iran, Islamic Republic Of Iraq Ireland Isle of Man Israel Italy Jamaica Japan Jersey Jordan Kazakhstan Kenya Kiribati Korea, Republic of Kuwait Kyrgyzstan Laos Latvia Lebanon Lesotho Liberia Libyan Arab Jamahiriya Liechtenstein Lithuania Luxembourg Macao Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia, Federated States of Moldova, Republic of Monaco Mongolia Montenegro Montserrat Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands Netherlands Antilles New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island North Korea North Macedonia Northern Mariana Islands Norway Oman Pakistan Palau Palestinian Territory, Occupied Panama Papua New Guinea Paraguay Peru Philippines Pitcairn Islands Poland Portugal Puerto Rico Qatar Reunion Romania Russian Federation Rwanda Saint BarthÃ©lemy Saint Helena Saint Kitts and Nevis Saint Lucia Saint Martin Saint Martin Saint Pierre and Miquelon Saint Vincent and the Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia Serbia and Montenegro Seychelles Sierra Leone Singapore Sint Maarten Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia and the South Sandwich Islands South Sudan Spain Sri Lanka Sudan Suriname Svalbard and Jan Mayen Swaziland Sweden Switzerland Syrian Arab Republic Taiwan Tajikistan Tanzania, United Republic of Thailand Timor-Leste Togo Tokelau Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu Uganda Ukraine United Arab Emirates United Kingdom United States United States Minor Outlying Islands Uruguay Uzbekistan Vanuatu Venezuela Vietnam Virgin Islands, British Virgin Isla
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.94s
ğŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ğŸ”¬ Analyzer: Max iterations reached (2), proceeding to Writer

ğŸ”¬ Analyzer [2/2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] In 2024, there's a trend toward more complex multi-step agents, increased efficiency in LLM call usage, and the incorporation of quality checks through feedback and evaluation methods.
      [2] AI is increasingly integrated into developer tools, with new AI agent creation techniques emerging in tools like LangChain and LlamaIndex.
      [3] LLM-based human-agent systems combine human strengths with LLM capabilities to enhance system performance, reliability, and safety.
      [4] Every large LM trainer will be focusing on training models as agents, leading to increased competition, lower prices, and competitive smaller models by mid-2025.
      [5] Many agent implementations use LLMs as orchestrators, calling existing APIs as tools to streamline processes.
   â””â”€ Decision: Research complete (11 total findings)
   â””â”€ âœ… Research Subgraph completed (execution #1)
   â””â”€ Findings: 11 items
   â””â”€ Contents: 6 URLs read

ğŸ“¦ Compress: Compressing 11 findings, 6 contents
   â””â”€ Compressed to 2608 chars (from ~5851 raw chars)
   â””â”€ Sources cited: 6
   â””â”€ Preview:
      ## Key Findings
      - LLMs are increasingly used as decision-making agents due to their instruction interpretation, task management, and adaptability [1].
      - Research focuses on agent interaction, characterization, communication, and ability development within task environments [1].
      - Multi-agent systems based on LLMs are being explored, focusing on simulated domains, agent profiles, communication, and mechanisms that enhance agent capacities [1].
      - Trends in 2024 include more complex multi-step agents, increased efficiency in LLM call usage, and the incorporation of quality checks [3].
      - Human-agent systems combine human strengths with LLM capabilities to improve system performance, reliability, and safety [5].
      
      ## Detailed Information
      
      - **LLMs as Agents:** LLMs are widely adopted as decision-making agents, capable of interpreting instructions, managing sequential tasks, and adapting through feedback [1]. Many agent implementations use LLMs as orchestrators, calling existing APIs as tools to streamline processes [1].
      - **Multi-Agent Systems:** Research explores multi-agent systems based on LLMs, focusing on the simulated environments, agent profiling and communication strategies, and mechanisms contributing to agent capacity growth [1]. Studies also investigate the resilience of multi-agent collaboration in the presence of faulty agents [2].
      - **Human-Agent Systems:** LLM-based human-agent systems integrate human strengths with LLM capabilities to enhance system performance, reliability, and safety [5]. These systems involve various components like environment profiling, human feedback, interaction types (collaboration, competition, coopetition), orchestration paradigms, and communication structures [5].
      - **Tool Usage:** LLMs are used as autonomous agents and tool users, leveraging tools across knowledge grounding, web search, structured retrieval, code generation, API use, and system-level integration [1]. Frameworks are being developed to facilitate the building of LLM agents [1].
      - **2024 Trends:** In 2024, trends indicate a move towards more complex multi-step agents, increased efficiency in LLM call usage, and the incorporation of quality checks through feedback and evaluation methods [3]. AI is also being increasingly integrated into developer tools, with new AI agent creation techniques emerging [3].
      
      ## Sources
      [1] https://arxiv.org/html/2508.17281v1
      [2] https://openreview.net/forum?id=bkiM54QftZ
      [3] https://blog.langchain.com/langchain-state-of-ai-2024/
      [4] https://thenewstack.io/top-5-ai-engineering-trends-of-2024/
      [5] https://arxiv.org/html/2505.00753v1

âœï¸ Writer: Composing response from 11 findings
   â””â”€ Using compressed notes (2608 chars)

âœï¸ Writer: Generated response (3243 chars)
   â””â”€ Sources used:
      [1] https://arxiv.org/html/2508.17281v1
      [2] https://openreview.net/forum?id=bkiM54QftZ
      [3] https://blog.langchain.com/langchain-state-of-ai-2024/
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      
      2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ ì˜ì‚¬ ê²°ì • ëŠ¥ë ¥ í™œìš©, ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë°œì „, ê·¸ë¦¬ê³  ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ í†µí•©ì— ì§‘ì¤‘í•˜ê³  ìˆìœ¼ë©°, ë³µì¡í•œ ë©€í‹° ìŠ¤í… ì—ì´ì „íŠ¸ ê°œë°œ, LLM í˜¸ì¶œ íš¨ìœ¨ì„± ì¦ëŒ€, í’ˆì§ˆ ê²€ì‚¬ ë„ì…ì´ ì£¼ìš” íŠ¸ë Œë“œì…ë‹ˆë‹¤.
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   LLMì€ ëª…ë ¹ì–´ í•´ì„, ì‘ì—… ê´€ë¦¬, ì ì‘ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ì‚¬ ê²°ì • ì—ì´ì „íŠ¸ë¡œ ê´‘ë²”ìœ„í•˜ê²Œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤ [1].
      *   ì—°êµ¬ëŠ” ì‘ì—… í™˜ê²½ ë‚´ì—ì„œ ì—ì´ì „íŠ¸ ìƒí˜¸ ì‘ìš©, íŠ¹ì„± ë¶„ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ëŠ¥ë ¥ ê°œë°œì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤ [1].
      *   LLM ê¸°ë°˜ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½, ì—ì´ì „íŠ¸ í”„ë¡œíŒŒì¼ë§, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ì—ì´ì „íŠ¸ ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•œ ë©”ì»¤ë‹ˆì¦˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ íƒêµ¬ë˜ê³  ìˆìŠµë‹ˆë‹¤ [1].
      *   2024ë…„ íŠ¸ë Œë“œëŠ” ë”ìš± ë³µì¡í•œ ë©€í‹° ìŠ¤í… ì—ì´ì „íŠ¸, LLM í˜¸ì¶œ ì‚¬ìš©ì˜ íš¨ìœ¨ì„± ì¦ëŒ€, í’ˆì§ˆ ê²€ì‚¬ í†µí•©ì„ í¬í•¨í•©ë‹ˆë‹¤ [3].
      *   ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì¸ê°„ì˜ ê°•ì ê³¼ LLMì˜ ëŠ¥ë ¥ì„ ê²°í•©í•˜ì—¬ ì‹œìŠ¤í…œ ì„±ëŠ¥, ì‹ ë¢°ì„±, ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤ [5].
      
      ## ìƒì„¸ ë¶„ì„
      
      **LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ì˜ ì—­í•  í™•ëŒ€:**
      
      LLMì€ ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì„ ë„˜ì–´, ì§€ì‹œ ì‚¬í•­ì„ ì´í•´í•˜ê³ , ìˆœì°¨ì ì¸ ì‘ì—…ì„ ê´€ë¦¬í•˜ë©°, í”¼ë“œë°±ì„ í†µí•´ ìŠ¤ìŠ¤ë¡œ ì ì‘í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶˜ ì˜ì‚¬ ê²°ì • ì—ì´ì „íŠ¸ë¡œì„œ ìë¦¬ë§¤ê¹€í•˜ê³  ìˆìŠµë‹ˆë‹¤ [1]. ë§ì€ ì—ì´ì „íŠ¸ êµ¬í˜„ì²´ë“¤ì´ LLMì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œ í™œìš©í•˜ì—¬ ê¸°ì¡´ APIë¥¼ ë„êµ¬ë¡œ í˜¸ì¶œí•¨ìœ¼ë¡œì¨ í”„ë¡œì„¸ìŠ¤ë¥¼ íš¨ìœ¨í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤ [1]. ì´ëŠ” LLMì´ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ 'ë‘ë‡Œ' ì—­í• ì„ ìˆ˜í–‰í•˜ë©°, ì™¸ë¶€ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ í–‰ë™ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—¬í–‰ ê³„íš ì—ì´ì „íŠ¸ëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³ , í•­ê³µí¸ ê²€ìƒ‰ API, í˜¸í…” ì˜ˆì•½ API ë“±ì„ í˜¸ì¶œí•˜ì—¬ ìµœì ì˜ ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      
      **ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì§„í™”:**
      
      LLM ê¸°ë°˜ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ êµ¬ì¶•, ì—ì´ì „íŠ¸ í”„ë¡œíŒŒì¼ë§ ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ ê°œë°œ, ì—ì´ì „íŠ¸ ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•œ ë©”ì»¤ë‹ˆì¦˜ ì—°êµ¬ì— ì§‘ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤ [1]. íŠ¹íˆ, ê³ ì¥ë‚œ ì—ì´ì „íŠ¸ê°€ ì¡´ì¬í•  ë•Œ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—…ì˜ ë³µì›ë ¥ì„ ë¶„ì„í•˜ëŠ” ì—°êµ¬ëŠ” ì‹¤ì œ ì‹œìŠ¤í…œ ìš´ì˜ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤ [2]. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í™˜ê²½ì—ì„œ ê° ì—ì´ì „íŠ¸ì˜ ì—­í•  ì •ì˜, ìƒí˜¸ ì‘ìš© ë°©ì‹, ê·¸ë¦¬ê³  í˜‘ì—… ê³¼ì •ì—ì„œì˜ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ ì‹œìŠ¤í…œ ì „ì²´ì˜ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì¬ë‚œ ìƒí™© ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ê° ì—ì´ì „íŠ¸ëŠ” ì†Œë°©ê´€, ê²½ì°°ê´€, ì˜ë£Œì§„ ë“±ì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ë©°, ì„œë¡œ ì •ë³´ë¥¼ ê³µìœ í•˜ê³  í˜‘ë ¥í•˜ì—¬ íš¨ìœ¨ì ì¸ êµ¬ì¡° í™œë™ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      
      **ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì‹œë„ˆì§€ íš¨ê³¼:**
      
      LLM ê¸°ë°˜ì˜ ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì¸ê°„ì˜ ì§ê´€, ì°½ì˜ì„±, ìœ¤ë¦¬ì  íŒë‹¨ ëŠ¥ë ¥ê³¼ LLMì˜ ì •ë³´ ì²˜ë¦¬ ëŠ¥ë ¥, ìë™í™” ëŠ¥ë ¥, í™•ì¥ì„±ì„ ê²°í•©í•˜ì—¬ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤ [5]. í™˜ê²½ í”„ë¡œíŒŒì¼ë§, ì¸ê°„ í”¼ë“œë°± í™œìš©, í˜‘ì—…/ê²½ìŸ/ê³µìƒ ë“±ì˜ ë‹¤ì–‘í•œ ìƒí˜¸ ì‘ìš© ìœ í˜•, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨ëŸ¬ë‹¤ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ êµ¬ì¡° ë“± ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œë¥¼ í†µí•´ ì¸ê°„ê³¼ ì—ì´ì „íŠ¸ ê°„ì˜ íš¨ê³¼ì ì¸ í˜‘ë ¥ì„ ì§€ì›í•©ë‹ˆë‹¤ [5]. ì´ëŠ” ë³µì¡í•˜ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ìƒí™©ì—ì„œ ì¸ê°„ì˜ íŒë‹¨ë ¥ì„ ë³´ì¡°í•˜ê³ , ë°˜ë³µì ì´ê³  ì§€ë£¨í•œ ì‘ì—…ì„ ìë™í™”í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì˜ë£Œ ì§„ë‹¨ ì‹œìŠ¤í…œì—ì„œ LLMì€ í™˜ìì˜ ì¦ìƒì„ ë¶„ì„í•˜ê³  ê°€ëŠ¥ì„± ìˆëŠ” ì§ˆë³‘ ëª©ë¡ì„ ì œì‹œí•˜ë©°, ì˜ì‚¬ëŠ” LLMì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì§„ë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      
      **2024ë…„ ì£¼ìš” íŠ¸ë Œë“œ:**
      
      2024ë…„ì—ëŠ” ë”ìš± ë³µì¡í•œ ë©€í‹° ìŠ¤í… ì—ì´ì „íŠ¸ ê°œë°œ, LLM í˜¸ì¶œ ì‚¬ìš©ì˜ íš¨ìœ¨ì„± ì¦ëŒ€, í’ˆì§ˆ ê²€ì‚¬ í†µí•©ì´ ì£¼ìš” íŠ¸ë Œë“œë¡œ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤ [3]. ì´ëŠ” ë‹¨ìˆœíˆ ëª…ë ¹ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë„˜ì–´, ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê³ , ë¹„ìš© íš¨ìœ¨ì ì¸ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•˜ë©°, ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì—ì´ì „íŠ¸ì— ëŒ€í•œ ìš”êµ¬ê°€ ì¦ê°€í•˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, AIê°€ ê°œë°œì ë„êµ¬ì— í†µí•©ë˜ì–´ ìƒˆë¡œìš´ AI ì—ì´ì „íŠ¸ ìƒì„± ê¸°ìˆ ì´ ë“±ì¥í•˜ê³  ìˆë‹¤ëŠ” ì ì€ AI ì—ì´ì „íŠ¸ ê°œë°œì˜ ì§„ì… ì¥ë²½ì„ ë‚®ì¶”ê³ , ë” ë§ì€ ê°œë°œìë“¤ì´ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ ì¥ë ¤í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤ [3].
      
      ## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜
      
      *   [1] LLM as decision-making agents, agent interaction, characterization, communication, and ability development within task environments: https://arxiv.org/html/2508.17281v1
      *   [2] Resilience of multi-agent collaboration in the presence of faulty agents: https://openreview.net/forum?id=bkiM54QftZ
      *   [3] 2024 Trends: complex multi-step agents, increased efficiency in LLM call usage, quality checks: https://blog.langchain.com/langchain-state-of-ai-2024/
      *   [4] (ì¶”ê°€ ìë£Œ) AI Engineering Trends of 2024: https://thenewstack.io/top-5-ai-engineering-trends-of-2024/
      *   [5] Human-Agent Systems: https://arxiv.org/html/2505.00753v1
      
      ## ê²°ë¡  ë° í‰ê°€
      
      2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ í™œìš© ë²”ìœ„ë¥¼ ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìƒì„±ì—ì„œ ì˜ì‚¬ ê²°ì •, í˜‘ì—…, ì¸ê°„ê³¼ì˜ í˜‘ë ¥ìœ¼ë¡œ í™•ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ LLMì˜ ì ì¬ë ¥ì„ ê·¹ëŒ€í™”í•˜ê³ , ì‹¤ì œ ë¬¸ì œ í•´ê²°ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
      
      í–¥í›„ ì—°êµ¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì§„í–‰ë  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.
      
      *   **ì—ì´ì „íŠ¸ì˜ ìœ¤ë¦¬ì  ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ ê°•í™”:** LLM ì—ì´ì „íŠ¸ê°€ ì‚¬íšŒì  í¸ê²¬ì„ í•™ìŠµí•˜ê±°ë‚˜, ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
      *   **ì—ì´ì „íŠ¸ì˜ ì„¤ëª… ê°€ëŠ¥ì„± í–¥ìƒ:** ì—ì´ì „íŠ¸ê°€ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê³¼ì •ì„ íˆ¬ëª…í•˜ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì—°êµ¬ëŠ” ì‚¬ìš©ìì˜ ì‹ ë¢°ë¥¼ ë†’ì´ê³ , ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ì¸ì„ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
      *   **ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„± íƒìƒ‰:** LLM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì˜ë£Œ, êµìœ¡, ê¸ˆìœµ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©í•˜ì—¬ ì‹¤ì œ íš¨ìš©ì„±ì„ ê²€ì¦í•˜ê³ , ê°œì„ ì ì„ ë°œêµ´í•´ì•¼ í•©ë‹ˆë‹¤.

ğŸ” Critique: CARC Quality Evaluation...
   â””â”€ CARC Scores: C=4.0 A=3.5 R=4.2 C=4.0
   â””â”€ Total: 15.7/20 ğŸ‘ Good
   â””â”€ Feedback: The response provides a good overview of the trends in LLM-based agent systems research in 2024. However, it could benefit from more concrete examples and a more critical evaluation of the cited sources. Some of the sources appear to be preprints (arxiv.org), which, while potentially relevant, require careful scrutiny. The completeness is slightly affected by the abrupt ending of the 'í–¥í›„ ì—°êµ¬' section.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 9 Fixed Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´ì¤˜...
â”‚ Time: 34.19s
â”‚ LLM Calls: 2
â”‚ Search Calls: 0
â”‚ URLs Read: 6
â”‚ Iterations: 2
â”‚ Est. Tokens: 1323
â”‚ Response Length: 3243 chars
â”‚ Has Citations: âœ…
â”‚ CARC Quality: C=4.0 A=3.5 R=4.2 C=4.0 â†’ 15.7/20 ğŸ‘ Good
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ğŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½

2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ ì˜ì‚¬ ê²°ì • ëŠ¥ë ¥ í™œìš©, ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë°œì „, ê·¸ë¦¬ê³  ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ í†µí•©ì— ì§‘ì¤‘í•˜ê³  ìˆìœ¼ë©°, ë³µì¡í•œ ë©€í‹° ìŠ¤í… ì—ì´ì „íŠ¸ ê°œë°œ, LLM í˜¸ì¶œ íš¨ìœ¨ì„± ì¦ëŒ€, í’ˆì§ˆ ê²€ì‚¬ ë„ì…ì´ ì£¼ìš” íŠ¸ë Œë“œì…ë‹ˆë‹¤.

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   LLMì€ ëª…ë ¹ì–´ í•´ì„, ì‘ì—… ê´€ë¦¬, ì ì‘ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ì‚¬ ê²°ì • ì—ì´ì „íŠ¸ë¡œ ê´‘ë²”ìœ„í•˜ê²Œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤ [1].
*   ì—°êµ¬ëŠ” ì‘ì—… í™˜ê²½ ë‚´ì—ì„œ ì—ì´ì „íŠ¸ ìƒí˜¸ ì‘ìš©, íŠ¹ì„± ë¶„ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ëŠ¥ë ¥ ê°œë°œì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤ [1].
*   LLM ê¸°ë°˜ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½, ì—ì´ì „íŠ¸ í”„ë¡œíŒŒì¼ë§, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ì—ì´ì „íŠ¸ ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•œ ë©”ì»¤ë‹ˆì¦˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ íƒêµ¬ë˜ê³  ìˆìŠµë‹ˆë‹¤ [1].
*   2024ë…„ íŠ¸ë Œë“œëŠ” ë”ìš± ë³µì¡í•œ ë©€í‹° ìŠ¤í… ì—ì´ì „íŠ¸, LLM í˜¸ì¶œ ì‚¬ìš©ì˜ íš¨ìœ¨ì„± ì¦ëŒ€, í’ˆì§ˆ ê²€ì‚¬ í†µí•©ì„ í¬í•¨í•©ë‹ˆë‹¤ [3].
*   ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì¸ê°„ì˜ ê°•ì ê³¼ LLMì˜ ëŠ¥ë ¥ì„ ê²°í•©í•˜ì—¬ ì‹œìŠ¤í…œ ì„±ëŠ¥, ì‹ ë¢°ì„±, ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤ [5].

## ìƒì„¸ ë¶„ì„

**LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ì˜ ì—­í•  í™•ëŒ€:**

LLMì€ ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì„ ë„˜ì–´, ì§€ì‹œ ì‚¬í•­ì„ ì´í•´í•˜ê³ , ìˆœì°¨ì ì¸ ì‘ì—…ì„ ê´€ë¦¬í•˜ë©°, í”¼ë“œë°±ì„ í†µí•´ ìŠ¤ìŠ¤ë¡œ ì ì‘í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶˜ ì˜ì‚¬ ê²°ì • ì—ì´ì „íŠ¸ë¡œì„œ ìë¦¬ë§¤ê¹€í•˜ê³  ìˆìŠµë‹ˆë‹¤ [1]. ë§ì€ ì—ì´ì „íŠ¸ êµ¬í˜„ì²´ë“¤ì´ LLMì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œ í™œìš©í•˜ì—¬ ê¸°ì¡´ APIë¥¼ ë„êµ¬ë¡œ í˜¸ì¶œí•¨ìœ¼ë¡œì¨ í”„ë¡œì„¸ìŠ¤ë¥¼ íš¨ìœ¨í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤ [1]. ì´ëŠ” LLMì´ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ 'ë‘ë‡Œ' ì—­í• ì„ ìˆ˜í–‰í•˜ë©°, ì™¸ë¶€ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ í–‰ë™ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—¬í–‰ ê³„íš ì—ì´ì „íŠ¸ëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³ , í•­ê³µí¸ ê²€ìƒ‰ API, í˜¸í…” ì˜ˆì•½ API ë“±ì„ í˜¸ì¶œí•˜ì—¬ ìµœì ì˜ ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì§„í™”:**

LLM ê¸°ë°˜ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ êµ¬ì¶•, ì—ì´ì „íŠ¸ í”„ë¡œíŒŒì¼ë§ ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ ê°œë°œ, ì—ì´ì „íŠ¸ ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•œ ë©”ì»¤ë‹ˆì¦˜ ì—°êµ¬ì— ì§‘ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤ [1]. íŠ¹íˆ, ê³ ì¥ë‚œ ì—ì´ì „íŠ¸ê°€ ì¡´ì¬í•  ë•Œ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—…ì˜ ë³µì›ë ¥ì„ ë¶„ì„í•˜ëŠ” ì—°êµ¬ëŠ” ì‹¤ì œ ì‹œìŠ¤í…œ ìš´ì˜ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤ [2]. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í™˜ê²½ì—ì„œ ê° ì—ì´ì „íŠ¸ì˜ ì—­í•  ì •ì˜, ìƒí˜¸ ì‘ìš© ë°©ì‹, ê·¸ë¦¬ê³  í˜‘ì—… ê³¼ì •ì—ì„œì˜ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ ì‹œìŠ¤í…œ ì „ì²´ì˜ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì¬ë‚œ ìƒí™© ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ê° ì—ì´ì „íŠ¸ëŠ” ì†Œë°©ê´€, ê²½ì°°ê´€, ì˜ë£Œì§„ ë“±ì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ë©°, ì„œë¡œ ì •ë³´ë¥¼ ê³µìœ í•˜ê³  í˜‘ë ¥í•˜ì—¬ íš¨ìœ¨ì ì¸ êµ¬ì¡° í™œë™ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì‹œë„ˆì§€ íš¨ê³¼:**

LLM ê¸°ë°˜ì˜ ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì¸ê°„ì˜ ì§ê´€, ì°½ì˜ì„±, ìœ¤ë¦¬ì  íŒë‹¨ ëŠ¥ë ¥ê³¼ LLMì˜ ì •ë³´ ì²˜ë¦¬ ëŠ¥ë ¥, ìë™í™” ëŠ¥ë ¥, í™•ì¥ì„±ì„ ê²°í•©í•˜ì—¬ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤ [5]. í™˜ê²½ í”„ë¡œíŒŒì¼ë§, ì¸ê°„ í”¼ë“œë°± í™œìš©, í˜‘ì—…/ê²½ìŸ/ê³µìƒ ë“±ì˜ ë‹¤ì–‘í•œ ìƒí˜¸ ì‘ìš© ìœ í˜•, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨ëŸ¬ë‹¤ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ êµ¬ì¡° ë“± ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œë¥¼ í†µí•´ ì¸ê°„ê³¼ ì—ì´ì „íŠ¸ ê°„ì˜ íš¨ê³¼ì ì¸ í˜‘ë ¥ì„ ì§€ì›í•©ë‹ˆë‹¤ [5]. ì´ëŠ” ë³µì¡í•˜ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ìƒí™©ì—ì„œ ì¸ê°„ì˜ íŒë‹¨ë ¥ì„ ë³´ì¡°í•˜ê³ , ë°˜ë³µì ì´ê³  ì§€ë£¨í•œ ì‘ì—…ì„ ìë™í™”í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì˜ë£Œ ì§„ë‹¨ ì‹œìŠ¤í…œì—ì„œ LLMì€ í™˜ìì˜ ì¦ìƒì„ ë¶„ì„í•˜ê³  ê°€ëŠ¥ì„± ìˆëŠ” ì§ˆë³‘ ëª©ë¡ì„ ì œì‹œí•˜ë©°, ì˜ì‚¬ëŠ” LLMì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì§„ë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**2024ë…„ ì£¼ìš” íŠ¸ë Œë“œ:**

2024ë…„ì—ëŠ” ë”ìš± ë³µì¡í•œ ë©€í‹° ìŠ¤í… ì—ì´ì „íŠ¸ ê°œë°œ, LLM í˜¸ì¶œ ì‚¬ìš©ì˜ íš¨ìœ¨ì„± ì¦ëŒ€, í’ˆì§ˆ ê²€ì‚¬ í†µí•©ì´ ì£¼ìš” íŠ¸ë Œë“œë¡œ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤ [3]. ì´ëŠ” ë‹¨ìˆœíˆ ëª…ë ¹ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë„˜ì–´, ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê³ , ë¹„ìš© íš¨ìœ¨ì ì¸ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•˜ë©°, ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì—ì´ì „íŠ¸ì— ëŒ€í•œ ìš”êµ¬ê°€ ì¦ê°€í•˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, AIê°€ ê°œë°œì ë„êµ¬ì— í†µí•©ë˜ì–´ ìƒˆë¡œìš´ AI ì—ì´ì „íŠ¸ ìƒì„± ê¸°ìˆ ì´ ë“±ì¥í•˜ê³  ìˆë‹¤ëŠ” ì ì€ AI ì—ì´ì „íŠ¸ ê°œë°œì˜ ì§„ì… ì¥ë²½ì„ ë‚®ì¶”ê³ , ë” ë§ì€ ê°œë°œìë“¤ì´ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ ì¥ë ¤í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤ [3].

## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜

*   [1] LLM as decision-making agents, agent interaction, characterization, communication, and ability development within task environments: https://arxiv.org/html/2508.17281v1
*   [2] Resilience of multi-agent collaboration in the presence of faulty agents: https://openreview.net/forum?id=bkiM54QftZ
*   [3] 2024 Trends: complex multi-step agents, increased efficiency in LLM call usage, quality checks: https://blog.langchain.com/langchain-state-of-ai-2024/
*   [4] (ì¶”ê°€ ìë£Œ) AI Engineering Trends of 2024: https://thenewstack.io/top-5-ai-engineering-trends-of-2024/
*   [5] Human-Agent Systems: https://arxiv.org/html/2505.00753v1

## ê²°ë¡  ë° í‰ê°€

2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ í™œìš© ë²”ìœ„ë¥¼ ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìƒì„±ì—ì„œ ì˜ì‚¬ ê²°ì •, í˜‘ì—…, ì¸ê°„ê³¼ì˜ í˜‘ë ¥ìœ¼ë¡œ í™•ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ì¸ê°„-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ LLMì˜ ì ì¬ë ¥ì„ ê·¹ëŒ€í™”í•˜ê³ , ì‹¤ì œ ë¬¸ì œ í•´ê²°ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

í–¥í›„ ì—°êµ¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì§„í–‰ë  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.

*   **ì—ì´ì „íŠ¸ì˜ ìœ¤ë¦¬ì  ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ ê°•í™”:** LLM ì—ì´ì „íŠ¸ê°€ ì‚¬íšŒì  í¸ê²¬ì„ í•™ìŠµí•˜ê±°ë‚˜, ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
*   **ì—ì´ì „íŠ¸ì˜ ì„¤ëª… ê°€ëŠ¥ì„± í–¥ìƒ:** ì—ì´ì „íŠ¸ê°€ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê³¼ì •ì„ íˆ¬ëª…í•˜ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì—°êµ¬ëŠ” ì‚¬ìš©ìì˜ ì‹ ë¢°ë¥¼ ë†’ì´ê³ , ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ì¸ì„ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
*   **ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„± íƒìƒ‰:** LLM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì˜ë£Œ, êµìœ¡, ê¸ˆìœµ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©í•˜ì—¬ ì‹¤ì œ íš¨ìš©ì„±ì„ ê²€ì¦í•˜ê³ , ê°œì„ ì ì„ ë°œêµ´í•´ì•¼ í•©ë‹ˆë‹¤.
======================================================================


ğŸ“Š Running benchmark: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜...

ğŸ” Clarify: Analyzing query...
   â””â”€ Query: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ê³¼ ê°ê° ì–¸ì œ ì‚¬ìš©í•˜ë©´ ì¢‹ì€ì§€ ì„¤ëª…í•´ì¤˜
   â””â”€ Status: ğŸŸ¢ Clear
   â””â”€ Analysis: The query asks for a comparison between Retrieval-Augmented Generation (RAG) and Agent-based approaches, including when each approach is most suitable. The intent is clear: the user wants a comparison and guidance on when to use each method.
   â””â”€ Topics: Retrieval-Augmented Generation, Agent-based approach
ğŸ“‹ Planner: Creating research plan for: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜

ğŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] RAG vs Agent based approach
      [2] Retrieval Augmented Generation vs Agent
      [3] When to use RAG vs Agent
      [4] Advantages and disadvantages of RAG and Agent based systems
   â””â”€ Focus: RAG architecture and use cases, Agent based system architecture and use cases, Comparison of RAG and Agent based approaches, Trade-offs in selecting RAG vs Agent based systems

ğŸ¯ Supervisor [Phase 9]: Analyzing query complexity
   â””â”€ Query: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ê³¼ ê°ê° ì–¸ì œ ì‚¬ìš©í•˜ë©´ ì¢‹ì€ì§€ ì„¤ëª…í•´ì¤˜
   â””â”€ Planned queries: 4
   â””â”€ Complexity: ğŸŸ¡ MEDIUM
   â””â”€ Recommended: 2 iterations, depth 2
   â””â”€ Strategy: targeted
   â””â”€ Reasoning: The query requires comparing two different approaches (RAG and Agent-based), analyzing their differences, and determining appropriate use cases for each. This necessitates a medium level of research to gather sufficient information for comparison and analysis. The current plan with depth 2 is appropriate.

ğŸ”¬ Research Subgraph: Starting research loop...
   â””â”€ Supervisor config: MEDIUM, max 2 iterations, targeted strategy
ğŸ” Searcher [1]: Searching for: RAG vs Agent based approach

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems
      [2] https://azumo.com/artificial-intelligence/ai-insights/agentic-rag
      [3] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [4] https://www.fluid.ai/blog/agentic-rag-vs-traditional-rag-the-future-of-ai-decision-making
      [5] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
   â””â”€ Snippets:
      â€¢ Agents Using RAG: Agents that leverage RAG for informed decision-making enhance their ability to act based on comprehensive, up-to-date information. \  RAG with Agent-like Capabilities: RAG systems might incorporate simple agent behaviors, like adaptive retrieval or multi-step query processing. \  Hybrid Systems: Systems that can switch between RAG and agent modes depending on task requirements. \ [...] Purpose: RAG focuses on information retrieval and knowledge enhancement, while agents aim at task completion and action execution.  Operation Mode: RAG operates in a single pass for information lookup and response, whereas agents engage in multi-step, iterative processes.  State Management: RAG is generally stateless, focusing on the current query, while agents maintain state and context across interactions. [...] Understanding the differences and synergies between RAG and agent-based systems is vital for crafting effective AI solutions. RAG excels in providing informed, context-rich responses, while agents are superior for action-oriented tasks and maintaining operational context. The future of AI seems to lean towards hybrid models that harness the strengths of both, leading to more adaptive, intelligent, and efficient systems. This convergence is not just a trend but a necessity for tackling the
      â€¢ Agentic RAG represents a groundbreaking shift from traditional Retrieval-Augmented Generation (RAG) by introducing intelligent AI agents capable of multi-step reasoning, real-time decision-making, and information validation. While traditional RAG systems can only search and retrieve data, Agentic RAG systems enable AI to reason through problems, select the right data sources, and refine answers dynamically. This development is poised to transform industries that require complex decision-making, [...] According to IBM, Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. Think of it this way: traditional RAG is like having a brilliant librarian who can find any book you need. Agentic RAG? That's like having a whole research team that not only finds the books but also reads them, cross-references them, validates the information, and then comes back to you with exactly what you need to know. [...] The beauty of agentic RAG design is the flexibility. In its simplest form, agentic RAG is a router. You have at least two external knowledge sources, and the agent decides which to retrieve more context from. But for more complex scenarios? You can have a high-level master agent responsible for information retrieval by many specialist retrieval agents. It is comparable to having a project manager overseeing a team of specialists.
      â€¢ RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant, context-aware information. Traditional RAG improves LLMs by connecting them to external data sources, while Agentic RAG goes a step further by adding intelligent agents that handle decisions and complex tasks. If the task is simple and query-based, traditional RAG is enough. However, for more complex, multi-step processes, Agentic RAG offers more flexibility, adaptability, and accuracy. As AI [...] Agentic RAG is an evolution of the traditional RAG system. While RAG systems combine retrieval with generation, Agentic RAG introduces agents that play a more active role in the process. These agents are intelligent entities that make decisions about which resources to retrieve, how to process the data, and how to generate the response. In Agentic RAG, the agent orchestrates the entire process, enabling more complex, multi-step tasks that require deeper reasoning, tool integration, and informed [...] Traditional RAG relies on a single retrieval system, such as a vector database, to retrieve relevant information.  Agentic RAG, however, is deeply integrated with multiple retrieval systems, and the agents dynamically choose which system to use based on the context and complexity of the query.  ### Context-Awareness:
ğŸ’­ Think: Query: RAG vs Agent based approach | Found 5 results, 5 URLs. Key snippets: Agents Using RAG: Agents that leverage RAG for informed decision-making enhance their ability to act | Agentic RAG represents a groundbreaking shift from traditional Retrieval-Augmented Generation (RAG)  | RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://azumo.com/artificial-intelligence/ai-insig... (8015 chars)
ğŸ“– Read URL: https://www.marimsasolutions.com/data-technology-b... (5189 chars)
   âœ“ [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037]
      Preview: Error: HTTP 403 for URL: https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
   âœ“ [https://azumo.com/artificial-intelligence/ai-insights/agentic-rag]
      Preview: Agentic RAG: The Future of Autonomous AI vs Traditional RAG services Software Staffing Dedicated Team Project Management Virtual CTO All Nearshore Services Artificial Intelligence Custom Software Development Data Engineering Web Application Development AI Chatbots Mobile Development Cloud Services Game Development All Custom Software Solutions Technologies .NET AWS Android Angular C# DevOps Golang Java Node PHP Python React Ruby on Rails TypeScript Unity Engine Unreal Engine Vector Databases iOS All Technologies Airflow Azure Cohere Databricks Docker Elastic Firebase Flutter Go Google Cloud Jenkins Kubernetes LLaMA Mistral MongoDB NEXT.js PyTorch React Native Redshift Rust Scala Snowflake Tableau Terraform All Developers for Hire Industries Banking E-commerce Education Enterprise Financial Software Fintech Healthcare Hospitality Insurance Manufacturing Media &amp; Entertainment Retail SaaS Telemedicine All Industries Company About Us Clients Case Studies Awards Blog Handbook Join Our Team AI Tools Charlibot Valkyrie AI Schema Generator AI Readiness Assesment Project Pricing Estimator AI Road Map AI Software Spec Writer All AI Tools Contact Home Artificial Intelligence Agentic RAG Explained: The Future of Autonomous AI (and How It Differs from Traditional RAG) Agentic RAG Explained: The Future of Autonomous AI (and How It Differs from Traditional RAG) Agentic RAG represents a groundbreaking shift from traditional Retrieval-Augmented Generation (RAG) by introducing intelligent AI agents capable of multi-step reasoning, real-time decision-making, and information validation. While traditional RAG systems can only search and retrieve data, Agentic RAG systems enable AI to reason through problems, select the right data sources, and refine answers dynamically. This development is poised to transform industries that require complex decision-making, from market analysis to healthcare, providing more accurate and adaptable AI solutions. Written by: Guillermo Germade October 20, 2025 Table of Contents Enjoying Our AI Insights Visit our AI Blog to Read More of Our Thoughts and Best Practices TableGPT2: Transforming Large-Scale Data Analysis with AI How to Build a RAG System: A Complete Guide to Enterprise RAG Architecture Agentic RAG Explained: The Future of Autonomous AI (and How It Differs from Traditional RAG) Top RAG Tools to Boost Your LLM Workflows What is Vibe Coding and How to Manage Its Security Risks Best Vibe Coding Tools 2026: 10 Champions That Actually Make Coding Fun Top AI Programming Languages Top 6 Vector Database Solutions for RAG Applications in 2026 Which Industries Are Automating with AI the Most? AI Isnâ€™t Replacing Workers - Itâ€™s Enhancing Workflow, Experts Say What Is Model Context Protocol and How Itâ€™s Changing AI Integration Forever 10 Best Multilingual LLMs for Global-Scale Applications AI in the Workplace Statistics 2025: Adoption, Impact, and Outlook For the Future Top 8 Open Source Data Lakehouse Tools for 2025: Guide Top 10 MLOps Platforms for Scalable AI in 2025 10 Open Source LLMs You Can Fine-Tune for Agentic Workflow in 2026 Agentic AI vs Generative AI: Why Knowing the Difference Matters Now AI Solutions &amp; Services AI Development Services MLOps LLM Model Evaluation Model Context Protocol Development Agentic AI Retrieval Augmented Generation LLM Fine Tuning Natural Language Processing Computer Vision Generative AI Speak with a Top Rated Nearshore Software Developer How can we help... AI Development Chatbot Software Development Data Engineering Mobile Development Something Else We respect your privacy. No spam ever. Thank you! Your submission has been received! Oops! Something went wrong while submitting the form. What is Agentic RAG? The Future of Autonomous AI Explained If you&#x27;ve been keeping up with the AI community recently, you know there&#x27;s something peculiar going on. Do you remember when everyone was making a fuss about RAG (Retrieval-Augmented Generation) as if it were the next sliced 
   âœ“ [https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems]
      Preview: Understanding the Distinction: RAG vs Agent-Based AI Systems &mdash; Marimsa Solutions 0 Skip to Content About Us Blog Contact Us Careers Open Menu Close Menu About Us Blog Contact Us Careers Open Menu Close Menu About Us Blog Contact Us Careers Understanding the Distinction: RAG vs Agent-Based AI Systems Jan 22 Written By Brad Johnson The Ai Pipeline visualized as a manufacturing floor Understanding the Distinction: RAG vs Agent-Based AI Systems In the evolving landscape of AI, two methodologies stand out for enhancing AI capabilities: Retrieval-Augmented Generation (RAG) and Agent-Based Systems. While they share some common goals, their approaches and applications are distinct, yet complement each other in modern AI solutions. RAG Systems: Information-Centric RAG systems are designed to bolster an AI's knowledge base by integrating external information before generating responses. Picture RAG as a sophisticated librarian who: Searches through documents to find relevant information. Combines this information with the model's existing knowledge to provide informed responses. Grounds responses in specific, retrievable information, enhancing the accuracy and relevance of AI outputs. The RAG process involves retrieving relevant data from a knowledge base using advanced techniques like vector search, then augmenting the AI's prompt with this context to generate coherent, fact-based answers. This method significantly reduces the risk of "hallucinations" where AI might generate incorrect information based solely on its training data. Sources: yourGpt aws Agent-Based Systems: Action-Oriented Agent-based systems, in contrast, focus on autonomous action-taking and decision-making. An AI agent acts more like a proactive assistant who: Breaks down complex tasks into manageable steps. Executes actions based on situational understanding, possibly using tools, APIs, or other external resources. Learns from outcomes to improve future actions, maintaining state and context over time. These systems are designed for tasks requiring multiple steps, interaction with various systems, and continuous learning from experience. Agents can plan, decide, and act autonomously, making them ideal for environments where dynamic decision-making is crucial. * Key Differences Purpose : RAG focuses on information retrieval and knowledge enhancement, while agents aim at task completion and action execution. Operation Mode : RAG operates in a single pass for information lookup and response, whereas agents engage in multi-step, iterative processes. State Management : RAG is generally stateless, focusing on the current query, while agents maintain state and context across interactions. Tool Usage : RAG primarily leverages knowledge bases and embeddings, but agents can utilize a wide array of tools, APIs, and functions. Combining Both Approaches The integration of RAG and agent-based systems leads to more powerful AI applications: Example: Intelligence Analysis : RAG Component : Retrieves documents, finds historical patterns, and provides factual context. Agent Component : Plans the investigation strategy, decides on tool usage, coordinates with other systems, maintains state, and executes queries across databases. When to Use Which Use RAG When : You require factual, verifiable information. The task is primarily about retrieving information. Accuracy and sourcing are crucial. Responses need to be grounded in specific documents. Use Agents When : Tasks involve multiple steps or require interaction with external systems. Decision-making processes are necessary. Maintaining context across interactions is needed. Use Both When : Complex tasks require both information retrieval and action execution. Informed decision-making with contextual awareness is needed. Tasks involve both research and practical execution in long-running processes. Future Directions The lines between RAG and agent systems are increasingly blurring with the advent of new architectures: Agents Using
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 1.29s
ğŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ğŸ”¬ Analyzer [1/2]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] RAG focuses on information retrieval and knowledge enhancement.
      [2] Agents aim at informed decision-making based on up-to-date information.
      [3] Agentic RAG introduces intelligent AI agents capable of multi-step reasoning, real-time decision-making, and information validation, unlike traditional RAG which primarily searches and retrieves data.
      [4] For simple, query-based tasks, traditional RAG is sufficient; for complex, multi-step processes, Agentic RAG is more suitable.
      [5] Agentic RAG enables AI to act as a proactive partner, making real-time decisions independently.
   â””â”€ Decision: More research needed
   â””â”€ Next query: examples of when to use RAG vs Agentic RAG
ğŸ” Searcher [2]: Follow-up search for: examples of when to use RAG vs Agentic RAG

ğŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.multimodal.dev/post/ai-agents-vs-rag-vs-agentic-ai
      [4] https://www.datacamp.com/blog/agentic-rag
      [5] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
   â””â”€ Snippets:
      â€¢ Once weâ€™ve clarified your goals, we design and build using the framework that fits your current business readiness:   RAG â†’ When your priority is fast, accurate answers from internal data.  Example: A knowledge assistant trained on your HR policies or product manuals.   Agentic RAG â†’ When you need goal-driven, step-by-step reasoning with smart retrieval.  Example: A sales research agent that pulls competitive insights and drafts summaries. [...] Your team needs AI to reason through tasks, not just answer them.  Youâ€™re working with research-heavy, multi-step questions.  You want to simulate a helpful assistant, not just a search engine.  Example: Market research agents, onboarding helpers, email summarizers.  Agentic RAG is a step toward AI assistants; great for knowledge work that needs judgment.  #### Use MCP ifâ€¦ [...] The table below makes it easy for you to see the trade-offs:   RAG is best for quick wins with static content.  Agentic RAG is a smart bridge when goal-based reasoning is needed.  MCP is for building durable, intelligent systems with real decision-making power.
      â€¢ In e-commerce, RAG can be used to generate product descriptions by retrieving relevant product details and specifications.  Agentic RAG can take it a step further by handling complex queries such as recommending products based on user behavior, pricing analysis, and trends from different sources.  ### Challenges with RAG and Agentic RAG  Despite their advantages, both RAG and Agentic RAG face certain challenges: [...] Traditional RAG systems are useful for content creation tasks that require AI to retrieve information from various sources to generate articles, blogs, or reports.  Agentic RAG systems can take this further by generating highly customized content that requires reasoning, such as creating marketing materials based on the latest trends, or producing reports with visualizations like graphs or charts.  ### Healthcare: [...] Traditional RAG systems can be used in customer support to provide accurate answers to frequently asked questions by retrieving information from a knowledge base.  Agentic RAG systems, however, can handle more complex customer issues by interacting with multiple databases, making decisions, and generating responses that require multi-step reasoning, such as troubleshooting technical problems.  ### Content Creation:
      â€¢ RAG can be part of an agent, but agentic AI controls how and when itâ€™s used.  Use Case â€“ Insurance:   AgentFlow coordinates Document AI to classify claims  Uses RAG to fetch policy clause language  Engages Decision AI for final approval  Uses Report AI to generate audit-ready memos  ## AI Agents, Agentic AI, RAG In Practice  ### Example â€“ Automated Loan Underwriting (Finance) [...] You need a system that can make decisions, adapt to changes, and coordinate multiple steps or agents  The workflow involves dynamic goals, logic, or real-time prioritization  You want an AI system that acts like a work colleague, not just a tool  Use examples: Managing a full loan approval workflow, triaging insurance claims, coordinating multiple departments or systems.  ### Use RAG When... [...] While agentic AI is designed for autonomous and goal-directed behavior, RAG is a retrieval technique that helps improve the accuracy of generated text by pulling in relevant information. It doesn't have goals, plans, or autonomy.  It's best to understand the difference between agentic AI vs. RAG in the following way:   RAG is a tool within an agentâ€™s toolkit.  Agentic AI decides when and how to invoke RAG or other tools.
ğŸ’­ Think: Query: examples of when to use RAG vs Agentic RAG | Found 5 results, 5 URLs. Key snippets: Once weâ€™ve clarified your goals, we design and build using the framework that fits your current busi | In e-commerce, RAG can be used to generate product descriptions by retrieving relevant product detai | RAG can be part of an agent, but agentic AI controls how and when itâ€™s used.

Use Case â€“ Insur. Assessment: Is this sufficient or need more specific search?

ğŸ“– ContentReader: Reading 3 URLs in parallel ğŸš€
ğŸ“– Read URL: https://www.multimodal.dev/post/ai-agents-vs-rag-v... (8015 chars)
ğŸ“– Read URL: https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/... (8015 chars)
   âœ“ [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037]
      Preview: Error: HTTP 403 for URL: https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
   âœ“ [https://www.multimodal.dev/post/ai-agents-vs-rag-vs-agentic-ai]
      Preview: AI Agents vs. RAG vs. Agentic AI, Explained for the C-Suite Download Now: First-Ever Report on the State of Agentic AI in Credit Unions Solutions Finance Automate end-to-end finance workflows securely for 4x faster turnaround. Retail Banking Automation Corporate Banking Automation Financial Services Automation Credit Union Automation Payments Automation Credit Rating Agency Automation Business Loan Underwriting Insurance Automate end-to-end insurance workflows security for 4x faster turnaround. Life Insurance Automation P&amp;C Insurance Automation Health Insurance Automation Brokerage and Reinsurance Automation Commercial Insurance Automation Travel Insurance Automation Private Equity Portfolio Companies Accelerate turnaround times and maximize operational efficiency with AI-driven process automation. Platform All-In-One Agentic AI Platform For Process Automation Unstructured AI Processes unstructured data for RAG architectures and downstream GenAI applications. Document AI Trained on your schema to extract data and organize documents. Decision AI Makes business decisions from your data to minimize risk and maximize ROI. Database AI Turns raw data into insights for employees and customers. Conversational AI Uses unstructured data to provide client and employee support. Report AI Generates ready-to-publish content, from reports to blog posts. Resources Blogs Company news and guides on industry-specific AI. Podcasts Educational content series led by our founder. Featured customer story FORUM CU Streamlines Auto Loans With AgentFlow Webinars Live discussions and tips on enterprise AI. Customer Stories Case studies from previous and current customers. Company About Us Learn more about our mission. Careers Explore open positions. Security &amp; Trust See how we handle your data. Recognition Explore our industry recognition. Newsroom News and press coverage. Book a Demo Book a Demo Share on Enterprise AI June 18, 2025 AI Agents vs. RAG vs. Agentic AI, Explained for the C-Suite Agents vs RAG vs agentic AI: whatâ€™s the difference, and why should the C-suite care? This guide simplifies the tech so you can make smarter decisions. Share on LinkedIn X/Twitter Grab your AI use cases template Grab your free PDF Thank you! Download PDF Version Oops! Something went wrong while submitting the form. By Dario Lemut Writer By Dina Sostarec Editor By Ishita Jaiswal Editor Table of contents Example H2 Dario Lemut Dina Sostarec Ishita Jaiswal â€ Key Takeaways AI Agents autonomously execute specific tasks within a defined context. Agentic AI refers to systems of multiple AI agents that collaborate to achieve complex goals. RAG combines search (information retrieval) with generation to answer complex queries using external data. AgentFlow platform uses all three to automate regulated workflows in finance and insurance. Get 1% smarter about AI in financial services every week. Receive weekly micro lessons on agentic AI, our company updates, and tips from our team right in your inbox. Unsubscribe anytime. Thank you! Your submission has been received! Oops! Something went wrong while submitting the form. Some AI tools answer questions, some take action, and others are built to think ahead and solve problems. Here we break down these terms in plain language so you can make smarter decisions about what your business actually needs. Understanding The Key Terminology AI Agents According to the AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications, and Challenges paper , AI agents are software programs that autonomously execute specific tasks. They don&#x27;t only follow static instructions, but they can also observe, decide, and act based on goals, inputs, and changing environments. Therefore, AI agents rely on context, memory, and goals to carry out operations like data extraction, classification, or report drafting. AI agents interact through APIs, files, or databases and typically run inside enterprise systems. They&#x27;re designed to pursue objec
   âœ“ [https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/]
      Preview: RAG vs Agentic RAG vs MCP: A 2025 Comparison Guide for Business Leaders Skip to main content Get awesome and let's build together! +1 858-683-3692 Hit enter to search or ESC to close Close Search search Menu Services Web Development Full Stack Development SaaS Development Ruby on Rails Development Node.js Development React Development Angular Development Vue.js Development eCommerce Development PHP Development Firebase Development WordPress Development WooCommerce Development Shopify Development Shopify Apps Development Mobile App Development iOS App Development Android App Development Progressive Web Application React Native App Development Hybrid App Development Flutter App Development Roku App Development Apple tvOS App Development Apple WatchOS App Development Tablet App Development Google Tv App Development UX UI Services Enterprise Digital Transformation Web Data Extraction Scraping Big Data and Business Intelligence AWS Serverless Computing Robotic Process Automation AWS Cloud Computing AI &#038; Machine Learning Development DevOps Services Cloud Computing Services Business Software Development Software Development Partner Contentful Digital Agency Chia Blockchain farming Automation &#038; AI AI Development Services Power Platform Consulting Chatbot Development GenAI Integration Services AI Consulting Services AI Development with v0 &#038; Cursor Healthcare AI Agents AI Agent Development Workflow automation Services CMS &#038; eCommerce Identity &#038; Access Management Modern Data Stack Low Code Development Industries Healthcare Wound Care Software Development EHR/EMR Software Development HMO Automation Software Advance Imaging Software Solutions Telemedicine Software Development Services RPM Software Development Healthcare Mobile App Development Medical Device Software Development Life Sciences Software Development Healthcare Web Design &#038; Development Manufacturing Fitness FinTech Non-Profit eCommerce Retail Startups Our Work Solutions Cloud Solutions Cloud Application Development Custom Solutions Digital SMS/IVR Will Call with Twilio Digital Inspection Platform Digital Lending Platform Custom Software Development Marketplace Platform IoT Development Appointment Scheduling Software HME Software Development Business Software Solutions No-Code Solutions RPA Solution CRM Integrations Integrations Payment Gateway Google Calendar Integration Google Maps Integration OAuth Authentication Twilio API Integration OKTA Integration NetSuite Integration Salesforce API Integration SugarCRM &#038; SuiteCRM Integration VGS Integration Partner Hire Us Hire Mobile App Developer Hire Ruby on Rails Developer Hire Swift Developer Hire Full Stack Developer Hire Xamarin Developer Hire PHP Developer Hire Vue.js Developer Hire Angular JS Developer Hire React Developers Hire Node.js Developer Hire DevOps Engineer Blog Jumpstart My Project search RAG vs Agentic RAG vs MCP: A 2025 Comparison Guide for Business Leaders By Raj Sanghvi June 24, 2025 AI , Automation ChatGPT Perplexity Claude Social Facebook Twitter LinkedIn WhatsApp Email No Comments For business leaders exploring AI-powered solutions, terms like RAG, Agentic RAG, and MCP are now at the center of strategy discussions. But what do they actually mean, and which one is right for your organization? This guide cuts through the technical jargon and gets straight to the point: What are these AI frameworks? How do they differ in capabilities and complexity? Which is best suited for your goals? Whether youâ€™re leading a digital transformation initiative or simply looking to make smarter decisions with AI, this side-by-side comparison of Retrieval-Augmented Generation (RAG), Agentic RAG, and the Model Context Protocol (MCP) will help you confidently choose the right approach. Letâ€™s break it down. Contents hide 1 What Are RAG, Agentic RAG, and MCP? 1.1 RAG (Retrieval-Augmented Generation) 1.2 Agentic RAG 1.3 MCP (Model Context Protocol) 2 How RAG, Agentic RAG, and MCP Differ: Side-by-Side C
   â””â”€ â±ï¸ Parallel read: 3/3 URLs in 0.91s
ğŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ğŸ”¬ Analyzer: Max iterations reached (2), proceeding to Writer

ğŸ”¬ Analyzer [2/2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] RAG focuses on information retrieval and knowledge enhancement.
      [2] Agents aim at informed decision-making based on up-to-date information.
      [3] Agentic RAG introduces intelligent AI agents capable of multi-step reasoning, real-time decision-making, and information validation, unlike traditional RAG which primarily searches and retrieves data.
      [4] For simple, query-based tasks, traditional RAG is sufficient; for complex, multi-step processes, Agentic RAG is more suitable.
      [5] Agentic RAG enables AI to act as a proactive partner, making real-time decisions independently.
   â””â”€ Decision: Research complete (14 total findings)
   â””â”€ âœ… Research Subgraph completed (execution #1)
   â””â”€ Findings: 14 items
   â””â”€ Contents: 6 URLs read

ğŸ“¦ Compress: Compressing 14 findings, 6 contents
   â””â”€ Compressed to 2001 chars (from ~5136 raw chars)
   â””â”€ Sources cited: 5
   â””â”€ Preview:
      ## Key Findings
      - RAG focuses on information retrieval and knowledge enhancement [1].
      - Agents aim at informed decision-making based on up-to-date information [1].
      - Agentic RAG uses intelligent AI agents for multi-step reasoning, real-time decision-making, and information validation [3].
      - Traditional RAG suffices for simple, query-based tasks, while Agentic RAG is better for complex processes [3].
      - Agentic RAG allows AI to act proactively and make independent, real-time decisions [3].
      - RAG combines information retrieval with large language models (LLMs) to generate answers by retrieving relevant data and augmenting prompts [1].
      - RAG systems are information-centric [1].
      
      ## Detailed Information
      - **RAG (Retrieval-Augmented Generation):** RAG systems focus on information retrieval and knowledge enhancement [1]. They combine information retrieval with large language models to generate answers [1]. This involves retrieving relevant data from various sources and using it to augment prompts [1]. RAG systems are primarily information-centric [1].
      
      - **Agentic RAG:** Agentic RAG uses intelligent AI agents capable of multi-step reasoning, real-time decision-making, and information validation [3]. Unlike traditional RAG, Agentic RAG allows AI to act as a proactive partner, making independent, real-time decisions [3].
      
      - **RAG vs. Agentic RAG:** For simple, query-based tasks, traditional RAG is sufficient [3]. However, for complex, multi-step processes, Agentic RAG is more suitable [3]. Agents aim at informed decision-making based on up-to-date information [1].
      
      ## Sources
      [1] https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems
      [2] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [3] https://azumo.com/artificial-intelligence/ai-insights/agentic-rag
      [4] https://www.multimodal.dev/post/ai-agents-vs-rag-vs-agentic-ai
      [5] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037

âœï¸ Writer: Composing response from 14 findings
   â””â”€ Using compressed notes (2001 chars)

âœï¸ Writer: Generated response (3138 chars)
   â””â”€ Sources used:
      [1] https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems
      [2] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [3] https://azumo.com/artificial-intelligence/ai-insights/agentic-rag
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      
      RAGëŠ” ì •ë³´ ê²€ìƒ‰ ë° ì§€ì‹ ì¦ê°•ì— ì´ˆì ì„ ë§ì¶˜ ë°˜ë©´ [1], Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ìµœì‹  ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ëª©í‘œë¥¼ ë‘¡ë‹ˆë‹¤ [1]. Agentic RAGëŠ” ë‹¤ë‹¨ê³„ ì¶”ë¡ , ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì •, ì •ë³´ ê²€ì¦ì„ ìœ„í•´ ì§€ëŠ¥í˜• AI ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì— ë” ì í•©í•©ë‹ˆë‹¤ [3].
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   RAGëŠ” ì •ë³´ ê²€ìƒ‰ ë° ì§€ì‹ í–¥ìƒì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤ [1].
      *   AgentëŠ” ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ì— ì…ê°í•œ ì˜ì‚¬ ê²°ì •ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤ [1].
      *   Agentic RAGëŠ” ë‹¤ë‹¨ê³„ ì¶”ë¡ , ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì • ë° ì •ë³´ ê²€ì¦ì„ ìœ„í•´ ì§€ëŠ¥í˜• AI ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ [3].
      *   ê¸°ì¡´ RAGëŠ” ê°„ë‹¨í•œ ì¿¼ë¦¬ ê¸°ë°˜ ì‘ì—…ì— ì¶©ë¶„í•˜ì§€ë§Œ, Agentic RAGëŠ” ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ì— ë” ì í•©í•©ë‹ˆë‹¤ [3].
      *   Agentic RAGë¥¼ í†µí•´ AIëŠ” ëŠ¥ë™ì ìœ¼ë¡œ í–‰ë™í•˜ê³  ë…ë¦½ì ì¸ ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3].
      *   RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê²°í•©í•˜ì—¬ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ê°•í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ [1].
      *   RAG ì‹œìŠ¤í…œì€ ì •ë³´ ì¤‘ì‹¬ì ì…ë‹ˆë‹¤ [1].
      
      ## ìƒì„¸ ë¶„ì„
      
      ### RAG (Retrieval-Augmented Generation)
      
      RAGëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•´, ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì–¸ì–´ ëª¨ë¸ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ê°•í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤ [1].  ì¦‰, ì£¼ì–´ì§„ ì§ˆë¬¸ì— ì ì ˆí•œ ì •ë³´ë¥¼ ì°¾ê³ , ì´ë¥¼ LLMì—ê²Œ ì œê³µí•˜ì—¬ ë”ìš± ì •í™•í•˜ê³  í’ë¶€í•œ ë‹µë³€ì„ ì–»ë„ë¡ ë•ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤. RAG ì‹œìŠ¤í…œì€ ì£¼ë¡œ ì •ë³´ ê²€ìƒ‰ ë° ì§€ì‹ ì¦ê°•ì— ì´ˆì ì„ ë§ì¶”ë©°, ì‹œìŠ¤í…œì˜ ì¤‘ì‹¬ì€ 'ì •ë³´'ì…ë‹ˆë‹¤ [1]. ì´ëŠ” ì •ë³´ ê²€ìƒ‰ì˜ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì´ RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
      
      ### Agent ê¸°ë°˜ ì ‘ê·¼ë²• (Agentic RAG í¬í•¨)
      
      Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ RAGì™€ëŠ” ë‹¬ë¦¬, ì •ë³´ì— ê¸°ë°˜í•œ 'ì˜ì‚¬ ê²°ì •'ì— ë”ìš± ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤ [1]. AI ì—ì´ì „íŠ¸ëŠ” ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì œê³µí•˜ëŠ” ë° ê·¸ì¹˜ì§€ ì•Šê³ , ì£¼ì–´ì§„ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ëŠ¥ë™ì ìœ¼ë¡œ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤. Agentic RAGëŠ” ì´ëŸ¬í•œ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì— RAGì˜ ì •ë³´ ê²€ìƒ‰ ëŠ¥ë ¥ì„ ê²°í•©í•œ í˜•íƒœì…ë‹ˆë‹¤ [3]. ì¦‰, AI ì—ì´ì „íŠ¸ê°€ í•„ìš”í•œ ì •ë³´ë¥¼ RAGë¥¼ í†µí•´ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ë‹¨ê³„ ì¶”ë¡ ì„ ê±°ì³ ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.  Agentic RAGëŠ” ë³µì¡í•œ ë¬¸ì œ í•´ê²°ì— ìœ ìš©í•˜ë©°, AIê°€ ë…ë¦½ì ì¸ íŒë‹¨ì„ ë‚´ë¦¬ê³  í–‰ë™í•´ì•¼ í•˜ëŠ” ìƒí™©ì— ì í•©í•©ë‹ˆë‹¤ [3].
      
      ### RAG vs. Agentic RAG: ì‚¬ìš© ì‹œì  ë¹„êµ
      
      *   **ë‹¨ìˆœ ì¿¼ë¦¬ ê¸°ë°˜ ì‘ì—…**: ê°„ë‹¨í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì–»ëŠ” ë°ëŠ” ê¸°ì¡´ì˜ RAGë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤ [3]. ì˜ˆë¥¼ ë“¤ì–´, "XXíšŒì‚¬ì˜ 2023ë…„ ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€?"ì™€ ê°™ì€ ì§ì ‘ì ì¸ ì§ˆë¬¸ì—ëŠ” RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , LLMì´ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
      
      *   **ë³µì¡í•œ ë©€í‹° ìŠ¤í… í”„ë¡œì„¸ìŠ¤**: ë³µì¡í•œ ë¬¸ì œ í•´ê²°, ì˜ˆë¥¼ ë“¤ì–´, "XXíšŒì‚¬ì˜ ê²½ìŸì‚¬ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê³ , ê²½ìŸ ìš°ìœ„ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•œ 3ê°€ì§€ ì „ëµì„ ì œì•ˆí•˜ì‹œì˜¤"ì™€ ê°™ì€ ì‘ì—…ì—ëŠ” Agentic RAGê°€ ë” ì í•©í•©ë‹ˆë‹¤ [3]. ì´ ê²½ìš°, AI ì—ì´ì „íŠ¸ëŠ” ë¨¼ì € ê²½ìŸì‚¬ ì •ë³´ë¥¼ RAGë¥¼ í†µí•´ ê²€ìƒ‰í•˜ê³ , ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê²½ìŸ ìš°ìœ„ë¥¼ íŒŒì•…í•œ í›„, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ê²Œ ë©ë‹ˆë‹¤. ì´ì²˜ëŸ¼ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì¶”ë¡ ê³¼ ì˜ì‚¬ ê²°ì •ì´ í•„ìš”í•œ ì‘ì—…ì—ëŠ” Agentic RAGê°€ íš¨ê³¼ì ì…ë‹ˆë‹¤. Agentic RAGëŠ” ë˜í•œ ì •ë³´ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ê³  ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ëŠ” ë°ì—ë„ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3].
      
      ## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜
      
      *   [1] [https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems](https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems)
      *   [2] [https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/](https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/)
      *   [3] [https://azumo.com/artificial-intelligence/ai-insights/agentic-rag](https://azumo.com/artificial-intelligence/ai-insights/agentic-rag)
      *   [4] [https://www.multimodal.dev/post/ai-agents-vs-rag-vs-agentic-ai](https://www.multimodal.dev/post/ai-agents-vs-rag-vs-agentic-ai)
      *   [5] [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037](https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037)
      
      ## ê²°ë¡  ë° í‰ê°€
      
      RAGì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²• (íŠ¹íˆ Agentic RAG)ëŠ” ê°ê° ê³ ìœ í•œ ê°•ì ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì˜ ë³µì¡ì„±ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.  ë‹¨ìˆœí•œ ì •ë³´ ê²€ìƒ‰ ë° ìš”ì•½ì—ëŠ” RAGê°€ íš¨ìœ¨ì ì´ì§€ë§Œ, ë³µì¡í•œ ì¶”ë¡ , ì˜ì‚¬ ê²°ì •, ë¬¸ì œ í•´ê²°ì—ëŠ” Agentic RAGê°€ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.  Agentic RAGëŠ” AI ì‹œìŠ¤í…œì˜ ììœ¨ì„±ê³¼ ëŠ¥ë™ì„±ì„ í–¥ìƒì‹œì¼œ, ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ ë”ìš± í˜ì‹ ì ì¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ í•  ê²ƒì…ë‹ˆë‹¤. ì•ìœ¼ë¡œ Agentic RAGëŠ” ë”ìš± ë°œì „í•˜ì—¬, ë‹¨ìˆœí•œ ì •ë³´ ì œê³µì„ ë„˜ì–´, ì¸ê°„ì˜ ì‚¬ê³  ê³¼ì •ì„ ëª¨ë°©í•˜ê³ , ë³µì¡í•œ ë¬¸ì œì— ëŒ€í•œ ì°½ì˜ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤. ë‹¤ë§Œ, Agentic RAGì˜ ë³µì¡ì„±ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê°œë°œ ë° ìš´ì˜ ë¹„ìš©, ê·¸ë¦¬ê³  AI ì—ì´ì „íŠ¸ì˜ ì˜ì‚¬ ê²°ì • ê³¼ì •ì— ëŒ€í•œ íˆ¬ëª…ì„± í™•ë³´ëŠ” í•´ê²°í•´ì•¼ í•  ê³¼ì œì…ë‹ˆë‹¤.

ğŸ” Critique: CARC Quality Evaluation...
   â””â”€ CARC Scores: C=4.0 A=4.0 R=4.0 C=4.0
   â””â”€ Total: 16.0/20 âœ… Excellent
   â””â”€ Feedback: The response provides a good overview of the differences between RAG and Agent-based approaches, including Agentic RAG. It explains when to use each approach with clear examples. However, it could benefit from a more in-depth discussion of the limitations of each approach and potential challenges in implementation. Also, while the sources seem relevant, a deeper dive into the specific information extracted from each source would strengthen the accuracy score.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 9 Fixed Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ê³¼ ê°ê° ì–¸...
â”‚ Time: 27.53s
â”‚ LLM Calls: 2
â”‚ Search Calls: 0
â”‚ URLs Read: 6
â”‚ Iterations: 2
â”‚ Est. Tokens: 1195
â”‚ Response Length: 3138 chars
â”‚ Has Citations: âœ…
â”‚ CARC Quality: C=4.0 A=4.0 R=4.0 C=4.0 â†’ 16.0/20 ğŸ‘ Good
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ğŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½

RAGëŠ” ì •ë³´ ê²€ìƒ‰ ë° ì§€ì‹ ì¦ê°•ì— ì´ˆì ì„ ë§ì¶˜ ë°˜ë©´ [1], Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ìµœì‹  ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ëª©í‘œë¥¼ ë‘¡ë‹ˆë‹¤ [1]. Agentic RAGëŠ” ë‹¤ë‹¨ê³„ ì¶”ë¡ , ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì •, ì •ë³´ ê²€ì¦ì„ ìœ„í•´ ì§€ëŠ¥í˜• AI ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì— ë” ì í•©í•©ë‹ˆë‹¤ [3].

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   RAGëŠ” ì •ë³´ ê²€ìƒ‰ ë° ì§€ì‹ í–¥ìƒì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤ [1].
*   AgentëŠ” ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ì— ì…ê°í•œ ì˜ì‚¬ ê²°ì •ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤ [1].
*   Agentic RAGëŠ” ë‹¤ë‹¨ê³„ ì¶”ë¡ , ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì • ë° ì •ë³´ ê²€ì¦ì„ ìœ„í•´ ì§€ëŠ¥í˜• AI ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ [3].
*   ê¸°ì¡´ RAGëŠ” ê°„ë‹¨í•œ ì¿¼ë¦¬ ê¸°ë°˜ ì‘ì—…ì— ì¶©ë¶„í•˜ì§€ë§Œ, Agentic RAGëŠ” ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ì— ë” ì í•©í•©ë‹ˆë‹¤ [3].
*   Agentic RAGë¥¼ í†µí•´ AIëŠ” ëŠ¥ë™ì ìœ¼ë¡œ í–‰ë™í•˜ê³  ë…ë¦½ì ì¸ ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3].
*   RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê²°í•©í•˜ì—¬ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ê°•í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ [1].
*   RAG ì‹œìŠ¤í…œì€ ì •ë³´ ì¤‘ì‹¬ì ì…ë‹ˆë‹¤ [1].

## ìƒì„¸ ë¶„ì„

### RAG (Retrieval-Augmented Generation)

RAGëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•´, ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì–¸ì–´ ëª¨ë¸ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ê°•í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤ [1].  ì¦‰, ì£¼ì–´ì§„ ì§ˆë¬¸ì— ì ì ˆí•œ ì •ë³´ë¥¼ ì°¾ê³ , ì´ë¥¼ LLMì—ê²Œ ì œê³µí•˜ì—¬ ë”ìš± ì •í™•í•˜ê³  í’ë¶€í•œ ë‹µë³€ì„ ì–»ë„ë¡ ë•ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤. RAG ì‹œìŠ¤í…œì€ ì£¼ë¡œ ì •ë³´ ê²€ìƒ‰ ë° ì§€ì‹ ì¦ê°•ì— ì´ˆì ì„ ë§ì¶”ë©°, ì‹œìŠ¤í…œì˜ ì¤‘ì‹¬ì€ 'ì •ë³´'ì…ë‹ˆë‹¤ [1]. ì´ëŠ” ì •ë³´ ê²€ìƒ‰ì˜ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì´ RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

### Agent ê¸°ë°˜ ì ‘ê·¼ë²• (Agentic RAG í¬í•¨)

Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ RAGì™€ëŠ” ë‹¬ë¦¬, ì •ë³´ì— ê¸°ë°˜í•œ 'ì˜ì‚¬ ê²°ì •'ì— ë”ìš± ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤ [1]. AI ì—ì´ì „íŠ¸ëŠ” ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì œê³µí•˜ëŠ” ë° ê·¸ì¹˜ì§€ ì•Šê³ , ì£¼ì–´ì§„ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ëŠ¥ë™ì ìœ¼ë¡œ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤. Agentic RAGëŠ” ì´ëŸ¬í•œ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì— RAGì˜ ì •ë³´ ê²€ìƒ‰ ëŠ¥ë ¥ì„ ê²°í•©í•œ í˜•íƒœì…ë‹ˆë‹¤ [3]. ì¦‰, AI ì—ì´ì „íŠ¸ê°€ í•„ìš”í•œ ì •ë³´ë¥¼ RAGë¥¼ í†µí•´ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ë‹¨ê³„ ì¶”ë¡ ì„ ê±°ì³ ì‹¤ì‹œê°„ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.  Agentic RAGëŠ” ë³µì¡í•œ ë¬¸ì œ í•´ê²°ì— ìœ ìš©í•˜ë©°, AIê°€ ë…ë¦½ì ì¸ íŒë‹¨ì„ ë‚´ë¦¬ê³  í–‰ë™í•´ì•¼ í•˜ëŠ” ìƒí™©ì— ì í•©í•©ë‹ˆë‹¤ [3].

### RAG vs. Agentic RAG: ì‚¬ìš© ì‹œì  ë¹„êµ

*   **ë‹¨ìˆœ ì¿¼ë¦¬ ê¸°ë°˜ ì‘ì—…**: ê°„ë‹¨í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì–»ëŠ” ë°ëŠ” ê¸°ì¡´ì˜ RAGë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤ [3]. ì˜ˆë¥¼ ë“¤ì–´, "XXíšŒì‚¬ì˜ 2023ë…„ ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€?"ì™€ ê°™ì€ ì§ì ‘ì ì¸ ì§ˆë¬¸ì—ëŠ” RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , LLMì´ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.

*   **ë³µì¡í•œ ë©€í‹° ìŠ¤í… í”„ë¡œì„¸ìŠ¤**: ë³µì¡í•œ ë¬¸ì œ í•´ê²°, ì˜ˆë¥¼ ë“¤ì–´, "XXíšŒì‚¬ì˜ ê²½ìŸì‚¬ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê³ , ê²½ìŸ ìš°ìœ„ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•œ 3ê°€ì§€ ì „ëµì„ ì œì•ˆí•˜ì‹œì˜¤"ì™€ ê°™ì€ ì‘ì—…ì—ëŠ” Agentic RAGê°€ ë” ì í•©í•©ë‹ˆë‹¤ [3]. ì´ ê²½ìš°, AI ì—ì´ì „íŠ¸ëŠ” ë¨¼ì € ê²½ìŸì‚¬ ì •ë³´ë¥¼ RAGë¥¼ í†µí•´ ê²€ìƒ‰í•˜ê³ , ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê²½ìŸ ìš°ìœ„ë¥¼ íŒŒì•…í•œ í›„, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ê²Œ ë©ë‹ˆë‹¤. ì´ì²˜ëŸ¼ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì¶”ë¡ ê³¼ ì˜ì‚¬ ê²°ì •ì´ í•„ìš”í•œ ì‘ì—…ì—ëŠ” Agentic RAGê°€ íš¨ê³¼ì ì…ë‹ˆë‹¤. Agentic RAGëŠ” ë˜í•œ ì •ë³´ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ê³  ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ëŠ” ë°ì—ë„ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3].

## ê´€ë ¨ ìë£Œ ë° ì¶œì²˜

*   [1] [https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems](https://www.marimsasolutions.com/data-technology-blog/2025/1/7/understanding-the-distinction-rag-vs-agent-based-ai-systems)
*   [2] [https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/](https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/)
*   [3] [https://azumo.com/artificial-intelligence/ai-insights/agentic-rag](https://azumo.com/artificial-intelligence/ai-insights/agentic-rag)
*   [4] [https://www.multimodal.dev/post/ai-agents-vs-rag-vs-agentic-ai](https://www.multimodal.dev/post/ai-agents-vs-rag-vs-agentic-ai)
*   [5] [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037](https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037)

## ê²°ë¡  ë° í‰ê°€

RAGì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²• (íŠ¹íˆ Agentic RAG)ëŠ” ê°ê° ê³ ìœ í•œ ê°•ì ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì˜ ë³µì¡ì„±ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.  ë‹¨ìˆœí•œ ì •ë³´ ê²€ìƒ‰ ë° ìš”ì•½ì—ëŠ” RAGê°€ íš¨ìœ¨ì ì´ì§€ë§Œ, ë³µì¡í•œ ì¶”ë¡ , ì˜ì‚¬ ê²°ì •, ë¬¸ì œ í•´ê²°ì—ëŠ” Agentic RAGê°€ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.  Agentic RAGëŠ” AI ì‹œìŠ¤í…œì˜ ììœ¨ì„±ê³¼ ëŠ¥ë™ì„±ì„ í–¥ìƒì‹œì¼œ, ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ ë”ìš± í˜ì‹ ì ì¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ í•  ê²ƒì…ë‹ˆë‹¤. ì•ìœ¼ë¡œ Agentic RAGëŠ” ë”ìš± ë°œì „í•˜ì—¬, ë‹¨ìˆœí•œ ì •ë³´ ì œê³µì„ ë„˜ì–´, ì¸ê°„ì˜ ì‚¬ê³  ê³¼ì •ì„ ëª¨ë°©í•˜ê³ , ë³µì¡í•œ ë¬¸ì œì— ëŒ€í•œ ì°½ì˜ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤. ë‹¤ë§Œ, Agentic RAGì˜ ë³µì¡ì„±ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê°œë°œ ë° ìš´ì˜ ë¹„ìš©, ê·¸ë¦¬ê³  AI ì—ì´ì „íŠ¸ì˜ ì˜ì‚¬ ê²°ì • ê³¼ì •ì— ëŒ€í•œ íˆ¬ëª…ì„± í™•ë³´ëŠ” í•´ê²°í•´ì•¼ í•  ê³¼ì œì…ë‹ˆë‹¤.
======================================================================


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Phase 9 Fixed Summary (3 tests)
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Average Time: 30.05s
â•‘  Average Tokens: 1216
â•‘  Citation Rate: 100%
â•‘  CARC Quality: C=4.0 A=3.8 R=4.2 C=4.0 â†’ 16.1/20
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Results saved to: benchmark_results/phase_9_fixed_20251221_125424.json
