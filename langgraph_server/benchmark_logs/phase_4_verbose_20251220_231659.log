/home/isak/LangGraph_PJT/langgraph_web_ui/langgraph_server/src/agent/tools.py:36: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.
  tavily_tool = TavilySearchResults(

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë  Deep Research Benchmark - Phase 4
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë  Test Queries: 3
‚ïë  Verbose: ON (full response)
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


üìä Running benchmark: LangGraphÏôÄ CrewAIÏùò Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏïÑÌÇ§ÌÖçÏ≤òÎ•º ÎπÑÍµêÌïòÍ≥† Ïû•Îã®Ï†êÏùÑ Î∂ÑÏÑùÌï¥Ï§ò...

üîé Clarify: Analyzing query...
   ‚îî‚îÄ Query: LangGraphÏôÄ CrewAIÏùò Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏïÑÌÇ§ÌÖçÏ≤òÎ•º ÎπÑÍµêÌïòÍ≥† Ïû•Îã®Ï†êÏùÑ Î∂ÑÏÑùÌï¥Ï§ò
   ‚îî‚îÄ Status: üü¢ Clear
   ‚îî‚îÄ Analysis: The query asks for a comparison of multi-agent architectures of LangGraph and CrewAI, focusing on their pros and cons. The user has enough information to produce a reasonable answer.
   ‚îî‚îÄ Topics: LangGraph, CrewAI, Multi-Agent Architecture
üìã Planner: Creating research plan for: LangGraphÏôÄ CrewAIÏùò Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏïÑÌÇ§ÌÖçÏ≤òÎ•º ÎπÑÍµêÌïòÍ≥† Ïû•Îã®Ï†êÏùÑ Î∂ÑÏÑùÌï¥Ï§ò

üìã Planner: Generated 5 queries
   ‚îî‚îÄ Queries:
      [1] LangGraph vs CrewAI multi-agent architecture comparison
      [2] LangGraph multi-agent system
      [3] CrewAI multi-agent system
      [4] Advantages and disadvantages of LangGraph
      [5] Advantages and disadvantages of CrewAI
   ‚îî‚îÄ Focus: Architecture comparison, Advantages of LangGraph, Disadvantages of LangGraph, Advantages of CrewAI, Disadvantages of CrewAI
üîç Searcher [1]: Searching for: LangGraph vs CrewAI multi-agent architecture comparison

üîç Searcher: Found 5 results
   ‚îî‚îÄ URLs found:
      [1] https://www.zenml.io/blog/langgraph-vs-crewai
      [2] https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72
      [3] https://www.zams.com/blog/crewai-vs-langgraph
      [4] https://blog.langchain.com/langgraph-multi-agent-workflows/
      [5] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/
   ‚îî‚îÄ Snippets:
      ‚Ä¢ What's the learning curve difference between these frameworks? CrewAI offers faster initial setup with its role-based, YAML-configurable approach‚Äîteams can build working multi-agent systems in hours. LangGraph requires deeper understanding of graph structures, state management, and functional composition, typically taking days to weeks to master. However, LangGraph's complexity pays dividends in complex workflows requiring precise control, conditional routing, and advanced debugging. [...] Complex stateful workflows with branching logic: Choose LangGraph for its graph-based architecture, conditional routing, and time-travel debugging capabilities that handle non-linear agent interactions.  Rapid prototyping and POC development: Choose CrewAI for its intuitive role-based model and YAML configuration that enables working multi-agent systems in hours rather than days. [...] Recently Updated (November 2025): This comparison has been refreshed with major 2025 developments including LangGraph 1.0's stable release (October 2025), CrewAI's multimodal support and agentic RAG capabilities, updated market adoption statistics showing 85% of organizations now using AI agents, and the emergence of new interoperability protocols like A2A and MCP. All framework comparisons and integration information reflect current capabilities as of November 2025.
      ‚Ä¢ CrewAI organizes agents into teams and roles with goals and communication.  LangGraph is lower-level: you explicitly define logic and flow, ideal for precise control.  CrewAI is great for abstract task delegation; LangGraph is better for deterministic workflows.  ## LangGraph vs. AutoGen  AutoGen (by Microsoft) is designed for autonomous agent conversations. It lets agents talk to each other freely and decide what to do next. [...] LangGraph gives you more control. Instead of just assigning roles and letting them talk, you can specify exactly what happens when, in what order, and how data moves between steps. CrewAI is great for high-level tasks; LangGraph is better when you want tight control. [...] LangChain focuses on building LLM applications with chains and tools.  LangGraph extends LangChain by enabling stateful, multi-step workflows with branching and memory.  LangGraph uses LangChain under the hood but adds graph-based logic control.  ## LangGraph vs. CrewAI  CrewAI is like assigning roles in a team. You define what each agent does (writer, researcher, planner), and then they work together to complete a task.
      ‚Ä¢ While Crewai offers a beginner-friendly and is easy-to-use, it is limited in flexibility. On the other hand, LangGraph offers great control and flexibility but is not easy to quickly set up and get going.  > Both these platforms are primarily for software development teams.  When engineering teams want to research and quickly prototype, they go for Crew. And during production, they prefer LangGraph to develop agents for complex and detailed workflows. [...] ## Final verdict  To sum up, Crew and Langgraph are both powerful frameworks, each with its unique strengths and weaknesses. Choosing the right framework ultimately depends on your specific needs and expertise.  For beginners or those looking for a simple multi-agent orchestration framework Crew is the way to go. Its user friendly and modular design makes it easy to get started. [...] So, in case of LangGraph, more effort is needed for the initial set up and configuration, and comes with a steeper learning curve.  ### 2. Scalability  #### Crewai: Designed for research  It can scale well and handle a moderate number of agents and task-based workflows, however, conditional logic within workflows can be tricky. Crewai agents are a better fit when independent agents don‚Äôt need to constantly talk to each other, and not for real-time interaction-heavy use cases.
üí≠ Think: Query: LangGraph vs CrewAI multi-agent architecture comparison | Found 5 results, 5 URLs. Key snippets: What's the learning curve difference between these frameworks? CrewAI offers faster initial setup wi | CrewAI organizes agents into teams and roles with goals and communication.
 LangGraph is lower-level | While Crewai offers a beginner-friendly and is easy-to-use, it is limited in flexibility. On t. Assessment: Is this sufficient or need more specific search?

üìñ ContentReader: Reading 3 URLs
üìñ Read URL: https://www.zenml.io/blog/langgraph-vs-crewai... (8015 chars)
   ‚îî‚îÄ [https://www.zenml.io/blog/langgraph-vs-crewai]
      Preview: LangGraph vs CrewAI: Let‚Äôs Learn About the Differences - ZenML Blog Product DATA SCience Iterate at warp speed Accelerate your ML workflow seamlessly Auto-track everything Automatic logging and versioning Shared ML building blocks Boost team productivity with reusable components Infrastructure Backend flexibility, zero lock-in One framework for all your MLOps and LLMOps needs Limitless scaling Effortlessly deploy across clouds Streamline cloud expenses Gain clarity on resource usage and costs Organization ZenML Pro Our managed control plane for MLOps Open Source vs Pro Pick what works for your needs ZenML vs Other Tools Compare ZenML to other ML tools Solutions GENAI &amp; LLMS Finetuning LLMs Customize large language models for specific tasks Productionalizing a RAG application Deploy and scale RAG systems LLMOps Database A curated knowledge base of real-world implementations mlops Building Enterprise MLOps Platform architecture and best practices Abstract cloud compute Simplify management of cloud-based ML resources Track metrics and metadata Monitor and analyze ML model performance and data Success Stories JetBrains Software Adeo Leroy Merlin Retail Cross Screen Media Media View All Case Studies Learn more Developers Documentation Docs Comprehensive guides to use ZenML Deploying ZenML Understanding ZenML system architecture Tutorials Examples showing ZenML in action GUIDES Quickstart Quickly get your hands dirty Showcase Projects of ML use cases built with ZenML Starter Guide Get started with the basics COMMUNITY Slack Join our Slack Community Changelog Discover what‚Äôs new on ZenML Roadmap Join us on our MLOps journey Pricing Blog Case Studies Get Started Book a demo Software Engineering LangGraph vs CrewAI: Let‚Äôs Learn About the Differences Hamza Tahir Jun 28, 2025 ‚Ä¢ 12 mins All posts LLMOps Contents Get started with ZenML today Begin with open source tools Works with any infrastructure Secure, metadata-only tracking Book a demo Related Posts Metaflow vs MLflow vs ZenML: What‚Äôs the Difference? ZenML&#x27;s MCP Server Supports DXT: Making MLOps Conversations Frictionless This is also a heading This is a heading LangGraph and CrewAI are modern frameworks for orchestrating complex AI workflows with multiple LLM-driven agents. Both these intelligent systems are capable of sophisticated reasoning, planning, and autonomous action, and are becoming central to modern AI applications. However, they differ in abstraction, interfaces, and enterprise features. This LangGraph vs CrewAI article compares key attributes of these platforms, like: Workflow patterns Human-in-loop capabilities Parallelism and throttling Compliance and security Integration options Pricing We do this so you can exactly know when to use which one of these platforms. Recently Updated (November 2025) : This comparison has been refreshed with major 2025 developments including LangGraph 1.0&#x27;s stable release (October 2025), CrewAI&#x27;s multimodal support and agentic RAG capabilities, updated market adoption statistics showing 85% of organizations now using AI agents, and the emergence of new interoperability protocols like A2A and MCP. All framework comparisons and integration information reflect current capabilities as of November 2025. LangGraph vs CrewAI: Key Takeaways üßë‚Äçüíª LangGraph : It‚Äôs a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. üßë‚Äçüíª CrewAI : It‚Äôs a high-level framework for orchestrating autonomous AI agents working together as a crew. The platform abstracts away complexity by providing pre-built patterns for agent collaboration, role assignment, and task delegation. Framework Maturity &amp; Lineage The table below compared the framework maturity of LangGraph and CrewAI: Metric CrewAI LangGraph First public release v0.1.0 ‚Äî 14 Nov 2023 v0.0.9 ‚Äî 8 Jan 2024 GitHub stars 33.4 k 14.9 k Forks 4.5 k 2.5 k Commits 1 520 5 800 + PyPI downloads (last 30 days) 1.38 M 6.17 M LangChain dependency None; built from scratch, independent of LangChain Built on top of LangChain / uses langchain-core Production Readiness CrewAI 0.177.0 (Sep 2025), growing enterprise adoption LangGraph 1.0 (stable since Oct 2025), proven at scale Notable proof points 100,000 + developers certified through community courses Adopted by Klarna, Replit, Elastic, and others CrewAI launched a few months earlier than LangGraph (Nov 2023 vs Jan 2024), and it quickly attracted a large fanbase on GitHub ‚Äì 33 k stars vs LangGraph‚Äôs 15 k. On the other hand, LangGraph‚Äôs 5 800+ commits show a much faster development velocity compared to CrewAI‚Äôs 1 520. When looking at actual usage, LangGraph leads in monthly downloads (~ 6.17 M) compared to CrewAI (~ 1.38 M), indicating broader adoption in production deployments. LangGraph vs CrewAI: Feature Comparison Here‚Äôs a TL;DR of the features we compare for LangGraph and CrewAI. LangGraph vs CrewAI Features (Compact) Feature LangGraph CrewAI Workflow deployment patterns Parallel fan-out/fan-in Hierarchical agent teams Cyclical (looping) graphs with dynamic conditional routing Sequential and hierarchical processes (manager-led) Consensual process planned for future release Human-in-the-loop Pause nodes, checkpoints, breakpoints, and replay Workflow waits for human approval before resuming human_input=True prompts for confirmation Manager agent reviews and validates sub-tasks Parallel execution &amp; throttling Runs branches concurrently with transactional ‚Äúsupersteps‚Äù Concurrency limits handled by the environment Agents run tasks in parallel Hierarchical crews support configurable RPM throttle Enterprise security &amp; compliance Self-host or managed with API-key auth, RBAC Private-VPC deployments & custom SSO (OAuth/SAML) HIPAA & SOC2 compliance On-prem install, token-based APIs Fine-grained RBAC via web dashboard Integrations Full LangChain ecosystem: LLMs, memory stores, retrievers Includes LangSmith for tracing & observability 40+ built-in tools (LLMs, cloud services, databases) Python SDK, Zapier connectors & webhooks Pricing MIT open-source (free, 10 k nodes/mo); paid tiers‚ÄîDeveloper (100 k), Plus ($0.001/node + standby), Enterprise (custom). MIT open-source core; paid tiers‚ÄîBasic $99/mo, Standard $6 k/yr, Pro $12 k/yr, Enterprise $60 k/yr, Ultra $120 k/yr. Quick Selection Guide by Use Case: Complex stateful workflows with branching logic : Choose LangGraph for its graph-based architecture, conditional routing, and time-travel debugging capabilities that handle non-linear agent interactions. Rapid prototyping and POC development : Choose CrewAI for its intuitive role-based model and YAML configuration that enables working multi-agent systems in hours rather than days. Enterprise production at scale : Choose LangGraph for proven deployments at companies like LinkedIn and AppFolio, 1.0 API stability guarantee, and comprehensive LangSmith observability integration. Team-based workflows with clear roles : Choose CrewAI when your use case naturally maps to hierarchical team structures with managers, specialists, and clear task delegation patterns. Iterative agent development with debugging : Choose LangGraph for its checkpointing, breakpoints, and state inspection that enable mid-execution intervention and refinement. Multimodal AI applications : Choose CrewAI for native multimodal support (added 2025) or LangGraph with custom multimodal node implementations integrated through LangChain. Agentic RAG and knowledge management : Choose CrewAI for built-in query rewriting and native vector database integrations (Qdrant, Pinecone, Weaviate), or LangGraph for custom RAG architectures with precise retrieval control. Strict compliance requirements : Choose either‚ÄîLangGraph supports private VPC deployments with custom RBAC, while CrewAI Enterprise offers HIPAA/SOC2 certification and on-premise... [truncated]
   ‚îî‚îÄ [https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72]
      Preview: Error: HTTP 403 for URL: https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72
üìñ Read URL: https://www.zams.com/blog/crewai-vs-langgraph... (8015 chars)
   ‚îî‚îÄ [https://www.zams.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs. LangGraph: Multi agent framework comparison | Zams Integrations Customers Pricing Blog Login Login Get Started Get Started Technology April 19, 2025 Crewai vs. LangGraph: Which multi agent framework should you use? Yaagneshwaran Ganesh Objective feature comparison to help you decide - based on features, benefits, and ideal use cases. While there are different ways to build an AI agent from scratch, it‚Äôs great that you are taking the efficient approach of using multi agent frameworks. You‚Äôre probably here because you‚Äôve shortlisted Crew ai and LangGraph and want to decide which one is right for you. You‚Äôre in the right place. In this blog, we will compare the two in detail - on their features, benefits, and ideal use cases, including how agents connect to establish communication and interoperability. To get started, we need to have a basic understanding of multi agent systems. So, let‚Äôs first get a few basics out of the way. Why do you need a multi-agent framework? As your AI systems scale and you add multiple agents with different capabilities, the complexity of these applications grow. As the complexity grows, you will need a structured environment that orchestrates the agent activities, including the technical steps and requirements involved in building agents. That is where agentic frameworks come in. Multi agent frameworks provide you with a foundational structure for developing autonomous systems, and define parameters and protocols to handle interactions between multiple specialized agents. These frameworks also incorporate agent actions, which are fundamental components within a node-based AI framework, facilitating the execution of complex tasks. An agentic application can significantly enhance user experience and system efficiency by streamlining user interaction through minimal input and adaptive responses. Single agent systems These systems are autonomous but rely on one agent to handle a wide range of tasks, like a jack of all trades. For example, here‚Äôs how it works when requested for a sales pipeline report: As you can see, one agent carries out a series of tasks to accomplish the requested outcome. Single agent systems are great for specialized tasks where the problem is well defined and the scope is limited. But as your environment and context evolves, they fall short. Multi agent systems Multi agent systems, on the contrary, consist of multiple AI agents working together to achieve common goals. Let‚Äôs look at the same example of requesting to email the sales report, and see how the multi agent architecture manages specialized agents to execute it. Instead of one agent accomplishing all the tasks, the tasks are broken down into smaller components where each agent specializes in a specific task ‚Äì such as planning, integrating, analyzing, and more like a team of specialists working together, where each brings their unique expertise to the table. And because these AI agents can collaborate dynamically and run these tasks in parallel, they can tackle more complex problems where the environment is always changing and evolving. Multi agent interactions allow these AI agents to communicate within the system, monitor and debug in real-time, and handle handoffs efficiently, enabling dynamic workflows. The better you understand how these multi agents interact, the better you can optimize these systems and scale your operations, without worrying about bottlenecks or performance issues. And that‚Äôs exactly what multi agent frameworks help you with. Additionally, these frameworks give you a set of pre-packaged tools and features to help you quickly build any type of agent systems, be it knowledge oriented, process oriented or predictive. In short, agentic frameworks are the backbone of scalable, efficient and autonomous AI operations. With that said let‚Äôs get to the comparison. What is Crewai? It is an open-source multi agent orchestration framework, that helps you build multi agent systems, and integrate them with the latest LLMs and your codebase. The framework automates multi-agent workflows, enables them to communicate and collaborate on tasks as a team, and make decisions autonomously. Their modular design includes a range of tools such as agents, tools, tasks, processes, and an agent development kit, to engage, collect information, handle complex tasks, and manage their operations through tool calls. Crew‚Äôs hierarchical process generates a supervisor agent to oversee task execution and agent coordination. The agent engine facilitates the transition from prototype to production by managing various complexities including infrastructure, security, and performance evaluation, while integrating seamlessly with existing frameworks. With asynchronous tool execution, agents can work on different business processes concurrently, increasing productivity. Crew is primarily designed for research and quick prototypes. What is LangGraph framework (by LangChain)? LangGraph is an open-source AI framework to develop, deploy and manage advanced workflows for generative AI agents. Using graph-based architecture LangGraph handles the relationships between different components of the AI workflow. LangGraph applications offer robust features like scalable infrastructure and self-hosted deployment options that enhance workflow management and processing without adding overhead. Built on LangChain, a Python framework for AI applications, LangGraph excels at managing large language models. Function calling is integral to enhancing the capabilities of AI applications, particularly when combined with structured outputs and fine-tuning techniques. The LangGraph platform provides various deployment options, including self-hosted solutions, cloud SaaS, and the Bring Your Own Cloud (BYOC) option, catering to different user needs and preferences. With LangGraph Studio, a visual interface to develop workflows, users can reduce coding. One of LangGraph‚Äôs key features is its state management system which acts like a memory bank, storing information and enabling better state management and debugging. Users can run LangGraph Platform entirely on their own infrastructure as part of a Self-Hosted Enterprise solution, allowing companies to maintain control over their data while outsourcing the management of some services. The integrated development environment in LangGraph Studio is specifically tailored for AI agent development, offering powerful tools for visualization, real-time interaction, and debugging, which enhances the overall development experience for users working with agent workflows. This is crucial for graph execution as it allows managing individual agents as graph nodes in the system. LangGraph supports a human-in-the-loop approach, so human input can enhance AI decision making and user interactions. LangGraph is primarily designed for engineering teams and production. Architecture and design philosophy Architecture and design of agent frameworks play a huge role in determining their effectiveness to support development of complex AI applications. A well-designed framework ideally provides a modular and flexible structure, allowing you to easily integrate various components and tools. Additionally, the framework should support seamless interaction between multiple agents, making it easy to build sophisticated workflows and applications. Crewai agents approach Crew is an agent framework that adopts a collaborative intelligence approach, helping you create multi-agent systems where specialized agents work together to achieve shared objectives. This approach is particularly useful for applications requiring dynamic task allocation, large language models, and multi-agent orchestration. LangGraph agents framework LangGraph is an agent framework that takes a state-centric approach, providing a graph-based architecture to enable creation of complex workflows and applications. This approach is ideal for applications requiring sophisticated state management, kno... [truncated]
üî¨ Analyzer [1]: Analyzing 5 results, 3 contents

üî¨ Analyzer [1]: Analyzed 5 results, 3 contents
   ‚îî‚îÄ New findings:
      [1] CrewAI offers faster initial setup and is easier to use, while LangGraph requires a deeper understanding and more time to master.
      [2] CrewAI excels in abstract task delegation; LangGraph is better for deterministic workflows requiring precise control.
      [3] CrewAI is suitable for rapid prototyping, while LangGraph is preferred for production environments with complex workflows.
      [4] LangGraph is fully integrated into the LangChain ecosystem, providing access to its integrations and observability tools.
      [5] CrewAI follows a modular design, separating agent creation, task definition, and process orchestration.
   ‚îî‚îÄ Decision: More research needed
   ‚îî‚îÄ Next query: LangGraph vs CrewAI architecture comparison
üîç Searcher [2]: Follow-up search for: LangGraph vs CrewAI architecture comparison

üîç Searcher: Found 5 results
   ‚îî‚îÄ URLs found:
      [1] https://www.zenml.io/blog/langgraph-vs-crewai
      [2] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/
      [3] https://www.zams.com/blog/crewai-vs-langgraph
      [4] https://medium.com/@shuv.sdr/langgraph-architecture-and-design-280c365aaf2c
      [5] https://aaronyuqi.medium.com/first-hand-comparison-of-langgraph-crewai-and-autogen-30026e60b563
   ‚îî‚îÄ Snippets:
      ‚Ä¢ Key Workflow Patterns: [...] ## LangGraph vs CrewAI: Key Takeaways  üßë‚Äçüíª LangGraph: It‚Äôs a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. [...] | Feature | LangGraph | CrewAI |  ---  | Workflow deployment patterns |  Parallel fan-out/fan-in  Hierarchical agent teams  Cyclical (looping) graphs with dynamic conditional routing |  Sequential and hierarchical processes (manager-led)  Consensual process planned for future release |
      ‚Ä¢ LangGraph implements a graph-based architecture focused on managing application state through a central persistence layer. This architecture draws inspiration from established distributed computing models like Pregel and processing frameworks like Apache Beam, with a public interface reminiscent of NetworkX. The framework's design emphasizes stateful execution, allowing applications to maintain context across interactions. [...] The core architectural component in LangGraph is the StateGraph, which enables developers to define nodes (processing steps) and edges (transitions between steps) to create sophisticated workflows. This state-centric approach allows for checkpointing execution states, making it possible to implement features like memory persistence and human-in-the-loop interventions. [...] | Feature Category | CrewAI | LangGraph | BeeAI |  ---  --- | | Core Architecture | Standalone framework with no dependencies on other agent frameworks | Built by LangChain Inc. but can be used independently | IBM-developed open-source framework for multi-agent systems | | Programming Languages | Python | Python | Python and TypeScript with full parity |
      ‚Ä¢ | Category | CrewAI | LangGraph |  ---  | What it offers | ‚Ä¢ Simple orchestration of multi-agent teams  ‚Ä¢ Role/task assignment for agents  ‚Ä¢ Coordination and delegation mechanisms  ‚Ä¢ High-level abstractions to build agent teams quickly | ‚Ä¢ Fine-grained control over multi-agent workflows  ‚Ä¢ Graph-based architecture (agents as nodes, interactions as edges)  ‚Ä¢ Built-in support for complex state management, retries, event handling | [...] On the other hand, LangGraph built on LangChain provides more control. It‚Äôs a great choice for software development teams and engineering teams to develop complex workflows for specific use cases. LangGraph's agent capabilities allow agents to manage tasks independently while a supervisor orchestrates their interactions, enhancing overall efficiency and scalability. [...] LangGraph is an agent framework that takes a state-centric approach, providing a graph-based architecture to enable creation of complex workflows and applications. This approach is ideal for applications requiring sophisticated state management, knowledge retrieval, and distributed systems.  ## How to choose between Crewai and LangGraph?  Both are multi agent frameworks and they provide plenty of resources to get you started including tutorials, documentation, pre-built agents and tools.
üí≠ Think: Query: LangGraph vs CrewAI architecture comparison | Found 5 results, 5 URLs. Key snippets: Key Workflow Patterns: [...] ## LangGraph vs CrewAI: Key Takeaways

üßë‚Äçüíª LangGraph: It‚Äôs a framework  | LangGraph implements a graph-based architecture focused on managing application state through a cent | | Category | CrewAI | LangGraph |
 --- 
| What it offers | ‚Ä¢ Simple orchestration of multi-age. Assessment: Is this sufficient or need more specific search?

üìñ ContentReader: Reading 3 URLs
üìñ Read URL: https://www.zenml.io/blog/langgraph-vs-crewai... (8015 chars)
   ‚îî‚îÄ [https://www.zenml.io/blog/langgraph-vs-crewai]
      Preview: LangGraph vs CrewAI: Let‚Äôs Learn About the Differences - ZenML Blog Product DATA SCience Iterate at warp speed Accelerate your ML workflow seamlessly Auto-track everything Automatic logging and versioning Shared ML building blocks Boost team productivity with reusable components Infrastructure Backend flexibility, zero lock-in One framework for all your MLOps and LLMOps needs Limitless scaling Effortlessly deploy across clouds Streamline cloud expenses Gain clarity on resource usage and costs Organization ZenML Pro Our managed control plane for MLOps Open Source vs Pro Pick what works for your needs ZenML vs Other Tools Compare ZenML to other ML tools Solutions GENAI &amp; LLMS Finetuning LLMs Customize large language models for specific tasks Productionalizing a RAG application Deploy and scale RAG systems LLMOps Database A curated knowledge base of real-world implementations mlops Building Enterprise MLOps Platform architecture and best practices Abstract cloud compute Simplify management of cloud-based ML resources Track metrics and metadata Monitor and analyze ML model performance and data Success Stories JetBrains Software Adeo Leroy Merlin Retail Cross Screen Media Media View All Case Studies Learn more Developers Documentation Docs Comprehensive guides to use ZenML Deploying ZenML Understanding ZenML system architecture Tutorials Examples showing ZenML in action GUIDES Quickstart Quickly get your hands dirty Showcase Projects of ML use cases built with ZenML Starter Guide Get started with the basics COMMUNITY Slack Join our Slack Community Changelog Discover what‚Äôs new on ZenML Roadmap Join us on our MLOps journey Pricing Blog Case Studies Get Started Book a demo Software Engineering LangGraph vs CrewAI: Let‚Äôs Learn About the Differences Hamza Tahir Jun 28, 2025 ‚Ä¢ 12 mins All posts LLMOps Contents Get started with ZenML today Begin with open source tools Works with any infrastructure Secure, metadata-only tracking Book a demo Related Posts Metaflow vs MLflow vs ZenML: What‚Äôs the Difference? ZenML&#x27;s MCP Server Supports DXT: Making MLOps Conversations Frictionless This is also a heading This is a heading LangGraph and CrewAI are modern frameworks for orchestrating complex AI workflows with multiple LLM-driven agents. Both these intelligent systems are capable of sophisticated reasoning, planning, and autonomous action, and are becoming central to modern AI applications. However, they differ in abstraction, interfaces, and enterprise features. This LangGraph vs CrewAI article compares key attributes of these platforms, like: Workflow patterns Human-in-loop capabilities Parallelism and throttling Compliance and security Integration options Pricing We do this so you can exactly know when to use which one of these platforms. Recently Updated (November 2025) : This comparison has been refreshed with major 2025 developments including LangGraph 1.0&#x27;s stable release (October 2025), CrewAI&#x27;s multimodal support and agentic RAG capabilities, updated market adoption statistics showing 85% of organizations now using AI agents, and the emergence of new interoperability protocols like A2A and MCP. All framework comparisons and integration information reflect current capabilities as of November 2025. LangGraph vs CrewAI: Key Takeaways üßë‚Äçüíª LangGraph : It‚Äôs a framework from LangChain that helps you build stateful, multi-agent applications as graphs. LangGraph provides low-level control over agent workflows with built-in persistence, streaming support, and the ability to create complex branching logic. üßë‚Äçüíª CrewAI : It‚Äôs a high-level framework for orchestrating autonomous AI agents working together as a crew. The platform abstracts away complexity by providing pre-built patterns for agent collaboration, role assignment, and task delegation. Framework Maturity &amp; Lineage The table below compared the framework maturity of LangGraph and CrewAI: Metric CrewAI LangGraph First public release v0.1.0 ‚Äî 14 Nov 2023 v0.0.9 ‚Äî 8 Jan 2024 GitHub stars 33.4 k 14.9 k Forks 4.5 k 2.5 k Commits 1 520 5 800 + PyPI downloads (last 30 days) 1.38 M 6.17 M LangChain dependency None; built from scratch, independent of LangChain Built on top of LangChain / uses langchain-core Production Readiness CrewAI 0.177.0 (Sep 2025), growing enterprise adoption LangGraph 1.0 (stable since Oct 2025), proven at scale Notable proof points 100,000 + developers certified through community courses Adopted by Klarna, Replit, Elastic, and others CrewAI launched a few months earlier than LangGraph (Nov 2023 vs Jan 2024), and it quickly attracted a large fanbase on GitHub ‚Äì 33 k stars vs LangGraph‚Äôs 15 k. On the other hand, LangGraph‚Äôs 5 800+ commits show a much faster development velocity compared to CrewAI‚Äôs 1 520. When looking at actual usage, LangGraph leads in monthly downloads (~ 6.17 M) compared to CrewAI (~ 1.38 M), indicating broader adoption in production deployments. LangGraph vs CrewAI: Feature Comparison Here‚Äôs a TL;DR of the features we compare for LangGraph and CrewAI. LangGraph vs CrewAI Features (Compact) Feature LangGraph CrewAI Workflow deployment patterns Parallel fan-out/fan-in Hierarchical agent teams Cyclical (looping) graphs with dynamic conditional routing Sequential and hierarchical processes (manager-led) Consensual process planned for future release Human-in-the-loop Pause nodes, checkpoints, breakpoints, and replay Workflow waits for human approval before resuming human_input=True prompts for confirmation Manager agent reviews and validates sub-tasks Parallel execution &amp; throttling Runs branches concurrently with transactional ‚Äúsupersteps‚Äù Concurrency limits handled by the environment Agents run tasks in parallel Hierarchical crews support configurable RPM throttle Enterprise security &amp; compliance Self-host or managed with API-key auth, RBAC Private-VPC deployments & custom SSO (OAuth/SAML) HIPAA & SOC2 compliance On-prem install, token-based APIs Fine-grained RBAC via web dashboard Integrations Full LangChain ecosystem: LLMs, memory stores, retrievers Includes LangSmith for tracing & observability 40+ built-in tools (LLMs, cloud services, databases) Python SDK, Zapier connectors & webhooks Pricing MIT open-source (free, 10 k nodes/mo); paid tiers‚ÄîDeveloper (100 k), Plus ($0.001/node + standby), Enterprise (custom). MIT open-source core; paid tiers‚ÄîBasic $99/mo, Standard $6 k/yr, Pro $12 k/yr, Enterprise $60 k/yr, Ultra $120 k/yr. Quick Selection Guide by Use Case: Complex stateful workflows with branching logic : Choose LangGraph for its graph-based architecture, conditional routing, and time-travel debugging capabilities that handle non-linear agent interactions. Rapid prototyping and POC development : Choose CrewAI for its intuitive role-based model and YAML configuration that enables working multi-agent systems in hours rather than days. Enterprise production at scale : Choose LangGraph for proven deployments at companies like LinkedIn and AppFolio, 1.0 API stability guarantee, and comprehensive LangSmith observability integration. Team-based workflows with clear roles : Choose CrewAI when your use case naturally maps to hierarchical team structures with managers, specialists, and clear task delegation patterns. Iterative agent development with debugging : Choose LangGraph for its checkpointing, breakpoints, and state inspection that enable mid-execution intervention and refinement. Multimodal AI applications : Choose CrewAI for native multimodal support (added 2025) or LangGraph with custom multimodal node implementations integrated through LangChain. Agentic RAG and knowledge management : Choose CrewAI for built-in query rewriting and native vector database integrations (Qdrant, Pinecone, Weaviate), or LangGraph for custom RAG architectures with precise retrieval control. Strict compliance requirements : Choose either‚ÄîLangGraph supports private VPC deployments with custom RBAC, while CrewAI Enterprise offers HIPAA/SOC2 certification and on-premise... [truncated]
üìñ Read URL: https://developer.ibm.com/articles/awb-comparing-a... (13 chars)
   ‚îî‚îÄ [https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/]
      Preview: IBM Developer
üìñ Read URL: https://www.zams.com/blog/crewai-vs-langgraph... (8015 chars)
   ‚îî‚îÄ [https://www.zams.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs. LangGraph: Multi agent framework comparison | Zams Integrations Customers Pricing Blog Login Login Get Started Get Started Technology April 19, 2025 Crewai vs. LangGraph: Which multi agent framework should you use? Yaagneshwaran Ganesh Objective feature comparison to help you decide - based on features, benefits, and ideal use cases. While there are different ways to build an AI agent from scratch, it‚Äôs great that you are taking the efficient approach of using multi agent frameworks. You‚Äôre probably here because you‚Äôve shortlisted Crew ai and LangGraph and want to decide which one is right for you. You‚Äôre in the right place. In this blog, we will compare the two in detail - on their features, benefits, and ideal use cases, including how agents connect to establish communication and interoperability. To get started, we need to have a basic understanding of multi agent systems. So, let‚Äôs first get a few basics out of the way. Why do you need a multi-agent framework? As your AI systems scale and you add multiple agents with different capabilities, the complexity of these applications grow. As the complexity grows, you will need a structured environment that orchestrates the agent activities, including the technical steps and requirements involved in building agents. That is where agentic frameworks come in. Multi agent frameworks provide you with a foundational structure for developing autonomous systems, and define parameters and protocols to handle interactions between multiple specialized agents. These frameworks also incorporate agent actions, which are fundamental components within a node-based AI framework, facilitating the execution of complex tasks. An agentic application can significantly enhance user experience and system efficiency by streamlining user interaction through minimal input and adaptive responses. Single agent systems These systems are autonomous but rely on one agent to handle a wide range of tasks, like a jack of all trades. For example, here‚Äôs how it works when requested for a sales pipeline report: As you can see, one agent carries out a series of tasks to accomplish the requested outcome. Single agent systems are great for specialized tasks where the problem is well defined and the scope is limited. But as your environment and context evolves, they fall short. Multi agent systems Multi agent systems, on the contrary, consist of multiple AI agents working together to achieve common goals. Let‚Äôs look at the same example of requesting to email the sales report, and see how the multi agent architecture manages specialized agents to execute it. Instead of one agent accomplishing all the tasks, the tasks are broken down into smaller components where each agent specializes in a specific task ‚Äì such as planning, integrating, analyzing, and more like a team of specialists working together, where each brings their unique expertise to the table. And because these AI agents can collaborate dynamically and run these tasks in parallel, they can tackle more complex problems where the environment is always changing and evolving. Multi agent interactions allow these AI agents to communicate within the system, monitor and debug in real-time, and handle handoffs efficiently, enabling dynamic workflows. The better you understand how these multi agents interact, the better you can optimize these systems and scale your operations, without worrying about bottlenecks or performance issues. And that‚Äôs exactly what multi agent frameworks help you with. Additionally, these frameworks give you a set of pre-packaged tools and features to help you quickly build any type of agent systems, be it knowledge oriented, process oriented or predictive. In short, agentic frameworks are the backbone of scalable, efficient and autonomous AI operations. With that said let‚Äôs get to the comparison. What is Crewai? It is an open-source multi agent orchestration framework, that helps you build multi agent systems, and integrate them with the latest LLMs and your codebase. The framework automates multi-agent workflows, enables them to communicate and collaborate on tasks as a team, and make decisions autonomously. Their modular design includes a range of tools such as agents, tools, tasks, processes, and an agent development kit, to engage, collect information, handle complex tasks, and manage their operations through tool calls. Crew‚Äôs hierarchical process generates a supervisor agent to oversee task execution and agent coordination. The agent engine facilitates the transition from prototype to production by managing various complexities including infrastructure, security, and performance evaluation, while integrating seamlessly with existing frameworks. With asynchronous tool execution, agents can work on different business processes concurrently, increasing productivity. Crew is primarily designed for research and quick prototypes. What is LangGraph framework (by LangChain)? LangGraph is an open-source AI framework to develop, deploy and manage advanced workflows for generative AI agents. Using graph-based architecture LangGraph handles the relationships between different components of the AI workflow. LangGraph applications offer robust features like scalable infrastructure and self-hosted deployment options that enhance workflow management and processing without adding overhead. Built on LangChain, a Python framework for AI applications, LangGraph excels at managing large language models. Function calling is integral to enhancing the capabilities of AI applications, particularly when combined with structured outputs and fine-tuning techniques. The LangGraph platform provides various deployment options, including self-hosted solutions, cloud SaaS, and the Bring Your Own Cloud (BYOC) option, catering to different user needs and preferences. With LangGraph Studio, a visual interface to develop workflows, users can reduce coding. One of LangGraph‚Äôs key features is its state management system which acts like a memory bank, storing information and enabling better state management and debugging. Users can run LangGraph Platform entirely on their own infrastructure as part of a Self-Hosted Enterprise solution, allowing companies to maintain control over their data while outsourcing the management of some services. The integrated development environment in LangGraph Studio is specifically tailored for AI agent development, offering powerful tools for visualization, real-time interaction, and debugging, which enhances the overall development experience for users working with agent workflows. This is crucial for graph execution as it allows managing individual agents as graph nodes in the system. LangGraph supports a human-in-the-loop approach, so human input can enhance AI decision making and user interactions. LangGraph is primarily designed for engineering teams and production. Architecture and design philosophy Architecture and design of agent frameworks play a huge role in determining their effectiveness to support development of complex AI applications. A well-designed framework ideally provides a modular and flexible structure, allowing you to easily integrate various components and tools. Additionally, the framework should support seamless interaction between multiple agents, making it easy to build sophisticated workflows and applications. Crewai agents approach Crew is an agent framework that adopts a collaborative intelligence approach, helping you create multi-agent systems where specialized agents work together to achieve shared objectives. This approach is particularly useful for applications requiring dynamic task allocation, large language models, and multi-agent orchestration. LangGraph agents framework LangGraph is an agent framework that takes a state-centric approach, providing a graph-based architecture to enable creation of complex workflows and applications. This approach is ideal for applications requiring sophisticated state management, kno... [truncated]
üî¨ Analyzer [2]: Analyzing 5 results, 6 contents

üî¨ Analyzer [2]: Analyzed 5 results, 6 contents
   ‚îî‚îÄ New findings:
      [1] LangGraph offers fine-grained control over multi-agent workflows with a graph-based architecture and built-in state management, while CrewAI provides simple orchestration of multi-agent teams with role/task assignment and coordination mechanisms.
      [2] LangGraph allows for complex branching logic and stateful execution, drawing inspiration from distributed computing models.
      [3] CrewAI offers a clear object structure (Agent, Crew, Task) and seamless state management for agent coordination, but may be difficult to refine for complex systems due to logging limitations.
      [4] LangGraph focuses on simplicity, clarity, and modularity, with an emphasis on explicit state structures and independent, clearly defined nodes.
      [5] CrewAI facilitates quick startup time, while LangGraph requires more in-depth knowledge.
   ‚îî‚îÄ Decision: Research complete (14 total findings)

üì¶ Compress: Compressing 14 findings, 6 contents
   ‚îî‚îÄ Compressed to 2906 chars (from ~5152 raw chars)
   ‚îî‚îÄ Sources cited: 4
   ‚îî‚îÄ Preview:
      ## Key Findings
      - CrewAI offers faster initial setup and is easier to use compared to LangGraph [1], [3].
      - CrewAI excels in abstract task delegation, while LangGraph is better for deterministic workflows requiring precise control [1], [3].
      - CrewAI is suitable for rapid prototyping, while LangGraph is preferred for production environments with complex workflows [1], [3].
      - LangGraph is fully integrated into the LangChain ecosystem [1].
      - CrewAI follows a modular design, separating agent creation, task definition, and process orchestration [1].
      - LangGraph provides fine-grained control over multi-agent workflows with a graph-based architecture and built-in state management [1].
      - CrewAI provides simple orchestration of multi-agent teams with role/task assignment and coordination mechanisms [1].
      
      ## Detailed Information
      - **Ease of Use and Setup:** CrewAI offers faster initial setup and is generally easier to use, while LangGraph requires a deeper understanding and more time to master [1], [3]. CrewAI facilitates a quick startup time [1].
      
      - **Task Delegation and Workflow Control:** CrewAI excels in abstract task delegation [1], [3]. LangGraph is better suited for deterministic workflows that demand precise control [1], [3].
      
      - **Development Stage Suitability:** CrewAI is well-suited for rapid prototyping [1], [3]. LangGraph is preferred for production environments that involve intricate workflows [1], [3].
      
      - **LangChain Integration (LangGraph):** LangGraph is fully integrated into the LangChain ecosystem, providing access to its integrations and observability tools [1]. LangGraph uses create_react_agent.
      
      - **Modularity and Control (CrewAI):** CrewAI follows a modular design, which separates agent creation, task definition, and process orchestration [1]. CrewAI's standalone nature offers greater flexibility and control over agent behavior [1].
      
      - **Workflow Management and State Management (LangGraph):** LangGraph offers fine-grained control over multi-agent workflows through a graph-based architecture and built-in state management [1]. LangGraph allows for complex branching logic and stateful execution, drawing inspiration from distributed computing models [1]. LangGraph emphasizes explicit state structures and independent, clearly defined nodes [1].
      
      - **Orchestration and State Management (CrewAI):** CrewAI provides simple orchestration of multi-agent teams using role/task assignment and coordination mechanisms [1]. CrewAI offers a clear object structure (Agent, Crew, Task) and seamless state management for agent coordination [1].
      
      ## Sources
      [1] https://www.zenml.io/blog/langgraph-vs-crewai
      [2] https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72
      [3] https://www.zams.com/blog/crewai-vs-langgraph
      [4] https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/

‚úçÔ∏è Writer: Composing response from 14 findings
   ‚îî‚îÄ Using compressed notes (2906 chars)

‚úçÔ∏è Writer: Generated response (3550 chars)
   ‚îî‚îÄ Sources used:
      [1] https://www.zenml.io/blog/langgraph-vs-crewai
      [2] https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72
      [3] https://www.zams.com/blog/crewai-vs-langgraph
   ‚îî‚îÄ Response preview:
      ## ÌïµÏã¨ ÏöîÏïΩ
      
      CrewAIÎäî LangGraphÏóê ÎπÑÌï¥ Ï¥àÍ∏∞ ÏÑ§Ï†ïÏù¥ Îπ†Î•¥Í≥† ÏÇ¨Ïö©ÌïòÍ∏∞ Ïâ¨Ïö∞Î©∞, Ï∂îÏÉÅÏ†ÅÏù∏ ÏûëÏóÖ ÏúÑÏûÑÏóê ÌÉÅÏõîÌï©ÎãàÎã§. Î∞òÎ©¥ LangGraphÎäî Ï†ïÎ∞ÄÌïú Ï†úÏñ¥Í∞Ä ÌïÑÏöîÌïú Í≤∞Ï†ïÎ°†Ï†Å ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê Ï†ÅÌï©ÌïòÎ©∞, Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Í∞ÄÏßÑ ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê ÏÑ†Ìò∏Îê©ÎãàÎã§ [1], [3].
      
      ## Ï£ºÏöî Î∞úÍ≤¨ ÏÇ¨Ìï≠
      
      *   CrewAIÎäî LangGraphÏóê ÎπÑÌï¥ Ï¥àÍ∏∞ ÏÑ§Ï†ïÏù¥ Îπ†Î•¥Í≥† ÏÇ¨Ïö©ÌïòÍ∏∞ ÏâΩÏäµÎãàÎã§ [1], [3].
      *   CrewAIÎäî Ï∂îÏÉÅÏ†ÅÏù∏ ÏûëÏóÖ ÏúÑÏûÑÏóê Í∞ïÏ†êÏùÑ Í∞ÄÏßÄÎäî Î∞òÎ©¥, LangGraphÎäî Ï†ïÌôïÌïú Ï†úÏñ¥Í∞Ä ÌïÑÏöîÌïú Í≤∞Ï†ïÎ°†Ï†Å ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3].
      *   CrewAIÎäî Îπ†Î•∏ ÌîÑÎ°úÌÜ†ÌÉÄÏûÖ Ï†úÏûëÏóê Ï†ÅÌï©ÌïòÎ©∞, LangGraphÎäî Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Í∞ÄÏßÑ ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3].
      *   LangGraphÎäî LangChain ÏÉùÌÉúÍ≥ÑÏóê ÏôÑÏ†ÑÌûà ÌÜµÌï©ÎêòÏñ¥ ÏûàÏäµÎãàÎã§ [1].
      *   CrewAIÎäî ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±, ÏûëÏóÖ Ï†ïÏùò, ÌîÑÎ°úÏÑ∏Ïä§ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Î∂ÑÎ¶¨ÌïòÎäî Î™®ÎìàÌòï ÎîîÏûêÏù∏ÏùÑ Îî∞Î¶ÖÎãàÎã§ [1].
      *   LangGraphÎäî Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÏôÄ ÎÇ¥Ïû•Îêú ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê ÎåÄÌïú ÏÑ∏Î∞ÄÌïú Ï†úÏñ¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§ [1].
      *   CrewAIÎäî Ïó≠Ìï†/ÏûëÏóÖ Ìï†Îãπ Î∞è Ï°∞Ï†ï Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÌåÄÏùò Í∞ÑÎã®Ìïú Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1].
      
      ## ÏÉÅÏÑ∏ Î∂ÑÏÑù
      
      **1. ÏÇ¨Ïö© Ìé∏ÏùòÏÑ± Î∞è ÏÑ§Ï†ï:**
      
      CrewAIÎäî LangGraphÏóê ÎπÑÌï¥ Ï¥àÍ∏∞ ÏÑ§Ï†ïÏù¥ Ìõ®Ïî¨ Îπ†Î•¥Í≥† ÏßÅÍ¥ÄÏ†ÅÏûÖÎãàÎã§ [1], [3]. Ïù¥Îäî CrewAIÍ∞Ä Îçî ÏâΩÍ≤å Ï†ëÍ∑ºÌï† Ïàò ÏûàÎèÑÎ°ù ÏÑ§Í≥ÑÎêòÏóàÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÎ•º Ïù¥Ìï¥ÌïòÍ≥† Íµ¨ÏÑ±ÌïòÎäî Îç∞ Îçî ÎßéÏùÄ ÏãúÍ∞ÑÍ≥º ÎÖ∏Î†•Ïù¥ ÌïÑÏöîÌïòÎ©∞, LangChainÏóê ÎåÄÌïú ÍπäÏùÄ Ïù¥Ìï¥Î•º ÏöîÍµ¨Ìï† Ïàò ÏûàÏäµÎãàÎã§. Îî∞ÎùºÏÑú Îπ†Î•∏ ÌîÑÎ°úÌÜ†ÌÉÄÏûÖ Ï†úÏûëÏù¥ÎÇò Í∞ÑÎã®Ìïú Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Íµ¨Ï∂ïÏóêÎäî CrewAIÍ∞Ä Ïú†Î¶¨Ìï©ÎãàÎã§.
      
      **2. ÏûëÏóÖ ÏúÑÏûÑ Î∞è ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ï†úÏñ¥:**
      
      CrewAIÎäî ÏûëÏóÖÏùÑ Ï∂îÏÉÅÏ†ÅÏúºÎ°ú Ï†ïÏùòÌïòÍ≥† ÏóêÏù¥Ï†ÑÌä∏ÏóêÍ≤å ÏúÑÏûÑÌïòÎäî Îç∞ ÌÉÅÏõîÌï©ÎãàÎã§ [1], [3].  Í∞Å ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïó≠Ìï†Í≥º Ï±ÖÏûÑÏùÑ Ï†ïÏùòÌïòÍ≥†, ÏãúÏä§ÌÖúÏù¥ ÏûêÎèôÏúºÎ°ú ÏûëÏóÖÏùÑ Î∂ÑÎ∞∞ÌïòÍ≥† Ï°∞Ï†ïÌïòÎèÑÎ°ù ÏÑ§Í≥ÑÌï† Ïàò ÏûàÏäµÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Í∞Å Îã®Í≥ÑÎ≥ÑÎ°ú Ï†ïÌôïÌïú Ï†úÏñ¥Í∞Ä ÌïÑÏöîÌïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3].  ÌäπÏ†ï Ï°∞Í±¥Ïóê Îî∞Îùº Îã§Î•∏ Í≤ΩÎ°úÎ•º Ïã§ÌñâÌïòÍ±∞ÎÇò, ÏóêÏù¥Ï†ÑÌä∏ Í∞ÑÏùò ÏÉÅÌò∏ ÏûëÏö©ÏùÑ ÏÑ∏Î∞ÄÌïòÍ≤å Ï°∞Ï†ïÌï¥Ïïº ÌïòÎäî Í≤ΩÏö∞ LangGraphÏùò Ïú†Ïó∞ÏÑ±Ïù¥ ÎπõÏùÑ Î∞úÌï©ÎãàÎã§.
      
      **3. Í∞úÎ∞ú Îã®Í≥Ñ Ï†ÅÌï©ÏÑ±:**
      
      CrewAIÎäî Îπ†Î•∏ ÌîÑÎ°úÌÜ†ÌÉÄÏûÖ Ï†úÏûëÏóê Ïù¥ÏÉÅÏ†ÅÏûÖÎãàÎã§ [1], [3]. Í∞ÑÎã®ÌïòÍ≥† ÏßÅÍ¥ÄÏ†ÅÏù∏ APIÎ•º ÌÜµÌï¥ Îπ†Î•¥Í≤å ÏóêÏù¥Ï†ÑÌä∏Î•º Íµ¨ÏÑ±ÌïòÍ≥† ÏûëÏóÖÏùÑ Ìï†ÎãπÌïòÏó¨ ÏãúÏä§ÌÖúÏùò ÎèôÏûëÏùÑ Ïã§ÌóòÌï¥Î≥º Ïàò ÏûàÏäµÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º ÏïàÏ†ïÏ†ÅÏúºÎ°ú Ïã§ÌñâÌï¥Ïïº ÌïòÎäî ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3]. LangGraphÏùò Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÎäî Î≥µÏû°Ìïú Î°úÏßÅÏùÑ Î™ÖÌôïÌïòÍ≤å ÌëúÌòÑÌïòÍ≥†, ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Ïò§Î•ò Î∞úÏÉù Í∞ÄÎä•ÏÑ±ÏùÑ Ï§ÑÏó¨Ï§çÎãàÎã§.
      
      **4. LangChain ÌÜµÌï© (LangGraph):**
      
      LangGraphÎäî LangChain ÏÉùÌÉúÍ≥ÑÏóê ÏôÑÏ†ÑÌûà ÌÜµÌï©ÎêòÏñ¥ ÏûàÎã§Îäî Ïû•Ï†êÏù¥ ÏûàÏäµÎãàÎã§ [1]. Ïù¥Îäî LangChainÏùò Îã§ÏñëÌïú ÌÜµÌï© ÎèÑÍµ¨ÏôÄ Í¥ÄÏ∏°ÏÑ± ÎèÑÍµ¨Î•º ÌôúÏö©ÌïòÏó¨ LangGraph Í∏∞Î∞ò ÏãúÏä§ÌÖúÏùÑ Î™®ÎãàÌÑ∞ÎßÅÌïòÍ≥† ÎîîÎ≤ÑÍπÖÌïòÎäî Îç∞ Ïö©Ïù¥ÌïòÎã§Îäî Í≤ÉÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§. LangChainÏùò Î∞©ÎåÄÌïú Î¶¨ÏÜåÏä§Î•º ÌôúÏö©ÌïòÏó¨ ÏóêÏù¥Ï†ÑÌä∏Ïùò Í∏∞Îä•ÏùÑ ÌôïÏû•ÌïòÍ≥†, Ïô∏Î∂Ä Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ÏôÄÏùò Ïó∞ÎèôÏùÑ Í∞ÑÌé∏ÌïòÍ≤å Íµ¨ÌòÑÌï† Ïàò ÏûàÏäµÎãàÎã§.
      
      **5. Î™®ÎìàÏÑ± Î∞è Ï†úÏñ¥ (CrewAI):**
      
      CrewAIÎäî ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±, ÏûëÏóÖ Ï†ïÏùò, ÌîÑÎ°úÏÑ∏Ïä§ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Î™ÖÌôïÌïòÍ≤å Î∂ÑÎ¶¨ÌïòÎäî Î™®ÎìàÌòï ÎîîÏûêÏù∏ÏùÑ Ï±ÑÌÉùÌïòÍ≥† ÏûàÏäµÎãàÎã§ [1]. Ïù¥Îü¨Ìïú ÏÑ§Í≥ÑÎäî ÏãúÏä§ÌÖúÏùò Í∞Å Î∂ÄÎ∂ÑÏùÑ ÎèÖÎ¶ΩÏ†ÅÏúºÎ°ú Í∞úÎ∞úÌïòÍ≥† Ïú†ÏßÄÎ≥¥ÏàòÌï† Ïàò ÏûàÎèÑÎ°ù Ìï¥Ï§çÎãàÎã§. CrewAIÎäî ÎèÖÎ¶ΩÏ†ÅÏù∏ ÏóêÏù¥Ï†ÑÌä∏ ÌñâÎèôÏóê ÎåÄÌïú Îçî ÌÅ∞ Ïú†Ïó∞ÏÑ±Í≥º Ï†úÏñ¥Î†•ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1].
      
      **6. ÏõåÌÅ¨ÌîåÎ°úÏö∞ Í¥ÄÎ¶¨ Î∞è ÏÉÅÌÉú Í¥ÄÎ¶¨ (LangGraph):**
      
      LangGraphÎäî Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÏôÄ ÎÇ¥Ïû•Îêú ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê ÎåÄÌïú ÏÑ∏Î∞ÄÌïú Ï†úÏñ¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§ [1]. Î≥µÏû°Ìïú Î∂ÑÍ∏∞ Î°úÏßÅÍ≥º ÏÉÅÌÉú Í∏∞Î∞ò Ïã§ÌñâÏùÑ ÏßÄÏõêÌïòÏó¨, Î∂ÑÏÇ∞ Ïª¥Ìì®ÌåÖ Î™®Îç∏ÏóêÏÑú ÏòÅÍ∞êÏùÑ ÏñªÏóàÏäµÎãàÎã§ [1]. LangGraphÎäî Î™ÖÏãúÏ†ÅÏù∏ ÏÉÅÌÉú Íµ¨Ï°∞ÏôÄ ÎèÖÎ¶ΩÏ†ÅÏù¥Í≥† Î™ÖÌôïÌïòÍ≤å Ï†ïÏùòÎêú ÎÖ∏ÎìúÎ•º Í∞ïÏ°∞Ìï©ÎãàÎã§ [1]. `create_react_agent`ÏôÄ Í∞ôÏùÄ Í∏∞Îä•ÏùÑ ÌÜµÌï¥ LangChain ÏÉùÌÉúÍ≥ÑÏôÄÏùò Ïó∞ÎèôÏùÑ Í∞ïÌôîÌï©ÎãàÎã§.
      
      **7. Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖò Î∞è ÏÉÅÌÉú Í¥ÄÎ¶¨ (CrewAI):**
      
      CrewAIÎäî Ïó≠Ìï†/ÏûëÏóÖ Ìï†Îãπ Î∞è Ï°∞Ï†ï Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÌåÄÏùò Í∞ÑÎã®Ìïú Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1]. ÏóêÏù¥Ï†ÑÌä∏ Ï°∞Ï†ïÏóê ÎåÄÌïú Î™ÖÌôïÌïú Í∞ùÏ≤¥ Íµ¨Ï°∞ (Agent, Crew, Task)ÏôÄ ÏõêÌôúÌïú ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º Ï†úÍ≥µÌï©ÎãàÎã§ [1].
      
      ## Í¥ÄÎ†® ÏûêÎ£å Î∞è Ï∂úÏ≤ò
      
      *   [1] [https://www.zenml.io/blog/langgraph-vs-crewai](https://www.zenml.io/blog/langgraph-vs-crewai)
      *   [2] [https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72](https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72)
      *   [3] [https://www.zams.com/blog/crewai-vs-langgraph](https://www.zams.com/blog/crewai-vs-langgraph)
      *   [4] [https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/](https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/)
      
      ## Í≤∞Î°† Î∞è ÌèâÍ∞Ä
      
      CrewAIÏôÄ LangGraphÎäî Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Íµ¨Ï∂ïÏùÑ ÏúÑÌïú ÏÑúÎ°ú Îã§Î•∏ Ï†ëÍ∑º Î∞©ÏãùÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§. CrewAIÎäî ÏÇ¨Ïö©ÌïòÍ∏∞ Ïâ¨Ïö¥ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ÏôÄ Îπ†Î•∏ ÏÑ§Ï†ï ÏÜçÎèÑÎ•º ÌÜµÌï¥ Îπ†Î•¥Í≤å ÌîÑÎ°úÌÜ†ÌÉÄÏûÖÏùÑ Ï†úÏûëÌïòÍ≥† Ïã§ÌóòÌïòÎäî Îç∞ Ï†ÅÌï©Ìï©ÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Ï†ïÎ∞ÄÌïòÍ≤å Ï†úÏñ¥ÌïòÍ≥† Í¥ÄÎ¶¨Ìï¥Ïïº ÌïòÎäî ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§. LangChainÍ≥ºÏùò ÌÜµÌï©ÏùÄ LangGraphÏùò Îòê Îã§Î•∏ Í∞ïÎ†•Ìïú Ïû•Ï†êÏûÖÎãàÎã§.
      
      Ïñ¥Îñ§ ÌîÑÎ†àÏûÑÏõåÌÅ¨Î•º ÏÑ†ÌÉùÌï†ÏßÄÎäî ÌîÑÎ°úÏ†ùÌä∏Ïùò ÏöîÍµ¨ ÏÇ¨Ìï≠Í≥º Í∞úÎ∞úÌåÄÏùò ÏàôÎ†®ÎèÑÏóê Îî∞Îùº Îã¨ÎùºÏßëÎãàÎã§. Í∞ÑÎã®Ìïú ÏûëÏóÖ ÏúÑÏûÑÍ≥º Îπ†Î•∏ Í∞úÎ∞úÏù¥ Ï§ëÏöîÌïòÎã§Î©¥ CrewAIÍ∞Ä Ï¢ãÏùÄ ÏÑ†ÌÉùÏù¥ Îê† Ïàò ÏûàÏäµÎãàÎã§. Î≥µÏû°Ìïú Î°úÏßÅÍ≥º ÎÜíÏùÄ ÏïàÏ†ïÏÑ±Ïù¥ ÏöîÍµ¨ÎêúÎã§Î©¥ LangGraphÎ•º Í≥†Î†§Ìï¥Ïïº Ìï©ÎãàÎã§. Í∂ÅÍ∑πÏ†ÅÏúºÎ°úÎäî Í∞Å ÌîÑÎ†àÏûÑÏõåÌÅ¨Ïùò Ïû•Îã®Ï†êÏùÑ Ï∂©Î∂ÑÌûà Ïù¥Ìï¥ÌïòÍ≥†, ÌîÑÎ°úÏ†ùÌä∏Ïùò Î™©ÌëúÏóê Í∞ÄÏû• Ï†ÅÌï©Ìïú ÎèÑÍµ¨Î•º ÏÑ†ÌÉùÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§. Îëê ÌîÑÎ†àÏûÑÏõåÌÅ¨ Î™®Îëê ÌôúÎ∞úÌïú Ïª§ÎÆ§ÎãàÌã∞Î•º Í∞ÄÏßÄÍ≥† ÏûàÏúºÎØÄÎ°ú, ÌïÑÏöîÌïú Í≤ΩÏö∞ ÏßÄÏõêÏùÑ Î∞õÍ±∞ÎÇò Ï†ïÎ≥¥Î•º Í≥µÏú†ÌïòÎäî Îç∞ Ïñ¥Î†§ÏõÄÏù¥ ÏóÜÏùÑ Í≤ÉÏûÖÎãàÎã§.

‚îå‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚îÇ Phase 4 Benchmark Result
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ Query: LangGraphÏôÄ CrewAIÏùò Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏïÑÌÇ§ÌÖçÏ≤òÎ•º ÎπÑÍµêÌïòÍ≥† Ïû•Îã®Ï†êÏùÑ Î∂ÑÏÑùÌï¥Ï§ò...
‚îÇ Time: 26.54s
‚îÇ LLM Calls: 2
‚îÇ Search Calls: 2
‚îÇ URLs Read: 6
‚îÇ Iterations: 2
‚îÇ Est. Tokens: 1379
‚îÇ Response Length: 3550 chars
‚îÇ Has Citations: ‚úÖ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


======================================================================
üìÑ FULL RESPONSE:
======================================================================
## ÌïµÏã¨ ÏöîÏïΩ

CrewAIÎäî LangGraphÏóê ÎπÑÌï¥ Ï¥àÍ∏∞ ÏÑ§Ï†ïÏù¥ Îπ†Î•¥Í≥† ÏÇ¨Ïö©ÌïòÍ∏∞ Ïâ¨Ïö∞Î©∞, Ï∂îÏÉÅÏ†ÅÏù∏ ÏûëÏóÖ ÏúÑÏûÑÏóê ÌÉÅÏõîÌï©ÎãàÎã§. Î∞òÎ©¥ LangGraphÎäî Ï†ïÎ∞ÄÌïú Ï†úÏñ¥Í∞Ä ÌïÑÏöîÌïú Í≤∞Ï†ïÎ°†Ï†Å ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê Ï†ÅÌï©ÌïòÎ©∞, Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Í∞ÄÏßÑ ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê ÏÑ†Ìò∏Îê©ÎãàÎã§ [1], [3].

## Ï£ºÏöî Î∞úÍ≤¨ ÏÇ¨Ìï≠

*   CrewAIÎäî LangGraphÏóê ÎπÑÌï¥ Ï¥àÍ∏∞ ÏÑ§Ï†ïÏù¥ Îπ†Î•¥Í≥† ÏÇ¨Ïö©ÌïòÍ∏∞ ÏâΩÏäµÎãàÎã§ [1], [3].
*   CrewAIÎäî Ï∂îÏÉÅÏ†ÅÏù∏ ÏûëÏóÖ ÏúÑÏûÑÏóê Í∞ïÏ†êÏùÑ Í∞ÄÏßÄÎäî Î∞òÎ©¥, LangGraphÎäî Ï†ïÌôïÌïú Ï†úÏñ¥Í∞Ä ÌïÑÏöîÌïú Í≤∞Ï†ïÎ°†Ï†Å ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3].
*   CrewAIÎäî Îπ†Î•∏ ÌîÑÎ°úÌÜ†ÌÉÄÏûÖ Ï†úÏûëÏóê Ï†ÅÌï©ÌïòÎ©∞, LangGraphÎäî Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Í∞ÄÏßÑ ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3].
*   LangGraphÎäî LangChain ÏÉùÌÉúÍ≥ÑÏóê ÏôÑÏ†ÑÌûà ÌÜµÌï©ÎêòÏñ¥ ÏûàÏäµÎãàÎã§ [1].
*   CrewAIÎäî ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±, ÏûëÏóÖ Ï†ïÏùò, ÌîÑÎ°úÏÑ∏Ïä§ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Î∂ÑÎ¶¨ÌïòÎäî Î™®ÎìàÌòï ÎîîÏûêÏù∏ÏùÑ Îî∞Î¶ÖÎãàÎã§ [1].
*   LangGraphÎäî Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÏôÄ ÎÇ¥Ïû•Îêú ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê ÎåÄÌïú ÏÑ∏Î∞ÄÌïú Ï†úÏñ¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§ [1].
*   CrewAIÎäî Ïó≠Ìï†/ÏûëÏóÖ Ìï†Îãπ Î∞è Ï°∞Ï†ï Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÌåÄÏùò Í∞ÑÎã®Ìïú Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1].

## ÏÉÅÏÑ∏ Î∂ÑÏÑù

**1. ÏÇ¨Ïö© Ìé∏ÏùòÏÑ± Î∞è ÏÑ§Ï†ï:**

CrewAIÎäî LangGraphÏóê ÎπÑÌï¥ Ï¥àÍ∏∞ ÏÑ§Ï†ïÏù¥ Ìõ®Ïî¨ Îπ†Î•¥Í≥† ÏßÅÍ¥ÄÏ†ÅÏûÖÎãàÎã§ [1], [3]. Ïù¥Îäî CrewAIÍ∞Ä Îçî ÏâΩÍ≤å Ï†ëÍ∑ºÌï† Ïàò ÏûàÎèÑÎ°ù ÏÑ§Í≥ÑÎêòÏóàÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÎ•º Ïù¥Ìï¥ÌïòÍ≥† Íµ¨ÏÑ±ÌïòÎäî Îç∞ Îçî ÎßéÏùÄ ÏãúÍ∞ÑÍ≥º ÎÖ∏Î†•Ïù¥ ÌïÑÏöîÌïòÎ©∞, LangChainÏóê ÎåÄÌïú ÍπäÏùÄ Ïù¥Ìï¥Î•º ÏöîÍµ¨Ìï† Ïàò ÏûàÏäµÎãàÎã§. Îî∞ÎùºÏÑú Îπ†Î•∏ ÌîÑÎ°úÌÜ†ÌÉÄÏûÖ Ï†úÏûëÏù¥ÎÇò Í∞ÑÎã®Ìïú Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Íµ¨Ï∂ïÏóêÎäî CrewAIÍ∞Ä Ïú†Î¶¨Ìï©ÎãàÎã§.

**2. ÏûëÏóÖ ÏúÑÏûÑ Î∞è ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ï†úÏñ¥:**

CrewAIÎäî ÏûëÏóÖÏùÑ Ï∂îÏÉÅÏ†ÅÏúºÎ°ú Ï†ïÏùòÌïòÍ≥† ÏóêÏù¥Ï†ÑÌä∏ÏóêÍ≤å ÏúÑÏûÑÌïòÎäî Îç∞ ÌÉÅÏõîÌï©ÎãàÎã§ [1], [3].  Í∞Å ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïó≠Ìï†Í≥º Ï±ÖÏûÑÏùÑ Ï†ïÏùòÌïòÍ≥†, ÏãúÏä§ÌÖúÏù¥ ÏûêÎèôÏúºÎ°ú ÏûëÏóÖÏùÑ Î∂ÑÎ∞∞ÌïòÍ≥† Ï°∞Ï†ïÌïòÎèÑÎ°ù ÏÑ§Í≥ÑÌï† Ïàò ÏûàÏäµÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Í∞Å Îã®Í≥ÑÎ≥ÑÎ°ú Ï†ïÌôïÌïú Ï†úÏñ¥Í∞Ä ÌïÑÏöîÌïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3].  ÌäπÏ†ï Ï°∞Í±¥Ïóê Îî∞Îùº Îã§Î•∏ Í≤ΩÎ°úÎ•º Ïã§ÌñâÌïòÍ±∞ÎÇò, ÏóêÏù¥Ï†ÑÌä∏ Í∞ÑÏùò ÏÉÅÌò∏ ÏûëÏö©ÏùÑ ÏÑ∏Î∞ÄÌïòÍ≤å Ï°∞Ï†ïÌï¥Ïïº ÌïòÎäî Í≤ΩÏö∞ LangGraphÏùò Ïú†Ïó∞ÏÑ±Ïù¥ ÎπõÏùÑ Î∞úÌï©ÎãàÎã§.

**3. Í∞úÎ∞ú Îã®Í≥Ñ Ï†ÅÌï©ÏÑ±:**

CrewAIÎäî Îπ†Î•∏ ÌîÑÎ°úÌÜ†ÌÉÄÏûÖ Ï†úÏûëÏóê Ïù¥ÏÉÅÏ†ÅÏûÖÎãàÎã§ [1], [3]. Í∞ÑÎã®ÌïòÍ≥† ÏßÅÍ¥ÄÏ†ÅÏù∏ APIÎ•º ÌÜµÌï¥ Îπ†Î•¥Í≤å ÏóêÏù¥Ï†ÑÌä∏Î•º Íµ¨ÏÑ±ÌïòÍ≥† ÏûëÏóÖÏùÑ Ìï†ÎãπÌïòÏó¨ ÏãúÏä§ÌÖúÏùò ÎèôÏûëÏùÑ Ïã§ÌóòÌï¥Î≥º Ïàò ÏûàÏäµÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º ÏïàÏ†ïÏ†ÅÏúºÎ°ú Ïã§ÌñâÌï¥Ïïº ÌïòÎäî ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§ [1], [3]. LangGraphÏùò Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÎäî Î≥µÏû°Ìïú Î°úÏßÅÏùÑ Î™ÖÌôïÌïòÍ≤å ÌëúÌòÑÌïòÍ≥†, ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Ïò§Î•ò Î∞úÏÉù Í∞ÄÎä•ÏÑ±ÏùÑ Ï§ÑÏó¨Ï§çÎãàÎã§.

**4. LangChain ÌÜµÌï© (LangGraph):**

LangGraphÎäî LangChain ÏÉùÌÉúÍ≥ÑÏóê ÏôÑÏ†ÑÌûà ÌÜµÌï©ÎêòÏñ¥ ÏûàÎã§Îäî Ïû•Ï†êÏù¥ ÏûàÏäµÎãàÎã§ [1]. Ïù¥Îäî LangChainÏùò Îã§ÏñëÌïú ÌÜµÌï© ÎèÑÍµ¨ÏôÄ Í¥ÄÏ∏°ÏÑ± ÎèÑÍµ¨Î•º ÌôúÏö©ÌïòÏó¨ LangGraph Í∏∞Î∞ò ÏãúÏä§ÌÖúÏùÑ Î™®ÎãàÌÑ∞ÎßÅÌïòÍ≥† ÎîîÎ≤ÑÍπÖÌïòÎäî Îç∞ Ïö©Ïù¥ÌïòÎã§Îäî Í≤ÉÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§. LangChainÏùò Î∞©ÎåÄÌïú Î¶¨ÏÜåÏä§Î•º ÌôúÏö©ÌïòÏó¨ ÏóêÏù¥Ï†ÑÌä∏Ïùò Í∏∞Îä•ÏùÑ ÌôïÏû•ÌïòÍ≥†, Ïô∏Î∂Ä Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ÏôÄÏùò Ïó∞ÎèôÏùÑ Í∞ÑÌé∏ÌïòÍ≤å Íµ¨ÌòÑÌï† Ïàò ÏûàÏäµÎãàÎã§.

**5. Î™®ÎìàÏÑ± Î∞è Ï†úÏñ¥ (CrewAI):**

CrewAIÎäî ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±, ÏûëÏóÖ Ï†ïÏùò, ÌîÑÎ°úÏÑ∏Ïä§ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Î™ÖÌôïÌïòÍ≤å Î∂ÑÎ¶¨ÌïòÎäî Î™®ÎìàÌòï ÎîîÏûêÏù∏ÏùÑ Ï±ÑÌÉùÌïòÍ≥† ÏûàÏäµÎãàÎã§ [1]. Ïù¥Îü¨Ìïú ÏÑ§Í≥ÑÎäî ÏãúÏä§ÌÖúÏùò Í∞Å Î∂ÄÎ∂ÑÏùÑ ÎèÖÎ¶ΩÏ†ÅÏúºÎ°ú Í∞úÎ∞úÌïòÍ≥† Ïú†ÏßÄÎ≥¥ÏàòÌï† Ïàò ÏûàÎèÑÎ°ù Ìï¥Ï§çÎãàÎã§. CrewAIÎäî ÎèÖÎ¶ΩÏ†ÅÏù∏ ÏóêÏù¥Ï†ÑÌä∏ ÌñâÎèôÏóê ÎåÄÌïú Îçî ÌÅ∞ Ïú†Ïó∞ÏÑ±Í≥º Ï†úÏñ¥Î†•ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1].

**6. ÏõåÌÅ¨ÌîåÎ°úÏö∞ Í¥ÄÎ¶¨ Î∞è ÏÉÅÌÉú Í¥ÄÎ¶¨ (LangGraph):**

LangGraphÎäî Í∑∏ÎûòÌîÑ Í∏∞Î∞ò ÏïÑÌÇ§ÌÖçÏ≤òÏôÄ ÎÇ¥Ïû•Îêú ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê ÎåÄÌïú ÏÑ∏Î∞ÄÌïú Ï†úÏñ¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§ [1]. Î≥µÏû°Ìïú Î∂ÑÍ∏∞ Î°úÏßÅÍ≥º ÏÉÅÌÉú Í∏∞Î∞ò Ïã§ÌñâÏùÑ ÏßÄÏõêÌïòÏó¨, Î∂ÑÏÇ∞ Ïª¥Ìì®ÌåÖ Î™®Îç∏ÏóêÏÑú ÏòÅÍ∞êÏùÑ ÏñªÏóàÏäµÎãàÎã§ [1]. LangGraphÎäî Î™ÖÏãúÏ†ÅÏù∏ ÏÉÅÌÉú Íµ¨Ï°∞ÏôÄ ÎèÖÎ¶ΩÏ†ÅÏù¥Í≥† Î™ÖÌôïÌïòÍ≤å Ï†ïÏùòÎêú ÎÖ∏ÎìúÎ•º Í∞ïÏ°∞Ìï©ÎãàÎã§ [1]. `create_react_agent`ÏôÄ Í∞ôÏùÄ Í∏∞Îä•ÏùÑ ÌÜµÌï¥ LangChain ÏÉùÌÉúÍ≥ÑÏôÄÏùò Ïó∞ÎèôÏùÑ Í∞ïÌôîÌï©ÎãàÎã§.

**7. Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖò Î∞è ÏÉÅÌÉú Í¥ÄÎ¶¨ (CrewAI):**

CrewAIÎäî Ïó≠Ìï†/ÏûëÏóÖ Ìï†Îãπ Î∞è Ï°∞Ï†ï Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÌåÄÏùò Í∞ÑÎã®Ìïú Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖòÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1]. ÏóêÏù¥Ï†ÑÌä∏ Ï°∞Ï†ïÏóê ÎåÄÌïú Î™ÖÌôïÌïú Í∞ùÏ≤¥ Íµ¨Ï°∞ (Agent, Crew, Task)ÏôÄ ÏõêÌôúÌïú ÏÉÅÌÉú Í¥ÄÎ¶¨Î•º Ï†úÍ≥µÌï©ÎãàÎã§ [1].

## Í¥ÄÎ†® ÏûêÎ£å Î∞è Ï∂úÏ≤ò

*   [1] [https://www.zenml.io/blog/langgraph-vs-crewai](https://www.zenml.io/blog/langgraph-vs-crewai)
*   [2] [https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72](https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72)
*   [3] [https://www.zams.com/blog/crewai-vs-langgraph](https://www.zams.com/blog/crewai-vs-langgraph)
*   [4] [https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/](https://developer.ibm.com/articles/awb-comparing-ai-agent-frameworks-crewai-langgraph-and-beeai/)

## Í≤∞Î°† Î∞è ÌèâÍ∞Ä

CrewAIÏôÄ LangGraphÎäî Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Íµ¨Ï∂ïÏùÑ ÏúÑÌïú ÏÑúÎ°ú Îã§Î•∏ Ï†ëÍ∑º Î∞©ÏãùÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§. CrewAIÎäî ÏÇ¨Ïö©ÌïòÍ∏∞ Ïâ¨Ïö¥ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ÏôÄ Îπ†Î•∏ ÏÑ§Ï†ï ÏÜçÎèÑÎ•º ÌÜµÌï¥ Îπ†Î•¥Í≤å ÌîÑÎ°úÌÜ†ÌÉÄÏûÖÏùÑ Ï†úÏûëÌïòÍ≥† Ïã§ÌóòÌïòÎäî Îç∞ Ï†ÅÌï©Ìï©ÎãàÎã§. Î∞òÎ©¥, LangGraphÎäî Î≥µÏû°Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Ï†ïÎ∞ÄÌïòÍ≤å Ï†úÏñ¥ÌïòÍ≥† Í¥ÄÎ¶¨Ìï¥Ïïº ÌïòÎäî ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóê Îçî Ï†ÅÌï©Ìï©ÎãàÎã§. LangChainÍ≥ºÏùò ÌÜµÌï©ÏùÄ LangGraphÏùò Îòê Îã§Î•∏ Í∞ïÎ†•Ìïú Ïû•Ï†êÏûÖÎãàÎã§.

Ïñ¥Îñ§ ÌîÑÎ†àÏûÑÏõåÌÅ¨Î•º ÏÑ†ÌÉùÌï†ÏßÄÎäî ÌîÑÎ°úÏ†ùÌä∏Ïùò ÏöîÍµ¨ ÏÇ¨Ìï≠Í≥º Í∞úÎ∞úÌåÄÏùò ÏàôÎ†®ÎèÑÏóê Îî∞Îùº Îã¨ÎùºÏßëÎãàÎã§. Í∞ÑÎã®Ìïú ÏûëÏóÖ ÏúÑÏûÑÍ≥º Îπ†Î•∏ Í∞úÎ∞úÏù¥ Ï§ëÏöîÌïòÎã§Î©¥ CrewAIÍ∞Ä Ï¢ãÏùÄ ÏÑ†ÌÉùÏù¥ Îê† Ïàò ÏûàÏäµÎãàÎã§. Î≥µÏû°Ìïú Î°úÏßÅÍ≥º ÎÜíÏùÄ ÏïàÏ†ïÏÑ±Ïù¥ ÏöîÍµ¨ÎêúÎã§Î©¥ LangGraphÎ•º Í≥†Î†§Ìï¥Ïïº Ìï©ÎãàÎã§. Í∂ÅÍ∑πÏ†ÅÏúºÎ°úÎäî Í∞Å ÌîÑÎ†àÏûÑÏõåÌÅ¨Ïùò Ïû•Îã®Ï†êÏùÑ Ï∂©Î∂ÑÌûà Ïù¥Ìï¥ÌïòÍ≥†, ÌîÑÎ°úÏ†ùÌä∏Ïùò Î™©ÌëúÏóê Í∞ÄÏû• Ï†ÅÌï©Ìïú ÎèÑÍµ¨Î•º ÏÑ†ÌÉùÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§. Îëê ÌîÑÎ†àÏûÑÏõåÌÅ¨ Î™®Îëê ÌôúÎ∞úÌïú Ïª§ÎÆ§ÎãàÌã∞Î•º Í∞ÄÏßÄÍ≥† ÏûàÏúºÎØÄÎ°ú, ÌïÑÏöîÌïú Í≤ΩÏö∞ ÏßÄÏõêÏùÑ Î∞õÍ±∞ÎÇò Ï†ïÎ≥¥Î•º Í≥µÏú†ÌïòÎäî Îç∞ Ïñ¥Î†§ÏõÄÏù¥ ÏóÜÏùÑ Í≤ÉÏûÖÎãàÎã§.
======================================================================


üìä Running benchmark: 2024ÎÖÑ Î∞úÌëúÎêú LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Í¥ÄÎ†® ÎÖºÎ¨∏Îì§ÏùÑ Î∂ÑÏÑùÌïòÍ≥† Ï£ºÏöî Ìä∏Î†åÎìúÎ•º ÏÑ§Î™ÖÌï¥...

üîé Clarify: Analyzing query...
   ‚îî‚îÄ Query: 2024ÎÖÑ Î∞úÌëúÎêú LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Í¥ÄÎ†® ÎÖºÎ¨∏Îì§ÏùÑ Î∂ÑÏÑùÌïòÍ≥† Ï£ºÏöî Ìä∏Î†åÎìúÎ•º ÏÑ§Î™ÖÌï¥Ï§ò
   ‚îî‚îÄ Status: üü¢ Clear
   ‚îî‚îÄ Analysis: The query asks for an analysis of research papers related to LLM-based agent systems published in 2024, with a focus on identifying and explaining the key trends. It is specific and contains enough context.
   ‚îî‚îÄ Topics: LLM-based agent systems, Research paper analysis, Trend analysis, 2024 publications
üìã Planner: Creating research plan for: 2024ÎÖÑ Î∞úÌëúÎêú LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Í¥ÄÎ†® ÎÖºÎ¨∏Îì§ÏùÑ Î∂ÑÏÑùÌïòÍ≥† Ï£ºÏöî Ìä∏Î†åÎìúÎ•º ÏÑ§Î™ÖÌï¥

üìã Planner: Generated 4 queries
   ‚îî‚îÄ Queries:
      [1] LLM based agent system papers 2024
      [2] Large language model agent trends 2024
      [3] Autonomous agents using LLMs research 2024
      [4] Recent advances in LLM agents 2024
   ‚îî‚îÄ Focus: Architecture of LLM agents, Applications of LLM agents, Limitations of current LLM agents, Training methods for LLM agents
üîç Searcher [1]: Searching for: LLM based agent system papers 2024

üîç Searcher: Found 5 results
   ‚îî‚îÄ URLs found:
      [1] https://arxiv.org/abs/2402.01680
      [2] https://dl.acm.org/doi/10.1145/3712003
      [3] https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html
      [4] https://arxiv.org/html/2408.02479v2
      [5] https://pmc.ncbi.nlm.nih.gov/articles/PMC12492978/
   ‚îî‚îÄ Snippets:
      ‚Ä¢ From: Taicheng Guo [view email]     (/abs/2402.01680v1) Sun, 21 Jan 2024 23:36:14 UTC (5,000 KB)    [v2] Fri, 19 Apr 2024 01:15:16 UTC (5,001 KB)  Full-text links:  ## Access Paper:  View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors   View PDF  HTML (experimental)  TeX Source  view license  Current browse context:  cs.CL  < prev")    |    next >")  new  |  recent  | 2024-02  Change to browse by: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate  > cs > arXiv:2402.01680  # Computer Science > Computation and Language  arXiv:2402.01680 (cs)  Submitted on 21 Jan 2024 ([v1), last revised 19 Apr 2024 (this version, v2)]  # Title:Large Language Model based Multi-Agents: A Survey of Progress and Challenges  Authors:Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang [...] > Abstract:Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of
      ‚Ä¢ November 2022, we limited our review to papers published after this date (exclusion criterion 6). Furthermore, we excluded papers unrelated to SE (exclusion criterion 7) and those that mention LMA systems only in discussions or as future work, without presenting experimental results (exclusion criterion 8). After the third phase, we identified 41 primary studies directly relevant to our research focus. The search process was conducted on November 14th, 2024. [...] The paper must be written in English.  ‚úì  The paper must have an accessible full text.  ‚úì  The paper must adopt LMA techniques to solve SE-related tasks.  The paper has less than five pages.  ‚úò  Duplicate papers or similar studies authored by the same authors.  ‚úò  Books, keynote records, panel summaries, technical reports, theses, tool demos papers, editorials  ‚úò  The paper is a literature review or survey.  ‚úò  The paper does not utilize LMA systems, e.g., using a single LLM agent.  ‚úò [...] ## 5 Research Agenda
      ‚Ä¢ # MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution  Wei Tao, Yucheng Zhou, Yanlin Wang, Wenqiang Zhang, Hongyu Zhang, Yu Cheng  Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track  Bibtex Paper  ## Abstract [...] the empirical findings, we propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution, MAGIS, consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, [...] In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code.Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by
üí≠ Think: Query: LLM based agent system papers 2024 | Found 5 results, 5 URLs. Key snippets: From: Taicheng Guo [view email]   
 (/abs/2402.01680v1) Sun, 21 Jan 2024 23:36:14 UTC (5,000 KB)  
  | November 2022, we limited our review to papers published after this date (exclusion criterion 6). Fu | # MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution

Wei Tao, Yucheng Zhou, Y. Assessment: Is this sufficient or need more specific search?

üìñ ContentReader: Reading 3 URLs
üìñ Read URL: https://arxiv.org/abs/2402.01680... (5331 chars)
   ‚îî‚îÄ [https://arxiv.org/abs/2402.01680]
      Preview: [2402.01680] Large Language Model based Multi-Agents: A Survey of Progress and Challenges Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2402.01680 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2402.01680 (cs) [Submitted on 21 Jan 2024 ( v1 ), last revised 19 Apr 2024 (this version, v2)] Title: Large Language Model based Multi-Agents: A Survey of Progress and Challenges Authors: Taicheng Guo , Xiuying Chen , Yaqi Wang , Ruidi Chang , Shichao Pei , Nitesh V. Chawla , Olaf Wiest , Xiangliang Zhang View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors View PDF HTML (experimental) Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents&#39; capacities? For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository, dedicated to outlining the research on LLM-based multi-agent systems. Comments: This work is ongoing and we welcome your contribution! Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) Cite as: arXiv:2402.01680 [cs.CL] &nbsp; (or arXiv:2402.01680v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2402.01680 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Taicheng Guo [ view email ] [v1] Sun, 21 Jan 2024 23:36:14 UTC (5,000 KB) [v2] Fri, 19 Apr 2024 01:15:16 UTC (5,001 KB) Full-text links: Access Paper: View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2024-02 Change to browse by: cs cs.AI cs.MA References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status
   ‚îî‚îÄ [https://dl.acm.org/doi/10.1145/3712003]
      Preview: Error: HTTP 403 for URL: https://dl.acm.org/doi/10.1145/3712003
üìñ Read URL: https://papers.nips.cc/paper_files/paper/2024/hash... (2168 chars)
   ‚îî‚îÄ [https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html]
      Preview: MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution NeurIPS Proceedings Search MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution Wei Tao, Yucheng Zhou, Yanlin Wang, Wenqiang Zhang, Hongyu Zhang, Yu Cheng Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Bibtex Paper Abstract In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code.Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by the empirical findings, we propose a novel LLM-based M ulti- A gent framework for G itHub I ssue re S olution, MAGIS , consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub issues, significantly outperforming the baselines.Specifically, MAGIS achieves an eight-fold increase in resolved ratio over the direct application of GPT-4, the advanced LLM. DOI 10.52202/079017-1647 Name Change Policy &times; Requests for name changes in the electronic proceedings will be accepted with no questions asked. However name changes may cause bibliographic tracking issues. Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings. Use the "Report an Issue" link to request a name change. Report an Issue &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp; Name Change Policy Do not remove: This comment is monitored to verify that the site is working properly
üî¨ Analyzer [1]: Analyzing 5 results, 3 contents

üî¨ Analyzer [1]: Analyzed 5 results, 3 contents
   ‚îî‚îÄ New findings:
      [1] A survey paper titled 'Large Language Model based Multi-Agents: A Survey of Progress and Challenges' was published in April 2024.
      [2] MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution was published in NeurIPS 2024.
      [3] LLMs are being integrated and transformed into LLM-based agents in Software Engineering (SE).
      [4] The number of papers collected on LLMs and LLM-based agents has increased from 2020 to 2024, as shown in Figure 1.
   ‚îî‚îÄ Decision: More research needed
   ‚îî‚îÄ Next query: LLM-based agent systems trends 2024
üîç Searcher [2]: Follow-up search for: LLM-based agent systems trends 2024

üîç Searcher: Found 5 results
   ‚îî‚îÄ URLs found:
      [1] https://www.ijcai.org/proceedings/2024/890
      [2] https://arxiv.org/html/2510.04023v1
      [3] https://blog.promptlayer.com/types-of-llm-agent/
      [4] https://arxiv.org/html/2503.04596v2
      [5] https://pmc.ncbi.nlm.nih.gov/articles/PMC12602188/
   ‚îî‚îÄ Snippets:
      ‚Ä¢ Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to their notable capabilities in planning and reasoning, LLMs have been utilized as autonomous agents for the automatic execution of various tasks. Recently, LLM-based agent systems have rapidly evolved from single-agent planning or decision-making to operating as multi-agent systems, enhancing their ability in complex problem-solving and world simulation. To offer an overview of this dynamic field, [...] we present this survey to offer an in-depth discussion on the essential aspects and challenges of LLM-based multi-agent (LLM-MA) systems. Our objective is to provide readers with an in-depth understanding of these key points: the domains and settings where LLM-MA systems operate or simulate; the profiling and communication methods of these agents; and the means by which these agents develop their skills. For those interested in delving into this field, we also summarize the commonly used
      ‚Ä¢ multi-agent systems, we refer readers to the work of Ke et al. (Ke et al., 2025). In the context of data science, LLM agents have been applied to tasks such as data exploration (Cheng et al., 2023), automated machine learning (Hassan et al., 2023), and visualization and reporting (Yu et al., 2024). The next section outlines how agent architectures have evolved from classical AI agents to modern LLM-based agents designed for complex reasoning and tool orchestration. [...] al., 2024). [...] problems across text, code, and multimodal inputs (Achiam et al., 2023; Liu et al., 2024). Leveraging these advancements, recent work has shifted from static prompting to LLM-powered agents that perform planning, reasoning, tool use, and interactive decision-making (Shen et al., 2023; Yao et al., 2023). To improve factual grounding and reduce hallucinations, many LLM-based agents incorporate retrieval-augmented generation (RAG), which conditions outputs on dynamically retrieved external
      ‚Ä¢ The future of LLM agents lies in their seamless integration into our daily lives. These advancements will transform LLM agents from tools into partners, enhancing human capabilities and enriching our interactions with technology.  ## Conclusion  The evolution in types of LLM agents marks a leap in artificial intelligence, promising to reshape how we interact with technology and automate tasks. [...] Unlike traditional chatbots, which are limited to predefined responses, LLM Agents can exhibit complex reasoning, maintain memory of past interactions, and adapt their behavior based on environmental feedback. This enables them to handle intricate tasks across various domains, from automating workflows to providing personalized assistance  ## Different Types of LLM Agents [...] Platform  -- Prompt Management  -- Evaluations  -- Observability  -- Dataset Management  -- Prompt Chaining  Docs  Blog  Case Studies  Careers  Log in  Contact Us  Contact Us   Log In  Back   # LLM Agents Explained: Types, Use Cases, and Future Trends  By Erich H.   Nov 21, 2024  type of LLM agent
üí≠ Think: Query: LLM-based agent systems trends 2024 | Found 5 results, 5 URLs. Key snippets: Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to t | multi-agent systems, we refer readers to the work of Ke et al. (Ke et al., 2025). In the context of  | The future of LLM agents lies in their seamless integration into our daily lives. These advanc. Assessment: Is this sufficient or need more specific search?

üìñ ContentReader: Reading 3 URLs
üìñ Read URL: https://www.ijcai.org/proceedings/2024/890... (2267 chars)
   ‚îî‚îÄ [https://www.ijcai.org/proceedings/2024/890]
      Preview: Large Language Model Based Multi-agents: A Survey of Progress and Challenges | IJCAI Navigation Home Conferences Future Conferences Past Conferences Proceedings IJCAI 2025 Proceedings All Proceedings Awards Trustees/officers Current trustees Trustees Elect IJCAI Secretariat IJCAI Sponsorship and Publicity Officers IJCAI Team Local Arrangements Chairs Former Trustees serving on the Executive Committee Other Former Officers AI Journal About About IJCAI Contact Information Large Language Model Based Multi-agents: A Survey of Progress and Challenges Large Language Model Based Multi-agents: A Survey of Progress and Challenges Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence Survey Track. Pages 8048-8057. https://doi.org/10.24963/ijcai.2024/890 PDF BibTeX Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to their notable capabilities in planning and reasoning, LLMs have been utilized as autonomous agents for the automatic execution of various tasks. Recently, LLM-based agent systems have rapidly evolved from single-agent planning or decision-making to operating as multi-agent systems, enhancing their ability in complex problem-solving and world simulation. To offer an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects and challenges of LLM-based multi-agent (LLM-MA) systems. Our objective is to provide readers with an in-depth understanding of these key points: the domains and settings where LLM-MA systems operate or simulate; the profiling and communication methods of these agents; and the means by which these agents develop their skills. For those interested in delving into this field, we also summarize the commonly used datasets or benchmarks. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository (github.com/taichengguo/LLM_MultiAgents_Survey_Papers), dedicated to outlining the research of LLM-MA research. Keywords: Natural Language Processing: NLP: Language models Agent-based and Multi-agent Systems: MAS: Other Copyright &copy; 2025,
üìñ Read URL: https://arxiv.org/html/2510.04023v1... (8015 chars)
   ‚îî‚îÄ [https://arxiv.org/html/2510.04023v1]
      Preview: LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions 1 Introduction 2 Background 2.1 The Data Science Process and Automation 2.2 Large Language Models and LLM Agents 2.3 Architectures of LLM Agents 2.3.1 Core Modules of LLM-Based Agents 2.3.2 Design Dimensions. 2.4 From General Agents to Data Science Agents 2.4.1 Distinctive Characteristics of Data Science Agents Structured data proficiency. End-to-end lifecycle coverage. Deep tool orchestration. Collaboration and reflection. Trust, safety, and governance. 2.4.2 Illustrative Example: Fraud Detection Agent 2.5 Responsible AI Foundations for LLM Agents Agentic robustness. 3 Methodology 4 Taxonomy of Agentic AI Systems for Data Science 4.1 Lifecycle Stages (S1‚ÄìS6) 4.2 Cross-Cutting Design Attributes 5 Agentic Capabilities Across the Data Science Lifecycle 5.1 Business Understanding and Data Acquisition 5.2 Exploratory Data Analysis and Visualization 5.2.1 Domain Knowledge and Context-Aware Reasoning 5.2.2 Data Visualization 5.2.3 Multimodal Reasoning and Fusion in EDA 5.2.4 Interactive Analysis and Human‚ÄìAgent Collaboration 5.2.5 Reporting and Insight Generation 5.2.6 Trust and Safety in EDA 5.3 Feature Engineering (FE) 5.4 Model Building and Selection 5.4.1 Conventional Supervised Training and Selection 5.4.2 Reinforcement Learning and Preference Optimization for Agent Training RL and Preference-Based Alignment RL for Planning and Sequential Tool Use Multi-Agent Reinforcement Learning (MARL) 5.5 Interpretation and Explanation 5.6 Deployment and Monitoring 6 Evaluation and Benchmarking 6.1 Core Evaluation Dimensions 6.2 Functional vs. Process-Centric Evaluation 6.3 Benchmark Datasets and Frameworks 6.4 Evaluation Metrics and Key Performance Indicators (KPIs) Task Correctness. Pipeline-Level Success. Robustness and Reliability. Output Quality (Data, Visualization, and Models). Efficiency and Usability. 6.5 Human-in-the-Loop and Subjective Evaluation 6.6 Current Gaps in Evaluation 7 Open Challenges and Future Directions 7.1 Ambiguous Task Instruction 7.2 Limited Context Window 7.3 Security, Privacy, and Compliance 7.4 Trustworthiness, Reliability, and Alignment Building Trust and Transparency. Ensuring Reliability and Mitigating Hallucination. Achieving Human Aligned Behavior. 7.5 Robustness and Generalizability, 7.6 Benchmarking and Evaluation 7.7 Scalability and Efficiency 7.8 Societal, Ethical, and Economic Challenges 7.9 Multimodal Understanding and Reasoning 8 Conclusion \DocumentMetadata LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions Mizanur Rahman York University Toronto Canada mizanurr@yorku.ca , Amran Bhuiyan York University Canada amran.apece@gmail.com , Mohammed Saidul Islam York University Canada Vector Institute for AI Canada saidulis@yorku.ca , Md Tahmid Rahman Laskar York University Canada Dialpad Inc. Canada tahmid20@yorku.ca , Ridwan Mahbub York University Canada rmahbub@yorku.ca , Ahmed Masry York University Canada masry20@yorku.ca , Shafiq Joty Nanyang Technological University Singapore Salesforce AI Research USA shafiqrayhan@gmail.com and Enamul Hoque York University Canada enamulh@yorku.ca (2025) Abstract. Recent advances in large language models (LLMs) have enabled a new class of AI agents that automate multiple stages of the data science workflow by integrating planning, tool use, and multimodal reasoning across text, code, tables, and visuals. This survey presents the first comprehensive, lifecycle-aligned taxonomy of data science agents, systematically analyzing and mapping forty-five systems onto the six stages of the end-to-end data science process: business understanding and data acquisition, exploratory analysis and visualization, feature engineering, model building and selection, interpretation and explanation, and deployment and monitoring. In addition to lifecycle coverage, we annotate each agent along five cross-cutting design dimensions: reasoning and planning style, modality integration, tool orchestration depth, learning and alignment methods, and trust, safety, and governance mechanisms. Beyond classification, we provide a critical synthesis of agent capabilities, highlight strengths and limitations at each stage, and review emerging benchmarks and evaluation practices. Our analysis identifies three key trends: most systems emphasize exploratory analysis, visualization, and modeling while neglecting business understanding, deployment, and monitoring; multimodal reasoning and tool orchestration remain unresolved challenges; and over 90% lack explicit trust and safety mechanisms. We conclude by outlining open challenges in alignment stability, explainability, governance, and robust evaluation frameworks, and propose future research directions to guide the development of robust, trustworthy, low-latency, transparent, and broadly accessible data science agents. agentic AI, data science agents, multimodal models, reinforcement learning, large language models (LLMs), explainability, fairness, privacy, systematic review ‚Ä† ‚Ä† copyright: acmcopyright ‚Ä† ‚Ä† journalyear: 2025 ‚Ä† ‚Ä† doi: XXXXXXX.XXXXXXX ‚Ä† ‚Ä† journal: POMACS ‚Ä† ‚Ä† journalvolume: XX ‚Ä† ‚Ä† journalnumber: X ‚Ä† ‚Ä† article: XXX ‚Ä† ‚Ä† publicationmonth: 5 ‚Ä† ‚Ä† ccs: Agentic AI ‚Ä† ‚Ä† ccs: Data Science Agents 1. Introduction The growing demand for data-driven decision-making across industries has made data science an essential capability (Cao, 2017 ; Sarker, 2021 ) . However, realizing its full potential remains challenging due to steep skill barriers and the inherent complexity of end-to-end analytical workflows. Effective data science requires the seamless integration of expertise in business understanding, statistical analysis, data engineering, modeling, deployment, and visualization (Sarker, 2021 ) , a combination of skills rarely present within a single individual or even across many teams. This persistent expertise gap continues to limit the scalable adoption of data-driven practices, particularly among non-technical users who struggle to navigate the full analytical lifecycle from problem formulation to production deployment. Recent advances in Large Language Models (LLMs) are reshaping the landscape of data science by expanding their capabilities far beyond natural language understanding (Yang et al., 2024b ; Yu et al., 2024 ) . LLMs can ingest raw data, generate visualizations, perform statistical analyses, build predictive models, and produce deployment-ready code, all through natural language interactions (Cheng et al., 2023 ; Hassan et al., 2023 ) . These capabilities lower the entry barrier to advanced analytics and enable users without programming or machine learning expertise to engage with complex data science workflows. Leveraging these capabilities, researchers are increasingly developing autonomous agents, widely regarded as a pathway toward Artificial General Intelligence (AGI), that can reason, plan, and execute multi-step tasks. These agents are being applied across diverse domains, including software development (Hong et al., 2023 ) , data science (Zhang et al., 2024b ) , robotics (Kannan et al., 2024 ) , societal simulation (Guo et al., 2024a ) , policy modeling (Qian et al., 2024 ) , gaming (Plaat et al., 2025 ; Wang et al., 2024b ) , scientific discovery (Novikov et al., 2025 ) , and advanced mathematical problem solving at the International Mathematical Olympiad level (Castelvecchi, 2025 ) . Unlike traditional static systems, these agents decompose high-level objectives into subtasks, dynamically select and coordinate tools, and adapt their behavior based on intermediate feedback, thereby managing complex evolving, and long-horizon analytical workflows. A growing number of these agents are now being designed specifically for data science tasks, known as data science (DS) agents. Centered on LLMs and extended with external tools, they aim to support the full data science lifecycle, from business understanding and data acquisition to... [truncated]
üìñ Read URL: https://blog.promptlayer.com/types-of-llm-agent/... (8015 chars)
   ‚îî‚îÄ [https://blog.promptlayer.com/types-of-llm-agent/]
      Preview: 7 Types of LLM Agents: A Comprehensive Guide (2024) Platform -- Prompt Management -- Evaluations -- Observability -- Dataset Management -- Prompt Chaining Docs Blog Case Studies Careers Log in Contact Us Contact Us Log In Back LLM Agents Explained: Types, Use Cases, and Future Trends By &nbsp;Erich H. Nov 21, 2024 type of LLM agent Large Language Model (LLM) agents have rapidly evolved, becoming one of the hot topics in the tech industry. Initially designed for natural language processing tasks, LLMs can now serve as autonomous agents capable of complex decision-making and task execution. In this guide, we‚Äôll explore the basics of LLM Agents, their types (such as Conversational Agents, Task-Oriented Agents, Creative Agents, and more), real-world applications, and the emerging trends driving their evolution. Whether you're a tech enthusiast, a professional exploring AI, or someone curious about how these systems work, this guide will provide valuable insights into the ever-expanding world of LLM Agents. What are LLM Agents? LLM Agents are advanced AI systems that leverage large language models to autonomously perform tasks by interpreting inputs, planning actions, and executing them using integrated tools. Unlike traditional chatbots, which are limited to predefined responses, LLM Agents can exhibit complex reasoning, maintain memory of past interactions, and adapt their behavior based on environmental feedback. This enables them to handle intricate tasks across various domains, from automating workflows to providing personalized assistance Different Types of LLM Agents In 2024, Large Language Model (LLM) agents have diversified into specialized categories, each tailored to specific functionalities and applications. Here's an overview of the different types of LLM agents: 1. Conversational Agents These agents engage in natural dialogue with users, providing information, answering questions, and assisting with various tasks. They rely on LLMs to understand and generate human-like responses. Example : Customer support chatbots that handle inquiries and provide solutions. 2. Task-Oriented Agents Focused on performing specific tasks or achieving predefined objectives, these agents interact with users to understand their needs and then execute actions to fulfill those needs. Example : AI assistants that schedule appointments or manage emails. 3. Creative Agents Capable of generating original and creative content such as artwork, music, or writing, these agents use LLMs to understand human preferences and artistic styles, enabling them to produce content that resonates with audiences. Example : Content generation tools that draft articles or create digital art. 4. Collaborative Agents These agents work alongside humans to accomplish shared goals or tasks, facilitating communication, coordination, and cooperation between team members or between humans and machines. LLMs may support collaborative agents by assisting in decision-making, generating reports, or providing insights. Example: Project management bots that help teams coordinate tasks and deadlines. 5. Multimodal Agents Extending beyond text, multimodal agents process and generate content across various formats, including audio, images, and video. This capability allows for richer and more immersive interactions. Example: Virtual assistants that can interpret visual data or generate images based on textual descriptions. 6. Autonomous Agents Designed to operate with minimal human intervention, autonomous agents can make decisions and perform actions independently. They are often used in environments where continuous operation is essential. Example: Robotic process automation bots that handle repetitive tasks in business processes. 7. Multi-Agent Systems Involving multiple LLM agents working collaboratively, these systems tackle complex tasks by leveraging the strengths of various specialized agents. They communicate and coordinate to achieve common objectives. Example: A team of agents where one gathers data, another analyzes it, and a third generates reports based on the analysis. Understanding these categories helps in selecting the appropriate type of LLM agent for specific applications, ensuring optimal performance and user experience. üç∞ Interesting in building your own agents? PromptLayer provides the tools to manage and monitor prompts with your whole team.&nbsp; Get started here. Real-World Applications of LLM Agents LLM agents are now essential across industries, providing innovative solutions to complex challenges. Below are some notable real-world applications across different industries: Healthcare Clinical Decision Support : LLM agents assist healthcare professionals by analyzing patient data and medical literature to provide evidence-based treatment recommendations. For instance, Meditron, a Llama-based model, has been fine-tuned on clinical guidelines and medical research to enhance diagnostic accuracy and patient care. Patient Interaction : Virtual health assistants powered by LLMs engage with patients, offering personalized health advice, appointment scheduling, and medication reminders, thereby improving patient engagement and adherence to treatment plans. Finance Fraud Detection : Financial institutions employ LLM agents to monitor transactions and identify patterns indicative of fraudulent activities, enhancing security and trust in financial systems. Investment Analysis : LLM agents analyze vast financial datasets to provide insights into market trends, aiding investors in making informed decisions. They can generate comprehensive reports and forecasts based on real-time data. Education Personalized Learning : Educational platforms utilize LLM agents to create customized learning experiences, adapting content to individual student needs and learning styles. For example, AI tutors can simulate classroom interactions, providing tailored feedback and support. Content Creation : LLM agents assist educators in developing course materials, quizzes, and interactive content, streamlining the curriculum development process and ensuring content relevance. Legal Document Review : Law firms leverage LLM agents to analyze legal documents, contracts, and case law, expediting the review process and identifying critical information with high accuracy. Legal Research : LLM agents can quickly retrieve and summarize pertinent legal precedents and statutes, supporting attorneys in case preparation and strategy development. Customer Service Automated Support : Companies deploy LLM-powered chatbots to handle customer inquiries, providing instant responses and resolving common issues, thereby enhancing customer satisfaction and reducing operational costs.&nbsp; Sentiment Analysis : LLM agents analyze customer feedback to gauge sentiment, enabling businesses to address concerns proactively and improve their products or services. Media and Entertainment Content Generation : LLM agents are used to create scripts, articles, and marketing materials, assisting writers and marketers in generating creative content efficiently. Interactive Experiences : In gaming and virtual reality, LLM agents enable dynamic storytelling and character interactions, providing users with immersive and personalized experiences. Emerging Trends and Future Prospects As we look ahead, LLM agents are poised to move past traditional applications, embedding themselves into the very fabric of our daily lives. Beyond their current roles, these agents can become integral components of our personal and professional ecosystems, operating seamlessly and sometimes imperceptibly. Ambient Intelligence Integration Agents could be built into ambient intelligence systems, continuously monitoring and interpreting our environments to provide context-aware assistance. Imagine a workspace where an LLM agent autonomously organizes your schedule, drafts emails based on brief verbal cues, and anticipates your informational needs by proactively gathering r... [truncated]
üî¨ Analyzer [2]: Analyzing 5 results, 6 contents

üî¨ Analyzer [2]: Analyzed 5 results, 6 contents
   ‚îî‚îÄ New findings:
      [1] A survey paper titled 'Large Language Model based Multi-Agents: A Survey of Progress and Challenges' was published in April 2024.
      [2] MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution was published in NeurIPS 2024.
      [3] LLMs are being integrated and transformed into LLM-based agents in Software Engineering (SE).
      [4] LLM agents are evolving from single-agent systems to multi-agent systems, enhancing their problem-solving capabilities.
   ‚îî‚îÄ Decision: More research needed
   ‚îî‚îÄ Next query: 2024 LLM agent system trends
üîç Searcher [3]: Follow-up search for: 2024 LLM agent system trends

üîç Searcher: Found 5 results
   ‚îî‚îÄ URLs found:
      [1] https://blog.promptlayer.com/types-of-llm-agent/
      [2] https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue
      [3] https://thenewstack.io/top-5-ai-engineering-trends-of-2024/
      [4] https://astralinsights.ai/wp-content/uploads/2024/07/AI-Multi-Agent-LLM-MAS-Systems-July-2024.pdf
      [5] https://manusai.online/blog/llm-agents-research-2024
   ‚îî‚îÄ Snippets:
      ‚Ä¢ The future of LLM agents lies in their seamless integration into our daily lives. These advancements will transform LLM agents from tools into partners, enhancing human capabilities and enriching our interactions with technology.  ## Conclusion  The evolution in types of LLM agents marks a leap in artificial intelligence, promising to reshape how we interact with technology and automate tasks. [...] Future LLM agents could be developed with advanced emotional intelligence, enabling them to recognize and respond to human emotions with empathy. In customer service, for instance, an LLM agent could detect frustration in a client's tone and adjust its responses to de-escalate tension, providing a more personalized and human-like interaction. This emotional ability could extend to mental health applications, where agents offer supportive dialogues to individuals in need. [...] Large Language Model (LLM) agents have rapidly evolved, becoming one of the hot topics in the tech industry. Initially designed for natural language processing tasks, LLMs can now serve as autonomous agents capable of complex decision-making and task execution.  In this guide, we‚Äôll explore the basics of LLM Agents, their types (such as Conversational Agents, Task-Oriented Agents, Creative Agents, and more), real-world applications, and the emerging trends driving their evolution.
      ‚Ä¢ A significant trend observed in 2024 and continuing into 2025 is the strategic shift towards developing smaller, yet highly capable LLMs. Models such as TinyGPT, TinyGPT-V, and TinyLlama (1.1 billion parameters) exemplify this movement, demonstrating that high performance does not exclusively correlate with massive scale. This focus on efficiency is critical for broader accessibility and deployment, enabling LLMs to run effectively on devices with limited memory, such as mobile applications, [...] LLMs are increasingly being equipped with the ability to access and integrate real-time data, significantly enhancing their factual accuracy and reducing the phenomenon of "hallucinations"‚Äîthe generation of incorrect or nonsensical outputs. Tools like Microsoft Copilot leverage real-time internet access to validate answers, and future models are expected to include references and citations by default, raising the bar for accuracy and transparency. This capability allows LLMs to provide more [...] Simultaneously, the use of synthetic data for training LLMs is emerging as a transformative trend in 2025. Traditionally, LLM development has been constrained by the availability and quality of real-world data. Synthetic data, artificially generated yet representative of real-world patterns, addresses this limitation, enabling the creation of larger and more diverse training datasets. This not only accelerates development but also offers opportunities to mitigate biases present in real-world
      ‚Ä¢ This time last year, I wrote that AI engineering in 2023 was defined by a proliferation of LLMs and an expansion of AI dev tooling. In 2024, those trends continued ‚Äî but also the market for both LLMs and AI development tools matured considerably. This year, AI got integrated into the core tools of developers (IDEs), while new techniques for creating ‚ÄúAI agents‚Äù arose in secondary tools like LangChain and LlamaIndex. The types of LLMs available also became more varied, with smaller models and [...] Meanwhile, in a separate presentation at the World‚Äôs Fair, LlamaIndex creator Jerry Liu pitched agents as the natural successor to RAG (Retrieval-Augmented Generation), the most common method of integrating a pretrained LLM with an external data source. LlamaIndex calls its AI agents ‚Äúknowledge assistants,‚Äù perhaps to make them more enterprise-friendly.
üí≠ Think: Query: 2024 LLM agent system trends | Found 5 results, 5 URLs. Key snippets: The future of LLM agents lies in their seamless integration into our daily lives. These advancements | A significant trend observed in 2024 and continuing into 2025 is the strategic shift towards develop | This time last year, I wrote that AI engineering in 2023 was defined by a proliferation of LLM. Assessment: Is this sufficient or need more specific search?

üìñ ContentReader: Reading 3 URLs
üìñ Read URL: https://blog.promptlayer.com/types-of-llm-agent/... (8015 chars)
   ‚îî‚îÄ [https://blog.promptlayer.com/types-of-llm-agent/]
      Preview: 7 Types of LLM Agents: A Comprehensive Guide (2024) Platform -- Prompt Management -- Evaluations -- Observability -- Dataset Management -- Prompt Chaining Docs Blog Case Studies Careers Log in Contact Us Contact Us Log In Back LLM Agents Explained: Types, Use Cases, and Future Trends By &nbsp;Erich H. Nov 21, 2024 type of LLM agent Large Language Model (LLM) agents have rapidly evolved, becoming one of the hot topics in the tech industry. Initially designed for natural language processing tasks, LLMs can now serve as autonomous agents capable of complex decision-making and task execution. In this guide, we‚Äôll explore the basics of LLM Agents, their types (such as Conversational Agents, Task-Oriented Agents, Creative Agents, and more), real-world applications, and the emerging trends driving their evolution. Whether you're a tech enthusiast, a professional exploring AI, or someone curious about how these systems work, this guide will provide valuable insights into the ever-expanding world of LLM Agents. What are LLM Agents? LLM Agents are advanced AI systems that leverage large language models to autonomously perform tasks by interpreting inputs, planning actions, and executing them using integrated tools. Unlike traditional chatbots, which are limited to predefined responses, LLM Agents can exhibit complex reasoning, maintain memory of past interactions, and adapt their behavior based on environmental feedback. This enables them to handle intricate tasks across various domains, from automating workflows to providing personalized assistance Different Types of LLM Agents In 2024, Large Language Model (LLM) agents have diversified into specialized categories, each tailored to specific functionalities and applications. Here's an overview of the different types of LLM agents: 1. Conversational Agents These agents engage in natural dialogue with users, providing information, answering questions, and assisting with various tasks. They rely on LLMs to understand and generate human-like responses. Example : Customer support chatbots that handle inquiries and provide solutions. 2. Task-Oriented Agents Focused on performing specific tasks or achieving predefined objectives, these agents interact with users to understand their needs and then execute actions to fulfill those needs. Example : AI assistants that schedule appointments or manage emails. 3. Creative Agents Capable of generating original and creative content such as artwork, music, or writing, these agents use LLMs to understand human preferences and artistic styles, enabling them to produce content that resonates with audiences. Example : Content generation tools that draft articles or create digital art. 4. Collaborative Agents These agents work alongside humans to accomplish shared goals or tasks, facilitating communication, coordination, and cooperation between team members or between humans and machines. LLMs may support collaborative agents by assisting in decision-making, generating reports, or providing insights. Example: Project management bots that help teams coordinate tasks and deadlines. 5. Multimodal Agents Extending beyond text, multimodal agents process and generate content across various formats, including audio, images, and video. This capability allows for richer and more immersive interactions. Example: Virtual assistants that can interpret visual data or generate images based on textual descriptions. 6. Autonomous Agents Designed to operate with minimal human intervention, autonomous agents can make decisions and perform actions independently. They are often used in environments where continuous operation is essential. Example: Robotic process automation bots that handle repetitive tasks in business processes. 7. Multi-Agent Systems Involving multiple LLM agents working collaboratively, these systems tackle complex tasks by leveraging the strengths of various specialized agents. They communicate and coordinate to achieve common objectives. Example: A team of agents where one gathers data, another analyzes it, and a third generates reports based on the analysis. Understanding these categories helps in selecting the appropriate type of LLM agent for specific applications, ensuring optimal performance and user experience. üç∞ Interesting in building your own agents? PromptLayer provides the tools to manage and monitor prompts with your whole team.&nbsp; Get started here. Real-World Applications of LLM Agents LLM agents are now essential across industries, providing innovative solutions to complex challenges. Below are some notable real-world applications across different industries: Healthcare Clinical Decision Support : LLM agents assist healthcare professionals by analyzing patient data and medical literature to provide evidence-based treatment recommendations. For instance, Meditron, a Llama-based model, has been fine-tuned on clinical guidelines and medical research to enhance diagnostic accuracy and patient care. Patient Interaction : Virtual health assistants powered by LLMs engage with patients, offering personalized health advice, appointment scheduling, and medication reminders, thereby improving patient engagement and adherence to treatment plans. Finance Fraud Detection : Financial institutions employ LLM agents to monitor transactions and identify patterns indicative of fraudulent activities, enhancing security and trust in financial systems. Investment Analysis : LLM agents analyze vast financial datasets to provide insights into market trends, aiding investors in making informed decisions. They can generate comprehensive reports and forecasts based on real-time data. Education Personalized Learning : Educational platforms utilize LLM agents to create customized learning experiences, adapting content to individual student needs and learning styles. For example, AI tutors can simulate classroom interactions, providing tailored feedback and support. Content Creation : LLM agents assist educators in developing course materials, quizzes, and interactive content, streamlining the curriculum development process and ensuring content relevance. Legal Document Review : Law firms leverage LLM agents to analyze legal documents, contracts, and case law, expediting the review process and identifying critical information with high accuracy. Legal Research : LLM agents can quickly retrieve and summarize pertinent legal precedents and statutes, supporting attorneys in case preparation and strategy development. Customer Service Automated Support : Companies deploy LLM-powered chatbots to handle customer inquiries, providing instant responses and resolving common issues, thereby enhancing customer satisfaction and reducing operational costs.&nbsp; Sentiment Analysis : LLM agents analyze customer feedback to gauge sentiment, enabling businesses to address concerns proactively and improve their products or services. Media and Entertainment Content Generation : LLM agents are used to create scripts, articles, and marketing materials, assisting writers and marketers in generating creative content efficiently. Interactive Experiences : In gaming and virtual reality, LLM agents enable dynamic storytelling and character interactions, providing users with immersive and personalized experiences. Emerging Trends and Future Prospects As we look ahead, LLM agents are poised to move past traditional applications, embedding themselves into the very fabric of our daily lives. Beyond their current roles, these agents can become integral components of our personal and professional ecosystems, operating seamlessly and sometimes imperceptibly. Ambient Intelligence Integration Agents could be built into ambient intelligence systems, continuously monitoring and interpreting our environments to provide context-aware assistance. Imagine a workspace where an LLM agent autonomously organizes your schedule, drafts emails based on brief verbal cues, and anticipates your informational needs by proactively gathering r... [truncated]
üìñ Read URL: https://www.linkedin.com/pulse/evolving-landscape-... (8015 chars)
   ‚îî‚îÄ [https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue]
      Preview: The Evolving Landscape of Large Language Models (2024-2025) Agree & Join LinkedIn By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement , Privacy Policy , and Cookie Policy . Skip to main content LinkedIn Top Content People Learning Jobs Games Join now Sign in #Techfriday The Evolving Landscape of Large Language Models (2024-2025) Report this article Hahn Software Hahn Software Your expert for artificial intelligence and customised software | development, project management, data &amp; AI. Published Aug 1, 2025 + Follow I. Executive Summary The period spanning 2024 to 2025 marks a pivotal phase in the evolution of Large Language Models (LLMs), characterized by their rapid transition from specialized research tools to indispensable components in mainstream business applications. The global market for LLMs is experiencing exponential growth, valued at $6.4 billion in 2024 and projected to reach $36.1 billion by 2030, reflecting widespread enterprise adoption across sectors such as finance, healthcare, and technology. This expansion is driven by significant technological advancements, including the development of smaller, more efficient models, the widespread integration of multimodal capabilities, and a pronounced focus on reasoning-centric architectures. Concurrently, the increasing maturity of open-source LLMs is democratizing access and fostering innovation, while sophisticated fine-tuning techniques and the use of synthetic data are accelerating their production readiness. The impact of LLMs on software development is profound, transforming traditional methodologies and fostering new paradigms like "Vibe Coding." These AI-powered coding assistants are enhancing developer productivity, automating repetitive tasks, and improving code quality across the entire Software Development Lifecycle (SDLC). However, this rapid integration also brings critical considerations, including the persistent challenges of hallucinations, inherent biases, and the substantial environmental footprint associated with LLM training and inference. Addressing these concerns necessitates robust ethical frameworks, transparent development practices, and, crucially, sustained human oversight to ensure responsible and effective AI deployment. II. The Current State of Large Language Models A. Foundational Advancements and Market Growth The trajectory of Large Language Models has seen an unprecedented acceleration from academic curiosities to foundational enterprise technologies. The market's valuation underscores this shift, with a projected compound annual growth rate that highlights a significant investment and reliance on these systems. Enterprises are integrating LLMs to drive automation, extract deeper insights from vast datasets, and enhance customer interactions, moving beyond initial exploratory phases to advanced, integrated implementations within their core operations. This widespread adoption is a testament to the tangible value LLMs are delivering, from streamlining complex workflows to enabling entirely new forms of customer engagement. B. Key Technological Shifts The technological landscape of LLMs is undergoing dynamic transformations, pushing the boundaries of what these models can achieve and how they are deployed. The Rise of Smaller, More Efficient Models A significant trend observed in 2024 and continuing into 2025 is the strategic shift towards developing smaller, yet highly capable LLMs. Models such as TinyGPT, TinyGPT-V, and TinyLlama (1.1 billion parameters) exemplify this movement, demonstrating that high performance does not exclusively correlate with massive scale. This focus on efficiency is critical for broader accessibility and deployment, enabling LLMs to run effectively on devices with limited memory, such as mobile applications, low-power hardware, or in environments with constrained internet access. The emergence of sparse expert models, which activate only relevant parts of their network for specific tasks, further enhances speed and energy efficiency, optimizing resource utilization while maintaining robust performance. This development expands the practical utility of LLMs beyond large-scale data centers, opening avenues for on-device AI and edge computing. Mainstreaming of Multimodal AI Multimodal AI has transitioned from a specialized research area to a mainstream capability, profoundly impacting how users interact with AI systems. OpenAI's GPT-4o, released in May 2024, marked a significant milestone by enabling real-time understanding and response across text, images, and audio. This was quickly followed by similar advancements from other major players, including Google's Gemini 2.0 and Meta's LLaMA 3.2, and Anthropic's Claude 3.5 Sonnet. These models can process and generate content across various modalities, expanding AI's utility in creative tools, enhancing accessibility features, and revolutionizing customer service interactions. For instance, Google's Veo demo showcasing a knife slicing through fruit exemplifies the increasingly realistic and versatile nature of AI-generated video content. The ability to integrate and interpret diverse data types allows for more nuanced and comprehensive AI applications, mirroring human perception more closely. OpenAI's 4o image generation, which integrates text and visual creation into a unified system, allows for multi-turn generation where users can refine images conversationally, demonstrating a sophisticated interplay between language and visuals. Emphasis on Reasoning-Centric Architectures and Interpretability The evolution of LLMs is increasingly prioritizing sophisticated reasoning capabilities over mere pattern recognition. OpenAI's o1, released in December 2024, signaled a significant shift towards a "reasoning-first" architecture, emphasizing structured thinking for complex problem-solving. This focus addresses one of the long-standing challenges in AI: the ability to perform logical deduction and explain its decision-making process. Tools like SHAP, LIME, and attention visualization are gaining traction to help users understand how LLMs arrive at their conclusions, which is particularly crucial in high-stakes domains such as healthcare and finance where transparency and accountability are paramount. This move towards interpretability is not merely a technical refinement but a fundamental step towards building trust and enabling responsible deployment of AI systems. Research is actively challenging the simplified view that LLMs merely "predict the next word," revealing that these models may engage in far more complex internal reasoning and conceptual representation. Advancements in Fine-Tuning Techniques The efficiency and accessibility of deploying LLMs have been significantly bolstered by advancements in fine-tuning techniques. Methods such as prompt tuning and various hybrid approaches allow organizations to customize models for specific tasks without the prohibitive cost and time associated with retraining them from scratch. The integration of Automated Machine Learning (AutoML) further streamlines this process by automating decisions like hyperparameter selection, making fine-tuning more accessible to a broader range of developers and accelerating the journey from development to production readiness. These techniques enable rapid adaptation of general-purpose LLMs to specialized domains, unlocking new application possibilities and reducing development cycles. The Growing Influence of Open-Source LLMs Open-source LLMs have emerged as a powerful force, challenging the dominance of proprietary models and fostering a more collaborative and flexible development ecosystem. Models like Mistral, DeepSeek-V3, and Meta's LLaMA 3.2 have demonstrated strong performance while being publicly available, granting developers greater control and flexibility to build custom applications. This open approach encourages community collaboration, leading to continuous improvements in... [truncated]
üìñ Read URL: https://thenewstack.io/top-5-ai-engineering-trends... (8015 chars)
   ‚îî‚îÄ [https://thenewstack.io/top-5-ai-engineering-trends-of-2024/]
      Preview: Top 5 AI Engineering Trends of 2024 - The New Stack TNS OK SUBSCRIBE Join our community of software engineering leaders and aspirational developers. Always stay in-the-know by getting the most important news and exclusive content delivered fresh to your inbox to learn more about at-scale software development. EMAIL ADDRESS REQUIRED SUBSCRIBE RESUBSCRIPTION REQUIRED &nbsp; It seems that you've previously unsubscribed from our newsletter in the past. Click the button below to open the re-subscribe form in a new tab. When you're done, simply close that tab and continue with this form to complete your subscription. RE-SUBSCRIBE The New Stack does not sell your information or share it with unaffiliated third parties. By continuing, you agree to our Terms of Use and Privacy Policy . Welcome and thank you for joining The New Stack community! Please answer a few simple questions to help us deliver the news and resources you are interested in. FIRST NAME REQUIRED LAST NAME REQUIRED COMPANY NAME REQUIRED COUNTRY REQUIRED Select ... United States Canada India United Kingdom Germany France --- Afghanistan Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and Barbuda Argentina Armenia Aruba Asia/Pacific Region Australia Austria Azerbaijan Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bonaire, Sint Eustatius and Saba Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory Brunei Darussalam Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Chile China Christmas Island Cocos (Keeling) Islands Colombia Comoros Congo Congo, The Democratic Republic of the Cook Islands Costa Rica Croatia Cuba Cura√ßao Cyprus Czech Republic C√¥te d'Ivoire Denmark Djibouti Dominica Dominican Republic Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Ethiopia Falkland Islands (Malvinas) Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern Territories Gabon Gambia Georgia Germany Ghana Gibraltar Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-Bissau Guyana Haiti Heard Island and Mcdonald Islands Holy See (Vatican City State) Honduras Hong Kong Hungary Iceland India Indonesia Iran, Islamic Republic Of Iraq Ireland Isle of Man Israel Italy Jamaica Japan Jersey Jordan Kazakhstan Kenya Kiribati Korea, Republic of Kuwait Kyrgyzstan Laos Latvia Lebanon Lesotho Liberia Libyan Arab Jamahiriya Liechtenstein Lithuania Luxembourg Macao Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia, Federated States of Moldova, Republic of Monaco Mongolia Montenegro Montserrat Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands Netherlands Antilles New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island North Korea North Macedonia Northern Mariana Islands Norway Oman Pakistan Palau Palestinian Territory, Occupied Panama Papua New Guinea Paraguay Peru Philippines Pitcairn Islands Poland Portugal Puerto Rico Qatar Reunion Romania Russian Federation Rwanda Saint Barth√©lemy Saint Helena Saint Kitts and Nevis Saint Lucia Saint Martin Saint Martin Saint Pierre and Miquelon Saint Vincent and the Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia Serbia and Montenegro Seychelles Sierra Leone Singapore Sint Maarten Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia and the South Sandwich Islands South Sudan Spain Sri Lanka Sudan Suriname Svalbard and Jan Mayen Swaziland Sweden Switzerland Syrian Arab Republic Taiwan Tajikistan Tanzania, United Republic of Thailand Timor-Leste Togo Tokelau Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu Uganda Ukraine United Arab Emirates United Kingdom United States United States Minor Outlying Islands Uruguay Uzbekistan Vanuatu Venezuela Vietnam Virgin Islands, British Virgin Islands, U.S. Wallis and Futuna Western Sahara Yemen Zambia Zimbabwe √Öland Islands ZIPCODE REQUIRED Great to meet you! Tell us a bit about your job so we can cover the topics you find most relevant. What is your job level? REQUIRED --> Select ... C-Level VP/Director Manager/Supervisor Mid Level or Senior Non-Managerial Staff Entry Level/Junior Staff Freelancer/Contractor Student/Intern Other ... Which of these most closely describes your job role? REQUIRED Select ... Developer/Software Engineer SysAdmin/Operations/SRE Architect Security Professional DevOps Engineer/Team Community Manager/Developer Advocate IT management, including CIO/CISO/CTO Business Development/Marketing/Sales Enthusiast/Hobbyist Other ... How many employees are in the organization you work with? REQUIRED Select ... Self-employed 2-10 11-50 51-250 251-1,000 1,001-10,000 > 10,000 I am not working What option best describes the type of organization you work for? REQUIRED Select ... ‚ÄúEnd user‚Äù organization that primarily uses IT products and services to support their business deliverables Hardware / software vendor or supplier Cloud service provider or managed service provider System integrator or IT consulting firm Other ... Which of the following best describes your organization's primary industry? REQUIRED Select ... Advertising/Marketing Aerospace/Aviation Agriculture Automotive Biotech/Pharmaceutical Business Services (accounting, consulting, etc.) Computers/Information Technology Construction Education Facilities/Service Industry Finance/Financial Services (banking, insurance, etc.) Government Healthcare Human Resources Legal Life sciences (biotech, pharmaceuticals, etc.) Manufacturing Media Non-profit Real Estate Retail/Consumer Goods Telecommunications Transportation/Logistics Travel/Hospitality/Entertainment Utility/Energy Other ... LINKEDIN PROFILE URL &nbsp; Welcome! We‚Äôre so glad you‚Äôre here. You can expect all the best TNS content to arrive Monday through Friday to keep you on top of the news and at the top of your game. What‚Äôs next? Check your inbox for a confirmation email where you can adjust your preferences and even join additional groups. Follow TNS on your favorite social media networks. --> Become a TNS follower on LinkedIn . Check out the latest featured and trending stories while you wait for your first TNS newsletter. PREV 1 of 2 NEXT VOXPOP As a JavaScript developer, what non-React tools do you use most often? &#10003; Angular 0% &#10003; Astro 0% &#10003; Svelte 0% &#10003; Vue.js 0% &#10003; Other 0% &#10003; I only use React 0% &#10003; I don't use JavaScript 0% Thanks for your opinion! Subscribe below to get the final results, published exclusively in our TNS Update newsletter: SUBMIT &nbsp; NEW! Try Stackie AI ARCHITECTURE Cloud Native Ecosystem Containers Databases Edge Computing Infrastructure as Code Linux Microservices Open Source Networking Storage ENGINEERING AI AI Engineering API Management Backend development Data Frontend Development Large Language Models Security Software Development WebAssembly OPERATIONS AI Operations CI/CD Cloud Services DevOps Kubernetes Observability Operations Platform Engineering PROGRAMMING C++ Developer tools Go Java JavaScript Programming Languages Python Rust TypeScript CHANNELS Podcasts Ebooks Events Webinars Newsletter TNS RSS Feeds THE NEW STACK About / Contact Sponsors Advertise With Us Contributions PODCASTS EBOOKS EVENTS WEBINARS NEWSLETTER CONTRIBUTE ARCHITECTURE ENGINEERING OPERATIONS PROGRAMMING Cloud Native Ecosystem Containers Databases Edge Computing Infrastructure as Code Linux Microservices Open Source Networking Storage Building a Cloud-to-Edge Architecture Across 40K Global Locations Nov 20th 2025 10:00am, by Vicki Walker Knative Has Finally Graduated From the CNCF Nov 12th 2025 3:00pm, by Steven J. Vaughan-Nichols Migrating VMs to Kubernetes: A Roadmap for Cloud Native Enterprises Nov 3rd 2025 5:07am, by Janakiram MSV Can the 50-Year-Old Actor Model Rescue Agentic AI? Oct 22nd 202... [truncated]
üî¨ Analyzer [3]: Analyzing 5 results, 9 contents

üî¨ Analyzer: Max iterations reached, proceeding to Writer

üî¨ Analyzer [3]: Analyzed 5 results, 9 contents
   ‚îî‚îÄ New findings:
      [1] A survey paper titled 'Large Language Model based Multi-Agents: A Survey of Progress and Challenges' was published in April 2024.
      [2] MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution was published in NeurIPS 2024.
      [3] LLMs are being integrated and transformed into LLM-based agents in Software Engineering (SE).
      [4] The number of papers collected on LLMs and LLM-based agents has increased from 2020 to 2024.
      [5] LLM agents are evolving from single-agent systems to multi-agent systems, enhancing their problem-solving capabilities.
   ‚îî‚îÄ Decision: Research complete (14 total findings)

üì¶ Compress: Compressing 14 findings, 9 contents
   ‚îî‚îÄ Compressed to 2170 chars (from ~5717 raw chars)
   ‚îî‚îÄ Sources cited: 8
   ‚îî‚îÄ Preview:
      ## Key Findings
      - LLMs are increasingly integrated into Software Engineering (SE) as LLM-based agents [3].
      - The number of papers on LLMs and LLM-based agents has increased from 2020 to 2024 [4].
      - LLM agents are evolving from single-agent systems to multi-agent systems [3].
      - Smaller, highly capable LLMs like TinyGPT, TinyGPT-V, and TinyLlama are being developed [4].
      - "Large Language Model based Multi-Agents: A Survey of Progress and Challenges" was published in April 2024 [2, 7].
      - MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution was published in NeurIPS 2024 [1].
      
      ## Detailed Information
      
      - **General Trends:** Large Language Models (LLMs) are being widely adopted and transformed into LLM-based agents within the field of Software Engineering (SE) [3]. There is a clear trend of increasing research interest in LLMs and LLM-based agents, demonstrated by the rising number of publications from 2020 to 2024 [4].
      
      - **Evolution of LLM Agents:** LLM agents are evolving from single-agent systems to more complex multi-agent systems, which enhances their ability to solve complex problems [3].
      
      - **Smaller LLMs:** A notable trend in 2024 is the development of smaller, yet highly capable LLMs, including models like TinyGPT, TinyGPT-V, and TinyLlama [4].
      
      - **Publications:**
          - A survey paper titled "Large Language Model based Multi-Agents: A Survey of Progress and Challenges" was published in April 2024 [2, 7].
          - "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution" was published in NeurIPS 2024 [1]. This framework addresses the challenges LLMs face in resolving GitHub issues, especially at the repository level.
      
      ## Sources
      [1] https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html
      [2] https://www.ijcai.org/proceedings/2024/890
      [3] https://arxiv.org/html/2510.04023v1
      [4] https://thenewstack.io/top-5-ai-engineering-trends-of-2024/
      [5] https://dl.acm.org/doi/10.1145/3712003
      [6] https://blog.promptlayer.com/types-of-llm-agent/
      [7] https://arxiv.org/abs/2402.01680
      [8] https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue

‚úçÔ∏è Writer: Composing response from 14 findings
   ‚îî‚îÄ Using compressed notes (2170 chars)

‚úçÔ∏è Writer: Generated response (3626 chars)
   ‚îî‚îÄ Sources used:
      [1] https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html
      [2] https://www.ijcai.org/proceedings/2024/890
      [3] https://arxiv.org/html/2510.04023v1
   ‚îî‚îÄ Response preview:
      ## ÌïµÏã¨ ÏöîÏïΩ
      
      2024ÎÖÑ LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Ïó∞Íµ¨Îäî ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ Î∂ÑÏïºÏóêÏÑú LLMÏùò ÌôúÏö© Ï¶ùÍ∞Ä, Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°úÏùò ÏßÑÌôî, Í∑∏Î¶¨Í≥† Îçî ÏûëÍ≥† Ìö®Ïú®Ï†ÅÏù∏ LLM Í∞úÎ∞úÏù¥ÎùºÎäî ÏÑ∏ Í∞ÄÏßÄ Ï£ºÏöî Ìä∏Î†åÎìúÎ•º Î≥¥Ïó¨Ï§ÄÎã§. Ïù¥Îü¨Ìïú Î∞úÏ†ÑÏùÄ GitHub Ïù¥Ïäà Ìï¥Í≤∞Í≥º Í∞ôÏùÄ Ïã§Ï†ú Î¨∏Ï†ú Ìï¥Í≤∞Ïóê LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò Ï†ÅÏö© Í∞ÄÎä•ÏÑ±ÏùÑ ÌôïÏû•ÌïòÍ≥† ÏûàÎã§.
      
      ## Ï£ºÏöî Î∞úÍ≤¨ ÏÇ¨Ìï≠
      
      *   ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ(SE) Î∂ÑÏïºÏóêÏÑú LLMÏù¥ LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏Î°ú ÌÜµÌï©ÎêòÎäî ÏÇ¨Î°ÄÍ∞Ä Ï¶ùÍ∞ÄÌïòÍ≥† ÏûàÎã§ [3].
      *   LLM Î∞è LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏Ïóê ÎåÄÌïú ÎÖºÎ¨∏ ÏàòÎäî 2020ÎÖÑÎ∂ÄÌÑ∞ 2024ÎÖÑÍπåÏßÄ Íæ∏Ï§ÄÌûà Ï¶ùÍ∞ÄÌïòÍ≥† ÏûàÎã§ [4].
      *   LLM ÏóêÏù¥Ï†ÑÌä∏Îäî Îã®Ïùº ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏóêÏÑú Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°ú ÏßÑÌôîÌïòÍ≥† ÏûàÎã§ [3].
      *   TinyGPT, TinyGPT-V Î∞è TinyLlamaÏôÄ Í∞ôÏù¥ ÏûëÏßÄÎßå Îõ∞Ïñ¥ÎÇú ÏÑ±Îä•ÏùÑ Í∞ÄÏßÑ LLMÏù¥ Í∞úÎ∞úÎêòÍ≥† ÏûàÎã§ [4].
      *   "Large Language Model based Multi-Agents: A Survey of Progress and Challenges"ÎùºÎäî ÏÑúÎ≤†Ïù¥ ÎÖºÎ¨∏Ïù¥ 2024ÎÖÑ 4ÏõîÏóê Î∞úÌëúÎêòÏóàÎã§ [2, 7].
      *   GitHub Ïù¥Ïäà Ìï¥Í≤∞ÏùÑ ÏúÑÌïú LLM Í∏∞Î∞ò Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÌîÑÎ†àÏûÑÏõåÌÅ¨Ïù∏ MAGISÍ∞Ä NeurIPS 2024Ïóê Î∞úÌëúÎêòÏóàÎã§ [1].
      
      ## ÏÉÅÏÑ∏ Î∂ÑÏÑù
      
      LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùÄ 2024ÎÖÑÏóê Îì§Ïñ¥ÏÑúÎ©¥ÏÑú ÎçîÏö± ÏÑ±ÏàôÌïòÍ≥† Îã§ÏñëÌïú ÌòïÌÉúÎ°ú Î∞úÏ†ÑÌïòÍ≥† ÏûàÎã§. Ï£ºÏöî Ìä∏Î†åÎìúÎ•º Ï§ëÏã¨ÏúºÎ°ú ÏÉÅÏÑ∏ÌïòÍ≤å Î∂ÑÏÑùÌïòÎ©¥ Îã§ÏùåÍ≥º Í∞ôÎã§.
      
      *   **ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ(SE) Î∂ÑÏïºÎ°úÏùò ÌôïÏû•:** LLMÏùÄ Îçî Ïù¥ÏÉÅ Îã®ÏàúÌïú ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ Î™®Îç∏Ïù¥ ÏïÑÎãå, SE Î∂ÑÏïºÏùò Îã§ÏñëÌïú Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÎäî ÎèÑÍµ¨Î°ú ÏûêÎ¶¨Îß§ÍπÄÌïòÍ≥† ÏûàÎã§ [3]. Ïù¥Îäî ÏΩîÎìú ÏÉùÏÑ±, Î≤ÑÍ∑∏ ÏàòÏ†ï, Î¨∏ÏÑú ÏûêÎèô ÏÉùÏÑ± Îì± Îã§ÏñëÌïú Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏùÑ ÌÜµÌï¥ ÎÇòÌÉÄÎÇòÍ≥† ÏûàÏúºÎ©∞, LLM ÏóêÏù¥Ï†ÑÌä∏Í∞Ä SE ÌîÑÎ°úÏÑ∏Ïä§Ïùò Ìö®Ïú®ÏÑ±ÏùÑ ÎÜíÏù¥Îäî Îç∞ Í∏∞Ïó¨ÌïòÍ≥† ÏûàÏùåÏùÑ Î≥¥Ïó¨Ï§ÄÎã§.
      
      *   **Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°úÏùò ÏßÑÌôî:** Ï¥àÍ∏∞ LLM ÏóêÏù¥Ï†ÑÌä∏Îäî Ï£ºÎ°ú Îã®Ïùº ÏóêÏù¥Ï†ÑÌä∏ ÌòïÌÉúÎ°ú ÏûëÎèôÌñàÏßÄÎßå, Î≥µÏû°Ìïú Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥ÏÑúÎäî Ïó¨Îü¨ ÏóêÏù¥Ï†ÑÌä∏ Í∞ÑÏùò ÌòëÏóÖÏù¥ ÌïÑÏàòÏ†ÅÏù¥Îã§. Îî∞ÎùºÏÑú, 2024ÎÖÑÏóêÎäî Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏóê ÎåÄÌïú Ïó∞Íµ¨Í∞Ä ÌôúÎ∞úÌïòÍ≤å ÏßÑÌñâÎêòÍ≥† ÏûàÏúºÎ©∞, Í∞Å ÏóêÏù¥Ï†ÑÌä∏Îäî ÌäπÏ†ï Ïó≠Ìï†ÏùÑ ÏàòÌñâÌïòÍ≥† ÏÑúÎ°ú ÌòëÎ†•ÌïòÏó¨ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÎäî Î∞©ÏãùÏúºÎ°ú Î∞úÏ†ÑÌïòÍ≥† ÏûàÎã§ [3]. Ïù¥Îü¨Ìïú ÏãúÏä§ÌÖúÏùÄ GitHub Ïù¥Ïäà Ìï¥Í≤∞ [1]Í≥º Í∞ôÏù¥ Î≥µÏû°ÌïòÍ≥† Îã§Îã®Í≥ÑÏùò ÏûëÏóÖÏóê Ï†ÅÌï©ÌïòÎã§.
      
      *   **ÏûëÍ≥† Ìö®Ïú®Ï†ÅÏù∏ LLM Í∞úÎ∞ú:** LLMÏùò ÌÅ¨Í∏∞Í∞Ä ÌÅ¥ÏàòÎ°ù ÏÑ±Îä•Ïù¥ Ìñ•ÏÉÅÎêòÎäî Í≤ΩÌñ•Ïù¥ ÏûàÏßÄÎßå, Ïó∞ÏÇ∞ ÏûêÏõê Î∞è ÎπÑÏö© Ï∏°Î©¥ÏóêÏÑú Î∂ÄÎã¥Ïù¥ ÌÅ¨Îã§. Îî∞ÎùºÏÑú, TinyGPT, TinyGPT-V, TinyLlamaÏôÄ Í∞ôÏù¥ ÏûëÏßÄÎßå Îõ∞Ïñ¥ÎÇú ÏÑ±Îä•ÏùÑ Í∞ÄÏßÑ LLM Í∞úÎ∞úÏù¥ Ï§ëÏöîÌïú Ìä∏Î†åÎìúÎ°ú Î∂ÄÏÉÅÌïòÍ≥† ÏûàÎã§ [4]. Ïù¥Îü¨Ìïú Î™®Îç∏ÏùÄ Ï†úÌïúÎêú ÏûêÏõêÏùÑ Í∞ÄÏßÑ ÌôòÍ≤ΩÏóêÏÑúÎèÑ Ìö®Í≥ºÏ†ÅÏúºÎ°ú ÏûëÎèôÌï† Ïàò ÏûàÏúºÎ©∞, LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò ÌôúÏö© Î≤îÏúÑÎ•º ÎÑìÌûàÎäî Îç∞ Í∏∞Ïó¨ÌïúÎã§.
      
      *   **Ïó∞Íµ¨ ÎèôÌñ•:** LLM ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏóê ÎåÄÌïú Ïó∞Íµ¨Îäî ÏñëÏ†Å, ÏßàÏ†ÅÏúºÎ°ú Î™®Îëê ÏÑ±Ïû•ÌïòÍ≥† ÏûàÎã§. "Large Language Model based Multi-Agents: A Survey of Progress and Challenges" [2, 7]ÏôÄ Í∞ôÏùÄ ÏÑúÎ≤†Ïù¥ ÎÖºÎ¨∏ÏùÄ Ìï¥Îãπ Î∂ÑÏïºÏùò Ïó∞Íµ¨ ÎèôÌñ•ÏùÑ Ï†ïÎ¶¨ÌïòÍ≥† Ìñ•ÌõÑ Ïó∞Íµ¨ Î∞©Ìñ•ÏùÑ Ï†úÏãúÌïòÎäî Îç∞ Ï§ëÏöîÌïú Ïó≠Ìï†ÏùÑ ÌïúÎã§. ÎòêÌïú, NeurIPSÏôÄ Í∞ôÏùÄ Ï†ÄÎ™ÖÌïú ÌïôÌöåÏóê "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution" [1]Í≥º Í∞ôÏùÄ Ïó∞Íµ¨ Í≤∞Í≥ºÍ∞Ä Î∞úÌëúÎêòÎäî Í≤ÉÏùÄ LLM ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏù¥ ÌïôÍ≥ÑÏóêÏÑúÎèÑ Ï§ëÏöîÌïú Ïó∞Íµ¨ Ï£ºÏ†úÎ°ú Ïù∏Ï†ïÎ∞õÍ≥† ÏûàÏùåÏùÑ ÏùòÎØ∏ÌïúÎã§. MAGISÎäî LLMÏù¥ GitHub Ïù¥Ïäà Ìï¥Í≤∞Ïóê Ïñ¥Î†§ÏõÄÏùÑ Í≤™Îäî Î∂ÄÎ∂ÑÏùÑ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°ú Í∑πÎ≥µÌïòÎ†§Îäî ÏãúÎèÑÎ°ú, Ïã§Ï†ú Î¨∏Ï†ú Ìï¥Í≤∞Ïóê LLM ÏóêÏù¥Ï†ÑÌä∏Î•º Ï†ÅÏö©Ìïú ÎåÄÌëúÏ†ÅÏù∏ ÏÇ¨Î°ÄÏù¥Îã§.
      
      ## Í¥ÄÎ†® ÏûêÎ£å Î∞è Ï∂úÏ≤ò
      
      *   [1] MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution: [https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html](https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html)
      *   [2] Large Language Model based Multi-Agents: A Survey of Progress and Challenges: [https://www.ijcai.org/proceedings/2024/890](https://www.ijcai.org/proceedings/2024/890)
      *   [3] LLMs are increasingly integrated into Software Engineering (SE) as LLM-based agents: [https://arxiv.org/html/2510.04023v1](https://arxiv.org/html/2510.04023v1)
      *   [4] Top 5 AI Engineering Trends of 2024: [https://thenewstack.io/top-5-ai-engineering-trends-of-2024/](https://thenewstack.io/top-5-ai-engineering-trends-of-2024/)
      *   [5] (Ï∂úÏ≤ò Ï†ïÎ≥¥ ÏóÜÏùå - ÏõêÎ≥∏ Î¨∏ÏÑúÏóê URL ÎàÑÎùΩ)
      *   [6] (Ï∂úÏ≤ò Ï†ïÎ≥¥ ÏóÜÏùå - ÏõêÎ≥∏ Î¨∏ÏÑúÏóê URL ÎàÑÎùΩ)
      *   [7] arXiv version of Large Language Model based Multi-Agents: A Survey of Progress and Challenges: [https://arxiv.org/abs/2402.01680](https://arxiv.org/abs/2402.01680)
      *   [8] (Ï∂úÏ≤ò Ï†ïÎ≥¥ ÏóÜÏùå - ÏõêÎ≥∏ Î¨∏ÏÑúÏóê URL ÎàÑÎùΩ)
      
      ## Í≤∞Î°† Î∞è ÌèâÍ∞Ä
      
      2024ÎÖÑ LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Ïó∞Íµ¨Îäî ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ Î∂ÑÏïºÏóêÏÑúÏùò ÌôúÏö© Í∞ÄÎä•ÏÑ±ÏùÑ ÌôïÏû•ÌïòÍ≥†, Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùÑ ÌÜµÌï¥ Î≥µÏû°Ìïú Î¨∏Ï†ú Ìï¥Í≤∞ Îä•Î†•ÏùÑ Ìñ•ÏÉÅÏãúÌÇ§Î©∞, ÏûëÍ≥† Ìö®Ïú®Ï†ÅÏù∏ LLM Í∞úÎ∞úÏùÑ ÌÜµÌï¥ ÌôúÏö© Î≤îÏúÑÎ•º ÎÑìÌûàÎäî Î∞©Ìñ•ÏúºÎ°ú ÏßÑÌñâÎêòÍ≥† ÏûàÎã§. Ïù¥Îü¨Ìïú Ìä∏Î†åÎìúÎäî LLM ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ïã§Ï†ú ÏÇ∞ÏóÖ ÌòÑÏû•ÏóêÏÑú ÎçîÏö± ÎÑêÎ¶¨ ÏÇ¨Ïö©Îê† Ïàò ÏûàÎèÑÎ°ù Í∏∞Ïó¨Ìï† Í≤ÉÏúºÎ°ú ÏòàÏÉÅÎêúÎã§.
      
      Ìñ•ÌõÑ Ïó∞Íµ¨Îäî Îã§ÏùåÍ≥º Í∞ôÏùÄ Î∞©Ìñ•ÏúºÎ°ú ÏßÑÌñâÎê† ÌïÑÏöîÍ∞Ä ÏûàÎã§.
      
      *   **Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùò ÌòëÏóÖ Ï†ÑÎûµ:** Îã§ÏñëÌïú Ïó≠Ìï†ÏùÑ Í∞ÄÏßÑ ÏóêÏù¥Ï†ÑÌä∏Îì§Ïù¥ Ìö®Í≥ºÏ†ÅÏúºÎ°ú ÌòëÎ†•ÌïòÍ≥† Ï†ïÎ≥¥Î•º Í≥µÏú†ÌïòÎäî Ï†ÑÎûµÏóê ÎåÄÌïú Ïó∞Íµ¨Í∞Ä ÌïÑÏöîÌïòÎã§.
      *   **LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïã†Î¢∞ÏÑ± Î∞è ÏïàÏ†ïÏÑ± ÌôïÎ≥¥:** LLMÏùÄ ÎïåÎïåÎ°ú ÏûòÎ™ªÎêú Ï†ïÎ≥¥Î•º ÏÉùÏÑ±ÌïòÍ±∞ÎÇò ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•òÎ•º Î∞úÏÉùÏãúÌÇ¨ Ïàò ÏûàÏúºÎØÄÎ°ú, LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïã†Î¢∞ÏÑ± Î∞è ÏïàÏ†ïÏÑ±ÏùÑ ÌôïÎ≥¥ÌïòÍ∏∞ ÏúÑÌïú Ïó∞Íµ¨Í∞Ä Ï§ëÏöîÌïòÎã§.
      *   **ÌäπÏ†ï ÎèÑÎ©îÏù∏Ïóê ÌäπÌôîÎêú LLM ÏóêÏù¥Ï†ÑÌä∏ Í∞úÎ∞ú:** ÌäπÏ†ï ÏÇ∞ÏóÖ Î∂ÑÏïº ÎòêÎäî Î¨∏Ï†ú ÏòÅÏó≠Ïóê ÏµúÏ†ÅÌôîÎêú LLM ÏóêÏù¥Ï†ÑÌä∏Î•º Í∞úÎ∞úÌïòÏó¨ Ïã§ÏßàÏ†ÅÏù∏ Ìö®Ïö©ÏÑ±ÏùÑ ÎÜíÏó¨Ïïº ÌïúÎã§.
      
      Ïù¥Îü¨Ìïú ÎÖ∏Î†•ÏùÑ ÌÜµÌï¥ LLM ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùÄ ÎçîÏö± Í∞ïÎ†•ÌïòÍ≥† Ïã†Î¢∞Ìï† Ïàò ÏûàÎäî ÎèÑÍµ¨Î°ú Î∞úÏ†ÑÌïòÏó¨, Îã§ÏñëÌïú Î∂ÑÏïºÏóêÏÑú ÌòÅÏã†Ï†ÅÏù∏ Î≥ÄÌôîÎ•º Ïù¥ÎÅåÏñ¥ÎÇº Ïàò ÏûàÏùÑ Í≤ÉÏù¥Îã§.

‚îå‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚îÇ Phase 4 Benchmark Result
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ Query: 2024ÎÖÑ Î∞úÌëúÎêú LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Í¥ÄÎ†® ÎÖºÎ¨∏Îì§ÏùÑ Î∂ÑÏÑùÌïòÍ≥† Ï£ºÏöî Ìä∏Î†åÎìúÎ•º ÏÑ§Î™ÖÌï¥Ï§ò...
‚îÇ Time: 35.55s
‚îÇ LLM Calls: 2
‚îÇ Search Calls: 3
‚îÇ URLs Read: 9
‚îÇ Iterations: 3
‚îÇ Est. Tokens: 1347
‚îÇ Response Length: 3626 chars
‚îÇ Has Citations: ‚úÖ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


======================================================================
üìÑ FULL RESPONSE:
======================================================================
## ÌïµÏã¨ ÏöîÏïΩ

2024ÎÖÑ LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Ïó∞Íµ¨Îäî ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ Î∂ÑÏïºÏóêÏÑú LLMÏùò ÌôúÏö© Ï¶ùÍ∞Ä, Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°úÏùò ÏßÑÌôî, Í∑∏Î¶¨Í≥† Îçî ÏûëÍ≥† Ìö®Ïú®Ï†ÅÏù∏ LLM Í∞úÎ∞úÏù¥ÎùºÎäî ÏÑ∏ Í∞ÄÏßÄ Ï£ºÏöî Ìä∏Î†åÎìúÎ•º Î≥¥Ïó¨Ï§ÄÎã§. Ïù¥Îü¨Ìïú Î∞úÏ†ÑÏùÄ GitHub Ïù¥Ïäà Ìï¥Í≤∞Í≥º Í∞ôÏùÄ Ïã§Ï†ú Î¨∏Ï†ú Ìï¥Í≤∞Ïóê LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò Ï†ÅÏö© Í∞ÄÎä•ÏÑ±ÏùÑ ÌôïÏû•ÌïòÍ≥† ÏûàÎã§.

## Ï£ºÏöî Î∞úÍ≤¨ ÏÇ¨Ìï≠

*   ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ(SE) Î∂ÑÏïºÏóêÏÑú LLMÏù¥ LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏Î°ú ÌÜµÌï©ÎêòÎäî ÏÇ¨Î°ÄÍ∞Ä Ï¶ùÍ∞ÄÌïòÍ≥† ÏûàÎã§ [3].
*   LLM Î∞è LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏Ïóê ÎåÄÌïú ÎÖºÎ¨∏ ÏàòÎäî 2020ÎÖÑÎ∂ÄÌÑ∞ 2024ÎÖÑÍπåÏßÄ Íæ∏Ï§ÄÌûà Ï¶ùÍ∞ÄÌïòÍ≥† ÏûàÎã§ [4].
*   LLM ÏóêÏù¥Ï†ÑÌä∏Îäî Îã®Ïùº ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏóêÏÑú Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°ú ÏßÑÌôîÌïòÍ≥† ÏûàÎã§ [3].
*   TinyGPT, TinyGPT-V Î∞è TinyLlamaÏôÄ Í∞ôÏù¥ ÏûëÏßÄÎßå Îõ∞Ïñ¥ÎÇú ÏÑ±Îä•ÏùÑ Í∞ÄÏßÑ LLMÏù¥ Í∞úÎ∞úÎêòÍ≥† ÏûàÎã§ [4].
*   "Large Language Model based Multi-Agents: A Survey of Progress and Challenges"ÎùºÎäî ÏÑúÎ≤†Ïù¥ ÎÖºÎ¨∏Ïù¥ 2024ÎÖÑ 4ÏõîÏóê Î∞úÌëúÎêòÏóàÎã§ [2, 7].
*   GitHub Ïù¥Ïäà Ìï¥Í≤∞ÏùÑ ÏúÑÌïú LLM Í∏∞Î∞ò Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÌîÑÎ†àÏûÑÏõåÌÅ¨Ïù∏ MAGISÍ∞Ä NeurIPS 2024Ïóê Î∞úÌëúÎêòÏóàÎã§ [1].

## ÏÉÅÏÑ∏ Î∂ÑÏÑù

LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùÄ 2024ÎÖÑÏóê Îì§Ïñ¥ÏÑúÎ©¥ÏÑú ÎçîÏö± ÏÑ±ÏàôÌïòÍ≥† Îã§ÏñëÌïú ÌòïÌÉúÎ°ú Î∞úÏ†ÑÌïòÍ≥† ÏûàÎã§. Ï£ºÏöî Ìä∏Î†åÎìúÎ•º Ï§ëÏã¨ÏúºÎ°ú ÏÉÅÏÑ∏ÌïòÍ≤å Î∂ÑÏÑùÌïòÎ©¥ Îã§ÏùåÍ≥º Í∞ôÎã§.

*   **ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ(SE) Î∂ÑÏïºÎ°úÏùò ÌôïÏû•:** LLMÏùÄ Îçî Ïù¥ÏÉÅ Îã®ÏàúÌïú ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ Î™®Îç∏Ïù¥ ÏïÑÎãå, SE Î∂ÑÏïºÏùò Îã§ÏñëÌïú Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÎäî ÎèÑÍµ¨Î°ú ÏûêÎ¶¨Îß§ÍπÄÌïòÍ≥† ÏûàÎã§ [3]. Ïù¥Îäî ÏΩîÎìú ÏÉùÏÑ±, Î≤ÑÍ∑∏ ÏàòÏ†ï, Î¨∏ÏÑú ÏûêÎèô ÏÉùÏÑ± Îì± Îã§ÏñëÌïú Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏùÑ ÌÜµÌï¥ ÎÇòÌÉÄÎÇòÍ≥† ÏûàÏúºÎ©∞, LLM ÏóêÏù¥Ï†ÑÌä∏Í∞Ä SE ÌîÑÎ°úÏÑ∏Ïä§Ïùò Ìö®Ïú®ÏÑ±ÏùÑ ÎÜíÏù¥Îäî Îç∞ Í∏∞Ïó¨ÌïòÍ≥† ÏûàÏùåÏùÑ Î≥¥Ïó¨Ï§ÄÎã§.

*   **Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°úÏùò ÏßÑÌôî:** Ï¥àÍ∏∞ LLM ÏóêÏù¥Ï†ÑÌä∏Îäî Ï£ºÎ°ú Îã®Ïùº ÏóêÏù¥Ï†ÑÌä∏ ÌòïÌÉúÎ°ú ÏûëÎèôÌñàÏßÄÎßå, Î≥µÏû°Ìïú Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥ÏÑúÎäî Ïó¨Îü¨ ÏóêÏù¥Ï†ÑÌä∏ Í∞ÑÏùò ÌòëÏóÖÏù¥ ÌïÑÏàòÏ†ÅÏù¥Îã§. Îî∞ÎùºÏÑú, 2024ÎÖÑÏóêÎäî Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏóê ÎåÄÌïú Ïó∞Íµ¨Í∞Ä ÌôúÎ∞úÌïòÍ≤å ÏßÑÌñâÎêòÍ≥† ÏûàÏúºÎ©∞, Í∞Å ÏóêÏù¥Ï†ÑÌä∏Îäî ÌäπÏ†ï Ïó≠Ìï†ÏùÑ ÏàòÌñâÌïòÍ≥† ÏÑúÎ°ú ÌòëÎ†•ÌïòÏó¨ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÎäî Î∞©ÏãùÏúºÎ°ú Î∞úÏ†ÑÌïòÍ≥† ÏûàÎã§ [3]. Ïù¥Îü¨Ìïú ÏãúÏä§ÌÖúÏùÄ GitHub Ïù¥Ïäà Ìï¥Í≤∞ [1]Í≥º Í∞ôÏù¥ Î≥µÏû°ÌïòÍ≥† Îã§Îã®Í≥ÑÏùò ÏûëÏóÖÏóê Ï†ÅÌï©ÌïòÎã§.

*   **ÏûëÍ≥† Ìö®Ïú®Ï†ÅÏù∏ LLM Í∞úÎ∞ú:** LLMÏùò ÌÅ¨Í∏∞Í∞Ä ÌÅ¥ÏàòÎ°ù ÏÑ±Îä•Ïù¥ Ìñ•ÏÉÅÎêòÎäî Í≤ΩÌñ•Ïù¥ ÏûàÏßÄÎßå, Ïó∞ÏÇ∞ ÏûêÏõê Î∞è ÎπÑÏö© Ï∏°Î©¥ÏóêÏÑú Î∂ÄÎã¥Ïù¥ ÌÅ¨Îã§. Îî∞ÎùºÏÑú, TinyGPT, TinyGPT-V, TinyLlamaÏôÄ Í∞ôÏù¥ ÏûëÏßÄÎßå Îõ∞Ïñ¥ÎÇú ÏÑ±Îä•ÏùÑ Í∞ÄÏßÑ LLM Í∞úÎ∞úÏù¥ Ï§ëÏöîÌïú Ìä∏Î†åÎìúÎ°ú Î∂ÄÏÉÅÌïòÍ≥† ÏûàÎã§ [4]. Ïù¥Îü¨Ìïú Î™®Îç∏ÏùÄ Ï†úÌïúÎêú ÏûêÏõêÏùÑ Í∞ÄÏßÑ ÌôòÍ≤ΩÏóêÏÑúÎèÑ Ìö®Í≥ºÏ†ÅÏúºÎ°ú ÏûëÎèôÌï† Ïàò ÏûàÏúºÎ©∞, LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò ÌôúÏö© Î≤îÏúÑÎ•º ÎÑìÌûàÎäî Îç∞ Í∏∞Ïó¨ÌïúÎã§.

*   **Ïó∞Íµ¨ ÎèôÌñ•:** LLM ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏóê ÎåÄÌïú Ïó∞Íµ¨Îäî ÏñëÏ†Å, ÏßàÏ†ÅÏúºÎ°ú Î™®Îëê ÏÑ±Ïû•ÌïòÍ≥† ÏûàÎã§. "Large Language Model based Multi-Agents: A Survey of Progress and Challenges" [2, 7]ÏôÄ Í∞ôÏùÄ ÏÑúÎ≤†Ïù¥ ÎÖºÎ¨∏ÏùÄ Ìï¥Îãπ Î∂ÑÏïºÏùò Ïó∞Íµ¨ ÎèôÌñ•ÏùÑ Ï†ïÎ¶¨ÌïòÍ≥† Ìñ•ÌõÑ Ïó∞Íµ¨ Î∞©Ìñ•ÏùÑ Ï†úÏãúÌïòÎäî Îç∞ Ï§ëÏöîÌïú Ïó≠Ìï†ÏùÑ ÌïúÎã§. ÎòêÌïú, NeurIPSÏôÄ Í∞ôÏùÄ Ï†ÄÎ™ÖÌïú ÌïôÌöåÏóê "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution" [1]Í≥º Í∞ôÏùÄ Ïó∞Íµ¨ Í≤∞Í≥ºÍ∞Ä Î∞úÌëúÎêòÎäî Í≤ÉÏùÄ LLM ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏù¥ ÌïôÍ≥ÑÏóêÏÑúÎèÑ Ï§ëÏöîÌïú Ïó∞Íµ¨ Ï£ºÏ†úÎ°ú Ïù∏Ï†ïÎ∞õÍ≥† ÏûàÏùåÏùÑ ÏùòÎØ∏ÌïúÎã§. MAGISÎäî LLMÏù¥ GitHub Ïù¥Ïäà Ìï¥Í≤∞Ïóê Ïñ¥Î†§ÏõÄÏùÑ Í≤™Îäî Î∂ÄÎ∂ÑÏùÑ Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏúºÎ°ú Í∑πÎ≥µÌïòÎ†§Îäî ÏãúÎèÑÎ°ú, Ïã§Ï†ú Î¨∏Ï†ú Ìï¥Í≤∞Ïóê LLM ÏóêÏù¥Ï†ÑÌä∏Î•º Ï†ÅÏö©Ìïú ÎåÄÌëúÏ†ÅÏù∏ ÏÇ¨Î°ÄÏù¥Îã§.

## Í¥ÄÎ†® ÏûêÎ£å Î∞è Ï∂úÏ≤ò

*   [1] MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution: [https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html](https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html)
*   [2] Large Language Model based Multi-Agents: A Survey of Progress and Challenges: [https://www.ijcai.org/proceedings/2024/890](https://www.ijcai.org/proceedings/2024/890)
*   [3] LLMs are increasingly integrated into Software Engineering (SE) as LLM-based agents: [https://arxiv.org/html/2510.04023v1](https://arxiv.org/html/2510.04023v1)
*   [4] Top 5 AI Engineering Trends of 2024: [https://thenewstack.io/top-5-ai-engineering-trends-of-2024/](https://thenewstack.io/top-5-ai-engineering-trends-of-2024/)
*   [5] (Ï∂úÏ≤ò Ï†ïÎ≥¥ ÏóÜÏùå - ÏõêÎ≥∏ Î¨∏ÏÑúÏóê URL ÎàÑÎùΩ)
*   [6] (Ï∂úÏ≤ò Ï†ïÎ≥¥ ÏóÜÏùå - ÏõêÎ≥∏ Î¨∏ÏÑúÏóê URL ÎàÑÎùΩ)
*   [7] arXiv version of Large Language Model based Multi-Agents: A Survey of Progress and Challenges: [https://arxiv.org/abs/2402.01680](https://arxiv.org/abs/2402.01680)
*   [8] (Ï∂úÏ≤ò Ï†ïÎ≥¥ ÏóÜÏùå - ÏõêÎ≥∏ Î¨∏ÏÑúÏóê URL ÎàÑÎùΩ)

## Í≤∞Î°† Î∞è ÌèâÍ∞Ä

2024ÎÖÑ LLM Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖú Ïó∞Íµ¨Îäî ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ Î∂ÑÏïºÏóêÏÑúÏùò ÌôúÏö© Í∞ÄÎä•ÏÑ±ÏùÑ ÌôïÏû•ÌïòÍ≥†, Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùÑ ÌÜµÌï¥ Î≥µÏû°Ìïú Î¨∏Ï†ú Ìï¥Í≤∞ Îä•Î†•ÏùÑ Ìñ•ÏÉÅÏãúÌÇ§Î©∞, ÏûëÍ≥† Ìö®Ïú®Ï†ÅÏù∏ LLM Í∞úÎ∞úÏùÑ ÌÜµÌï¥ ÌôúÏö© Î≤îÏúÑÎ•º ÎÑìÌûàÎäî Î∞©Ìñ•ÏúºÎ°ú ÏßÑÌñâÎêòÍ≥† ÏûàÎã§. Ïù¥Îü¨Ìïú Ìä∏Î†åÎìúÎäî LLM ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ïã§Ï†ú ÏÇ∞ÏóÖ ÌòÑÏû•ÏóêÏÑú ÎçîÏö± ÎÑêÎ¶¨ ÏÇ¨Ïö©Îê† Ïàò ÏûàÎèÑÎ°ù Í∏∞Ïó¨Ìï† Í≤ÉÏúºÎ°ú ÏòàÏÉÅÎêúÎã§.

Ìñ•ÌõÑ Ïó∞Íµ¨Îäî Îã§ÏùåÍ≥º Í∞ôÏùÄ Î∞©Ìñ•ÏúºÎ°ú ÏßÑÌñâÎê† ÌïÑÏöîÍ∞Ä ÏûàÎã§.

*   **Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùò ÌòëÏóÖ Ï†ÑÎûµ:** Îã§ÏñëÌïú Ïó≠Ìï†ÏùÑ Í∞ÄÏßÑ ÏóêÏù¥Ï†ÑÌä∏Îì§Ïù¥ Ìö®Í≥ºÏ†ÅÏúºÎ°ú ÌòëÎ†•ÌïòÍ≥† Ï†ïÎ≥¥Î•º Í≥µÏú†ÌïòÎäî Ï†ÑÎûµÏóê ÎåÄÌïú Ïó∞Íµ¨Í∞Ä ÌïÑÏöîÌïòÎã§.
*   **LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïã†Î¢∞ÏÑ± Î∞è ÏïàÏ†ïÏÑ± ÌôïÎ≥¥:** LLMÏùÄ ÎïåÎïåÎ°ú ÏûòÎ™ªÎêú Ï†ïÎ≥¥Î•º ÏÉùÏÑ±ÌïòÍ±∞ÎÇò ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•òÎ•º Î∞úÏÉùÏãúÌÇ¨ Ïàò ÏûàÏúºÎØÄÎ°ú, LLM ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïã†Î¢∞ÏÑ± Î∞è ÏïàÏ†ïÏÑ±ÏùÑ ÌôïÎ≥¥ÌïòÍ∏∞ ÏúÑÌïú Ïó∞Íµ¨Í∞Ä Ï§ëÏöîÌïòÎã§.
*   **ÌäπÏ†ï ÎèÑÎ©îÏù∏Ïóê ÌäπÌôîÎêú LLM ÏóêÏù¥Ï†ÑÌä∏ Í∞úÎ∞ú:** ÌäπÏ†ï ÏÇ∞ÏóÖ Î∂ÑÏïº ÎòêÎäî Î¨∏Ï†ú ÏòÅÏó≠Ïóê ÏµúÏ†ÅÌôîÎêú LLM ÏóêÏù¥Ï†ÑÌä∏Î•º Í∞úÎ∞úÌïòÏó¨ Ïã§ÏßàÏ†ÅÏù∏ Ìö®Ïö©ÏÑ±ÏùÑ ÎÜíÏó¨Ïïº ÌïúÎã§.

Ïù¥Îü¨Ìïú ÎÖ∏Î†•ÏùÑ ÌÜµÌï¥ LLM ÏóêÏù¥Ï†ÑÌä∏ ÏãúÏä§ÌÖúÏùÄ ÎçîÏö± Í∞ïÎ†•ÌïòÍ≥† Ïã†Î¢∞Ìï† Ïàò ÏûàÎäî ÎèÑÍµ¨Î°ú Î∞úÏ†ÑÌïòÏó¨, Îã§ÏñëÌïú Î∂ÑÏïºÏóêÏÑú ÌòÅÏã†Ï†ÅÏù∏ Î≥ÄÌôîÎ•º Ïù¥ÎÅåÏñ¥ÎÇº Ïàò ÏûàÏùÑ Í≤ÉÏù¥Îã§.
======================================================================


üìä Running benchmark: RAG(Retrieval-Augmented Generation)ÏôÄ Agent Í∏∞Î∞ò Ï†ëÍ∑ºÎ≤ïÏùò...

üîé Clarify: Analyzing query...
   ‚îî‚îÄ Query: RAG(Retrieval-Augmented Generation)ÏôÄ Agent Í∏∞Î∞ò Ï†ëÍ∑ºÎ≤ïÏùò Ï∞®Ïù¥Ï†êÍ≥º Í∞ÅÍ∞Å Ïñ∏Ï†ú ÏÇ¨Ïö©ÌïòÎ©¥ Ï¢ãÏùÄÏßÄ ÏÑ§Î™ÖÌï¥Ï§ò
   ‚îî‚îÄ Status: üü¢ Clear
   ‚îî‚îÄ Analysis: The user is asking for a comparison between Retrieval-Augmented Generation (RAG) and Agent-based approaches, including when each is most appropriate to use. The query is specific and well-defined.
   ‚îî‚îÄ Topics: Retrieval-Augmented Generation, Agent-based approach
üìã Planner: Creating research plan for: RAG(Retrieval-Augmented Generation)ÏôÄ Agent Í∏∞Î∞ò Ï†ëÍ∑ºÎ≤ïÏùò

üìã Planner: Generated 5 queries
   ‚îî‚îÄ Queries:
      [1] RAG vs Agent-based approach
      [2] Retrieval-Augmented Generation vs Agent
      [3] When to use RAG vs Agent
      [4] RAG advantages and disadvantages
      [5] Agent-based approach advantages and disadvantages
   ‚îî‚îÄ Focus: Differences between RAG and Agent-based approaches, Use cases for RAG, Use cases for Agent-based approaches, Advantages and disadvantages of each approach
üîç Searcher [1]: Searching for: RAG vs Agent-based approach

üîç Searcher: Found 5 results
   ‚îî‚îÄ URLs found:
      [1] https://www.pingcap.com/article/agentic-rag-vs-traditional-rag-key-differences-benefits/
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
      [4] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [5] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
   ‚îî‚îÄ Snippets:
      ‚Ä¢ ### Traditional RAG vs Agentic RAG  The key differences between traditional RAG and agentic RAG center on agency, workflow, and adaptability. Traditional RAG uses a static workflow. It relies on predefined queries and structured input. Agentic RAG introduces autonomous AI agents that adjust prompts and strategies in real time. This agentic approach enables dynamic decision-making and iterative reasoning. [...] Agency and autonomy define the agentic RAG approach. Autonomous AI agents in agentic RAG decide which information to search and how to process it. They adjust prompts dynamically based on goals and context. This agentic capability allows for real-time adaptability. [...] | Approach | Traditional RAG | Agentic RAG |  ---  | Methodology | Reactive, relies on predefined queries | Proactive, autonomously determines needs | | Human Guidance | Requires explicit human guidance | Operates with minimal human intervention | | Adaptability | Limited adaptability | High adaptability, integrates diverse data | | Problem-Solving | Static information retrieval | Active problem-solving through dynamic retrieval |
      ‚Ä¢ Agentic RAG is an evolution of the traditional RAG system. While RAG systems combine retrieval with generation, Agentic RAG introduces agents that play a more active role in the process. These agents are intelligent entities that make decisions about which resources to retrieve, how to process the data, and how to generate the response. In Agentic RAG, the agent orchestrates the entire process, enabling more complex, multi-step tasks that require deeper reasoning, tool integration, and informed [...] RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant, context-aware information. Traditional RAG improves LLMs by connecting them to external data sources, while Agentic RAG goes a step further by adding intelligent agents that handle decisions and complex tasks. If the task is simple and query-based, traditional RAG is enough. However, for more complex, multi-step processes, Agentic RAG offers more flexibility, adaptability, and accuracy. As AI [...] Traditional RAG relies on a single retrieval system, such as a vector database, to retrieve relevant information.  Agentic RAG, however, is deeply integrated with multiple retrieval systems, and the agents dynamically choose which system to use based on the context and complexity of the query.  ### Context-Awareness:
      ‚Ä¢ Agentic RAG innovates the retrieval augmentation concept by broadening it from static, single-turn interactions to the multi-step context of autonomous agents. While RAG focuses on factual grounding, AI Agents provide planning capabilities and adaptability within complex environments. By integrating these two models, agentic RAG seeks to develop autonomous systems that efficiently navigate iterative decision-making tasks without experiencing hallucinations.
üí≠ Think: Query: RAG vs Agent-based approach | Found 5 results, 5 URLs. Key snippets: ### Traditional RAG vs Agentic RAG

The key differences between traditional RAG and agentic RAG cent | Agentic RAG is an evolution of the traditional RAG system. While RAG systems combine retrieval with  | Agentic RAG innovates the retrieval augmentation concept by broadening it from static, single-. Assessment: Is this sufficient or need more specific search?

üìñ ContentReader: Reading 3 URLs
üìñ Read URL: https://www.pingcap.com/article/agentic-rag-vs-tra... (8015 chars)
   ‚îî‚îÄ [https://www.pingcap.com/article/agentic-rag-vs-traditional-rag-key-differences-benefits/]
      Preview: Traditional RAG and Agentic RAG Key Differences Explained Product An open-source distributed SQL database trusted by innovators to power transactional, AI, and other modern applications. Product Overview Deployment Options TiDB Cloud TiDB Self-Managed Pricing Ecosystem Integrations TiKV TiSpark OSS Insight Solutions Customer Stories Trusted and verified by innovation leaders around the world. By Industry AI Fintech eCommerce SaaS By Use Case Lower Infrastructure Costs Enable Operational Intelligence Modernize MySQL Workloads Build GenAI Applications Resources Learn Blog eBooks &amp; Whitepapers Videos &amp; Replays Horizontal Scaling Engage Events &amp; Webinars Discord Community Developer Hub TiDB SCaiLE PingCAP University Courses Hands-on Labs Certifications Company Trust Hub Explore how TiDB ensures the confidentiality and availability of your data. About Press Releases &amp; News About Us Careers Partners Contact Us Docs Sign In Start for Free Product TiDB Overview --> An open-source distributed SQL database trusted by innovators to power transactional, AI, and other modern applications. Product Overview Deployment Options TiDB Cloud TiDB Self-Managed Pricing Ecosystem Integrations TiKV TiSpark OSS Insight Solutions Customer Stories Customer Stories --> Trusted and verified by innovation leaders around the world. By Industry AI Fintech eCommerce SaaS By Use Case Lower Infrastructure Costs Enable Operational Intelligence Modernize MySQL Workloads Build GenAI Applications Resources Learn Blog eBooks &amp; Whitepapers Videos &amp; Replays Horizontal Scaling Engage Events &amp; Webinars Discord Community Developer Hub TiDB SCaiLE PingCAP University Courses Hands-on Labs Certifications Company Trust Hub Trust Hub --> Explore how TiDB ensures the confidentiality and availability of your data. About Press Releases &amp; News About Us Careers Partners Contact Us Docs Sign In Start for Free Traditional RAG and Agentic RAG Key Differences Explained TiDB Team Traditional RAG uses a simpler workflow and suits static tasks. Agentic RAG offers greater adaptability and handles complex, multi-step queries. Industry experts note that traditional RAG works well for small applications with fixed FAQs. Agentic RAG fits evolving tasks and can dynamically use multiple knowledge sources. Choosing between these systems matters because selecting the right AI solution affects reliability, cost, and capability. Key Differences Traditional RAG vs Agentic RAG The key differences between traditional RAG and agentic RAG center on agency, workflow, and adaptability. Traditional RAG uses a static workflow. It relies on predefined queries and structured input. Agentic RAG introduces autonomous AI agents that adjust prompts and strategies in real time. This agentic approach enables dynamic decision-making and iterative reasoning. Approach Traditional RAG Agentic RAG Methodology Reactive, relies on predefined queries Proactive, autonomously determines needs Human Guidance Requires explicit human guidance Operates with minimal human intervention Adaptability Limited adaptability High adaptability, integrates diverse data Problem-Solving Static information retrieval Active problem-solving through dynamic retrieval Traditional RAG depends on human guidance. It cannot refine responses without manual intervention. Agentic RAG operates with minimal human input. Autonomous AI agents analyze context and user intent. They continuously re-evaluate information retrieval strategies. This agentic process enhances adaptability and performance. Agency and Autonomy Agency and autonomy define the agentic RAG approach. Autonomous AI agents in agentic RAG decide which information to search and how to process it. They adjust prompts dynamically based on goals and context. This agentic capability allows for real-time adaptability. Agentic RAG employs autonomous AI agents for dynamic decision-making. It enhances contextual understanding and adapts to changing user needs. Traditional RAG systems follow static workflows and lack the ability to refine responses. Agentic RAG continuously analyzes context and user intent, allowing for dynamic data retrieval. The key differences between traditional RAG and agentic RAG highlight the importance of agency, workflow flexibility, and adaptability. Agentic RAG leverages autonomous AI agents to deliver advanced reasoning and dynamic problem-solving. Traditional RAG provides reliable results for simple, static tasks but cannot match the agentic approach in complex scenarios. Retrieval-Augmented Generation Explained Retrieval-augmented generation (RAG) combines the strengths of information retrieval and natural language generation. This approach allows AI systems to fetch relevant data from external sources and generate coherent responses. The core features of RAG include a retrieval module and a generation module. These modules work together to improve the accuracy and relevance of ai outputs. Traditional RAG Features Traditional rag uses a straightforward workflow. The retrieval module identifies and fetches documents from a knowledge base using vector search and keyword matching. The generation module then combines this data with the original query to create a response. The augmentation step integrates retrieved information through document concatenation and embedding-based integration. The generation phase processes the augmented input using transformer architectures. Core Component Description Retrieval Module Identifies and fetches relevant documents from external sources based on a given query. Generation Module Combines retrieved data with the original input to synthesize a coherent response. Retrieval Process Involves searching through a knowledge base using vector search and keyword matching. Augmentation Step Integrates retrieved information with the original query through document concatenation and embedding-based integration. Generation Phase Processes the augmented input using transformer architectures and fine-tuning strategies for coherent responses. Traditional rag handles queries in a single pass. It relies on fixed retrieval strategies and limited context windows. Multi-step reasoning requires extra classifiers and models. In practical applications, AI teams use metrics like MRR, nDCG, Precision, Recall, and F1 to evaluate performance. For customer support, AI measures resolution rate and customer satisfaction. For sales enablement, ai tracks deal acceleration and content utilization. Agentic RAG Features Agentic rag introduces autonomy and adaptability. Autonomous AI agents identify missing elements and seek out information for task completion. They use dynamic information retrieval to access real-time data. Augmented generation integrates external information into contextually relevant responses. A feedback loop refines outputs based on user feedback, enabling continuous improvement. Autonomy: Agents identify and seek out missing elements for task completion. Dynamic Retrieval: Agents access real-time data for accurate outputs. Augmented Generation: Agents integrate external information into coherent responses. Feedback Loop: Agents refine responses based on feedback for continuous improvement. Agentic rag breaks queries into sub-queries and adapts retrieval strategies based on context. It excels at multi-step reasoning across documents. The system interacts with tools and databases without needing extra classifiers. Agentic rag demonstrates scalability by adjusting task granularity and scheduling tasks dynamically. Ai systems using agentic rag show enhanced responsiveness and robustness, even in complex environments. Benefits Traditional RAG Advantages Traditional RAG offers several advantages for organizations seeking reliable AI solutions. Teams often choose traditional rag for its simplicity and speed. The system uses a straightforward workflow, which reduces operational complexity. Many businesses find traditional rag cost-effective for sta... [truncated]
   ‚îî‚îÄ [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037]
      Preview: Error: HTTP 403 for URL: https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
üìñ Read URL: https://www.digitalocean.com/community/conceptual-... (8015 chars)
   ‚îî‚îÄ [https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis]
      Preview: RAG, AI Agents, and Agentic RAG: An In-Depth Review and Comparative Analysis | DigitalOcean Blog Docs Get Support Contact Sales DigitalOcean Products Featured Products Droplets Scalable virtual machines Kubernetes Scale more effectively Gradient‚Ñ¢ AI Agentic Cloud Build and scale with AI Cloudways Managed cloud hosting App Platform Get apps to market faster Managed Databases Fully-managed database hosting Compute Droplets Kubernetes CPU-Optimized Droplets Functions App Platform Gradient‚Ñ¢ AI Agentic Cloud GPU Droplets 1-Click Models Platform Bare Metal GPUs Backups &amp; Snapshots Backups Snapshots SnapShooter Networking Virtual Private Cloud (VPC) Partner Network Connect Cloud Firewalls Load Balancers DNS DDoS Protection Managed Databases MongoDB Kafka MySQL PostgreSQL Valkey OpenSearch Storage Spaces Object Storage Volume Block Storage Network File Storage Developer Tools API CLI Support Plans Monitoring Uptime Identity and Access Management Marketplace Droplet 1-Click Kubernetes 1-Click AI 1-Click Models Add-Ons Cloud Website Hosting Cloudways See all products Solutions AI and Machine Learning Develop, train, and deploy AI apps GPUs Platform 1-Click Models HR Knowledge Assistant Code Copilot Support Ticket Triage Recommendation Engine Blockchain Infrastructure for decentralized apps Blogs, Forums and Content Websites Lightning-fast, reliable CMS hosting Wordpress Ghost Mastodon Data Analytics Real-time data processing at scale Data Streaming AdTech &amp; Martech Kafka Developer Tools DevOps and CI/CD solutions CI/CD Prototyping Digital Marketing Agencies Power your clients‚Äô websites and campaigns Freelancer IT Consulting Ecommerce Build beautiful online storefronts Dropshipping WooCommerce Magento Game Development Low-latency multiplayer servers Minecraft Hosting IoT Connect to the power of the cloud Kafka ISVs Streamlined ISV application development Secure Web Hosting Powerful protection from DDoS and more Private VPN Startup Cloud Hosting Scalable, cost-effective infrastructure Small Business Video Streaming High-bandwidth, low-latency delivery Kafka Web and Mobile Apps Simple cross-platform app hosting cPanel Docker Next.js Node.js Website Hosting Fast page loads and reliable site uptime VPS Hosting Virtual Machines Get help Migration Assistance Talk to an expert See all solutions Developers Our Community Community Home DevOps and development guides CSS-Tricks All things web design The Wave Content to level up your business. Resources Tutorials Questions and Answers Marketplace Tools Write for DOnations Cloud Chats Customer Stories DigitalOcean Blog Pricing Calculator Get Involved DigitalOcean Startups Open Source Sponsorships Hacktoberfest Deploy 2025 Wavemakers Program Documentation Quickstart Compute Gradient‚Ñ¢ AI Platform Storage Managed Databases Containers Billing API Reference Partners DigitalOcean Partner Programs Become a Partner Partner Services Program DigitalOcean AI Partner Program Marketplace DigitalOcean Startups Connect with a Partner Partner Programs Resources Customer Stories DigitalOcean Onboarding Series Training for Agencies and Freelancers Price Estimate Calculator Featured Partner Articles Cloud cost optimization best practices Read more How to choose a cloud provider Read more DigitalOcean vs. AWS Lightsail: Which Cloud Platform is Right for You? Read more Questions? Talk to an expert Pricing Log in Log in to: Community DigitalOcean Sign up Sign up for: Community DigitalOcean Blog Docs Get Support Contact Sales Log in Log in to: Community DigitalOcean Sign up Sign up for: Community DigitalOcean Tutorials Questions Product Docs Cloud Chats Search Community Report this What is the reason for this report? This undefined is spam This undefined is offensive This undefined is off-topic This undefined is other Submit Table of contents Introduction Prerequisites Definition and Conceptual Overview of RAG Key Paradigms of RAG Modular RAG AI Agents Autonomy and Adaptability How ModelBased Reflex Agents Work Types of GoalBased Agents Strengths of GoalBased Agents Limitations of GoalBased Agents How UtilityBased Agents Work Strengths of UtilityBased Agents Limitations of UtilityBased Agents Understanding the AI Agents Stack Understanding MultiAgent Systems Using DigitalOceans GenAI Platform for AI Agent Development Agentic RAG The Synthesis of RetrievalAugmented Generation and Autonomy Strengths and Synergies Conclusion References Conceptual Articles AI/ML RAG, AI Agents, and Agentic RAG: An In-Depth Review and Comparative Analysis Conceptual Article RAG, AI Agents, and Agentic RAG: An In-Depth Review and Comparative Analysis Published on January 14, 2025 AI/ML Write for DO Write for DO By Adrien Payong and Shaoni Mukherjee Table of contents Popular topics Introduction AI is steadily progressing as scientists develop methods for knowledge sharing, information representation, reasoning, and decision-making. The Retrieval-Augmented Generation has recently attracted attention due to its capacity to ground large language models to external, up-to-date knowledge. In the meantime, AI agents ‚Äîintelligent software that can perceive and respond to their environment‚Äî are essential for tasks involving sequential decision-making, flexibility, and planning. As tasks become more complex, relying solely on one approach (RAG or AI agents) may not be enough. This has resulted in Agentic RAG , which merges RAG‚Äôs knowledge capabilities with AI agents‚Äô decision-making skills. This article thoroughly explores RAG, AI agents, and Agentic RAG, emphasizing their theoretical background, foundational principles, and use cases. Prerequisites Before exploring the complexities of AI Agents, Multi-Agent Systems, and the concept of Retrieval-Augmented Generation, it‚Äôs important to understand the following foundational elements: Fundamentals of Artificial Intelligence : Understanding key AI principles like machine learning and natural language processing. Retrieval-Augmented Generation : Insight into how RAG combines retrieval methods with generative models. Autonomous Systems : A fundamental understanding of the importance of autonomy in modern AI applications. Definition and Conceptual Overview of RAG Retrieval-augmented generation merges large language models with retrieval systems, grounding responses in external data instead of relying solely on the training parameters. Traditional LLMs, despite their power, often produce plausible but factually incorrect responses known as hallucinations. Integrating an external retrieval step allows RAG to fetch and add factual or contextual information. An application of the RAG system can be described in the diagram below: Image Source For example, if a user asks a large language model like ChatGPT about a trending news story, the model‚Äôs limitations become apparent. It relies on outdated, static information and cannot access real-time updates. RAG addresses this by drawing the latest relevant data from external sources. So, when a user inquires about a news story, RAG fetches the most recent articles or reports related to that question, which are combined with the original query to form a more informative prompt. This augmented prompt enables the language model to generate well-knowledgeable and accurate responses by integrating retrieved knowledge into its output. Consequently, RAG improves the model‚Äôs ability to deliver precise and timely information, especially in fields requiring real-time updates, like news, scientific advancements, or financial markets. Key Paradigms of RAG The RAG research model is undergoing important evolution, which can be categorized into three distinct phases: Naive RAG, Advanced RAG, and Modular RAG, as illustrated in the image below: Image Source Naive RAG: Initial Methods and Limitations The Naive Retrieval-Augmented Generation method represented the initial phase of retrieval-augmented techniques. It uses a straightforward pipeline consisting of: Indexing: Documents are divided into smaller... [truncated]
üî¨ Analyzer [1]: Analyzing 5 results, 3 contents

üî¨ Analyzer [1]: Analyzed 5 results, 3 contents
   ‚îî‚îÄ New findings:
      [1] Traditional RAG uses a static workflow with predefined queries, while Agentic RAG uses autonomous AI agents that adjust prompts and strategies in real time, enabling dynamic decision-making.
      [2] Agentic RAG introduces agents that actively manage information retrieval, integrating it into their reasoning process and refining queries.
      [3] Agentic RAG allows for complex, multi-step tasks requiring deeper reasoning and tool integration, whereas traditional RAG is simpler and faster.
      [4] Agentic RAG broadens the retrieval augmentation concept to multi-step interactions with autonomous agents.
   ‚îî‚îÄ Decision: More research needed
   ‚îî‚îÄ Next query: examples of when to use RAG vs Agentic RAG
üîç Searcher [2]: Follow-up search for: examples of when to use RAG vs Agentic RAG

üîç Searcher: Found 5 results
   ‚îî‚îÄ URLs found:
      [1] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [2] https://www.datacamp.com/blog/agentic-rag
      [3] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [4] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
      [5] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
   ‚îî‚îÄ Snippets:
      ‚Ä¢ RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant, context-aware information. Traditional RAG improves LLMs by connecting them to external data sources, while Agentic RAG goes a step further by adding intelligent agents that handle decisions and complex tasks. If the task is simple and query-based, traditional RAG is enough. However, for more complex, multi-step processes, Agentic RAG offers more flexibility, adaptability, and accuracy. As AI [...] 3. Generation: Finally, the LLM uses the augmented input to generate a response. The result is a more accurate and contextually relevant answer. [...] Traditional RAG relies on a single retrieval system, such as a vector database, to retrieve relevant information.  Agentic RAG, however, is deeply integrated with multiple retrieval systems, and the agents dynamically choose which system to use based on the context and complexity of the query.  ### Context-Awareness:
      ‚Ä¢ # Agentic RAG: How It Works, Use Cases, Comparison With RAG  Learn about Agentic RAG, an AI paradigm combining agentic AI and RAG for autonomous information access and generation.  Feb 12, 2025  ¬∑ 6 min read  Agentic RAG combines agentic AI‚Äôs decision-making with RAG‚Äôs ability to pull in dynamic data. This makes AI systems more independent, flexible, and capable of tackling real-world problems independently. [...] Beyond simply fetching information, autonomous agents can use agentic RAG to adapt their responses to the specific context of a customer's issue. For instance, if a customer is inquiring about a delayed order, the agent can not only provide the relevant shipping information but also proactively offer solutions such as expedited shipping or discounts. [...] In contrast, agentic RAG systems are designed to be proactive and autonomous. By continuously analyzing the context and user intent, agentic RAG systems can autonomously retrieve and integrate relevant information from diverse sources, including real-time data streams and external APIs. This proactive approach enables them to generate comprehensive and contextually relevant responses without requiring explicit human intervention.
      ‚Ä¢ Once we‚Äôve clarified your goals, we design and build using the framework that fits your current business readiness:   RAG ‚Üí When your priority is fast, accurate answers from internal data.  Example: A knowledge assistant trained on your HR policies or product manuals.   Agentic RAG ‚Üí When you need goal-driven, step-by-step reasoning with smart retrieval.  Example: A sales research agent that pulls competitive insights and drafts summaries. [...] Agentic RAG adds goal-driven reasoning to traditional RAG. RAG AI agents and Agentic RAG represent two stages of intelligent retrieval systems, starting with basic response generation and evolving into systems with planning and tool-use capabilities. [...] ## Which One Should You Use: RAG, Agentic RAG, or MCP?  Each of these approaches, RAG, Agentic RAG, and MCP, has clear strengths. The right choice depends on your business goals, technical capabilities, and the complexity of the tasks you‚Äôre trying to automate.  Let‚Äôs break it down by use case:  #### Use RAG if‚Ä¶
üí≠ Think: Query: examples of when to use RAG vs Agentic RAG | Found 5 results, 5 URLs. Key snippets: RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant, cont | # Agentic RAG: How It Works, Use Cases, Comparison With RAG

Learn about Agentic RAG, an AI paradigm | Once we‚Äôve clarified your goals, we design and build using the framework that fits your curren. Assessment: Is this sufficient or need more specific search?

üìñ ContentReader: Reading 3 URLs
   ‚îî‚îÄ [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037]
      Preview: Error: HTTP 403 for URL: https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
   ‚îî‚îÄ [https://www.datacamp.com/blog/agentic-rag]
      Preview: Error: HTTP 403 for URL: https://www.datacamp.com/blog/agentic-rag
üìñ Read URL: https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/... (8015 chars)
   ‚îî‚îÄ [https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/]
      Preview: RAG vs Agentic RAG vs MCP: A 2025 Comparison Guide for Business Leaders Skip to main content Get awesome and let's build together! +1 858-683-3692 Hit enter to search or ESC to close Close Search search Menu Services Web Development Full Stack Development SaaS Development Ruby on Rails Development Node.js Development React Development Angular Development Vue.js Development eCommerce Development PHP Development Firebase Development WordPress Development WooCommerce Development Shopify Development Shopify Apps Development Mobile App Development iOS App Development Android App Development Progressive Web Application React Native App Development Hybrid App Development Flutter App Development Roku App Development Apple tvOS App Development Apple WatchOS App Development Tablet App Development Google Tv App Development UX UI Services Enterprise Digital Transformation Web Data Extraction Scraping Big Data and Business Intelligence AWS Serverless Computing Robotic Process Automation AWS Cloud Computing AI &#038; Machine Learning Development DevOps Services Cloud Computing Services Business Software Development Software Development Partner Contentful Digital Agency Chia Blockchain farming Automation &#038; AI AI Development Services Power Platform Consulting Chatbot Development GenAI Integration Services AI Consulting Services AI Development with v0 &#038; Cursor Healthcare AI Agents AI Agent Development Workflow automation Services CMS &#038; eCommerce Identity &#038; Access Management Modern Data Stack Low Code Development Industries Healthcare Wound Care Software Development EHR/EMR Software Development HMO Automation Software Advance Imaging Software Solutions Telemedicine Software Development Services RPM Software Development Healthcare Mobile App Development Medical Device Software Development Life Sciences Software Development Healthcare Web Design &#038; Development Manufacturing Fitness FinTech Non-Profit eCommerce Retail Startups Our Work Solutions Cloud Solutions Cloud Application Development Custom Solutions Digital SMS/IVR Will Call with Twilio Digital Inspection Platform Digital Lending Platform Custom Software Development Marketplace Platform IoT Development Appointment Scheduling Software HME Software Development Business Software Solutions No-Code Solutions RPA Solution CRM Integrations Integrations Payment Gateway Google Calendar Integration Google Maps Integration OAuth Authentication Twilio API Integration OKTA Integration NetSuite Integration Salesforce API Integration SugarCRM &#038; SuiteCRM Integration VGS Integration Partner Hire Us Hire Mobile App Developer Hire Ruby on Rails Developer Hire Swift Developer Hire Full Stack Developer Hire Xamarin Developer Hire PHP Developer Hire Vue.js Developer Hire Angular JS Developer Hire React Developers Hire Node.js Developer Hire DevOps Engineer Blog Jumpstart My Project search RAG vs Agentic RAG vs MCP: A 2025 Comparison Guide for Business Leaders By Raj Sanghvi June 24, 2025 AI , Automation ChatGPT Perplexity Claude Social Facebook Twitter LinkedIn WhatsApp Email No Comments For business leaders exploring AI-powered solutions, terms like RAG, Agentic RAG, and MCP are now at the center of strategy discussions. But what do they actually mean, and which one is right for your organization? This guide cuts through the technical jargon and gets straight to the point: What are these AI frameworks? How do they differ in capabilities and complexity? Which is best suited for your goals? Whether you‚Äôre leading a digital transformation initiative or simply looking to make smarter decisions with AI, this side-by-side comparison of Retrieval-Augmented Generation (RAG), Agentic RAG, and the Model Context Protocol (MCP) will help you confidently choose the right approach. Let‚Äôs break it down. Contents hide 1 What Are RAG, Agentic RAG, and MCP? 1.1 RAG (Retrieval-Augmented Generation) 1.2 Agentic RAG 1.3 MCP (Model Context Protocol) 2 How RAG, Agentic RAG, and MCP Differ: Side-by-Side Comparison 3 Which One Should You Use: RAG, Agentic RAG, or MCP? 4 Why Bitcot is the Right Partner No Matter Which AI Framework You Choose 5 Final Thoughts 6 FAQs What Are RAG, Agentic RAG, and MCP? Before diving into comparisons, let‚Äôs define each approach in clear, business-relevant terms: what they are, what they do, and where they fit in real-world AI use cases. RAG (Retrieval-Augmented Generation) RAG enhances large language models (LLMs) by letting them ‚Äúlook things up.‚Äù Instead of relying only on what the model was trained on, RAG retrieves relevant documents or knowledge from an external source (like a database or vector store) before generating a response. Use it for: Chatbots that answer based on company knowledge. Customer service bots with access to FAQs and manuals. Sales reps that summarize case studies or product info on demand. Strength: High-accuracy answers using up-to-date, controlled content. Limitation: Passive; answers only what‚Äôs asked, no autonomy or reasoning. Agentic RAG Agentic RAG adds goal-driven reasoning to traditional RAG. RAG AI agents and Agentic RAG represent two stages of intelligent retrieval systems, starting with basic response generation and evolving into systems with planning and tool-use capabilities. This evolution introduces a layer of autonomy that RAG alone cannot achieve. Instead of just answering questions, the AI becomes an agent that can plan steps, retrieve multiple pieces of information over time, use tools (like web search or APIs), and reflect on progress toward a goal. Use it for: Research agents that proactively gather insights. Internal assistants that answer, verify, and summarize from multiple sources. Complex workflows where context evolves. Strength: Autonomy + search = more useful, more flexible. Limitation: Harder to control, test, or explain compared to simple RAG. RAG AI agents and Agentic RAG represent two stages of intelligent retrieval systems, starting with basic response generation and evolving into systems with planning and tool-use capabilities. This evolution introduces a layer of autonomy that RAG alone cannot achieve. MCP (Model Context Protocol) MCP is a framework for building modular, transparent, and fully autonomous AI agents. It organizes everything an agent needs, its memory, tools, instructions, and roles, into a reusable ‚Äúprotocol‚Äù that drives how it reasons, acts, and evolves. Use it for: Building AI agents with MCP that interact seamlessly with tools, data, and people. Agents that learn from feedback and adapt over time. Enterprise AI that‚Äôs structured, auditable, and explainable. Strength: Full agent control, modularity, and long-term memory. Limitation: Requires thoughtful design; best used when agents must act autonomously with accountability. How RAG, Agentic RAG, and MCP Differ: Side-by-Side Comparison The comparison of MCP vs RAG in AI highlights the progression from simple retrieval-based responses (RAG) to more dynamic, goal-oriented systems (Agentic RAG), and ultimately to MCP, offering long-term memory, autonomy, and multi-system integration. The table below makes it easy for you to see the trade-offs: RAG is best for quick wins with static content. Agentic RAG is a smart bridge when goal-based reasoning is needed. MCP is for building durable, intelligent systems with real decision-making power. Feature / Capability RAG Agentic RAG MCP Primary Function Answering questions using retrieved content Multi-step reasoning with goal-driven retrieval Building modular, fully autonomous agents Autonomy None Partial (task-focused) Full autonomy (reasoning + action) Memory Stateless Limited (per session/task) Persistent memory &amp; state tracking Use of Tools None Can use tools/APIs during reasoning Tool-using via structured interface Task Complexity Simple Q&amp;A Medium-complex (e.g., research, synthesis) High-complex (multi-tool, multi-step workflows) Best For Knowledge chatbots, FAQ bots Research agents, assistant-style tasks Enterprise agen... [truncated]
üî¨ Analyzer [2]: Analyzing 5 results, 6 contents

üî¨ Analyzer [2]: Analyzed 5 results, 6 contents
   ‚îî‚îÄ New findings:
      [1] Traditional RAG is suitable for simple, query-based tasks needing quick, accurate answers from internal data, like a knowledge assistant for HR policies.
      [2] Agentic RAG excels in complex, multi-step processes needing goal-driven reasoning and smart retrieval, exemplified by a sales research agent drafting summaries.
      [3] Agentic RAG combines agentic AI's decision-making with RAG's data retrieval, making AI systems more independent and flexible.
      [4] Agentic RAG development is motivated by use cases needing context-aware generation and real-time actions, like advanced robotics or legal advisory services.
      [5] Traditional RAG follows a simple query, retrieve, generate process and is generally faster and less expensive, while Agentic RAG involves dynamic agent queries, refinement, and context management.
   ‚îî‚îÄ Decision: Research complete (9 total findings)

üì¶ Compress: Compressing 9 findings, 6 contents
   ‚îî‚îÄ Compressed to 2495 chars (from ~4225 raw chars)
   ‚îî‚îÄ Sources cited: 5
   ‚îî‚îÄ Preview:
      ## Key Findings
      - Traditional RAG employs a static workflow with predefined queries, while Agentic RAG utilizes autonomous AI agents for dynamic adjustments [1], [5].
      - Agentic RAG integrates information retrieval into the reasoning process, refining queries and managing context actively [1], [3].
      - Agentic RAG is suitable for complex, multi-step tasks requiring deeper reasoning and tool integration, whereas traditional RAG is simpler and faster [1].
      - Agentic RAG combines agentic AI's decision-making with RAG's data retrieval, enhancing AI system independence and flexibility [1].
      
      ## Detailed Information
      
      **Core Differences:**
      
      Traditional RAG operates with a static workflow and predefined queries [1], [5]. In contrast, Agentic RAG uses autonomous AI agents that can dynamically adjust prompts and strategies in real time [1], [5]. This allows for more dynamic decision-making [1]. Agentic RAG broadens the concept of retrieval augmentation to include multi-step interactions managed by autonomous agents [1]. Traditional RAG follows a simple query, retrieve, generate process and is generally faster and less expensive than Agentic RAG [1]. Agentic RAG involves dynamic agent queries, refinement, and context management [1].
      
      **Agent Capabilities in Agentic RAG:**
      
      Agentic RAG actively manages information retrieval, integrating it into the agent's reasoning process and refining queries as needed [1], [3]. This approach enables more complex, multi-step tasks that demand deeper reasoning and the integration of various tools [1].
      
      **Use Case Suitability:**
      
      Traditional RAG is well-suited for simple, query-based tasks that require quick, accurate answers from internal data, such as a knowledge assistant for HR policies [1]. Agentic RAG excels in complex, multi-step processes that need goal-driven reasoning and intelligent retrieval, as exemplified by a sales research agent drafting summaries [1]. The development of Agentic RAG is driven by use cases that require context-aware generation and real-time actions, such as advanced robotics or legal advisory services [1].
      
      ## Sources
      [1] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
      [4] https://www.datacamp.com/blog/agentic-rag
      [5] https://www.pingcap.com/article/agentic-rag-vs-traditional-rag-key-differences-benefits/

‚úçÔ∏è Writer: Composing response from 9 findings
   ‚îî‚îÄ Using compressed notes (2495 chars)

‚úçÔ∏è Writer: Generated response (2719 chars)
   ‚îî‚îÄ Sources used:
      [1] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
   ‚îî‚îÄ Response preview:
      ## ÌïµÏã¨ ÏöîÏïΩ
      
      RAG (Retrieval-Augmented Generation)Îäî Ï†ïÎ≥¥ Í≤ÄÏÉâÏùÑ ÌÜµÌï¥ ÏÉùÏÑ± Î™®Îç∏Ïùò ÏÑ±Îä•ÏùÑ Ìñ•ÏÉÅÏãúÌÇ§Îäî Í∏∞Ïà†Ïù¥Î©∞, Agent Í∏∞Î∞ò Ï†ëÍ∑ºÎ≤ïÏùÄ ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÌôúÏö©ÌïòÏó¨ ÎçîÏö± ÎèôÏ†ÅÏù∏ Ï†ïÎ≥¥ Í≤ÄÏÉâ Î∞è Ï∂îÎ°†ÏùÑ Í∞ÄÎä•ÌïòÍ≤å Ìï©ÎãàÎã§. Agentic RAGÎäî Î≥µÏû°Ìïú ÏûëÏóÖÏóê, Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî Í∞ÑÎã®Ìïú ÏûëÏóÖÏóê Ï†ÅÌï©Ìï©ÎãàÎã§ [1].
      
      ## Ï£ºÏöî Î∞úÍ≤¨ ÏÇ¨Ìï≠
      
      *   Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî ÎØ∏Î¶¨ Ï†ïÏùòÎêú ÏøºÎ¶¨Î•º ÏÇ¨Ïö©ÌïòÎäî Ï†ïÏ†ÅÏù∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Îî∞Î•¥ÏßÄÎßå, Agentic RAGÎäî ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÏÇ¨Ïö©ÌïòÏó¨ Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÏøºÎ¶¨Î•º ÎèôÏ†ÅÏúºÎ°ú Ï°∞Ï†ïÌï©ÎãàÎã§ [1], [5].
      *   Agentic RAGÎäî Ï†ïÎ≥¥ Í≤ÄÏÉâÏùÑ Ï∂îÎ°† Í≥ºÏ†ïÏóê ÌÜµÌï©ÌïòÏó¨ ÏøºÎ¶¨Î•º Í∞úÏÑ†ÌïòÍ≥† Ïª®ÌÖçÏä§Ìä∏Î•º Îä•ÎèôÏ†ÅÏúºÎ°ú Í¥ÄÎ¶¨Ìï©ÎãàÎã§ [1], [3].
      *   Agentic RAGÎäî Ïã¨Ï∏µÏ†ÅÏù∏ Ï∂îÎ°†Í≥º ÎèÑÍµ¨ ÌÜµÌï©Ïù¥ ÌïÑÏöîÌïú Î≥µÏû°Ìïú Îã§Îã®Í≥Ñ ÏûëÏóÖÏóê Ï†ÅÌï©ÌïòÎ©∞, Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî Îçî Í∞ÑÎã®ÌïòÍ≥† Îπ†Î¶ÖÎãàÎã§ [1].
      *   Agentic RAGÎäî Agentic AIÏùò ÏùòÏÇ¨ Í≤∞Ï†ï Îä•Î†•Í≥º RAGÏùò Îç∞Ïù¥ÌÑ∞ Í≤ÄÏÉâ Îä•Î†•ÏùÑ Í≤∞Ìï©ÌïòÏó¨ AI ÏãúÏä§ÌÖúÏùò ÎèÖÎ¶ΩÏÑ±Í≥º Ïú†Ïó∞ÏÑ±ÏùÑ Ìñ•ÏÉÅÏãúÌÇµÎãàÎã§ [1].
      
      ## ÏÉÅÏÑ∏ Î∂ÑÏÑù
      
      **RAGÏôÄ Agentic RAGÏùò ÌïµÏã¨ Ï∞®Ïù¥Ï†ê:**
      
      Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî ÎØ∏Î¶¨ Ï†ïÏùòÎêú ÏøºÎ¶¨Î•º Í∏∞Î∞òÏúºÎ°ú Ï†ïÏ†ÅÏù∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Îî∞Î¶ÖÎãàÎã§ [1], [5]. Ï¶â, Ìïú Î≤à ÏÑ§Ï†ïÎêú ÏøºÎ¶¨ÏôÄ Í≤ÄÏÉâ Î∞©ÏãùÏùÄ Î≥ÄÍ≤ΩÎêòÏßÄ ÏïäÏäµÎãàÎã§. Î∞òÎ©¥, Agentic RAGÎäî ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÌôúÏö©ÌïòÏó¨ ÌîÑÎ°¨ÌîÑÌä∏ÏôÄ Ï†ÑÎûµÏùÑ Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÎèôÏ†ÅÏúºÎ°ú Ï°∞Ï†ïÌï† Ïàò ÏûàÏäµÎãàÎã§ [1], [5]. Ïù¥Îü¨Ìïú ÎèôÏ†ÅÏù∏ Ï°∞Ï†ï Îä•Î†•ÏùÄ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï£ºÏñ¥ÏßÑ Î™©ÌëúÎ•º Îã¨ÏÑ±ÌïòÍ∏∞ ÏúÑÌï¥ ÌïÑÏöîÌïú Ï†ïÎ≥¥Î•º Ïä§Ïä§Î°ú ÌåêÎã®ÌïòÍ≥† Í≤ÄÏÉâÌïòÎäî Îä•Î†•ÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§ [1]. Agentic RAGÎäî Îã®ÏàúÌïú "ÏøºÎ¶¨ - Í≤ÄÏÉâ - ÏÉùÏÑ±" ÌîÑÎ°úÏÑ∏Ïä§Î•º ÎÑòÏñ¥, ÏûêÏú®Ï†ÅÏù∏ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Í¥ÄÎ¶¨ÌïòÎäî Îã§Îã®Í≥Ñ ÏÉÅÌò∏ ÏûëÏö©ÏùÑ Ìè¨Ìï®ÌïòÎäî Îçî ÎÑìÏùÄ Í∞úÎÖêÏùò Í≤ÄÏÉâ Ï¶ùÍ∞ïÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1]. Îî∞ÎùºÏÑú, Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú Agentic RAGÎ≥¥Îã§ Îπ†Î•¥Í≥† ÎπÑÏö©Ïù¥ Ï†ÄÎ†¥ÌïòÏßÄÎßå, Agentic RAGÎäî ÎèôÏ†ÅÏù∏ ÏóêÏù¥Ï†ÑÌä∏ ÏøºÎ¶¨, Í∞úÏÑ† Î∞è Ïª®ÌÖçÏä§Ìä∏ Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Îçî Î≥µÏû°Ìïú ÏûëÏóÖÏùÑ Ï≤òÎ¶¨Ìï† Ïàò ÏûàÏäµÎãàÎã§ [1].
      
      **Agentic RAGÏóêÏÑú ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïó≠Ìï†:**
      
      Agentic RAGÏóêÏÑú ÏóêÏù¥Ï†ÑÌä∏Îäî Ï†ïÎ≥¥ Í≤ÄÏÉâÏùÑ Îä•ÎèôÏ†ÅÏúºÎ°ú Í¥ÄÎ¶¨ÌïòÎ©∞, Ïù¥Î•º ÏóêÏù¥Ï†ÑÌä∏Ïùò Ï∂îÎ°† Í≥ºÏ†ïÏóê ÌÜµÌï©ÌïòÍ≥† ÌïÑÏöîÏóê Îî∞Îùº ÏøºÎ¶¨Î•º Í∞úÏÑ†Ìï©ÎãàÎã§ [1], [3]. ÏóêÏù¥Ï†ÑÌä∏Îäî Îã®ÏàúÌûà Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÎäî Í≤ÉÏù¥ ÏïÑÎãàÎùº, Í≤ÄÏÉâÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ï∂îÎ°†ÌïòÍ≥†, ÌïÑÏöîÌïú Í≤ΩÏö∞ Ï∂îÍ∞ÄÏ†ÅÏù∏ Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÍ±∞ÎÇò Í≤ÄÏÉâ Ï†ÑÎûµÏùÑ Î≥ÄÍ≤ΩÌïòÎäî Îì±Ïùò Îä•ÎèôÏ†ÅÏù∏ Ïó≠Ìï†ÏùÑ ÏàòÌñâÌï©ÎãàÎã§. Ïù¥Îü¨Ìïú Ï†ëÍ∑º Î∞©ÏãùÏùÄ Îã§ÏñëÌïú ÎèÑÍµ¨Ïùò ÌÜµÌï©Í≥º Ïã¨Ï∏µÏ†ÅÏù∏ Ï∂îÎ°†Ïù¥ ÌïÑÏöîÌïú Î≥µÏû°Ìïú Îã§Îã®Í≥Ñ ÏûëÏóÖÏùÑ Í∞ÄÎä•ÌïòÍ≤å Ìï©ÎãàÎã§ [1]. ÏòàÎ•º Îì§Ïñ¥, ÏóêÏù¥Ï†ÑÌä∏Îäî Ïó¨Îü¨ Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î•º Í≤ÄÏÉâÌïòÍ≥†, Í≤ÄÏÉâÎêú Ï†ïÎ≥¥Î•º ÏöîÏïΩÌïòÍ≥†, ÏöîÏïΩÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ï∂îÍ∞ÄÏ†ÅÏù∏ ÏßàÎ¨∏ÏùÑ ÏÉùÏÑ±ÌïòÍ≥†, Îã§Ïãú Í≤ÄÏÉâÌïòÎäî Í≥ºÏ†ïÏùÑ Î∞òÎ≥µÌïòÏó¨ ÏµúÏ¢ÖÏ†ÅÏù∏ Í≤∞Í≥ºÎ¨ºÏùÑ ÏÉùÏÑ±Ìï† Ïàò ÏûàÏäµÎãàÎã§.
      
      **ÏÇ¨Ïö© ÏÇ¨Î°Ä Ï†ÅÌï©ÏÑ±:**
      
      Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî HR Ï†ïÏ±ÖÏóê ÎåÄÌïú ÏßÄÏãù ÏßÄÏõêÍ≥º Í∞ôÏù¥ ÎÇ¥Î∂Ä Îç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ Îπ†Î•¥Í≥† Ï†ïÌôïÌïú ÎãµÎ≥ÄÏùÑ ÌïÑÏöîÎ°ú ÌïòÎäî Í∞ÑÎã®Ìïú ÏøºÎ¶¨ Í∏∞Î∞ò ÏûëÏóÖÏóê Ï†ÅÌï©Ìï©ÎãàÎã§ [1]. Î∞òÎ©¥, Agentic RAGÎäî ÏòÅÏóÖ Ïó∞Íµ¨ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä ÏöîÏïΩ Ï¥àÏïàÏùÑ ÏûëÏÑ±ÌïòÎäî Í≤ÉÍ≥º Í∞ôÏù¥ Î™©Ìëú ÏßÄÌñ•Ï†ÅÏù∏ Ï∂îÎ°†Í≥º ÏßÄÎä•Ï†ÅÏù∏ Í≤ÄÏÉâÏù¥ ÌïÑÏöîÌïú Î≥µÏû°Ìïú Îã§Îã®Í≥Ñ ÌîÑÎ°úÏÑ∏Ïä§Ïóê Ï†ÅÌï©Ìï©ÎãàÎã§ [1]. Agentic RAGÏùò Í∞úÎ∞úÏùÄ Í≥†Í∏â Î°úÎ¥á Í≥µÌïô ÎòêÎäî Î≤ïÎ•† ÏûêÎ¨∏ ÏÑúÎπÑÏä§ÏôÄ Í∞ôÏù¥ Ïª®ÌÖçÏä§Ìä∏ Ïù∏Ïãù ÏÉùÏÑ± Î∞è Ïã§ÏãúÍ∞Ñ ÏûëÏóÖÏùÑ ÌïÑÏöîÎ°ú ÌïòÎäî ÏÇ¨Ïö© ÏÇ¨Î°ÄÏóê ÏùòÌï¥ Ï£ºÎèÑÎê©ÎãàÎã§ [1]. ÏòàÎ•º Îì§Ïñ¥, Î°úÎ¥áÏù¥ ÌäπÏ†ï Î¨ºÏ≤¥Î•º Ï∞æÍ∏∞ ÏúÑÌï¥ Ï£ºÎ≥Ä ÌôòÍ≤ΩÏùÑ ÌÉêÏÉâÌïòÍ≥†, Ï∞æÏùÄ Î¨ºÏ≤¥Ïóê ÎåÄÌïú Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÍ≥†, Í≤ÄÏÉâÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Î¨ºÏ≤¥Î•º Ï°∞ÏûëÌïòÎäî Îì±Ïùò ÏûëÏóÖÏùÑ ÏàòÌñâÌï† Ïàò ÏûàÏäµÎãàÎã§.
      
      ## Í¥ÄÎ†® ÏûêÎ£å Î∞è Ï∂úÏ≤ò
      
      *   [1] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      *   [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      *   [3] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
      *   [4] https://www.datacamp.com/blog/agentic-rag
      *   [5] https://www.pingcap.com/article/agentic-rag-vs-traditional-rag-key-differences-benefits/
      
      ## Í≤∞Î°† Î∞è ÌèâÍ∞Ä
      
      RAGÏôÄ Agentic RAGÎäî Í∞ÅÍ∞Å Ïû•Îã®Ï†êÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÏúºÎ©∞, ÌäπÏ†ï ÏûëÏóÖÏùò Î≥µÏû°ÏÑ±Í≥º ÏöîÍµ¨ ÏÇ¨Ìï≠Ïóê Îî∞Îùº Ï†ÅÏ†àÌïú Î∞©Î≤ïÏùÑ ÏÑ†ÌÉùÌï¥Ïïº Ìï©ÎãàÎã§. Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî Í∞ÑÎã®ÌïòÍ≥† Îπ†Î•∏ ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÎäî Îç∞ Ìö®Í≥ºÏ†ÅÏù¥ÏßÄÎßå, Î≥µÏû°Ìïú Ï∂îÎ°†Í≥º Îã§ÏñëÌïú ÎèÑÍµ¨ ÌÜµÌï©Ïù¥ ÌïÑÏöîÌïú ÏûëÏóÖÏóêÎäî Agentic RAGÍ∞Ä Îçî Ï†ÅÌï©Ìï©ÎãàÎã§. Agentic RAGÎäî ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÌôúÏö©ÌïòÏó¨ Ï†ïÎ≥¥ Í≤ÄÏÉâ ÌîÑÎ°úÏÑ∏Ïä§Î•º ÎçîÏö± ÏßÄÎä•Ï†ÅÏù¥Í≥† ÎèôÏ†ÅÏúºÎ°ú ÎßåÎì§ Ïàò ÏûàÏúºÎ©∞, Ïù¥Î•º ÌÜµÌï¥ ÎçîÏö± Í∞ïÎ†•ÌïòÍ≥† Ïú†Ïó∞Ìïú AI ÏãúÏä§ÌÖúÏùÑ Íµ¨Ï∂ïÌï† Ïàò ÏûàÏäµÎãàÎã§. ÌïòÏßÄÎßå Agentic RAGÎäî Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎ≥¥Îã§ Î≥µÏû°ÌïòÍ≥† ÎπÑÏö©Ïù¥ ÎßéÏù¥ Îì§ Ïàò ÏûàÏúºÎØÄÎ°ú, ÏûëÏóÖÏùò Î≥µÏû°ÏÑ±Í≥º ÏòàÏÇ∞ÏùÑ Í≥†Î†§ÌïòÏó¨ Ï†ÅÏ†àÌïú Î∞©Î≤ïÏùÑ ÏÑ†ÌÉùÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§. Ìñ•ÌõÑ Agentic RAGÏùò Î∞úÏ†ÑÏùÄ AI ÏãúÏä§ÌÖúÏùò ÏûêÏú®ÏÑ±Í≥º Ï†ÅÏùëÏÑ±ÏùÑ ÎçîÏö± Ìñ•ÏÉÅÏãúÏºú Îã§ÏñëÌïú Î∂ÑÏïºÏóêÏÑú ÌòÅÏã†Ï†ÅÏù∏ ÏÜîÎ£®ÏÖòÏùÑ Ï†úÍ≥µÌï† Í≤ÉÏúºÎ°ú Í∏∞ÎåÄÎê©ÎãàÎã§.

‚îå‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚îÇ Phase 4 Benchmark Result
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ Query: RAG(Retrieval-Augmented Generation)ÏôÄ Agent Í∏∞Î∞ò Ï†ëÍ∑ºÎ≤ïÏùò Ï∞®Ïù¥Ï†êÍ≥º Í∞ÅÍ∞Å Ïñ∏...
‚îÇ Time: 26.77s
‚îÇ LLM Calls: 2
‚îÇ Search Calls: 2
‚îÇ URLs Read: 6
‚îÇ Iterations: 2
‚îÇ Est. Tokens: 1107
‚îÇ Response Length: 2719 chars
‚îÇ Has Citations: ‚úÖ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


======================================================================
üìÑ FULL RESPONSE:
======================================================================
## ÌïµÏã¨ ÏöîÏïΩ

RAG (Retrieval-Augmented Generation)Îäî Ï†ïÎ≥¥ Í≤ÄÏÉâÏùÑ ÌÜµÌï¥ ÏÉùÏÑ± Î™®Îç∏Ïùò ÏÑ±Îä•ÏùÑ Ìñ•ÏÉÅÏãúÌÇ§Îäî Í∏∞Ïà†Ïù¥Î©∞, Agent Í∏∞Î∞ò Ï†ëÍ∑ºÎ≤ïÏùÄ ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÌôúÏö©ÌïòÏó¨ ÎçîÏö± ÎèôÏ†ÅÏù∏ Ï†ïÎ≥¥ Í≤ÄÏÉâ Î∞è Ï∂îÎ°†ÏùÑ Í∞ÄÎä•ÌïòÍ≤å Ìï©ÎãàÎã§. Agentic RAGÎäî Î≥µÏû°Ìïú ÏûëÏóÖÏóê, Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî Í∞ÑÎã®Ìïú ÏûëÏóÖÏóê Ï†ÅÌï©Ìï©ÎãàÎã§ [1].

## Ï£ºÏöî Î∞úÍ≤¨ ÏÇ¨Ìï≠

*   Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî ÎØ∏Î¶¨ Ï†ïÏùòÎêú ÏøºÎ¶¨Î•º ÏÇ¨Ïö©ÌïòÎäî Ï†ïÏ†ÅÏù∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Îî∞Î•¥ÏßÄÎßå, Agentic RAGÎäî ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÏÇ¨Ïö©ÌïòÏó¨ Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÏøºÎ¶¨Î•º ÎèôÏ†ÅÏúºÎ°ú Ï°∞Ï†ïÌï©ÎãàÎã§ [1], [5].
*   Agentic RAGÎäî Ï†ïÎ≥¥ Í≤ÄÏÉâÏùÑ Ï∂îÎ°† Í≥ºÏ†ïÏóê ÌÜµÌï©ÌïòÏó¨ ÏøºÎ¶¨Î•º Í∞úÏÑ†ÌïòÍ≥† Ïª®ÌÖçÏä§Ìä∏Î•º Îä•ÎèôÏ†ÅÏúºÎ°ú Í¥ÄÎ¶¨Ìï©ÎãàÎã§ [1], [3].
*   Agentic RAGÎäî Ïã¨Ï∏µÏ†ÅÏù∏ Ï∂îÎ°†Í≥º ÎèÑÍµ¨ ÌÜµÌï©Ïù¥ ÌïÑÏöîÌïú Î≥µÏû°Ìïú Îã§Îã®Í≥Ñ ÏûëÏóÖÏóê Ï†ÅÌï©ÌïòÎ©∞, Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî Îçî Í∞ÑÎã®ÌïòÍ≥† Îπ†Î¶ÖÎãàÎã§ [1].
*   Agentic RAGÎäî Agentic AIÏùò ÏùòÏÇ¨ Í≤∞Ï†ï Îä•Î†•Í≥º RAGÏùò Îç∞Ïù¥ÌÑ∞ Í≤ÄÏÉâ Îä•Î†•ÏùÑ Í≤∞Ìï©ÌïòÏó¨ AI ÏãúÏä§ÌÖúÏùò ÎèÖÎ¶ΩÏÑ±Í≥º Ïú†Ïó∞ÏÑ±ÏùÑ Ìñ•ÏÉÅÏãúÌÇµÎãàÎã§ [1].

## ÏÉÅÏÑ∏ Î∂ÑÏÑù

**RAGÏôÄ Agentic RAGÏùò ÌïµÏã¨ Ï∞®Ïù¥Ï†ê:**

Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî ÎØ∏Î¶¨ Ï†ïÏùòÎêú ÏøºÎ¶¨Î•º Í∏∞Î∞òÏúºÎ°ú Ï†ïÏ†ÅÏù∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Îî∞Î¶ÖÎãàÎã§ [1], [5]. Ï¶â, Ìïú Î≤à ÏÑ§Ï†ïÎêú ÏøºÎ¶¨ÏôÄ Í≤ÄÏÉâ Î∞©ÏãùÏùÄ Î≥ÄÍ≤ΩÎêòÏßÄ ÏïäÏäµÎãàÎã§. Î∞òÎ©¥, Agentic RAGÎäî ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÌôúÏö©ÌïòÏó¨ ÌîÑÎ°¨ÌîÑÌä∏ÏôÄ Ï†ÑÎûµÏùÑ Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÎèôÏ†ÅÏúºÎ°ú Ï°∞Ï†ïÌï† Ïàò ÏûàÏäµÎãàÎã§ [1], [5]. Ïù¥Îü¨Ìïú ÎèôÏ†ÅÏù∏ Ï°∞Ï†ï Îä•Î†•ÏùÄ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï£ºÏñ¥ÏßÑ Î™©ÌëúÎ•º Îã¨ÏÑ±ÌïòÍ∏∞ ÏúÑÌï¥ ÌïÑÏöîÌïú Ï†ïÎ≥¥Î•º Ïä§Ïä§Î°ú ÌåêÎã®ÌïòÍ≥† Í≤ÄÏÉâÌïòÎäî Îä•Î†•ÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§ [1]. Agentic RAGÎäî Îã®ÏàúÌïú "ÏøºÎ¶¨ - Í≤ÄÏÉâ - ÏÉùÏÑ±" ÌîÑÎ°úÏÑ∏Ïä§Î•º ÎÑòÏñ¥, ÏûêÏú®Ï†ÅÏù∏ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Í¥ÄÎ¶¨ÌïòÎäî Îã§Îã®Í≥Ñ ÏÉÅÌò∏ ÏûëÏö©ÏùÑ Ìè¨Ìï®ÌïòÎäî Îçî ÎÑìÏùÄ Í∞úÎÖêÏùò Í≤ÄÏÉâ Ï¶ùÍ∞ïÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§ [1]. Îî∞ÎùºÏÑú, Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú Agentic RAGÎ≥¥Îã§ Îπ†Î•¥Í≥† ÎπÑÏö©Ïù¥ Ï†ÄÎ†¥ÌïòÏßÄÎßå, Agentic RAGÎäî ÎèôÏ†ÅÏù∏ ÏóêÏù¥Ï†ÑÌä∏ ÏøºÎ¶¨, Í∞úÏÑ† Î∞è Ïª®ÌÖçÏä§Ìä∏ Í¥ÄÎ¶¨Î•º ÌÜµÌï¥ Îçî Î≥µÏû°Ìïú ÏûëÏóÖÏùÑ Ï≤òÎ¶¨Ìï† Ïàò ÏûàÏäµÎãàÎã§ [1].

**Agentic RAGÏóêÏÑú ÏóêÏù¥Ï†ÑÌä∏Ïùò Ïó≠Ìï†:**

Agentic RAGÏóêÏÑú ÏóêÏù¥Ï†ÑÌä∏Îäî Ï†ïÎ≥¥ Í≤ÄÏÉâÏùÑ Îä•ÎèôÏ†ÅÏúºÎ°ú Í¥ÄÎ¶¨ÌïòÎ©∞, Ïù¥Î•º ÏóêÏù¥Ï†ÑÌä∏Ïùò Ï∂îÎ°† Í≥ºÏ†ïÏóê ÌÜµÌï©ÌïòÍ≥† ÌïÑÏöîÏóê Îî∞Îùº ÏøºÎ¶¨Î•º Í∞úÏÑ†Ìï©ÎãàÎã§ [1], [3]. ÏóêÏù¥Ï†ÑÌä∏Îäî Îã®ÏàúÌûà Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÎäî Í≤ÉÏù¥ ÏïÑÎãàÎùº, Í≤ÄÏÉâÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ï∂îÎ°†ÌïòÍ≥†, ÌïÑÏöîÌïú Í≤ΩÏö∞ Ï∂îÍ∞ÄÏ†ÅÏù∏ Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÍ±∞ÎÇò Í≤ÄÏÉâ Ï†ÑÎûµÏùÑ Î≥ÄÍ≤ΩÌïòÎäî Îì±Ïùò Îä•ÎèôÏ†ÅÏù∏ Ïó≠Ìï†ÏùÑ ÏàòÌñâÌï©ÎãàÎã§. Ïù¥Îü¨Ìïú Ï†ëÍ∑º Î∞©ÏãùÏùÄ Îã§ÏñëÌïú ÎèÑÍµ¨Ïùò ÌÜµÌï©Í≥º Ïã¨Ï∏µÏ†ÅÏù∏ Ï∂îÎ°†Ïù¥ ÌïÑÏöîÌïú Î≥µÏû°Ìïú Îã§Îã®Í≥Ñ ÏûëÏóÖÏùÑ Í∞ÄÎä•ÌïòÍ≤å Ìï©ÎãàÎã§ [1]. ÏòàÎ•º Îì§Ïñ¥, ÏóêÏù¥Ï†ÑÌä∏Îäî Ïó¨Îü¨ Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î•º Í≤ÄÏÉâÌïòÍ≥†, Í≤ÄÏÉâÎêú Ï†ïÎ≥¥Î•º ÏöîÏïΩÌïòÍ≥†, ÏöîÏïΩÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ï∂îÍ∞ÄÏ†ÅÏù∏ ÏßàÎ¨∏ÏùÑ ÏÉùÏÑ±ÌïòÍ≥†, Îã§Ïãú Í≤ÄÏÉâÌïòÎäî Í≥ºÏ†ïÏùÑ Î∞òÎ≥µÌïòÏó¨ ÏµúÏ¢ÖÏ†ÅÏù∏ Í≤∞Í≥ºÎ¨ºÏùÑ ÏÉùÏÑ±Ìï† Ïàò ÏûàÏäµÎãàÎã§.

**ÏÇ¨Ïö© ÏÇ¨Î°Ä Ï†ÅÌï©ÏÑ±:**

Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî HR Ï†ïÏ±ÖÏóê ÎåÄÌïú ÏßÄÏãù ÏßÄÏõêÍ≥º Í∞ôÏù¥ ÎÇ¥Î∂Ä Îç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ Îπ†Î•¥Í≥† Ï†ïÌôïÌïú ÎãµÎ≥ÄÏùÑ ÌïÑÏöîÎ°ú ÌïòÎäî Í∞ÑÎã®Ìïú ÏøºÎ¶¨ Í∏∞Î∞ò ÏûëÏóÖÏóê Ï†ÅÌï©Ìï©ÎãàÎã§ [1]. Î∞òÎ©¥, Agentic RAGÎäî ÏòÅÏóÖ Ïó∞Íµ¨ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä ÏöîÏïΩ Ï¥àÏïàÏùÑ ÏûëÏÑ±ÌïòÎäî Í≤ÉÍ≥º Í∞ôÏù¥ Î™©Ìëú ÏßÄÌñ•Ï†ÅÏù∏ Ï∂îÎ°†Í≥º ÏßÄÎä•Ï†ÅÏù∏ Í≤ÄÏÉâÏù¥ ÌïÑÏöîÌïú Î≥µÏû°Ìïú Îã§Îã®Í≥Ñ ÌîÑÎ°úÏÑ∏Ïä§Ïóê Ï†ÅÌï©Ìï©ÎãàÎã§ [1]. Agentic RAGÏùò Í∞úÎ∞úÏùÄ Í≥†Í∏â Î°úÎ¥á Í≥µÌïô ÎòêÎäî Î≤ïÎ•† ÏûêÎ¨∏ ÏÑúÎπÑÏä§ÏôÄ Í∞ôÏù¥ Ïª®ÌÖçÏä§Ìä∏ Ïù∏Ïãù ÏÉùÏÑ± Î∞è Ïã§ÏãúÍ∞Ñ ÏûëÏóÖÏùÑ ÌïÑÏöîÎ°ú ÌïòÎäî ÏÇ¨Ïö© ÏÇ¨Î°ÄÏóê ÏùòÌï¥ Ï£ºÎèÑÎê©ÎãàÎã§ [1]. ÏòàÎ•º Îì§Ïñ¥, Î°úÎ¥áÏù¥ ÌäπÏ†ï Î¨ºÏ≤¥Î•º Ï∞æÍ∏∞ ÏúÑÌï¥ Ï£ºÎ≥Ä ÌôòÍ≤ΩÏùÑ ÌÉêÏÉâÌïòÍ≥†, Ï∞æÏùÄ Î¨ºÏ≤¥Ïóê ÎåÄÌïú Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÍ≥†, Í≤ÄÏÉâÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Î¨ºÏ≤¥Î•º Ï°∞ÏûëÌïòÎäî Îì±Ïùò ÏûëÏóÖÏùÑ ÏàòÌñâÌï† Ïàò ÏûàÏäµÎãàÎã§.

## Í¥ÄÎ†® ÏûêÎ£å Î∞è Ï∂úÏ≤ò

*   [1] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
*   [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
*   [3] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
*   [4] https://www.datacamp.com/blog/agentic-rag
*   [5] https://www.pingcap.com/article/agentic-rag-vs-traditional-rag-key-differences-benefits/

## Í≤∞Î°† Î∞è ÌèâÍ∞Ä

RAGÏôÄ Agentic RAGÎäî Í∞ÅÍ∞Å Ïû•Îã®Ï†êÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÏúºÎ©∞, ÌäπÏ†ï ÏûëÏóÖÏùò Î≥µÏû°ÏÑ±Í≥º ÏöîÍµ¨ ÏÇ¨Ìï≠Ïóê Îî∞Îùº Ï†ÅÏ†àÌïú Î∞©Î≤ïÏùÑ ÏÑ†ÌÉùÌï¥Ïïº Ìï©ÎãàÎã§. Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎäî Í∞ÑÎã®ÌïòÍ≥† Îπ†Î•∏ ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÎäî Îç∞ Ìö®Í≥ºÏ†ÅÏù¥ÏßÄÎßå, Î≥µÏû°Ìïú Ï∂îÎ°†Í≥º Îã§ÏñëÌïú ÎèÑÍµ¨ ÌÜµÌï©Ïù¥ ÌïÑÏöîÌïú ÏûëÏóÖÏóêÎäî Agentic RAGÍ∞Ä Îçî Ï†ÅÌï©Ìï©ÎãàÎã§. Agentic RAGÎäî ÏûêÏú®Ï†ÅÏù∏ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÌôúÏö©ÌïòÏó¨ Ï†ïÎ≥¥ Í≤ÄÏÉâ ÌîÑÎ°úÏÑ∏Ïä§Î•º ÎçîÏö± ÏßÄÎä•Ï†ÅÏù¥Í≥† ÎèôÏ†ÅÏúºÎ°ú ÎßåÎì§ Ïàò ÏûàÏúºÎ©∞, Ïù¥Î•º ÌÜµÌï¥ ÎçîÏö± Í∞ïÎ†•ÌïòÍ≥† Ïú†Ïó∞Ìïú AI ÏãúÏä§ÌÖúÏùÑ Íµ¨Ï∂ïÌï† Ïàò ÏûàÏäµÎãàÎã§. ÌïòÏßÄÎßå Agentic RAGÎäî Ï†ÑÌÜµÏ†ÅÏù∏ RAGÎ≥¥Îã§ Î≥µÏû°ÌïòÍ≥† ÎπÑÏö©Ïù¥ ÎßéÏù¥ Îì§ Ïàò ÏûàÏúºÎØÄÎ°ú, ÏûëÏóÖÏùò Î≥µÏû°ÏÑ±Í≥º ÏòàÏÇ∞ÏùÑ Í≥†Î†§ÌïòÏó¨ Ï†ÅÏ†àÌïú Î∞©Î≤ïÏùÑ ÏÑ†ÌÉùÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§. Ìñ•ÌõÑ Agentic RAGÏùò Î∞úÏ†ÑÏùÄ AI ÏãúÏä§ÌÖúÏùò ÏûêÏú®ÏÑ±Í≥º Ï†ÅÏùëÏÑ±ÏùÑ ÎçîÏö± Ìñ•ÏÉÅÏãúÏºú Îã§ÏñëÌïú Î∂ÑÏïºÏóêÏÑú ÌòÅÏã†Ï†ÅÏù∏ ÏÜîÎ£®ÏÖòÏùÑ Ï†úÍ≥µÌï† Í≤ÉÏúºÎ°ú Í∏∞ÎåÄÎê©ÎãàÎã§.
======================================================================


‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë  Phase 4 Summary (3 tests)
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë  Average Time: 29.62s
‚ïë  Average Tokens: 1278
‚ïë  Citation Rate: 100%
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìÅ Results saved to: benchmark_results/phase_4_20251220_231829.json
