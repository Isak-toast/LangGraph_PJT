/home/isak/LangGraph_PJT/langgraph_web_ui/langgraph_server/src/agent/tools.py:36: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.
  tavily_tool = TavilySearchResults(

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Deep Research Benchmark - Phase 3
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Test Queries: 3
â•‘  Verbose: ON (full response)
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ðŸ“Š Running benchmark: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ìž¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜...

ðŸ”Ž Clarify: Analyzing query...
   â””â”€ Query: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ìž¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜
   â””â”€ Status: ðŸŸ¢ Clear
   â””â”€ Analysis: The query asks for a comparison of multi-agent architectures of LangGraph and CrewAI, including their advantages and disadvantages. The query is clear and specific.
   â””â”€ Topics: LangGraph, CrewAI, Multi-agent architecture, Comparison of architectures
ðŸ“‹ Planner: Creating research plan for: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ìž¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜

ðŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] LangGraph vs CrewAI multi-agent architecture comparison
      [2] LangGraph multi-agent benefits and drawbacks
      [3] CrewAI multi-agent benefits and drawbacks
      [4] LangGraph and CrewAI architecture differences
   â””â”€ Focus: Multi-agent architecture, LangGraph, CrewAI, Comparison, Pros and cons
ðŸ” Searcher [1]: Searching for: LangGraph vs CrewAI multi-agent architecture comparison

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.zams.com/blog/crewai-vs-langgraph
      [2] https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72
      [3] https://blog.langchain.com/langgraph-multi-agent-workflows/
      [4] https://aaronyuqi.medium.com/first-hand-comparison-of-langgraph-crewai-and-autogen-30026e60b563
      [5] https://aws.amazon.com/blogs/machine-learning/build-a-multi-agent-system-with-langgraph-and-mistral-on-aws/
   â””â”€ Snippets:
      â€¢ | Category | CrewAI | LangGraph |  ---  | What it offers | â€¢ Simple orchestration of multi-agent teams  â€¢ Role/task assignment for agents  â€¢ Coordination and delegation mechanisms  â€¢ High-level abstractions to build agent teams quickly | â€¢ Fine-grained control over multi-agent workflows  â€¢ Graph-based architecture (agents as nodes, interactions as edges)  â€¢ Built-in support for complex state management, retries, event handling | [...] LangGraph is an agent framework that takes a state-centric approach, providing a graph-based architecture to enable creation of complex workflows and applications. This approach is ideal for applications requiring sophisticated state management, knowledge retrieval, and distributed systems.  ## How to choose between Crewai and LangGraph?  Both are multi agent frameworks and they provide plenty of resources to get you started including tutorials, documentation, pre-built agents and tools. [...] On the other hand, LangGraph built on LangChain provides more control. Itâ€™s a great choice for software development teams and engineering teams to develop complex workflows for specific use cases. LangGraph's agent capabilities allow agents to manage tasks independently while a supervisor orchestrates their interactions, enhancing overall efficiency and scalability.
      â€¢ LangChain focuses on building LLM applications with chains and tools.  LangGraph extends LangChain by enabling stateful, multi-step workflows with branching and memory.  LangGraph uses LangChain under the hood but adds graph-based logic control.  ## LangGraph vs. CrewAI  CrewAI is like assigning roles in a team. You define what each agent does (writer, researcher, planner), and then they work together to complete a task. [...] LangGraph gives you more control. Instead of just assigning roles and letting them talk, you can specify exactly what happens when, in what order, and how data moves between steps. CrewAI is great for high-level tasks; LangGraph is better when you want tight control. [...] CrewAI organizes agents into teams and roles with goals and communication.  LangGraph is lower-level: you explicitly define logic and flow, ideal for precise control.  CrewAI is great for abstract task delegation; LangGraph is better for deterministic workflows.  ## LangGraph vs. AutoGen  AutoGen (by Microsoft) is designed for autonomous agent conversations. It lets agents talk to each other freely and decide what to do next.
      â€¢ Another key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.  ### CrewAI  Another key framework we want to highlight is CrewAI. CrewAI has emerged recently as a popular way to create multi-agent "teams". Compared to LangGraph, CrewAI is a higher-level framework, while LangGraph gives much more lower-level controllability over your agents. [...] Today, we're excited to highlight a second set of use cases for `langgraph` - multi-agent workflows. In this blog we will cover:   What does "multi-agent" mean?  Why are "multi-agent" workflows interesting?  Three concrete examples of using LangGraph for multi-agent workflows  Two examples of third-party applications built on top of LangGraph using multi-agent workflows (GPT-Newspaper and CrewAI)  Comparison to other frameworks (Autogen and CrewAI)  ## What is "multi-agent"?  ðŸ’¡ [...] Autogen emerged as perhaps the first multi-agent framework. The biggest difference in mental model between LangGraph and Autogen is in construction of the agents. LangGraph prefers an approach where you explicitly define different agents and transition probabilities, preferring to represent it as a graph. Autogen frames it more as a "conversation". We believe that this "graph" framing makes it more intuitive and provides better developer experience for constructing more complex and opinionated
ðŸ’­ Think: Query: LangGraph vs CrewAI multi-agent architecture comparison | Found 5 results, 5 URLs. Key snippets: | Category | CrewAI | LangGraph |
 --- 
| What it offers | â€¢ Simple orchestration of multi-agent tea | LangChain focuses on building LLM applications with chains and tools.
 LangGraph extends LangChain b | Another key difference between Autogen and LangGraph is that LangGraph is fully integrated int. Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
ðŸ“– Read URL: https://www.zams.com/blog/crewai-vs-langgraph... (8015 chars)
   â””â”€ [https://www.zams.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs. LangGraph: Multi agent framework comparison | Zams Integrations Customers Pricing Blog Login Login Get Started Get Started Technology April 19, 2025 Crewai vs. LangGraph: Which multi agent framework should you use? Yaagneshwaran Ganesh Objective feature comparison to help you decide - based on features, benefits, and ideal use cases. While there are different ways to build an AI agent from scratch, itâ€™s great that you are taking the efficient approach of using multi agent frameworks. Youâ€™re probably here because youâ€™ve shortlisted Crew ai and LangGraph and want to decide which one is right for you. Youâ€™re in the right place. In this blog, we will compare the two in detail - on their features, benefits, and ideal use cases, including how agents connect to establish communication and interoperability. To get started, we need to have a basic understanding of multi agent systems. So, letâ€™s first get a few basics out of the way. Why do you need a multi-agent framework? As your AI systems scale and you add multiple agents with different capabilities, the complexity of these applications grow. As the complexity grows, you will need a structured environment that orchestrates the agent activities, including the technical steps and requirements involved in building agents. That is where agentic frameworks come in. Multi agent frameworks provide you with a foundational structure for developing autonomous systems, and define parameters and protocols to handle interactions between multiple specialized agents. These frameworks also incorporate agent actions, which are fundamental components within a node-based AI framework, facilitating the execution of complex tasks. An agentic application can significantly enhance user experience and system efficiency by streamlining user interaction through minimal input and adaptive responses. Single agent systems These systems are autonomous but rely on one agent to handle a wide range of tasks, like a jack of all trades. For example, hereâ€™s how it works when requested for a sales pipeline report: As you can see, one agent carries out a series of tasks to accomplish the requested outcome. Single agent systems are great for specialized tasks where the problem is well defined and the scope is limited. But as your environment and context evolves, they fall short. Multi agent systems Multi agent systems, on the contrary, consist of multiple AI agents working together to achieve common goals. Letâ€™s look at the same example of requesting to email the sales report, and see how the multi agent architecture manages specialized agents to execute it. Instead of one agent accomplishing all the tasks, the tasks are broken down into smaller components where each agent specializes in a specific task â€“ such as planning, integrating, analyzing, and more like a team of specialists working together, where each brings their unique expertise to the table. And because these AI agents can collaborate dynamically and run these tasks in parallel, they can tackle more complex problems where the environment is always changing and evolving. Multi agent interactions allow these AI agents to communicate within the system, monitor and debug in real-time, and handle handoffs efficiently, enabling dynamic workflows. The better you understand how these multi agents interact, the better you can optimize these systems and scale your operations, without worrying about bottlenecks or performance issues. And thatâ€™s exactly what multi agent frameworks help you with. Additionally, these frameworks give you a set of pre-packaged tools and features to help you quickly build any type of agent systems, be it knowledge oriented, process oriented or predictive. In short, agentic frameworks are the backbone of scalable, efficient and autonomous AI operations. With that said letâ€™s get to the comparison. What is Crewai? It is an open-source multi agent orchestration framework, that helps you build multi agent systems, and integrate them with the latest LLMs and your codebase. The framework automates multi-agent workflows, enables them to communicate and collaborate on tasks as a team, and make decisions autonomously. Their modular design includes a range of tools such as agents, tools, tasks, processes, and an agent development kit, to engage, collect information, handle complex tasks, and manage their operations through tool calls. Crewâ€™s hierarchical process generates a supervisor agent to oversee task execution and agent coordination. The agent engine facilitates the transition from prototype to production by managing various complexities including infrastructure, security, and performance evaluation, while integrating seamlessly with existing frameworks. With asynchronous tool execution, agents can work on different business processes concurrently, increasing productivity. Crew is primarily designed for research and quick prototypes. What is LangGraph framework (by LangChain)? LangGraph is an open-source AI framework to develop, deploy and manage advanced workflows for generative AI agents. Using graph-based architecture LangGraph handles the relationships between different components of the AI workflow. LangGraph applications offer robust features like scalable infrastructure and self-hosted deployment options that enhance workflow management and processing without adding overhead. Built on LangChain, a Python framework for AI applications, LangGraph excels at managing large language models. Function calling is integral to enhancing the capabilities of AI applications, particularly when combined with structured outputs and fine-tuning techniques. The LangGraph platform provides various deployment options, including self-hosted solutions, cloud SaaS, and the Bring Your Own Cloud (BYOC) option, catering to different user needs and preferences. With LangGraph Studio, a visual interface to develop workflows, users can reduce coding. One of LangGraphâ€™s key features is its state management system which acts like a memory bank, storing information and enabling better state management and debugging. Users can run LangGraph Platform entirely on their own infrastructure as part of a Self-Hosted Enterprise solution, allowing companies to maintain control over their data while outsourcing the management of some services. The integrated development environment in LangGraph Studio is specifically tailored for AI agent development, offering powerful tools for visualization, real-time interaction, and debugging, which enhances the overall development experience for users working with agent workflows. This is crucial for graph execution as it allows managing individual agents as graph nodes in the system. LangGraph supports a human-in-the-loop approach, so human input can enhance AI decision making and user interactions. LangGraph is primarily designed for engineering teams and production. Architecture and design philosophy Architecture and design of agent frameworks play a huge role in determining their effectiveness to support development of complex AI applications. A well-designed framework ideally provides a modular and flexible structure, allowing you to easily integrate various components and tools. Additionally, the framework should support seamless interaction between multiple agents, making it easy to build sophisticated workflows and applications. Crewai agents approach Crew is an agent framework that adopts a collaborative intelligence approach, helping you create multi-agent systems where specialized agents work together to achieve shared objectives. This approach is particularly useful for applications requiring dynamic task allocation, large language models, and multi-agent orchestration. LangGraph agents framework LangGraph is an agent framework that takes a state-centric approach, providing a graph-based architecture to enable creation of complex workflows and applications. This approach is ideal for applications requiring sophisticated state management, kno... [truncated]
   â””â”€ [https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72]
      Preview: Error: HTTP 403 for URL: https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72
ðŸ“– Read URL: https://blog.langchain.com/langgraph-multi-agent-w... (8015 chars)
   â””â”€ [https://blog.langchain.com/langgraph-multi-agent-workflows/]
      Preview: LangGraph: Multi-Agent Workflows Skip to content Case Studies In the Loop Web Home Try LangSmith Docs Sign in Subscribe LangGraph: Multi-Agent Workflows By LangChain 6 min read Jan 23, 2024 Links Python Examples JS Examples YouTube Last week we highlighted LangGraph - a new package (available in both Python and JS ) to better enable creation of LLM workflows containing cycles , which are a critical component of most agent runtimes. As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain , and a second that was a version of that aimed at message passing and chat models. Today, we're excited to highlight a second set of use cases for langgraph - multi-agent workflows. In this blog we will cover: What does "multi-agent" mean? Why are "multi-agent" workflows interesting? Three concrete examples of using LangGraph for multi-agent workflows Two examples of third-party applications built on top of LangGraph using multi-agent workflows (GPT-Newspaper and CrewAI) Comparison to other frameworks (Autogen and CrewAI) What is "multi-agent"? ðŸ’¡ When we are talking about "multi-agent", we are talking about multiple independent actors powered by language models connected in a specific way . Each agent can have its own prompt, LLM, tools, and other custom code to best collaborate with the other agents. That means there are two main considerations when thinking about different multi-agent workflows: What are the multiple independent agents? How are those agents connected? This thinking lends itself incredibly well to a graph representation, such as that provided by langgraph . In this approach, each agent is a node in the graph, and their connections are represented as an edge. The control flow is managed by edges, and they communicate by adding to the graph's state. Note: a very related concept here is the concept of state machines, which we explicitly called out as a category of cognitive architectures. When viewed in this way, the independent agent nodes become the states, and how those agents are connected is the transition matrices. Since a state machine can be viewed as a labeled, directed graph , we will think of these things in the same way. Benefits of multi-agent designs "If one agent can't work well, then why is multi-agent useful?" Grouping tools/responsibilities can give better results. An agent is more likely to succeed on a focused task than if it has to select from dozens of tools. Separate prompts can give better results. Each prompt can have its own instructions and few-shot examples. Each agent could even be powered by a separate fine-tuned LLM! Helpful conceptual model to develop. You can evaluate and improve each agent individually without breaking the larger application. Multi-agent designs allow you to divide complicated problems into tractable units of work that can be targeted by specialized agents and LLM programs. Multi-agent examples We've added three separate example of multi-agent workflows to the langgraph repo. Each of these has slightly different answers for the above two questions, which we will go over when we highlight the examples. It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with! Multi Agent Collaboration Code links : Python JS In this example, the different agents collaborate on a shared scratchpad of messages. This means that all the work either of them do is visible to the other. This has the benefit that other agents can see all the individual steps done. This has the downside that sometimes is it overly verbose and unnecessary to pass ALL this information along, and sometimes only the final answer from an agent is needed. We call this collaboration because of the shared nature the scratchpad. What are the multiple independent agents? In this case, the independent agents are actually just a single LLM call. Specifically, they are a specific prompt template (to format inputs in a specific way with a specific system message) plus an LLM call. How are those agents connected? Here is a visualization of how these agents are connected: The main thing controlling the state transitions is the router , but it is a rule-based router and so is rather quite simple. Basically, after each LLM call it looks at the output. If a tool is invoked, then it calls that tool. If no tool is called and the LLM responds "FINAL ANSWER" then it returns to the user. Otherwise (if no tool is called and the LLM does not respond "FINAL ANSWER") then it goes to the other LLM. Agent Supervisor Examples: Python JS In this example, multiple agents are connected, but compared to above they do NOT share a shared scratchpad. Rather, they have their own independent scratchpads, and then their final responses are appended to a global scratchpad. What are the multiple independent agents? In this case, the independent agents are a LangChain agent. This means they have their own individual prompt, LLM, and tools. When called, it's not just a single LLM call, but rather a run of the AgentExecutor. How are those agents connected? An agent supervisor is responsible for routing to individual agents. In this way, the supervisor can also be thought of an agent whose tools are other agents! Hierarchical Agent Teams Examples: Python JS This is similar to the above example, but now the agents in the nodes are actually other langgraph objects themselves. This provides even more flexibility than using LangChain AgentExecutor as the agent runtime. We call this hierarchical teams because the subagents can in a way be thought of as teams. What are the multiple independent agents? These are now other langgraph agents. How are those agents connected? A supervisor agent connects them. YouTube Walkthrough We've added a YouTube video to walk through these three examples. Hopefully this helps makes these complex topics a little easier to understand! Third Party Applications As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents. GPT-Newspaper This is a new project by the minds by GPT-Researcher . GPT-Newspaper is an innovative autonomous agent designed to create personalized newspapers tailored to user preferences. GPT Newspaper revolutionizes the way we consume news by leveraging the power of AI to curate, write, design, and edit content based on individual tastes and interests. The architecture consists of six specialized sub-agents. There is one key step - a writer &lt;&gt; critique loop which adds in a helpful cycle. Other Frameworks LangGraph is not the first framework to support multi-agent workflows. Most of the difference between these frameworks largely lies in the mental models and concepts they introduce. Autogen Autogen emerged as perhaps the first multi-agent framework. The biggest difference in mental model between LangGraph and Autogen is in construction of the agents. LangGraph prefers an approach where you explicitly define different agents and transition probabilities, preferring to represent it as a graph. Autogen frames it more as a "conversation". We believe that this "graph" framing makes it more intuitive and provides better developer experience for constructing more complex and opinionated workflows where you really want to control the transition probabilities between nodes. It also supports workflows that aren't explicitly captured by "conversations." Another key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability. CrewAI Another key framework we want to highlight is CrewAI. CrewAI has emerged recently as a popular way to create multi-agent "teams". Compared to LangGraph, CrewAI is a highe... [truncated]
ðŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ðŸ”¬ Analyzer [1]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] CrewAI offers simple orchestration of multi-agent teams with role/task assignment and coordination mechanisms.
      [2] LangGraph provides fine-grained control over multi-agent workflows with a graph-based architecture and state management.
      [3] CrewAI is a higher-level framework, while LangGraph offers lower-level controllability.
      [4] LangGraph is integrated into the LangChain ecosystem, enabling use of LangChain integrations and LangSmith observability.
      [5] CrewAI has a clear object structure (Agent, Crew, Task) and seamless state management.
   â””â”€ Decision: More research needed
   â””â”€ Next query: LangGraph vs CrewAI multi-agent architecture comparison pros and cons
ðŸ” Searcher [2]: Follow-up search for: LangGraph vs CrewAI multi-agent architecture comparison pros and cons

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://medium.com/@saeedhajebi/langgraph-is-not-a-true-agentic-framework-3f010c780857
      [2] https://www.leanware.co/insights/langgraph-vs-crewai-comparison
      [3] https://www.zams.com/blog/crewai-vs-langgraph
      [4] https://www.amplework.com/blog/langgraph-vs-autogen-vs-crewai-multi-agent-framework/
      [5] https://blog.langchain.com/langgraph-multi-agent-workflows/
   â””â”€ Snippets:
      â€¢ The trade-off is clear: CrewAI gives you convenience but hides internal logic, whereas LangGraph exposes all the moving parts. As noted in industry comparisons, â€œif CrewAI is like using a ready-made template, LangGraph is like coding your system from scratch with a powerful library â€” more effort but also more flexibility.â€(  LangGraph vs. Original LangChain Agents: Evolution of Control  LangChain Agents (Classic): [...] The fundamental difference is in how multi-agent interactions are managed: AutoGen allows for emergent, flexible agent interactions, while LangGraph requires explicit definition of all potential interaction patterns.  LangGraph vs. CrewAI: Ease of Use vs. Customizability  CrewAI: [...] Aaron Yuâ€™s comparison of frameworks highlights this issue: â€œLangGraph [has] rigid state management â€” state needs to be well-defined upfront, which can become complex and messy in more intricate agentic networks.â€(  This complexity contrasts with frameworks like CrewAI, which according to the same analysis offers â€œseamless state management with out-of-the-box agent coordination.â€(
      â€¢ CrewAI was designed specifically for multi-agent systems with better abstractions for agent collaboration. Agents communicate naturally, delegate tasks, and operate in parallel. LangGraph can implement multi-agent patterns but requires explicit graph design for coordination. For workflows primarily about multiple agents collaborating autonomously, CrewAI's model fits better. For workflows needing precise control over agent interactions, LangGraph provides more determinism.  ## Related Posts [...] Neither is universally better. LangGraph provides durable execution, persistent state management, and LangChain ecosystem integration, making it suitable for production systems requiring reliability. CrewAI offers faster development with autonomous agents and less boilerplate, fitting prototypes and simpler workflows. Choose based on priorities: control and durability versus speed and agent autonomy.  Can I use CrewAI for production workflows? [...] LangGraph runs nodes in parallel if there are no dependencies. You control concurrency through graph design. Rate limiting requires wrapping calls or adding delay nodes.  CrewAI supports asynchronous execution out of the box. Multiple agents can run in parallel, with configurable concurrency limits. Async support makes I/O-heavy workflows more efficient.  ### 5. Enterprise Compliance and Security  Neither framework handles authentication, authorization, or audit logging.
      â€¢ While Crewai offers a beginner-friendly and is easy-to-use, it is limited in flexibility. On the other hand, LangGraph offers great control and flexibility but is not easy to quickly set up and get going.  > Both these platforms are primarily for software development teams.  When engineering teams want to research and quickly prototype, they go for Crew. And during production, they prefer LangGraph to develop agents for complex and detailed workflows. [...] So, in case of LangGraph, more effort is needed for the initial set up and configuration, and comes with a steeper learning curve.  ### 2. Scalability  #### Crewai: Designed for research  It can scale well and handle a moderate number of agents and task-based workflows, however, conditional logic within workflows can be tricky. Crewai agents are a better fit when independent agents donâ€™t need to constantly talk to each other, and not for real-time interaction-heavy use cases. [...] LangGraph manages concurrent, stateful agent workflows with high efficiency as it is built to handle large volumes of simultaneous agent events with great control.  While LangGraph is highly tunable, you need to actively optimize it for best performance. Streaming intermediate steps can enhance user experience by providing real-time updates on agent reasoning and actions.  ### 4. Cost and community support  #### Crewai: Open-source and expanding community
ðŸ’­ Think: Query: LangGraph vs CrewAI multi-agent architecture comparison pros and cons | Found 5 results, 5 URLs. Key snippets: The trade-off is clear: CrewAI gives you convenience but hides internal logic, whereas LangGraph exp | CrewAI was designed specifically for multi-agent systems with better abstractions for agent collabor | While Crewai offers a beginner-friendly and is easy-to-use, it is limited in flexibility. On t. Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
   â””â”€ [https://medium.com/@saeedhajebi/langgraph-is-not-a-true-agentic-framework-3f010c780857]
      Preview: Error: HTTP 403 for URL: https://medium.com/@saeedhajebi/langgraph-is-not-a-true-agentic-framework-3f010c780857
ðŸ“– Read URL: https://www.leanware.co/insights/langgraph-vs-crew... (8015 chars)
   â””â”€ [https://www.leanware.co/insights/langgraph-vs-crewai-comparison]
      Preview: --> LangGraph vs CrewAI: Feature, Pricing &amp; Use Case Comparison top of page Services Staff Augmentation AI Strategy &amp; Integration Services Data Engineering Solutions Digital Products Development Testimonials Case Studies About Us Our Culture Tech Stack React.js Python Angular Vue.JS React Native Flutter Swift All technologies Engagement Models Contact Us Let&#x27;s Talk Let&#x27;s Talk Learn more at Clutch &nbsp;and&nbsp; Tech Times Got a Project in Mind? Letâ€™s Talk! Full Name * Your company email * Tell us about your project * How did you hear about us? * Get in Touch LangGraph vs CrewAI: Feature, Pricing &amp; Use Case Comparison Leanware Editorial Team Nov 13 7 min read AI agent orchestration frameworks have made it easier for teams to build automation systems. Instead of coding every rule or path, you can now create agents that handle tasks and coordinate with each other. LangGraph and CrewAI tackle this in different ways. Letâ€™s look at how each framework works, what they do well, and where they make the most sense in production. What Is LangGraph? LangGraph is an open-source orchestration framework for building stateful, long-running agents. Itâ€™s part of the LangChain ecosystem but can also run independently. Workflows in LangGraph are modeled as state graphs , where nodes represent actions and edges define control flow. Each node takes in the current state, performs an operation, like calling a language model, querying a database, or executing custom logic, and returns an updated state. This structure keeps execution paths clear and easy to debug. LangGraph is built for teams that need reliable, production-grade automation with clear control and visibility. Itâ€™s a good fit for workflows that require consistency and human oversight, like customer operations or document processing. Core Capabilities Durable execution : Workflows can recover automatically from crashes or restarts, resuming from the last checkpoint. This is useful for long-running processes like approvals or batch jobs. Human-in-the-loop : You can pause execution at any point, wait for human input, and resume later with that input included. State is stored persistently, so workflows can pause indefinitely. Memory management : Supports both short-term and long-term memory. Agents retain conversation history and past context across sessions for consistent decision-making. LangSmith integration : Provides debugging tools and observability. You can trace execution paths, inspect state transitions, and monitor runtime metrics. Flexible agent creation: Use create_react_agent for quick setup or build custom graphs manually for full control over logic and flow. What Is CrewAI? CrewAI is a Python framework built independently of LangChain. Itâ€™s open source under the MIT license and focuses on multi-agent coordination. The framework offers two main approaches: Crews for autonomous agent collaboration and Flows for event-driven workflow control. Crews organize agents by roles such as researcher, writer, or analyst and assign them tasks. Flows manage complex execution paths with conditional branching and state management. CrewAI focuses on speed and simplicity. It needs less setup than graph-based frameworks, so you can build multi-agent systems with only a small amount of code. Core Capabilities CrewAI handles multi-agent workflows through key features: Agent structure: Work is organized around agents with roles, goals, and backstories that define how they behave. Tasks assign objectives and specify which agent handles them. Work can run sequentially or in hierarchical mode, where a manager agent delegates tasks. Autonomous operation: Agents handle tasks independently. They choose tools, request help from other agents, and escalate tasks they canâ€™t complete. This coordination comes from configuration rather than hardcoded routing. Flows for control: Event-driven workflows use decorators like @start , @ listen , and @router . Conditions can be combined with or _ and and _ for more complex triggers, allowing a mix of autonomous agents and structured control in the same application. Tool integration: Python functions can be marked with @tool , making them accessible to agents. CrewAI manages discovery and parameter extraction automatically. Enterprise features: The AMP Suite provides tracing, observability, a control plane, and support options, with the Crew Control Plane available for free trials. LangGraph vs CrewAI: Key Differences 1. Framework Maturity &amp; Development Lineage LangGraph is part of the LangChain ecosystem and benefits from its established tools and production deployments. The team maintains compatibility with major LLM providers and actively addresses edge cases. CrewAI is newer and developed by an independent team. Features are released quickly, though documentation can lag. Community activity is strong, and bleeding-edge features often appear first, but LangGraph is generally more stable for production systems. 2. Workflow Deployment Patterns LangGraph relies on explicit graph definitions. You build a StateGraph, add nodes, define edges with conditions, and compile the graph. This approach gives precise control but requires upfront design. CrewAI uses a higher-level, declarative approach. Agents and tasks are defined in Python or YAML, then run in a Crew. Flows provide event-driven control with decorators. This reduces boilerplate but hides some execution details. Graphs help with complex branching, while CrewAI works well for simpler sequences. 3. Human-in-the-Loop Capabilities LangGraph handles human input through interrupt nodes and persistent state. Workflows can pause, wait for approval, and resume without losing context. State persists indefinitely, and checkpoints let you audit decisions. CrewAI supports human input via callbacks or a human_input parameter. Agents can request input, but long pauses require custom state handling. 4. Parallel Agent Execution and Throttling LangGraph runs nodes in parallel if there are no dependencies. You control concurrency through graph design. Rate limiting requires wrapping calls or adding delay nodes. CrewAI supports asynchronous execution out of the box. Multiple agents can run in parallel, with configurable concurrency limits. Async support makes I/O-heavy workflows more efficient. 5. Enterprise Compliance and Security Neither framework handles authentication, authorization, or audit logging. LangGraph stores state in memory, SQLite, or PostgreSQL, letting you control encryption and sensitive data. CrewAI uses the Python process permissions and the AMP Suite for observability and control, but access control needs to be implemented separately. Both require custom solutions for compliance, user management, and audit trails. Integration Support LangGraph Integrations LangGraph connects with LangChain tools, including LLMs like OpenAI and Anthropic, vector databases such as Pinecone and Chroma, and document loaders. Memory integrations preserve context between nodes, and tool actions like web search, SQL queries, API calls, and Python execution are supported. LangSmith adds tracing, metrics, and visualization, with paid plans from $39/month. CrewAI Integrations CrewAI works with LLMs via direct API calls or LangChain wrappers, letting each agent use a different model. Tools are exposed with the @tool decorator, including web search, file operations, and HTTP requests. FastAPI integration allows workflows to run as REST APIs, with async support for efficient execution. Pricing Comparison LangGraph Pricing LangGraph connects with LangChain tools, including LLMs like OpenAI and Anthropic, vector databases such as Pinecone and Chroma, and document loaders. Memory integrations preserve context between nodes, and tool actions like web search, SQL queries, API calls, and Python execution are supported. LangSmith adds tracing, metrics, and visualization, with paid plans from $39/month. CrewAI Pricing CrewAI works with LLMs via di... [truncated]
ðŸ“– Read URL: https://www.zams.com/blog/crewai-vs-langgraph... (8015 chars)
   â””â”€ [https://www.zams.com/blog/crewai-vs-langgraph]
      Preview: Crewai vs. LangGraph: Multi agent framework comparison | Zams Integrations Customers Pricing Blog Login Login Get Started Get Started Technology April 19, 2025 Crewai vs. LangGraph: Which multi agent framework should you use? Yaagneshwaran Ganesh Objective feature comparison to help you decide - based on features, benefits, and ideal use cases. While there are different ways to build an AI agent from scratch, itâ€™s great that you are taking the efficient approach of using multi agent frameworks. Youâ€™re probably here because youâ€™ve shortlisted Crew ai and LangGraph and want to decide which one is right for you. Youâ€™re in the right place. In this blog, we will compare the two in detail - on their features, benefits, and ideal use cases, including how agents connect to establish communication and interoperability. To get started, we need to have a basic understanding of multi agent systems. So, letâ€™s first get a few basics out of the way. Why do you need a multi-agent framework? As your AI systems scale and you add multiple agents with different capabilities, the complexity of these applications grow. As the complexity grows, you will need a structured environment that orchestrates the agent activities, including the technical steps and requirements involved in building agents. That is where agentic frameworks come in. Multi agent frameworks provide you with a foundational structure for developing autonomous systems, and define parameters and protocols to handle interactions between multiple specialized agents. These frameworks also incorporate agent actions, which are fundamental components within a node-based AI framework, facilitating the execution of complex tasks. An agentic application can significantly enhance user experience and system efficiency by streamlining user interaction through minimal input and adaptive responses. Single agent systems These systems are autonomous but rely on one agent to handle a wide range of tasks, like a jack of all trades. For example, hereâ€™s how it works when requested for a sales pipeline report: As you can see, one agent carries out a series of tasks to accomplish the requested outcome. Single agent systems are great for specialized tasks where the problem is well defined and the scope is limited. But as your environment and context evolves, they fall short. Multi agent systems Multi agent systems, on the contrary, consist of multiple AI agents working together to achieve common goals. Letâ€™s look at the same example of requesting to email the sales report, and see how the multi agent architecture manages specialized agents to execute it. Instead of one agent accomplishing all the tasks, the tasks are broken down into smaller components where each agent specializes in a specific task â€“ such as planning, integrating, analyzing, and more like a team of specialists working together, where each brings their unique expertise to the table. And because these AI agents can collaborate dynamically and run these tasks in parallel, they can tackle more complex problems where the environment is always changing and evolving. Multi agent interactions allow these AI agents to communicate within the system, monitor and debug in real-time, and handle handoffs efficiently, enabling dynamic workflows. The better you understand how these multi agents interact, the better you can optimize these systems and scale your operations, without worrying about bottlenecks or performance issues. And thatâ€™s exactly what multi agent frameworks help you with. Additionally, these frameworks give you a set of pre-packaged tools and features to help you quickly build any type of agent systems, be it knowledge oriented, process oriented or predictive. In short, agentic frameworks are the backbone of scalable, efficient and autonomous AI operations. With that said letâ€™s get to the comparison. What is Crewai? It is an open-source multi agent orchestration framework, that helps you build multi agent systems, and integrate them with the latest LLMs and your codebase. The framework automates multi-agent workflows, enables them to communicate and collaborate on tasks as a team, and make decisions autonomously. Their modular design includes a range of tools such as agents, tools, tasks, processes, and an agent development kit, to engage, collect information, handle complex tasks, and manage their operations through tool calls. Crewâ€™s hierarchical process generates a supervisor agent to oversee task execution and agent coordination. The agent engine facilitates the transition from prototype to production by managing various complexities including infrastructure, security, and performance evaluation, while integrating seamlessly with existing frameworks. With asynchronous tool execution, agents can work on different business processes concurrently, increasing productivity. Crew is primarily designed for research and quick prototypes. What is LangGraph framework (by LangChain)? LangGraph is an open-source AI framework to develop, deploy and manage advanced workflows for generative AI agents. Using graph-based architecture LangGraph handles the relationships between different components of the AI workflow. LangGraph applications offer robust features like scalable infrastructure and self-hosted deployment options that enhance workflow management and processing without adding overhead. Built on LangChain, a Python framework for AI applications, LangGraph excels at managing large language models. Function calling is integral to enhancing the capabilities of AI applications, particularly when combined with structured outputs and fine-tuning techniques. The LangGraph platform provides various deployment options, including self-hosted solutions, cloud SaaS, and the Bring Your Own Cloud (BYOC) option, catering to different user needs and preferences. With LangGraph Studio, a visual interface to develop workflows, users can reduce coding. One of LangGraphâ€™s key features is its state management system which acts like a memory bank, storing information and enabling better state management and debugging. Users can run LangGraph Platform entirely on their own infrastructure as part of a Self-Hosted Enterprise solution, allowing companies to maintain control over their data while outsourcing the management of some services. The integrated development environment in LangGraph Studio is specifically tailored for AI agent development, offering powerful tools for visualization, real-time interaction, and debugging, which enhances the overall development experience for users working with agent workflows. This is crucial for graph execution as it allows managing individual agents as graph nodes in the system. LangGraph supports a human-in-the-loop approach, so human input can enhance AI decision making and user interactions. LangGraph is primarily designed for engineering teams and production. Architecture and design philosophy Architecture and design of agent frameworks play a huge role in determining their effectiveness to support development of complex AI applications. A well-designed framework ideally provides a modular and flexible structure, allowing you to easily integrate various components and tools. Additionally, the framework should support seamless interaction between multiple agents, making it easy to build sophisticated workflows and applications. Crewai agents approach Crew is an agent framework that adopts a collaborative intelligence approach, helping you create multi-agent systems where specialized agents work together to achieve shared objectives. This approach is particularly useful for applications requiring dynamic task allocation, large language models, and multi-agent orchestration. LangGraph agents framework LangGraph is an agent framework that takes a state-centric approach, providing a graph-based architecture to enable creation of complex workflows and applications. This approach is ideal for applications requiring sophisticated state management, kno... [truncated]
ðŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ðŸ”¬ Analyzer [2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] CrewAI offers a convenient, beginner-friendly approach to multi-agent systems but hides internal logic and has limited flexibility.
      [2] LangGraph exposes all the moving parts, offering great control and flexibility, but requires more effort to set up and get going.
      [3] CrewAI is designed for rapid setup and intuitive team-based agent collaboration.
      [4] LangGraph offers more customization and scalability for complex workflows and is integrated into the LangChain ecosystem.
      [5] CrewAI's model fits better for workflows primarily about multiple agents collaborating autonomously, whereas LangGraph provides more determinism for workflows needing precise control over agent interactions.
   â””â”€ Decision: Research complete (12 total findings)

ðŸ“¦ Compress: Compressing 12 findings, 6 contents
   â””â”€ Compressed to 2451 chars (from ~4992 raw chars)
   â””â”€ Sources cited: 5
   â””â”€ Preview:
      ## Key Findings
      - CrewAI and LangGraph are frameworks for building multi-agent systems, each with distinct strengths [1], [5].
      - CrewAI is designed for rapid prototyping and intuitive team collaboration, making it beginner-friendly [1], [5].
      - LangGraph offers greater control, customization, and scalability, particularly for complex workflows, and integrates with the LangChain ecosystem [3], [5].
      - The choice between CrewAI and LangGraph depends on the desired level of control, complexity of the workflow, and speed of development [1], [5].
      
      ## Detailed Information
      
      **Overview:**
      CrewAI and LangGraph are frameworks designed to simplify the development of multi-agent systems [1], [5]. CrewAI is a higher-level framework that provides a more streamlined experience, while LangGraph offers lower-level control and flexibility [1].
      
      **CrewAI:**
      CrewAI offers a clear object structure (Agent, Crew, Task) and seamless state management [1], [5]. It is designed for rapid setup and intuitive team-based agent collaboration, making it convenient and beginner-friendly [1]. CrewAI's model fits better for workflows primarily about multiple agents collaborating autonomously [1]. However, it can be difficult to refine for complex systems due to logging limitations and limited flexibility, as it hides internal logic [1], [5]. CrewAI is preferred for rapid prototyping [1].
      
      **LangGraph:**
      LangGraph provides fine-grained control over multi-agent workflows through a graph-based architecture and state management [3]. It exposes all the moving parts, offering great control and customization for complex workflows [5]. LangGraph provides more determinism for workflows needing precise control over agent interactions [1]. It is integrated into the LangChain ecosystem, enabling the use of LangChain integrations and LangSmith observability [3]. LangGraph requires more effort to set up initially but is favored for production environments [1].
      
      **Comparison:**
      CrewAI is suitable for workflows where multiple agents collaborate autonomously, whereas LangGraph is better suited for workflows needing precise control over agent interactions [1]. CrewAI prioritizes rapid setup and ease of use, while LangGraph emphasizes customization and scalability [1], [5].
      
      ## Sources
      [1] https://www.zams.com/blog/crewai-vs-langgraph
      [3] https://blog.langchain.com/langgraph-multi-agent-workflows/
      [5] https://www.leanware.co/insights/langgraph-vs-crewai-comparison

âœï¸ Writer: Composing response from 12 findings
   â””â”€ Using compressed notes (2451 chars)

âœï¸ Writer: Generated response (2646 chars)
   â””â”€ Sources used:
      [1] https://www.zams.com/blog/crewai-vs-langgraph
      [2] https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72
      [3] https://blog.langchain.com/langgraph-multi-agent-workflows/
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      
      CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆìž„ì›Œí¬ì´ì§€ë§Œ, CrewAIëŠ” ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ì œìž‘ê³¼ ì‰¬ìš´ íŒ€ í˜‘ì—…ì— ì¤‘ì ì„ ë‘ê³ , LangGraphëŠ” ë³µìž¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ë” ì„¸ë°€í•œ ì œì–´, ì‚¬ìš©ìž ì •ì˜, í™•ìž¥ì„±ì„ ì œê³µí•œë‹¤ [1], [5]. ë”°ë¼ì„œ í”„ë¡œì íŠ¸ì˜ ë³µìž¡ì„±, ê°œë°œ ì†ë„, í•„ìš”í•œ ì œì–´ ìˆ˜ì¤€ì— ë”°ë¼ ì í•©í•œ í”„ë ˆìž„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤ [1], [5].
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   CrewAIëŠ” ì‚¬ìš©ìž ì¹œí™”ì ì¸ ì¸í„°íŽ˜ì´ìŠ¤ì™€ ê°ì²´ êµ¬ì¡°(Agent, Crew, Task)ë¥¼ í†µí•´ ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ì œìž‘ì— ìš©ì´í•˜ë©°, ì—ì´ì „íŠ¸ ê°„ì˜ ìžìœ¨ì ì¸ í˜‘ì—…ì— ìµœì í™”ë˜ì–´ ìžˆë‹¤ [1], [5].
      *   LangGraphëŠ” ê·¸ëž˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ìƒíƒœ ê´€ë¦¬ë¥¼ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, LangChain ìƒíƒœê³„ì™€ì˜ í†µí•©ì„ í†µí•´ LangChainì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ ë° LangSmithì˜ ê´€ì¸¡ ê°€ëŠ¥ì„±ì„ í™œìš©í•  ìˆ˜ ìžˆë‹¤ [3], [5].
      *   CrewAIëŠ” ì´ˆê¸° ì„¤ì •ì´ ê°„íŽ¸í•˜ì§€ë§Œ ë‚´ë¶€ ë¡œì§ì´ ìˆ¨ê²¨ì ¸ ìžˆì–´ ë³µìž¡í•œ ì‹œìŠ¤í…œì„ ê°œì„ í•˜ê¸° ì–´ë µê³  ë¡œê¹… ì œí•œì´ ì¡´ìž¬í•œë‹¤ [1], [5].
      *   LangGraphëŠ” ì´ˆê¸° ì„¤ì •ì— ë” ë§Žì€ ë…¸ë ¥ì´ í•„ìš”í•˜ì§€ë§Œ, ì—ì´ì „íŠ¸ ìƒí˜¸ ìž‘ìš©ì— ëŒ€í•œ ì •í™•í•œ ì œì–´ê°€ í•„ìš”í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ì í•©í•˜ë©°, í”„ë¡œë•ì…˜ í™˜ê²½ì— ì„ í˜¸ëœë‹¤ [1].
      
      ## ìƒì„¸ ë¶„ì„
      
      CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì„ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ í”„ë ˆìž„ì›Œí¬ì´ì§€ë§Œ, ì ‘ê·¼ ë°©ì‹ê³¼ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ ë©´ì—ì„œ ì°¨ì´ê°€ ìžˆë‹¤. CrewAIëŠ” ë” ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œìžê°€ ë¹ ë¥´ê²Œ ì—ì´ì „íŠ¸ íŒ€ì„ êµ¬ì„±í•˜ê³  ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìžˆë„ë¡ ì§€ì›í•œë‹¤ [1], [5]. ë°˜ë©´, LangGraphëŠ” ë” ë‚®ì€ ìˆ˜ì¤€ì˜ ì œì–´ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œìžê°€ ì—ì´ì „íŠ¸ ê°„ì˜ ìƒí˜¸ ìž‘ìš©ê³¼ ì›Œí¬í”Œë¡œìš°ì˜ ê° ë‹¨ê³„ë¥¼ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤ [1].
      
      **CrewAI:** CrewAIëŠ” `Agent`, `Crew`, `Task`ë¼ëŠ” ëª…í™•í•œ ê°ì²´ êµ¬ì¡°ë¥¼ ì œê³µí•˜ì—¬ ì—ì´ì „íŠ¸ ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§ê´€ì ìœ¼ë¡œ ì„¤ê³„í•˜ê³  ê°œë°œí•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤ [1], [5]. íŠ¹ížˆ, ìƒíƒœ ê´€ë¦¬ê°€ ë‹¨ìˆœí•˜ê³  íŒ€ ê¸°ë°˜ ì—ì´ì „íŠ¸ í˜‘ì—…ì— ìµœì í™”ë˜ì–´ ìžˆì–´ ì´ˆë³´ìžë„ ì‰½ê²Œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìžˆë‹¤ [1]. í•˜ì§€ë§Œ CrewAIëŠ” ë‚´ë¶€ ë¡œì§ì„ ìˆ¨ê¸°ê³  ìžˆì–´ ì‹œìŠ¤í…œì˜ ë³µìž¡ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼ ë””ë²„ê¹… ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•ì´ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìžˆìœ¼ë©°, ë¡œê¹… ê¸°ëŠ¥ì˜ ì œí•œìœ¼ë¡œ ì‹œìŠ¤í…œì˜ ë™ìž‘ì„ ìžì„¸ížˆ ë¶„ì„í•˜ê¸° ì–´ë µë‹¤ëŠ” ë‹¨ì ì´ ìžˆë‹¤ [1], [5]. ë”°ë¼ì„œ, ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ì œìž‘ì´ë‚˜ ë¹„êµì  ê°„ë‹¨í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ì í•©í•˜ë‹¤ [1].
      
      **LangGraph:** LangGraphëŠ” ê·¸ëž˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê³ , ê° ë…¸ë“œ(ì—ì´ì „íŠ¸) ê°„ì˜ ì—°ê²°ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤ [3]. ì´ë¥¼ í†µí•´ ê°œë°œìžëŠ” ì—ì´ì „íŠ¸ ê°„ì˜ ì •ë³´ íë¦„, ì˜ì‚¬ ê²°ì • ê³¼ì •, ìƒíƒœ ë³€í™” ë“±ì„ ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìžˆìœ¼ë©°, ë³µìž¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìžˆë‹¤ [5]. ë˜í•œ, LangGraphëŠ” LangChain ìƒíƒœê³„ì™€ì˜ ê¸´ë°€í•œ í†µí•©ì„ í†µí•´ LangChainì˜ ë‹¤ì–‘í•œ ì»´í¬ë„ŒíŠ¸(ì˜ˆ: LLM, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)ë¥¼ í™œìš©í•˜ê³ , LangSmithë¥¼ í†µí•´ ì‹œìŠ¤í…œì˜ ë™ìž‘ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ë””ë²„ê¹…í•  ìˆ˜ ìžˆë‹¤ [3]. í•˜ì§€ë§Œ, LangGraphëŠ” ì´ˆê¸° ì„¤ì •ì— ë” ë§Žì€ ì‹œê°„ê³¼ ë…¸ë ¥ì´ í•„ìš”í•˜ë©°, ê·¸ëž˜í”„ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ì´í•´ë„ê°€ ìš”êµ¬ëœë‹¤ [1]. ë”°ë¼ì„œ, ë†’ì€ ìˆ˜ì¤€ì˜ ì‚¬ìš©ìž ì •ì˜, í™•ìž¥ì„±, ì œì–´ê°€ í•„ìš”í•œ ë³µìž¡í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ì í•©í•˜ë‹¤ [1], [5].
      
      **ì„ íƒ ê¸°ì¤€:** CrewAIëŠ” ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ ìžìœ¨ì ìœ¼ë¡œ í˜‘ì—…í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ì— ì í•©í•˜ë©°, LangGraphëŠ” ì—ì´ì „íŠ¸ ìƒí˜¸ ìž‘ìš©ì— ëŒ€í•œ ì •í™•í•œ ì œì–´ê°€ í•„ìš”í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ì í•©í•˜ë‹¤ [1]. CrewAIëŠ” ë¹ ë¥¸ ì„¤ì •ê³¼ ì‚¬ìš© íŽ¸ì˜ì„±ì„ ìš°ì„ ì‹œí•˜ë©°, LangGraphëŠ” ì‚¬ìš©ìž ì •ì˜ì™€ í™•ìž¥ì„±ì„ ê°•ì¡°í•œë‹¤ [1], [5]. ë”°ë¼ì„œ, í”„ë¡œì íŠ¸ì˜ ëª©í‘œì™€ ìš”êµ¬ ì‚¬í•­ì„ ì‹ ì¤‘í•˜ê²Œ ê³ ë ¤í•˜ì—¬ ì í•©í•œ í”„ë ˆìž„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.
      
      ## ê´€ë ¨ ìžë£Œ ë° ì¶œì²˜
      
      *   [1] https://www.zams.com/blog/crewai-vs-langgraph
      *   [3] https://blog.langchain.com/langgraph-multi-agent-workflows/
      *   [5] https://www.leanware.co/insights/langgraph-vs-crewai-comparison
      
      ## ê²°ë¡  ë° í‰ê°€
      
      CrewAIì™€ LangGraphëŠ” ê°ê°ì˜ ìž¥ë‹¨ì ì„ ê°€ì§„ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• í”„ë ˆìž„ì›Œí¬ì´ë‹¤. CrewAIëŠ” ë¹ ë¥¸ ê°œë°œ ì†ë„ì™€ ì‰¬ìš´ ì‚¬ìš©ë²•ì„ ì œê³µí•˜ë©°, LangGraphëŠ” ë†’ì€ ìˆ˜ì¤€ì˜ ì œì–´ì™€ ì‚¬ìš©ìž ì •ì˜ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ë”°ë¼ì„œ, ê°œë°œí•˜ê³ ìž í•˜ëŠ” ì‹œìŠ¤í…œì˜ ë³µìž¡ì„±, í•„ìš”í•œ ê¸°ëŠ¥, ê°œë°œ ê¸°ê°„ ë“±ì„ ê³ ë ¤í•˜ì—¬ ì í•©í•œ í”„ë ˆìž„ì›Œí¬ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. íŠ¹ížˆ, í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ì´ê³  í™•ìž¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ë©´ LangGraphë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì€ ì„ íƒì¼ ìˆ˜ ìžˆë‹¤. í•˜ì§€ë§Œ, ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ìž…ì„ ì œìž‘í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ CrewAIê°€ ë” íš¨ìœ¨ì ì¸ ì„ íƒì¼ ìˆ˜ ìžˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ, ë‘ í”„ë ˆìž„ì›Œí¬ ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ìœ ìš©í•œ ë„êµ¬ì´ë©°, ê°œë°œìžì˜ ìˆ™ë ¨ë„ì™€ í”„ë¡œì íŠ¸ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ìµœì ì˜ ì„ íƒì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆë‹¤.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 3 Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: LangGraphì™€ CrewAIì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ìž¥ë‹¨ì ì„ ë¶„ì„í•´ì¤˜...
â”‚ Time: 24.87s
â”‚ LLM Calls: 2
â”‚ Search Calls: 2
â”‚ URLs Read: 6
â”‚ Iterations: 2
â”‚ Est. Tokens: 1095
â”‚ Response Length: 2646 chars
â”‚ Has Citations: âœ…
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ðŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½

CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆìž„ì›Œí¬ì´ì§€ë§Œ, CrewAIëŠ” ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ì œìž‘ê³¼ ì‰¬ìš´ íŒ€ í˜‘ì—…ì— ì¤‘ì ì„ ë‘ê³ , LangGraphëŠ” ë³µìž¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ë” ì„¸ë°€í•œ ì œì–´, ì‚¬ìš©ìž ì •ì˜, í™•ìž¥ì„±ì„ ì œê³µí•œë‹¤ [1], [5]. ë”°ë¼ì„œ í”„ë¡œì íŠ¸ì˜ ë³µìž¡ì„±, ê°œë°œ ì†ë„, í•„ìš”í•œ ì œì–´ ìˆ˜ì¤€ì— ë”°ë¼ ì í•©í•œ í”„ë ˆìž„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤ [1], [5].

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   CrewAIëŠ” ì‚¬ìš©ìž ì¹œí™”ì ì¸ ì¸í„°íŽ˜ì´ìŠ¤ì™€ ê°ì²´ êµ¬ì¡°(Agent, Crew, Task)ë¥¼ í†µí•´ ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ì œìž‘ì— ìš©ì´í•˜ë©°, ì—ì´ì „íŠ¸ ê°„ì˜ ìžìœ¨ì ì¸ í˜‘ì—…ì— ìµœì í™”ë˜ì–´ ìžˆë‹¤ [1], [5].
*   LangGraphëŠ” ê·¸ëž˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ìƒíƒœ ê´€ë¦¬ë¥¼ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, LangChain ìƒíƒœê³„ì™€ì˜ í†µí•©ì„ í†µí•´ LangChainì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ ë° LangSmithì˜ ê´€ì¸¡ ê°€ëŠ¥ì„±ì„ í™œìš©í•  ìˆ˜ ìžˆë‹¤ [3], [5].
*   CrewAIëŠ” ì´ˆê¸° ì„¤ì •ì´ ê°„íŽ¸í•˜ì§€ë§Œ ë‚´ë¶€ ë¡œì§ì´ ìˆ¨ê²¨ì ¸ ìžˆì–´ ë³µìž¡í•œ ì‹œìŠ¤í…œì„ ê°œì„ í•˜ê¸° ì–´ë µê³  ë¡œê¹… ì œí•œì´ ì¡´ìž¬í•œë‹¤ [1], [5].
*   LangGraphëŠ” ì´ˆê¸° ì„¤ì •ì— ë” ë§Žì€ ë…¸ë ¥ì´ í•„ìš”í•˜ì§€ë§Œ, ì—ì´ì „íŠ¸ ìƒí˜¸ ìž‘ìš©ì— ëŒ€í•œ ì •í™•í•œ ì œì–´ê°€ í•„ìš”í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ì í•©í•˜ë©°, í”„ë¡œë•ì…˜ í™˜ê²½ì— ì„ í˜¸ëœë‹¤ [1].

## ìƒì„¸ ë¶„ì„

CrewAIì™€ LangGraphëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì„ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ í”„ë ˆìž„ì›Œí¬ì´ì§€ë§Œ, ì ‘ê·¼ ë°©ì‹ê³¼ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ ë©´ì—ì„œ ì°¨ì´ê°€ ìžˆë‹¤. CrewAIëŠ” ë” ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œìžê°€ ë¹ ë¥´ê²Œ ì—ì´ì „íŠ¸ íŒ€ì„ êµ¬ì„±í•˜ê³  ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìžˆë„ë¡ ì§€ì›í•œë‹¤ [1], [5]. ë°˜ë©´, LangGraphëŠ” ë” ë‚®ì€ ìˆ˜ì¤€ì˜ ì œì–´ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œìžê°€ ì—ì´ì „íŠ¸ ê°„ì˜ ìƒí˜¸ ìž‘ìš©ê³¼ ì›Œí¬í”Œë¡œìš°ì˜ ê° ë‹¨ê³„ë¥¼ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤ [1].

**CrewAI:** CrewAIëŠ” `Agent`, `Crew`, `Task`ë¼ëŠ” ëª…í™•í•œ ê°ì²´ êµ¬ì¡°ë¥¼ ì œê³µí•˜ì—¬ ì—ì´ì „íŠ¸ ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§ê´€ì ìœ¼ë¡œ ì„¤ê³„í•˜ê³  ê°œë°œí•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤ [1], [5]. íŠ¹ížˆ, ìƒíƒœ ê´€ë¦¬ê°€ ë‹¨ìˆœí•˜ê³  íŒ€ ê¸°ë°˜ ì—ì´ì „íŠ¸ í˜‘ì—…ì— ìµœì í™”ë˜ì–´ ìžˆì–´ ì´ˆë³´ìžë„ ì‰½ê²Œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìžˆë‹¤ [1]. í•˜ì§€ë§Œ CrewAIëŠ” ë‚´ë¶€ ë¡œì§ì„ ìˆ¨ê¸°ê³  ìžˆì–´ ì‹œìŠ¤í…œì˜ ë³µìž¡ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼ ë””ë²„ê¹… ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•ì´ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìžˆìœ¼ë©°, ë¡œê¹… ê¸°ëŠ¥ì˜ ì œí•œìœ¼ë¡œ ì‹œìŠ¤í…œì˜ ë™ìž‘ì„ ìžì„¸ížˆ ë¶„ì„í•˜ê¸° ì–´ë µë‹¤ëŠ” ë‹¨ì ì´ ìžˆë‹¤ [1], [5]. ë”°ë¼ì„œ, ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ì œìž‘ì´ë‚˜ ë¹„êµì  ê°„ë‹¨í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ì í•©í•˜ë‹¤ [1].

**LangGraph:** LangGraphëŠ” ê·¸ëž˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê³ , ê° ë…¸ë“œ(ì—ì´ì „íŠ¸) ê°„ì˜ ì—°ê²°ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤ [3]. ì´ë¥¼ í†µí•´ ê°œë°œìžëŠ” ì—ì´ì „íŠ¸ ê°„ì˜ ì •ë³´ íë¦„, ì˜ì‚¬ ê²°ì • ê³¼ì •, ìƒíƒœ ë³€í™” ë“±ì„ ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìžˆìœ¼ë©°, ë³µìž¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìžˆë‹¤ [5]. ë˜í•œ, LangGraphëŠ” LangChain ìƒíƒœê³„ì™€ì˜ ê¸´ë°€í•œ í†µí•©ì„ í†µí•´ LangChainì˜ ë‹¤ì–‘í•œ ì»´í¬ë„ŒíŠ¸(ì˜ˆ: LLM, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)ë¥¼ í™œìš©í•˜ê³ , LangSmithë¥¼ í†µí•´ ì‹œìŠ¤í…œì˜ ë™ìž‘ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ë””ë²„ê¹…í•  ìˆ˜ ìžˆë‹¤ [3]. í•˜ì§€ë§Œ, LangGraphëŠ” ì´ˆê¸° ì„¤ì •ì— ë” ë§Žì€ ì‹œê°„ê³¼ ë…¸ë ¥ì´ í•„ìš”í•˜ë©°, ê·¸ëž˜í”„ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ì´í•´ë„ê°€ ìš”êµ¬ëœë‹¤ [1]. ë”°ë¼ì„œ, ë†’ì€ ìˆ˜ì¤€ì˜ ì‚¬ìš©ìž ì •ì˜, í™•ìž¥ì„±, ì œì–´ê°€ í•„ìš”í•œ ë³µìž¡í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ì í•©í•˜ë‹¤ [1], [5].

**ì„ íƒ ê¸°ì¤€:** CrewAIëŠ” ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ ìžìœ¨ì ìœ¼ë¡œ í˜‘ì—…í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ì— ì í•©í•˜ë©°, LangGraphëŠ” ì—ì´ì „íŠ¸ ìƒí˜¸ ìž‘ìš©ì— ëŒ€í•œ ì •í™•í•œ ì œì–´ê°€ í•„ìš”í•œ ì›Œí¬í”Œë¡œìš°ì— ë” ì í•©í•˜ë‹¤ [1]. CrewAIëŠ” ë¹ ë¥¸ ì„¤ì •ê³¼ ì‚¬ìš© íŽ¸ì˜ì„±ì„ ìš°ì„ ì‹œí•˜ë©°, LangGraphëŠ” ì‚¬ìš©ìž ì •ì˜ì™€ í™•ìž¥ì„±ì„ ê°•ì¡°í•œë‹¤ [1], [5]. ë”°ë¼ì„œ, í”„ë¡œì íŠ¸ì˜ ëª©í‘œì™€ ìš”êµ¬ ì‚¬í•­ì„ ì‹ ì¤‘í•˜ê²Œ ê³ ë ¤í•˜ì—¬ ì í•©í•œ í”„ë ˆìž„ì›Œí¬ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.

## ê´€ë ¨ ìžë£Œ ë° ì¶œì²˜

*   [1] https://www.zams.com/blog/crewai-vs-langgraph
*   [3] https://blog.langchain.com/langgraph-multi-agent-workflows/
*   [5] https://www.leanware.co/insights/langgraph-vs-crewai-comparison

## ê²°ë¡  ë° í‰ê°€

CrewAIì™€ LangGraphëŠ” ê°ê°ì˜ ìž¥ë‹¨ì ì„ ê°€ì§„ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• í”„ë ˆìž„ì›Œí¬ì´ë‹¤. CrewAIëŠ” ë¹ ë¥¸ ê°œë°œ ì†ë„ì™€ ì‰¬ìš´ ì‚¬ìš©ë²•ì„ ì œê³µí•˜ë©°, LangGraphëŠ” ë†’ì€ ìˆ˜ì¤€ì˜ ì œì–´ì™€ ì‚¬ìš©ìž ì •ì˜ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ë”°ë¼ì„œ, ê°œë°œí•˜ê³ ìž í•˜ëŠ” ì‹œìŠ¤í…œì˜ ë³µìž¡ì„±, í•„ìš”í•œ ê¸°ëŠ¥, ê°œë°œ ê¸°ê°„ ë“±ì„ ê³ ë ¤í•˜ì—¬ ì í•©í•œ í”„ë ˆìž„ì›Œí¬ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. íŠ¹ížˆ, í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ì´ê³  í™•ìž¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ë©´ LangGraphë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì€ ì„ íƒì¼ ìˆ˜ ìžˆë‹¤. í•˜ì§€ë§Œ, ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ìž…ì„ ì œìž‘í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ CrewAIê°€ ë” íš¨ìœ¨ì ì¸ ì„ íƒì¼ ìˆ˜ ìžˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ, ë‘ í”„ë ˆìž„ì›Œí¬ ëª¨ë‘ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ìœ ìš©í•œ ë„êµ¬ì´ë©°, ê°œë°œìžì˜ ìˆ™ë ¨ë„ì™€ í”„ë¡œì íŠ¸ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ìµœì ì˜ ì„ íƒì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆë‹¤.
======================================================================


ðŸ“Š Running benchmark: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´...

ðŸ”Ž Clarify: Analyzing query...
   â””â”€ Query: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´ì¤˜
   â””â”€ Status: ðŸŸ¢ Clear
   â””â”€ Analysis: The user requests analysis of LLM-based agent system papers published in 2024, and a summary of major trends. The query is specific, providing both the timeframe and the topic. No ambiguity is apparent.
   â””â”€ Topics: LLM-based agent systems, research trends, 2024 publications
ðŸ“‹ Planner: Creating research plan for: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´

ðŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] LLM based agent systems papers 2024
      [2] Large Language Model agent trends 2024
      [3] Agent system architecture using LLMs 2024
      [4] Recent advances in LLM agents 2024
   â””â”€ Focus: Agent architecture, Applications of LLM agents, Performance benchmarks, Tools used
ðŸ” Searcher [1]: Searching for: LLM based agent systems papers 2024

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.sciencedirect.com/science/article/pii/S1571064524001386
      [2] https://arxiv.org/abs/2402.01680
      [3] https://dl.acm.org/doi/10.1145/3712003
      [4] https://papers.nips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html
      [5] https://www.ijcai.org/proceedings/2024/0890.pdf
   â””â”€ Snippets:
      â€¢ Skip to article  My account  Sign in   View PDF  ## Physics of Life Reviews  Volume 51, December 2024, Pages 283-293  # Review LLMs and generative agent-based models for complex systems research  Author links open overlay panel, , , ,   rights and content  Under a Creative Commons license  Open access  ## Highlights   â€¢    We review the recent literature on LLMs and how these tools could shape research in different areas of complexity science.  â€¢ [...] ## Cited by (0)  1 :   These authors contributed equally to this work.  Â© 2024 The Author(s). Published by Elsevier B.V. [...] The advent of Large Language Models (LLMs) offers to transform research across natural and social sciences, offering new paradigms for understanding complex systems. In particular, Generative Agent-Based Models (GABMs), which integrate LLMs to simulate human behavior, have attracted increasing public attention due to their potential to model complex interactions in a wide range of artificial environments. This paper briefly reviews the disruptive role LLMs are playing in fields such as network
      â€¢ From: Taicheng Guo [view email]     (/abs/2402.01680v1) Sun, 21 Jan 2024 23:36:14 UTC (5,000 KB)    [v2] Fri, 19 Apr 2024 01:15:16 UTC (5,001 KB)  Full-text links:  ## Access Paper:  View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors   View PDF  HTML (experimental)  TeX Source  view license  Current browse context:  cs.CL  < prev")    |    next >")  new  |  recent  | 2024-02  Change to browse by: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate  > cs > arXiv:2402.01680  # Computer Science > Computation and Language  arXiv:2402.01680 (cs)  Submitted on 21 Jan 2024 ([v1), last revised 19 Apr 2024 (this version, v2)]  # Title:Large Language Model based Multi-Agents: A Survey of Progress and Challenges  Authors:Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang [...] > Abstract:Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of
      â€¢ November 2022, we limited our review to papers published after this date (exclusion criterion 6). Furthermore, we excluded papers unrelated to SE (exclusion criterion 7) and those that mention LMA systems only in discussions or as future work, without presenting experimental results (exclusion criterion 8). After the third phase, we identified 41 primary studies directly relevant to our research focus. The search process was conducted on November 14th, 2024. [...] ## 5 Research Agenda [...] The paper must be written in English.  âœ“  The paper must have an accessible full text.  âœ“  The paper must adopt LMA techniques to solve SE-related tasks.  The paper has less than five pages.  âœ˜  Duplicate papers or similar studies authored by the same authors.  âœ˜  Books, keynote records, panel summaries, technical reports, theses, tool demos papers, editorials  âœ˜  The paper is a literature review or survey.  âœ˜  The paper does not utilize LMA systems, e.g., using a single LLM agent.  âœ˜
ðŸ’­ Think: Query: LLM based agent systems papers 2024 | Found 5 results, 5 URLs. Key snippets: Skip to article

My account

Sign in

 View PDF

## Physics of Life Reviews

Volume 51, December 202 | From: Taicheng Guo [view email]   
 (/abs/2402.01680v1) Sun, 21 Jan 2024 23:36:14 UTC (5,000 KB)  
  | November 2022, we limited our review to papers published after this date (exclusion criterion . Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
   â””â”€ [https://www.sciencedirect.com/science/article/pii/S1571064524001386]
      Preview: Error: HTTP 403 for URL: https://www.sciencedirect.com/science/article/pii/S1571064524001386
ðŸ“– Read URL: https://arxiv.org/abs/2402.01680... (5331 chars)
   â””â”€ [https://arxiv.org/abs/2402.01680]
      Preview: [2402.01680] Large Language Model based Multi-Agents: A Survey of Progress and Challenges Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2402.01680 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2402.01680 (cs) [Submitted on 21 Jan 2024 ( v1 ), last revised 19 Apr 2024 (this version, v2)] Title: Large Language Model based Multi-Agents: A Survey of Progress and Challenges Authors: Taicheng Guo , Xiuying Chen , Yaqi Wang , Ruidi Chang , Shichao Pei , Nitesh V. Chawla , Olaf Wiest , Xiangliang Zhang View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors View PDF HTML (experimental) Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents&#39; capacities? For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository, dedicated to outlining the research on LLM-based multi-agent systems. Comments: This work is ongoing and we welcome your contribution! Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) Cite as: arXiv:2402.01680 [cs.CL] &nbsp; (or arXiv:2402.01680v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2402.01680 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Taicheng Guo [ view email ] [v1] Sun, 21 Jan 2024 23:36:14 UTC (5,000 KB) [v2] Fri, 19 Apr 2024 01:15:16 UTC (5,001 KB) Full-text links: Access Paper: View a PDF of the paper titled Large Language Model based Multi-Agents: A Survey of Progress and Challenges, by Taicheng Guo and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2024-02 Change to browse by: cs cs.AI cs.MA References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status
   â””â”€ [https://dl.acm.org/doi/10.1145/3712003]
      Preview: Error: HTTP 403 for URL: https://dl.acm.org/doi/10.1145/3712003
ðŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ðŸ”¬ Analyzer [1]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] Physics of Life Reviews published a review in December 2024 discussing LLMs and generative agent-based models for complex systems research.
      [2] A survey paper titled 'Large Language Model based Multi-Agents: A Survey of Progress and Challenges' was submitted to arXiv in January 2024 and revised in April 2024.
      [3] The survey recognizes the LLM-MA field is in its early stages and rapidly evolving.
      [4] MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution was presented at NeurIPS 2024.
      [5] A study identified 41 primary studies directly relevant to research focus by November 14th, 2024.
   â””â”€ Decision: More research needed
   â””â”€ Next query: recent trends in LLM-based agent systems 2024
ðŸ” Searcher [2]: Follow-up search for: recent trends in LLM-based agent systems 2024

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
      [2] https://arxiv.org/html/2510.04023v1
      [3] https://www.emergentmind.com/topics/llm-based-agent-frameworks
      [4] https://blog.promptlayer.com/types-of-llm-agent/
      [5] https://www.turing.com/resources/top-llm-trends
   â””â”€ Snippets:
      â€¢ An important caveat here lies in how the agents are implemented. Most deployments use an LLM as a thin wrapper/orchestrator that "calls" existing APIs as tools. In essence, this trend represents a shift from a less manual approach " clicking fetch data, upload to Salesforce, and generate report buttons" to a more streamlined approach "saying generate report" while an LLM-enabled pipeline handles the clicking. [...] Trend: LLMs act as thin orchestration layers that translate natural language requests into multiple of API calls (minimizes clicks and intermediate tasks).  ## 2. â€œAgent-Nativeâ€ Foundation Models [...] This shift toward "agent-native" architectures reflects a growing understanding that effective agents need more than just typical language modeling capabilities - they need built-in capabilities for planning, tool use, and coordination.  Before: LLMs focused solely on language modeling. Capabilities like planning, tool use, and task decomposition/reasoning implemented external to the model.
      â€¢ Recent work also introduces protocol-based connectors such as the Model Context Protocol (MCP), which standardize how agents access external tools and data sources (Anthropic, 2024). MCP provides a unified interface layer that reduces custom integration overhead and enhances reproducibility, security, and auditability across IDE, desktop, and API environments. By integrating these modules, LLM-based agents move beyond static language models to function as interactive, context-aware systems [...] running analyses, training models, generating visualizations, and presenting results (Hassan et al., 2023; Yu et al., 2024). Early systems such as HuggingGPT (Shen et al., 2023), GPT-4 as a Data Analyst (Cheng et al., 2023), and AutoML-Agent (Trirat et al., 2024) exemplify this approach by combining LLMs with external tools to perform multi-step analytical workflows, and recent applications in healthcare demonstrate their adaptability to specialized high stakes decision-making tasks (Qiu et [...] We searched across multiple sources, including peer-reviewed journals, preprints, and major AI venues such as NeurIPS, ICLR, ACL, AAAI, and TMLR, as well as indexing platforms such as Google Scholar. The search targeted papers published between 2023 and 2025, reflecting the recent surge of work on LLM-based agentic systems. Representative search terms included DS agents, LLM agents, multimodal agents, tool-using agents, trustworthy AI systems, and data science automation. This search window
      â€¢ The design of LLM-based agent frameworks is grounded in a modular conception that decomposes agentic cognition into separableâ€”but tightly interactingâ€”components. A consensus emerges around formalizing the agent loop as a cycle of Perception â†’ Planning â†’ Action â†’ Memory, enhanced by tool integrations and self-verification (Zeng et al., 6 Nov 2025, Mi et al., 6 Apr 2025, Zhao et al., 25 Aug 2025, Zhang et al., 3 Oct 2024, Hassouna et al., 17 Sep 2024). The dominant structures are: [...] LLM-based agent frameworks now provide a modular, empirically validated, and theory-driven basis for constructing scalable, interpretable, and domain-extensible autonomous systems. Their evolution is shaped by interdisciplinary adoption, developer experience, and the continued fusion of symbolic, sub-symbolic, and socio-technical perspectives (Wang et al., 1 Dec 2025, Zhao et al., 25 Aug 2025).  ### Sponsor  Organize your preprints, BibTeX, and PDFs with Paperpile.  Paperpile  ### Whiteboard [...] Monolithic and pipelined models are prominent in end-to-end software development (SDAgent-Single, SDAgent-DT), whereas ensemble and graph-based coordination excels in settings demanding parallelism, dynamic task assignment, or robustness (Zeng et al., 6 Nov 2025, Oueslati et al., 5 Nov 2025, Aratchige et al., 13 Mar 2025, Jia et al., 13 Mar 2025, Wang et al., 20 Apr 2025).  ## 3. Key Evaluation Protocols and Benchmarks
ðŸ’­ Think: Query: recent trends in LLM-based agent systems 2024 | Found 5 results, 5 URLs. Key snippets: An important caveat here lies in how the agents are implemented. Most deployments use an LLM as a th | Recent work also introduces protocol-based connectors such as the Model Context Protocol (MCP), whic | The design of LLM-based agent frameworks is grounded in a modular conception that decomposes a. Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
ðŸ“– Read URL: https://newsletter.victordibia.com/p/ai-agents-202... (8015 chars)
   â””â”€ [https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building]
      Preview: AI Agents 2024 Rewind - A Year of Building and Learning Designing with AI Subscribe Sign in Designing with AI Podcast AI Agents 2024 Rewind - A Year of Building and Learning 43 2 15 1Ã— 0:00 Current time: 0:00 / Total time: -13:30 -13:30 Audio playback is not supported on your browser. Please upgrade. AI Agents 2024 Rewind - A Year of Building and Learning Issue #26 | What were the top 5 trends in AI Multi-Agent Systems from 2024? What can we expect in 2025? Victor Dibia, PhD Jan 02, 2025 43 2 15 Share Transcript I spent a good chunk of 2024 focused on multi-agent system s - contributing to AutoGen - an OSS framework for building multi-agent apps, and working on a book on the topic . A lot has happened! This post is an attempt to catalog some of the key events into themes, and a reflection on where things might be headed. The content here is likely subjective (my viewpoint on what was interesting) and is based on a list agent/multi-agent news items I curated over the last year. TLDR: Five key observations from building and studying AI agents in 2024: Enterprises are adopting agents, but with some caveats Teams are building &quot;agent-native&quot; foundation models from the ground up Interface automation agents dominated early commercial applications A Shift to Complex Tasks and the Rise of Frameworks Benchmarks reveal both progress and limitations 1. Enterprise Adoption of Agents in Products .. with Caveats Many enterprises and startups have adopted the term â€œagentsâ€ in products, describing them broadly at systems that act on a userâ€™s behalf with the goal of saving the user time and avoiding tedious/busy work . Some examples below: Microsoft Copilot Agents : â€œThese AI-driven agents assist users in performing a variety of tasks, working alongside you to offer suggestions, automate repetitive tasks, and provide insights to help you make informed decisionâ€ Salesforce Agentforce : â€œAgentforce is a proactive, autonomous AI application that provides specialized, always-on support to employees or customers. You can equip Agentforce with any necessary business knowledge to execute tasks according to its specific roleâ€œ Sema4.ai agents. Sema4 goes a bit further than other offerings in their claims - â€œ&quot;RPA fall short when it comes to complex, knowledge-based work. They lack the ability to reason, make judgments, and adapt to real-world changes.â€ LinkedIn HR Assistant : â€œStarting today, recruiters can choose to delegate time-consuming tasks to Hiring Assistant including finding candidates and assisting in applicant review, so they can focus on the most strategic, people-centric parts of their jobâ€ An important caveat here lies in how the agents are implemented. Most deployments use an LLM as a thin wrapper/orchestrator that &quot;calls&quot; existing APIs as tools. In essence, this trend represents a shift from a less manual approach &quot; clicking fetch data, upload to Salesforce, and generate report buttons&quot; to a more streamlined approach &quot;saying generate report&quot; while an LLM-enabled pipeline handles the clicking. This is clearly the responsible approach - retaining the reliability of existing APIs while improving user experience by minimizing repetitive steps. It is also non-trivial, as ensuring reliable tool selection at production scale remains challenging. While this is still several steps removed from truly autonomous assistants (the holy grail of agents), it represents a first step toward that journey. Before - Separate apps and apis that users interact with to complete business tasks in products Trend : LLMs act as thin orchestration layers that translate natural language requests into multiple of API calls (minimizes clicks and intermediate tasks). 2. â€œAgent-Nativeâ€ Foundation Models An interesting development this year was seeing teams build foundation models specifically designed for agency . What does this mean? Well, a good agent must do a few things well - reason through multi-step plans for tasks, act (use tools), appropriately leverage memory , and communicate with other agents. The important trend here is that these agentic capabilities are now being â€œliftedâ€ into the generative model itself. OpenAI o1 emphasizes reasoning - planning, task decomposition etc that previously would have been spread across multiple agent actions. Right at the end of the year, (December 20), OpenAI announced (but not yet released) the o3 family of models - with even more impressive reasoning capabilities and test-time compute! Test time compute allows models to dynamically allocate additional computational resources (reasoning/thinking time) depending on the complexity of the task. The Gemini models from Google likewise makes progress here with Gemini 2.0 Flashâ€™s native user interface action-capabilities , along with other improvements like multimodal reasoning, long context understanding, complex instruction following and planning, compositional function-calling, native tool use and improved latency There were also advances in models that could do more things . Multimodal output - The Gemini 2.0 Flash from Google is a natively multimodal input (text, images) and output (text, image and audio) model. Huge! ChatGPT advanced voice mode: Movie generation: Movie Gen from Meta a specialized movie generation model. Lynn Cherny writes about Veo 2 - a video generation model from Google and many other creativity tools in this post . This shift toward &quot;agent-native&quot; architectures reflects a growing understanding that effective agents need more than just typical language modeling capabilities - they need built-in capabilities for planning, tool use, and coordination. Before : LLMs focused solely on language modeling. Capabilities like planning, tool use, and task decomposition/reasoning implemented external to the model. Trend : Models now designed from the ground up with built-in capabilities for multi-step task decomposition, planning, tool use, and multimodal interactions. 3. Interface Agents Take Center Stage If there was one application area that dominated commercial agent deployments in 2024, it was interface agents - agents that accomplish tasks by driving interfaces (web browsers, desktop OS etc). Interface Agents - Building Multi-Agent Applications that Act via Controlling Interfaces (Browsers, Apps) Victor Dibia, PhD Â· April 29, 2024 Read full story Startups like Kura AI and Runner H released agent products that solve tasks by driving web browsers. Microsoft's OmniParser improved how agents interact with GUI elements. The new version of AutoGen (and AutoGen Studio) provides a WebSurferAgent preset that can solve tasks by driving a web browser. ChatGPT screen sharing : â€œChatGPT Advanced Voice Mode with vision can also understand whatâ€™s on a deviceâ€™s screen via screen sharingâ€ Anthropic Claude Computer Use : â€œdevelopers can direct Claude to use computers the way people doâ€”by looking at a screen, moving a cursor, clicking buttons, and typing text.â€ Project Mariner from Google â€œcombines strong multimodal understanding and reasoning capabilities to automate tasks using your browser.â€ Browser Use extension : â€œMake websites accessible for AI agentsâ€ The focus on interface automation makes sense - it's where agents can deliver immediate value by automating repetitive tasks across existing disparate applications . Before : The action space of agents was typically from programmatic tools and code execution Trend : Direct manipulation of user interfaces (web, desktop) as the primary method for agent action. 4. A Shift to Complex Tasks and the Rise of Frameworks Multi-agent systems or even just agents are emerging as an approach to solving problems. A common source of angst this year has been around the performance of agents and hence if they are more hype than substance . In a langchain survey , 41% of respondents mention performance as the primary bottleneck to using agents. In my opinion this confusion is rooted in a poor (or perhaps evolving)... [truncated]
ðŸ“– Read URL: https://arxiv.org/html/2510.04023v1... (8015 chars)
   â””â”€ [https://arxiv.org/html/2510.04023v1]
      Preview: LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions 1 Introduction 2 Background 2.1 The Data Science Process and Automation 2.2 Large Language Models and LLM Agents 2.3 Architectures of LLM Agents 2.3.1 Core Modules of LLM-Based Agents 2.3.2 Design Dimensions. 2.4 From General Agents to Data Science Agents 2.4.1 Distinctive Characteristics of Data Science Agents Structured data proficiency. End-to-end lifecycle coverage. Deep tool orchestration. Collaboration and reflection. Trust, safety, and governance. 2.4.2 Illustrative Example: Fraud Detection Agent 2.5 Responsible AI Foundations for LLM Agents Agentic robustness. 3 Methodology 4 Taxonomy of Agentic AI Systems for Data Science 4.1 Lifecycle Stages (S1â€“S6) 4.2 Cross-Cutting Design Attributes 5 Agentic Capabilities Across the Data Science Lifecycle 5.1 Business Understanding and Data Acquisition 5.2 Exploratory Data Analysis and Visualization 5.2.1 Domain Knowledge and Context-Aware Reasoning 5.2.2 Data Visualization 5.2.3 Multimodal Reasoning and Fusion in EDA 5.2.4 Interactive Analysis and Humanâ€“Agent Collaboration 5.2.5 Reporting and Insight Generation 5.2.6 Trust and Safety in EDA 5.3 Feature Engineering (FE) 5.4 Model Building and Selection 5.4.1 Conventional Supervised Training and Selection 5.4.2 Reinforcement Learning and Preference Optimization for Agent Training RL and Preference-Based Alignment RL for Planning and Sequential Tool Use Multi-Agent Reinforcement Learning (MARL) 5.5 Interpretation and Explanation 5.6 Deployment and Monitoring 6 Evaluation and Benchmarking 6.1 Core Evaluation Dimensions 6.2 Functional vs. Process-Centric Evaluation 6.3 Benchmark Datasets and Frameworks 6.4 Evaluation Metrics and Key Performance Indicators (KPIs) Task Correctness. Pipeline-Level Success. Robustness and Reliability. Output Quality (Data, Visualization, and Models). Efficiency and Usability. 6.5 Human-in-the-Loop and Subjective Evaluation 6.6 Current Gaps in Evaluation 7 Open Challenges and Future Directions 7.1 Ambiguous Task Instruction 7.2 Limited Context Window 7.3 Security, Privacy, and Compliance 7.4 Trustworthiness, Reliability, and Alignment Building Trust and Transparency. Ensuring Reliability and Mitigating Hallucination. Achieving Human Aligned Behavior. 7.5 Robustness and Generalizability, 7.6 Benchmarking and Evaluation 7.7 Scalability and Efficiency 7.8 Societal, Ethical, and Economic Challenges 7.9 Multimodal Understanding and Reasoning 8 Conclusion \DocumentMetadata LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions Mizanur Rahman York University Toronto Canada mizanurr@yorku.ca , Amran Bhuiyan York University Canada amran.apece@gmail.com , Mohammed Saidul Islam York University Canada Vector Institute for AI Canada saidulis@yorku.ca , Md Tahmid Rahman Laskar York University Canada Dialpad Inc. Canada tahmid20@yorku.ca , Ridwan Mahbub York University Canada rmahbub@yorku.ca , Ahmed Masry York University Canada masry20@yorku.ca , Shafiq Joty Nanyang Technological University Singapore Salesforce AI Research USA shafiqrayhan@gmail.com and Enamul Hoque York University Canada enamulh@yorku.ca (2025) Abstract. Recent advances in large language models (LLMs) have enabled a new class of AI agents that automate multiple stages of the data science workflow by integrating planning, tool use, and multimodal reasoning across text, code, tables, and visuals. This survey presents the first comprehensive, lifecycle-aligned taxonomy of data science agents, systematically analyzing and mapping forty-five systems onto the six stages of the end-to-end data science process: business understanding and data acquisition, exploratory analysis and visualization, feature engineering, model building and selection, interpretation and explanation, and deployment and monitoring. In addition to lifecycle coverage, we annotate each agent along five cross-cutting design dimensions: reasoning and planning style, modality integration, tool orchestration depth, learning and alignment methods, and trust, safety, and governance mechanisms. Beyond classification, we provide a critical synthesis of agent capabilities, highlight strengths and limitations at each stage, and review emerging benchmarks and evaluation practices. Our analysis identifies three key trends: most systems emphasize exploratory analysis, visualization, and modeling while neglecting business understanding, deployment, and monitoring; multimodal reasoning and tool orchestration remain unresolved challenges; and over 90% lack explicit trust and safety mechanisms. We conclude by outlining open challenges in alignment stability, explainability, governance, and robust evaluation frameworks, and propose future research directions to guide the development of robust, trustworthy, low-latency, transparent, and broadly accessible data science agents. agentic AI, data science agents, multimodal models, reinforcement learning, large language models (LLMs), explainability, fairness, privacy, systematic review â€  â€  copyright: acmcopyright â€  â€  journalyear: 2025 â€  â€  doi: XXXXXXX.XXXXXXX â€  â€  journal: POMACS â€  â€  journalvolume: XX â€  â€  journalnumber: X â€  â€  article: XXX â€  â€  publicationmonth: 5 â€  â€  ccs: Agentic AI â€  â€  ccs: Data Science Agents 1. Introduction The growing demand for data-driven decision-making across industries has made data science an essential capability (Cao, 2017 ; Sarker, 2021 ) . However, realizing its full potential remains challenging due to steep skill barriers and the inherent complexity of end-to-end analytical workflows. Effective data science requires the seamless integration of expertise in business understanding, statistical analysis, data engineering, modeling, deployment, and visualization (Sarker, 2021 ) , a combination of skills rarely present within a single individual or even across many teams. This persistent expertise gap continues to limit the scalable adoption of data-driven practices, particularly among non-technical users who struggle to navigate the full analytical lifecycle from problem formulation to production deployment. Recent advances in Large Language Models (LLMs) are reshaping the landscape of data science by expanding their capabilities far beyond natural language understanding (Yang et al., 2024b ; Yu et al., 2024 ) . LLMs can ingest raw data, generate visualizations, perform statistical analyses, build predictive models, and produce deployment-ready code, all through natural language interactions (Cheng et al., 2023 ; Hassan et al., 2023 ) . These capabilities lower the entry barrier to advanced analytics and enable users without programming or machine learning expertise to engage with complex data science workflows. Leveraging these capabilities, researchers are increasingly developing autonomous agents, widely regarded as a pathway toward Artificial General Intelligence (AGI), that can reason, plan, and execute multi-step tasks. These agents are being applied across diverse domains, including software development (Hong et al., 2023 ) , data science (Zhang et al., 2024b ) , robotics (Kannan et al., 2024 ) , societal simulation (Guo et al., 2024a ) , policy modeling (Qian et al., 2024 ) , gaming (Plaat et al., 2025 ; Wang et al., 2024b ) , scientific discovery (Novikov et al., 2025 ) , and advanced mathematical problem solving at the International Mathematical Olympiad level (Castelvecchi, 2025 ) . Unlike traditional static systems, these agents decompose high-level objectives into subtasks, dynamically select and coordinate tools, and adapt their behavior based on intermediate feedback, thereby managing complex evolving, and long-horizon analytical workflows. A growing number of these agents are now being designed specifically for data science tasks, known as data science (DS) agents. Centered on LLMs and extended with external tools, they aim to support the full data science lifecycle, from business understanding and data acquisition to... [truncated]
ðŸ“– Read URL: https://www.emergentmind.com/topics/llm-based-agen... (8015 chars)
   â””â”€ [https://www.emergentmind.com/topics/llm-based-agent-frameworks]
      Preview: LLM-Based Agent Frameworks Trending Papers Open Problems Email Digest Pricing Log in Sign up Discord Discord Logo Streamline Icon: https://streamlinehq.com Updates Trending Papers Open Problems Email Digest Pricing Log in Sign up Discord Discord Logo Streamline Icon: https://streamlinehq.com 0 }" @focus="focused = true" @click="focused = true; clicked = true" @click.away="clicked = false" @keydown="focused = true" @keydown.escape="setQuery(''); focused = false; clicked = false" @input.debounce.100ms="handleQueryChange();" @input="if ($event.target.value === '') { setQuery('') }" @keyup="if ($event.target.value === '') { setQuery('') }" @keydown.enter.prevent="if (!$event.shiftKey) { $refs.search_form.submit() } else { handleShiftEnter($event) }" maxlength="2000" >LLM-Based Agent Frameworks 0" class="autocomplete-section-title">Papers 0" x-text="`${addCommas(result.metric)} ${result.metric === 1 ? 'citation' : 'citations'}`"> 0" class="autocomplete-section-title">Topics Lightbulb On Streamline Icon: https://streamlinehq.com 0" class="autocomplete-section-title">Authors 0" class="autocomplete-section-title flex items-center justify-between pr-4"> Recent View all Magnifying Glass Streamline Icon: https://streamlinehq.com 2000 character limit reached Sponsor Information Square Streamline Icon: https://streamlinehq.com sidebar-left#trackSponsorClick" data-sponsor="paperpile"> Organize your preprints, BibTeX, and PDFs with Paperpile. sidebar-left#trackSponsorClick" data-sponsor="paperpile"> Get 30 days free Chrome Extension Enhance arXiv with our new Chrome Extension. Chrome Extension LLM-Based Agent Frameworks Updated 8 December 2025 LLM-based agent frameworks are modular systems that decompose agent cognition into perception, planning, action, and memory, enabling autonomous decision-making. They integrate tool APIs and memory mechanisms to support self-reflection, dynamic task delegation, and both single-agent and multi-agent architectures. Rigorous evaluation protocols using benchmarks like test pass rates and code smell reduction guide iterative improvements and practical deployments. LLMâ€“based agent frameworks constitute a technical foundation for constructing, orchestrating, and evaluating autonomous agents or multi-agent systems driven by the capabilities of advanced LLMs. These frameworks aim to provide robust abstractions, tool integrations, memory systems, planning components, and evaluation protocols that enable LLM-powered agents to perform complex, real-world tasks beyond simple prompting or one-shot language generation. The following sections present a systematic exposition of LLM-based agent frameworks, synthesizing current research on software engineering, scientific pipelines, decision support, empirical developer adoption, and unified modeling principles. 1. Foundational Concepts and Taxonomies The design of LLM-based agent frameworks is grounded in a modular conception that decomposes agentic cognition into separableâ€”but tightly interactingâ€”components. A consensus emerges around formalizing the agent loop as a cycle of Perception â†’ Planning â†’ Action â†’ Memory, enhanced by tool integrations and self-verification ( Zeng et al., 6 Nov 2025 , Mi et al., 6 Apr 2025 , Zhao et al., 25 Aug 2025 , Zhang et al., 3 Oct 2024 , Hassouna et al., 17 Sep 2024 ). The dominant structures are: Single-Agent, Tool-Based, and Multi-Agent Methods: As categorized in surveys, single-agent pipelines exploit LLM prompt engineering and self-reflection; tool-based models integrate external APIs or knowledge; multi-agent systems organize specialized roles and foster collaboration or competition ( Zhao et al., 25 Aug 2025 , Li, 9 Jun 2024 ). Unified Modeling Constructs: Core constructs include the LLM &quot;brain,&quot; memory buffers (ephemeral and persistent), planning modules (for goal decomposition), tool-calling APIs, and security/guardrail elements. The LLM-Agent-UMF further delineates a five-module core-agent: planning, memory, profile, action, and security ( Hassouna et al., 17 Sep 2024 ). Communication and Orchestration: Multi-agent frameworks support inter-agent messaging either through direct language channels, structured artifacts (JSON, API calls), or graph-based message-passing topologies ( Yang et al., 21 Nov 2024 , Zhang et al., 3 Oct 2024 , Zhao et al., 25 Aug 2025 ). 2. Architectural Patterns and Workflow Variants LLM-driven agent frameworks adopt a variety of workflow architectures, each targeting specific coordination, abstraction, and scalability requirements: Design Paradigm Core Features Representative Examples Monolithic Single-Agent Unified LLM loop, no inter-agent comms SDAgent-Single, BabyAGI Role-Decomposed Pipelines Sequential delegation (Developer, Tester, etc.) SDAgent-DT, AgentMediation, RefAgent Hierarchical/Managerâ€“Worker Active manager with passives; task routing LLM-Agent-UMF (hybrid), MetaGPT Ensemble/Debate Models Sampling/voting or iterative debate ChatEval, Agent Forest, CMD, MoA DAG/Graph-Structured Task/agent dependency graphs, flexible flows LangGraph, LGC-MARL, AgentCoord Concurrent Modular Asynchronous modules, shared state CMA (Concurrent Modular Agent) Monolithic and pipelined models are prominent in end-to-end software development (SDAgent-Single, SDAgent-DT), whereas ensemble and graph-based coordination excels in settings demanding parallelism, dynamic task assignment, or robustness ( Zeng et al., 6 Nov 2025 , Oueslati et al., 5 Nov 2025 , Aratchige et al., 13 Mar 2025 , Jia et al., 13 Mar 2025 , Wang et al., 20 Apr 2025 ). 3. Key Evaluation Protocols and Benchmarks A hallmark of mature agent frameworks is their coupling with rigorous, replicable evaluation suites: Hybrid Evaluation (Software Engineering): E2EDevBench, a dynamically curated benchmark of real-world PyPI projects, pairs automated test-case migration with requirement-driven LLM verification for granular measurement of requirement implementation, test pass-rate, and code coverage improvement ( Zeng et al., 6 Nov 2025 ). Domain-Specific Metrics: Frameworks targeting refactoring (RefAgent), mediation (AgentMediation), or decision support (LLM-driven explainable AI) employ metrics such as unit test pass-rate, code smell reduction rate, satisfaction/consensus rates, factor alignment, Nash equilibria computation, and LLM-judge rubrics ( Oueslati et al., 5 Nov 2025 , Chen et al., 8 Sep 2025 , Pehlke et al., 10 Nov 2025 ). Empirical Adoption Studies: Comparative analyses across ten open-source agent frameworks (LangChain, AutoGen, LangGraph, CrewAI, MetaGPT, LlamaIndex, Swarm, BabyAGI, Camel, Semantic Kernel) interrogate development efficiency, functional abstraction, learning cost, performance optimization, and maintainability based on large-scale developer discussions ( Wang et al., 1 Dec 2025 ). 4. Representative Frameworks and Empirical Performance Notable agent frameworks instantiate these principles with concrete engineering choices: SWE-Agent Architectures: SDAgent-Single, SDAgent-DT (Developerâ€“Tester), and SDAgent-DDT introduce controlled head-to-head benchmarking under E2EDevBench, revealing that separation of developer and tester roles (DT) improves requirement implementation (â‰ˆ53.5%) over single-agent or waterfall decompositions, and that planning/failure points overwhelmingly limit performance, not code emission ( Zeng et al., 6 Nov 2025 ). RefAgent: A multi-agent LLM system for Java refactoring, adopting a pipeline of planning, execution, compilation, and testing agents with self-reflective feedback loops. Achieves state-of-the-art median test pass rates (90%), code smell reduction (52.5%), and ablation studies show that context retrieval and iterative validation are indispensable ( Oueslati et al., 5 Nov 2025 ). GoalAct: Enforces dynamic global planning and hierarchical skill-based execution, outperforming ReAct baselines by 12.22% on LegalAgentBench and validating the advantages of persistent global objectives and decomposable skills (Searching, ... [truncated]
ðŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ðŸ”¬ Analyzer [2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] LLMs are used as orchestration layers translating natural language to API calls.
      [2] Model Context Protocol (MCP) standardizes how agents access external tools and data sources.
      [3] The agent loop is formalized as Perception -> Planning -> Action -> Memory, enhanced by tool integrations and self-verification.
      [4] LLM agents are used for content generation and interactive experiences.
      [5] In 2024, there was a shift from general-purpose LLMs to models tailored for specific industries and tasks.
   â””â”€ Decision: More research needed
   â””â”€ Next query: 2024 LLM agent architecture trends
ðŸ” Searcher [3]: Follow-up search for: 2024 LLM agent architecture trends

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue
      [2] https://www.amitysolutions.com/blog/llm-expectations-in-2024
      [3] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
      [4] https://thenewstack.io/top-5-ai-engineering-trends-of-2024/
      [5] https://medium.com/@gianluca.mondillo/how-ai-agents-really-work-beyond-the-hype-inside-the-architecture-aa6c892a5c2a
   â””â”€ Snippets:
      â€¢ A significant trend observed in 2024 and continuing into 2025 is the strategic shift towards developing smaller, yet highly capable LLMs. Models such as TinyGPT, TinyGPT-V, and TinyLlama (1.1 billion parameters) exemplify this movement, demonstrating that high performance does not exclusively correlate with massive scale. This focus on efficiency is critical for broader accessibility and deployment, enabling LLMs to run effectively on devices with limited memory, such as mobile applications, [...] The evolution of LLMs is increasingly prioritizing sophisticated reasoning capabilities over mere pattern recognition. OpenAI's o1, released in December 2024, signaled a significant shift towards a "reasoning-first" architecture, emphasizing structured thinking for complex problem-solving. This focus addresses one of the long-standing challenges in AI: the ability to perform logical deduction and explain its decision-making process. Tools like SHAP, LIME, and attention visualization are gaining [...] III. New LLM Releases and Key Players (2024-2025)  The LLM landscape in 2024-2025 is marked by intense competition and rapid innovation, with major players continuously releasing more powerful and versatile models.  ### A. OpenAI's Portfolio  OpenAI continues to lead in LLM innovation with a diverse portfolio addressing various needs:
      â€¢ As we look ahead to 2024, the expectations for LLMs are both exciting and transformative. From becoming smaller, faster, and smarter to leveraging agentic workflows and larger context sizes, LLMs are set to revolutionize various industries. The evolving role of prompt engineers into Agents Architects further highlights the dynamic nature of the AI field. These advancements promise to enhance the accuracy, efficiency, and applicability of LLMs, paving the way for a new era of AI-driven [...] For example, in a content creation application, an Agents Architect might design a workflow where one LLM agent generates an initial draft, another agent reviews and edits the content, and a third agent optimizes it for SEO. By coordinating these agents, the Agents Architect ensures that the final output is of high quality and meets all requirements. This shift underscores the need for AI professionals to continuously adapt and innovate in response to emerging technologies and methodologies. [...] With the rise of agentic workflows, the role of prompt engineers is undergoing a transformation. According to Andrew Ng, the future will see prompt engineers transitioning into "Agents Architects." This new role involves designing how groups of AI agents interact to perform complex tasks effectively. Instead of just crafting individual prompts, Agents Architects will focus on orchestrating multiple agents to collaborate and achieve the best results.
      â€¢ An important caveat here lies in _how_ the agents are implemented. Most deployments use an LLM as a thin wrapper/orchestrator that "calls" existing APIs as tools. In essence, this trend represents a shift from a less manual approach " clicking fetch data, upload to Salesforce, and generate report buttons" to a more streamlined approach "saying generate report" while an LLM-enabled pipeline handles the clicking. [...] >    Before: LLMs focused solely on language modeling. Capabilities like planning, tool use, and task decomposition/reasoning implemented external to the model. >  >    Trend: Models now designed from the ground up with built-in capabilities for multi-step task decomposition, planning, tool use, and multimodal interactions.  3. Interface Agents Take Center Stage  Image 8 [...] >    Before - Separate apps and apis that users interact with to complete business tasks in products >  >    Trend: LLMs act as thin orchestration layers that translate natural language requests into multiple of API calls (minimizes clicks and intermediate tasks).  2. â€œAgent-Nativeâ€ Foundation Models  Image 6  An interesting development this year was seeing teams build foundation models specifically designed for _agency_. What does this mean?
ðŸ’­ Think: Query: 2024 LLM agent architecture trends | Found 5 results, 5 URLs. Key snippets: A significant trend observed in 2024 and continuing into 2025 is the strategic shift towards develop | As we look ahead to 2024, the expectations for LLMs are both exciting and transformative. From becom | An important caveat here lies in _how_ the agents are implemented. Most deployments use an LLM. Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
ðŸ“– Read URL: https://www.linkedin.com/pulse/evolving-landscape-... (8015 chars)
   â””â”€ [https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue]
      Preview: The Evolving Landscape of Large Language Models (2024-2025) Agree & Join LinkedIn By clicking Continue to join or sign in, you agree to LinkedInâ€™s User Agreement , Privacy Policy , and Cookie Policy . Skip to main content LinkedIn Top Content People Learning Jobs Games Join now Sign in #Techfriday The Evolving Landscape of Large Language Models (2024-2025) Report this article Hahn Software Hahn Software Your expert for artificial intelligence and customised software | development, project management, data &amp; AI. Published Aug 1, 2025 + Follow I. Executive Summary The period spanning 2024 to 2025 marks a pivotal phase in the evolution of Large Language Models (LLMs), characterized by their rapid transition from specialized research tools to indispensable components in mainstream business applications. The global market for LLMs is experiencing exponential growth, valued at $6.4 billion in 2024 and projected to reach $36.1 billion by 2030, reflecting widespread enterprise adoption across sectors such as finance, healthcare, and technology. This expansion is driven by significant technological advancements, including the development of smaller, more efficient models, the widespread integration of multimodal capabilities, and a pronounced focus on reasoning-centric architectures. Concurrently, the increasing maturity of open-source LLMs is democratizing access and fostering innovation, while sophisticated fine-tuning techniques and the use of synthetic data are accelerating their production readiness. The impact of LLMs on software development is profound, transforming traditional methodologies and fostering new paradigms like "Vibe Coding." These AI-powered coding assistants are enhancing developer productivity, automating repetitive tasks, and improving code quality across the entire Software Development Lifecycle (SDLC). However, this rapid integration also brings critical considerations, including the persistent challenges of hallucinations, inherent biases, and the substantial environmental footprint associated with LLM training and inference. Addressing these concerns necessitates robust ethical frameworks, transparent development practices, and, crucially, sustained human oversight to ensure responsible and effective AI deployment. II. The Current State of Large Language Models A. Foundational Advancements and Market Growth The trajectory of Large Language Models has seen an unprecedented acceleration from academic curiosities to foundational enterprise technologies. The market's valuation underscores this shift, with a projected compound annual growth rate that highlights a significant investment and reliance on these systems. Enterprises are integrating LLMs to drive automation, extract deeper insights from vast datasets, and enhance customer interactions, moving beyond initial exploratory phases to advanced, integrated implementations within their core operations. This widespread adoption is a testament to the tangible value LLMs are delivering, from streamlining complex workflows to enabling entirely new forms of customer engagement. B. Key Technological Shifts The technological landscape of LLMs is undergoing dynamic transformations, pushing the boundaries of what these models can achieve and how they are deployed. The Rise of Smaller, More Efficient Models A significant trend observed in 2024 and continuing into 2025 is the strategic shift towards developing smaller, yet highly capable LLMs. Models such as TinyGPT, TinyGPT-V, and TinyLlama (1.1 billion parameters) exemplify this movement, demonstrating that high performance does not exclusively correlate with massive scale. This focus on efficiency is critical for broader accessibility and deployment, enabling LLMs to run effectively on devices with limited memory, such as mobile applications, low-power hardware, or in environments with constrained internet access. The emergence of sparse expert models, which activate only relevant parts of their network for specific tasks, further enhances speed and energy efficiency, optimizing resource utilization while maintaining robust performance. This development expands the practical utility of LLMs beyond large-scale data centers, opening avenues for on-device AI and edge computing. Mainstreaming of Multimodal AI Multimodal AI has transitioned from a specialized research area to a mainstream capability, profoundly impacting how users interact with AI systems. OpenAI's GPT-4o, released in May 2024, marked a significant milestone by enabling real-time understanding and response across text, images, and audio. This was quickly followed by similar advancements from other major players, including Google's Gemini 2.0 and Meta's LLaMA 3.2, and Anthropic's Claude 3.5 Sonnet. These models can process and generate content across various modalities, expanding AI's utility in creative tools, enhancing accessibility features, and revolutionizing customer service interactions. For instance, Google's Veo demo showcasing a knife slicing through fruit exemplifies the increasingly realistic and versatile nature of AI-generated video content. The ability to integrate and interpret diverse data types allows for more nuanced and comprehensive AI applications, mirroring human perception more closely. OpenAI's 4o image generation, which integrates text and visual creation into a unified system, allows for multi-turn generation where users can refine images conversationally, demonstrating a sophisticated interplay between language and visuals. Emphasis on Reasoning-Centric Architectures and Interpretability The evolution of LLMs is increasingly prioritizing sophisticated reasoning capabilities over mere pattern recognition. OpenAI's o1, released in December 2024, signaled a significant shift towards a "reasoning-first" architecture, emphasizing structured thinking for complex problem-solving. This focus addresses one of the long-standing challenges in AI: the ability to perform logical deduction and explain its decision-making process. Tools like SHAP, LIME, and attention visualization are gaining traction to help users understand how LLMs arrive at their conclusions, which is particularly crucial in high-stakes domains such as healthcare and finance where transparency and accountability are paramount. This move towards interpretability is not merely a technical refinement but a fundamental step towards building trust and enabling responsible deployment of AI systems. Research is actively challenging the simplified view that LLMs merely "predict the next word," revealing that these models may engage in far more complex internal reasoning and conceptual representation. Advancements in Fine-Tuning Techniques The efficiency and accessibility of deploying LLMs have been significantly bolstered by advancements in fine-tuning techniques. Methods such as prompt tuning and various hybrid approaches allow organizations to customize models for specific tasks without the prohibitive cost and time associated with retraining them from scratch. The integration of Automated Machine Learning (AutoML) further streamlines this process by automating decisions like hyperparameter selection, making fine-tuning more accessible to a broader range of developers and accelerating the journey from development to production readiness. These techniques enable rapid adaptation of general-purpose LLMs to specialized domains, unlocking new application possibilities and reducing development cycles. The Growing Influence of Open-Source LLMs Open-source LLMs have emerged as a powerful force, challenging the dominance of proprietary models and fostering a more collaborative and flexible development ecosystem. Models like Mistral, DeepSeek-V3, and Meta's LLaMA 3.2 have demonstrated strong performance while being publicly available, granting developers greater control and flexibility to build custom applications. This open approach encourages community collaboration, leading to continuous improvements in... [truncated]
ðŸ“– Read URL: https://www.amitysolutions.com/blog/llm-expectatio... (8015 chars)
   â””â”€ [https://www.amitysolutions.com/blog/llm-expectations-in-2024]
      Preview: LLM Expectations in 2024 âš ï¸ Alert: Protect Yourself from Scams Read more Solutions Business Intelligence GenAI Powered Business Intelligence Call Analytics Chat &amp; Social Analytics Call Fraud Protection Customer Engagement Customer Support AI Automation Outbound Call AI Debt Collection Inbound GenAI Call Agents Business Productivity GenAI Powered HR &amp; Administration Microsoft Teams Workplace Analytics AI Agent Management &amp; Creation Products Our products EkoAI Employee Experiences EkoAI SDK Agentic AI SDK Amity Bots Enterprise Chatbot Amity GenAI Platform Manage 1,000+ AI agents at once Other products of Amity Tollring Data Visualisation &amp; Business Intelligence Tools Amity Accentix Enterprise Voicebot Egg Digital AI Analytics, Data, and Marketing Analytics 365 Workplace Analytics for Microsoft Teams Newsroom Company About Amity Solutions Leadership News Partnership Career Customer Stories Contact sales Contact Sales ENG TH Talk to Sales Close Cookie Popup Cookie Preferences By clicking â€œAccept Allâ€, you agree to the storing of cookies on your device to enhance site navigation, analyze site usage and assist in our marketing efforts as outlined in our privacy policy . Strictly Necessary (Always Active) Cookies required to enable basic website functionality. Analytics Cookies helping us understand how this website performs, how visitors interact with the site, and whether there may be technical issues. Marketing Cookies used to deliver advertising that is more relevant to you and your interests. Personalization Cookies allowing the website to remember choices you make (such as your user name, language, or the region you are in). Customize Save Decline All Accept All Generative AI 2024 LLMs: Smaller, Faster, Smarter, More Collaborative Touchapon Kraisingkorn â€¢ June 6, 2024 2 min read Icon to share article on Facebook. Share on Facebook Icon to share article on LinkedIn Share on LinkedIn Icon to share article on X. Share on X Icon to share article on WhatsApp. Share on WhatsApp Copy link Introduction As we step into 2024, the evolution of Large Language Models (LLMs) is set to redefine the AI landscape. With advancements aimed at making these models smaller, faster, and smarter, coupled with innovative workflows to enhance their accuracy, the future of LLMs looks promising. This article explores the key expectations for LLMs in 2024, focusing on their efficiency, the rise of agentic workflows, larger context size support, and the evolving role of prompt engineers. LLMs Will Get Smaller, Faster, and Smarter The trend towards more efficient and compact models is gaining momentum. Leading AI companies like OpenAI, Anthropic, Meta, and Microsoft are at the forefront with models such as GPT-3.5-Turbo , Haiku , LLaMA 3 8B , and Phi-3 . Leading AI Models: GPT-3.5-Turbo, Haiku, LLaMA 3 8B, and Phi-3 The research shows that these smaller language models are able to match or even outperform larger and more expensive models like GPT-4 across various benchmarks. For instance, the compact Phi-3-mini model from Microsoft, with only 3.8 billion parameters, is able to rival the performance of models with significantly more parameters like Mixtral 8x7B and GPT-3.5. Similarly, the 8 billion parameter LLaMA 3 8B model from Meta has been found to be comparable or even better than the larger GPT-3.5 in certain tasks (Microsoft, 2024) . These advancements in model efficiency are anticipated to further reduce costs, making powerful LLMs more practical and widely available for diverse applications, from customer service chatbots to advanced data analytics. The ability of these smaller and more efficient models to match or exceed the performance of their larger counterparts is a significant development that is expected to democratize access to advanced AI capabilities. Businesses and startups will be able to leverage these cost-effective and energy-efficient LLMs to unlock new use cases and drive innovation. Agentic Workflow One of the most groundbreaking advancements in AI is the shift towards agentic workflows. Andrew Ng , a renowned AI expert, has underscored the significance of these workflows in driving substantial progress. He identifies four key design patterns for AI agentic workflows: Reflection Ability of AI Reflection: LLMs can enhance their effectiveness by reflecting on their own behavior. For example, an LLM used in a customer service application can analyze past interactions to identify patterns in customer queries and improve its responses over time. This self-reflective capability allows the model to learn from its mistakes and adapt to new scenarios, thereby increasing its accuracy and reliability. Tool Use: LLMs can act as agents by utilizing external tools for tasks such as search, code execution, and data manipulation. For instance, an LLM integrated with a financial analysis tool can automatically fetch real-time market data, perform complex calculations, and generate investment recommendations. This ability to leverage external tools extends the functionality of LLMs beyond text generation, making them versatile agents capable of handling a wide range of tasks. Planning: LLMs can autonomously decide on the sequence of steps to execute for complex tasks. Consider an LLM used in project management software. It can break down a project into smaller tasks, assign deadlines, and monitor progress, all while adjusting the plan based on real-time updates. This planning capability enables LLMs to manage intricate workflows efficiently, reducing the need for human intervention. Multi-Agent Collaboration Multi-Agent Collaboration: Prompting an LLM to play different roles for different parts of a complex task can summon a team of AI agents to perform the job more effectively. For example, in a medical diagnosis application, one LLM agent could focus on analyzing patient history, another on interpreting lab results, and a third on suggesting treatment options. By collaborating, these agents can provide a comprehensive diagnosis, improving the overall accuracy and reliability of the system. Ng asserts that these agentic workflows will drive significant AI progress, potentially surpassing the advancements of the next generation of foundation models. This structured and interactive problem-solving process will help improve accuracy and reduce hallucinations in LLM implementations. Larger Context Size Support Advancements in context size support are poised to revolutionize the capabilities of LLMs. Models like Google&#x27;s Gemini 1.5 now support context sizes of up to a million tokens, moving towards near-infinite memory capacities. This increased context size will enable more complex, multimodal use cases, such as video analytics and batch data processing. For instance, in video analytics, an LLM with a larger context size can analyze entire video streams rather than just individual frames. This holistic approach allows the model to understand context, detect anomalies, and generate insights more accurately. Similarly, in batch data processing, an LLM can handle large datasets in a single pass, making it possible to perform complex analyses and generate comprehensive reports without the need for multiple iterations. However, it is important to note that these advancements may not be suitable for Q&amp;A Retrieval-Augmented Generation (RAG) use cases due to cost and response time impacts. The increased computational requirements for handling larger context sizes can lead to higher operational costs and slower response times, making them less practical for applications that require real-time interactions. Prompt Engineers into Agents Architect With the rise of agentic workflows, the role of prompt engineers is undergoing a transformation. According to Andrew Ng, the future will see prompt engineers transitioning into &quot;Agents Architects.&quot; This new role involves designing how groups of AI agents interact to perform complex tasks effectively. Instead ... [truncated]
ðŸ“– Read URL: https://newsletter.victordibia.com/p/ai-agents-202... (8015 chars)
   â””â”€ [https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building]
      Preview: AI Agents 2024 Rewind - A Year of Building and Learning Designing with AI Subscribe Sign in Designing with AI Podcast AI Agents 2024 Rewind - A Year of Building and Learning 43 2 15 1Ã— 0:00 Current time: 0:00 / Total time: -13:30 -13:30 Audio playback is not supported on your browser. Please upgrade. AI Agents 2024 Rewind - A Year of Building and Learning Issue #26 | What were the top 5 trends in AI Multi-Agent Systems from 2024? What can we expect in 2025? Victor Dibia, PhD Jan 02, 2025 43 2 15 Share Transcript I spent a good chunk of 2024 focused on multi-agent system s - contributing to AutoGen - an OSS framework for building multi-agent apps, and working on a book on the topic . A lot has happened! This post is an attempt to catalog some of the key events into themes, and a reflection on where things might be headed. The content here is likely subjective (my viewpoint on what was interesting) and is based on a list agent/multi-agent news items I curated over the last year. TLDR: Five key observations from building and studying AI agents in 2024: Enterprises are adopting agents, but with some caveats Teams are building &quot;agent-native&quot; foundation models from the ground up Interface automation agents dominated early commercial applications A Shift to Complex Tasks and the Rise of Frameworks Benchmarks reveal both progress and limitations 1. Enterprise Adoption of Agents in Products .. with Caveats Many enterprises and startups have adopted the term â€œagentsâ€ in products, describing them broadly at systems that act on a userâ€™s behalf with the goal of saving the user time and avoiding tedious/busy work . Some examples below: Microsoft Copilot Agents : â€œThese AI-driven agents assist users in performing a variety of tasks, working alongside you to offer suggestions, automate repetitive tasks, and provide insights to help you make informed decisionâ€ Salesforce Agentforce : â€œAgentforce is a proactive, autonomous AI application that provides specialized, always-on support to employees or customers. You can equip Agentforce with any necessary business knowledge to execute tasks according to its specific roleâ€œ Sema4.ai agents. Sema4 goes a bit further than other offerings in their claims - â€œ&quot;RPA fall short when it comes to complex, knowledge-based work. They lack the ability to reason, make judgments, and adapt to real-world changes.â€ LinkedIn HR Assistant : â€œStarting today, recruiters can choose to delegate time-consuming tasks to Hiring Assistant including finding candidates and assisting in applicant review, so they can focus on the most strategic, people-centric parts of their jobâ€ An important caveat here lies in how the agents are implemented. Most deployments use an LLM as a thin wrapper/orchestrator that &quot;calls&quot; existing APIs as tools. In essence, this trend represents a shift from a less manual approach &quot; clicking fetch data, upload to Salesforce, and generate report buttons&quot; to a more streamlined approach &quot;saying generate report&quot; while an LLM-enabled pipeline handles the clicking. This is clearly the responsible approach - retaining the reliability of existing APIs while improving user experience by minimizing repetitive steps. It is also non-trivial, as ensuring reliable tool selection at production scale remains challenging. While this is still several steps removed from truly autonomous assistants (the holy grail of agents), it represents a first step toward that journey. Before - Separate apps and apis that users interact with to complete business tasks in products Trend : LLMs act as thin orchestration layers that translate natural language requests into multiple of API calls (minimizes clicks and intermediate tasks). 2. â€œAgent-Nativeâ€ Foundation Models An interesting development this year was seeing teams build foundation models specifically designed for agency . What does this mean? Well, a good agent must do a few things well - reason through multi-step plans for tasks, act (use tools), appropriately leverage memory , and communicate with other agents. The important trend here is that these agentic capabilities are now being â€œliftedâ€ into the generative model itself. OpenAI o1 emphasizes reasoning - planning, task decomposition etc that previously would have been spread across multiple agent actions. Right at the end of the year, (December 20), OpenAI announced (but not yet released) the o3 family of models - with even more impressive reasoning capabilities and test-time compute! Test time compute allows models to dynamically allocate additional computational resources (reasoning/thinking time) depending on the complexity of the task. The Gemini models from Google likewise makes progress here with Gemini 2.0 Flashâ€™s native user interface action-capabilities , along with other improvements like multimodal reasoning, long context understanding, complex instruction following and planning, compositional function-calling, native tool use and improved latency There were also advances in models that could do more things . Multimodal output - The Gemini 2.0 Flash from Google is a natively multimodal input (text, images) and output (text, image and audio) model. Huge! ChatGPT advanced voice mode: Movie generation: Movie Gen from Meta a specialized movie generation model. Lynn Cherny writes about Veo 2 - a video generation model from Google and many other creativity tools in this post . This shift toward &quot;agent-native&quot; architectures reflects a growing understanding that effective agents need more than just typical language modeling capabilities - they need built-in capabilities for planning, tool use, and coordination. Before : LLMs focused solely on language modeling. Capabilities like planning, tool use, and task decomposition/reasoning implemented external to the model. Trend : Models now designed from the ground up with built-in capabilities for multi-step task decomposition, planning, tool use, and multimodal interactions. 3. Interface Agents Take Center Stage If there was one application area that dominated commercial agent deployments in 2024, it was interface agents - agents that accomplish tasks by driving interfaces (web browsers, desktop OS etc). Interface Agents - Building Multi-Agent Applications that Act via Controlling Interfaces (Browsers, Apps) Victor Dibia, PhD Â· April 29, 2024 Read full story Startups like Kura AI and Runner H released agent products that solve tasks by driving web browsers. Microsoft's OmniParser improved how agents interact with GUI elements. The new version of AutoGen (and AutoGen Studio) provides a WebSurferAgent preset that can solve tasks by driving a web browser. ChatGPT screen sharing : â€œChatGPT Advanced Voice Mode with vision can also understand whatâ€™s on a deviceâ€™s screen via screen sharingâ€ Anthropic Claude Computer Use : â€œdevelopers can direct Claude to use computers the way people doâ€”by looking at a screen, moving a cursor, clicking buttons, and typing text.â€ Project Mariner from Google â€œcombines strong multimodal understanding and reasoning capabilities to automate tasks using your browser.â€ Browser Use extension : â€œMake websites accessible for AI agentsâ€ The focus on interface automation makes sense - it's where agents can deliver immediate value by automating repetitive tasks across existing disparate applications . Before : The action space of agents was typically from programmatic tools and code execution Trend : Direct manipulation of user interfaces (web, desktop) as the primary method for agent action. 4. A Shift to Complex Tasks and the Rise of Frameworks Multi-agent systems or even just agents are emerging as an approach to solving problems. A common source of angst this year has been around the performance of agents and hence if they are more hype than substance . In a langchain survey , 41% of respondents mention performance as the primary bottleneck to using agents. In my opinion this confusion is rooted in a poor (or perhaps evolving)... [truncated]
ðŸ”¬ Analyzer [3]: Analyzing 5 results, 9 contents

ðŸ”¬ Analyzer: Max iterations reached, proceeding to Writer

ðŸ”¬ Analyzer [3]: Analyzed 5 results, 9 contents
   â””â”€ New findings:
      [1] Strategic shift towards smaller, highly capable LLMs (e.g., TinyGPT, TinyLlama) for broader accessibility and deployment.
      [2] Expectations for LLMs in 2024 include becoming smaller, faster, smarter, and leveraging agentic workflows and larger context sizes.
      [3] LLMs are increasingly used as orchestrators for existing APIs, streamlining tasks through natural language commands.
      [4] The market for LLMs and AI development tools matured considerably in 2024, with AI integrated into core developer tools.
      [5] More sophisticated cognitive architectures are being explored to guide the design of more robust agents (e.g., connecting LLM agents to SOAR, ACT-R).
   â””â”€ Decision: Research complete (16 total findings)

ðŸ“¦ Compress: Compressing 16 findings, 9 contents
   â””â”€ Compressed to 3102 chars (from ~5379 raw chars)
   â””â”€ Sources cited: 8
   â””â”€ Preview:
      ## Key Findings
      - LLM-based multi-agent systems (LLM-MA) is a rapidly evolving field [5].
      - LLMs are utilized as orchestration layers, translating natural language into API calls [6, 13].
      - The agent loop is formalized as Perception -> Planning -> Action -> Memory, enhanced by tool integrations and self-verification [8].
      - There was a shift towards smaller, highly capable LLMs and increased integration of AI into core developer tools in 2024 [11, 14].
      
      ## Detailed Information
      
      **General Trends and Overviews**
      *   A review in Physics of Life Reviews discussed LLMs and generative agent-based models for complex systems research [8].
      *   The LLM-MA field is in its early stages and rapidly evolving [5].
      *   A survey paper titled 'Large Language Model based Multi-Agents: A Survey of Progress and Challenges' was submitted to arXiv in January 2024 and revised in April 2024 [5].
      
      **LLMs as Orchestration Layers**
      *   LLMs are used as orchestration layers, translating natural language into API calls [6, 13].
      *   LLMs are increasingly used as orchestrators for existing APIs, streamlining tasks through natural language commands [13].
      *   Model Context Protocol (MCP) standardizes how agents access external tools and data sources [7].
      
      **Agent Architecture and Functionality**
      *   The agent loop is formalized as Perception -> Planning -> Action -> Memory, enhanced by tool integrations and self-verification [8].
      *   More sophisticated cognitive architectures are being explored to guide the design of more robust agents (e.g., connecting LLM agents to SOAR, ACT-R) [15].
      
      **Specific Applications and Frameworks**
      *   MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution was presented at NeurIPS 2024 [4].
      *   LLM agents are used for content generation and interactive experiences [9].
      
      **Evolving Landscape in 2024**
      *   In 2024, there was a shift from general-purpose LLMs to models tailored for specific industries and tasks [10].
      *   Strategic shift towards smaller, highly capable LLMs (e.g., TinyGPT, TinyLlama) for broader accessibility and deployment [11].
      *   Expectations for LLMs in 2024 include becoming smaller, faster, smarter, and leveraging agentic workflows and larger context sizes [12].
      *   The market for LLMs and AI development tools matured considerably in 2024, with AI integrated into core developer tools [14].
      
      ## Sources
      [1] https://www.emergentmind.com/topics/llm-based-agent-frameworks
      [2] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
      [3] https://www.amitysolutions.com/blog/llm-expectations-in-2024
      [4] https://dl.acm.org/doi/10.1145/3712003
      [5] https://arxiv.org/abs/2402.01680
      [6] https://arxiv.org/html/2510.04023v1
      [7] https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue
      [8] https://www.sciencedirect.com/science/article/pii/S1571064524001386
      [9] Not provided in source URLs.
      [10] Not provided in source URLs.
      [11] Not provided in source URLs.
      [12] Not provided in source URLs.
      [13] Not provided in source URLs.
      [14] Not provided in source URLs.
      [15] Not provided in source URLs.

âœï¸ Writer: Composing response from 16 findings
   â””â”€ Using compressed notes (3102 chars)

âœï¸ Writer: Generated response (2895 chars)
   â””â”€ Sources used:
      [1] https://www.emergentmind.com/topics/llm-based-agent-frameworks
      [2] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
      [3] https://www.amitysolutions.com/blog/llm-expectations-in-2024
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      
      2024ë…„ì— ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì€ LLMì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œ í™œìš©í•˜ì—¬ API í˜¸ì¶œì„ ìžì—°ì–´ ëª…ë ¹ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë” ìž‘ì§€ë§Œ ê°•ë ¥í•œ LLMì„ í†µí•´ ì ‘ê·¼ì„±ê³¼ ë°°í¬ ìš©ì´ì„±ì„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•˜ê³  ìžˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ë˜í•œ, í•µì‹¬ ê°œë°œ ë„êµ¬ì— AI í†µí•©ì´ ê°€ì†í™”ë˜ëŠ” ì¶”ì„¸ê°€ ë‚˜íƒ€ë‚œë‹¤.
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   LLM ê¸°ë°˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(LLM-MA)ì€ ë¹ ë¥´ê²Œ ì§„í™”í•˜ëŠ” ë¶„ì•¼ì´ë‹¤ [5].
      *   LLMì€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œ í™œìš©ë˜ì–´ ìžì—°ì–´ë¥¼ API í˜¸ì¶œë¡œ ë³€í™˜í•œë‹¤ [6, 13].
      *   ì—ì´ì „íŠ¸ ë£¨í”„ëŠ” ì¸ì§€(Perception) -> ê³„íš(Planning) -> í–‰ë™(Action) -> ê¸°ì–µ(Memory)ìœ¼ë¡œ ê³µì‹í™”ë˜ë©°, ë„êµ¬ í†µí•© ë° ìžì²´ ê²€ì¦ì„ í†µí•´ ê°•í™”ëœë‹¤ [8].
      *   2024ë…„ì—ëŠ” ë” ìž‘ì§€ë§Œ ê³ ì„±ëŠ¥ LLMìœ¼ë¡œì˜ ì „í™˜ê³¼ í•µì‹¬ ê°œë°œ ë„êµ¬ì— AI í†µí•©ì´ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ë‚˜íƒ€ë‚¬ë‹¤ [11, 14].
      *   LLM ì—ì´ì „íŠ¸ëŠ” ê¹ƒí—ˆë¸Œ ì´ìŠˆ í•´ê²°, ì½˜í…ì¸  ìƒì„± ë° ì¸í„°ëž™í‹°ë¸Œ ê²½í—˜ì„ ìœ„í•´ ì‚¬ìš©ë˜ê³  ìžˆë‹¤ [4, 9].
      
      ## ìƒì„¸ ë¶„ì„
      
      2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ ë™í–¥ì€ í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì€ ì¸¡ë©´ì—ì„œ ë¶„ì„í•  ìˆ˜ ìžˆë‹¤.
      
      **1. LLMì˜ ì—­í•  ë³€í™”:**
      
      *   **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´:** LLMì€ ë” ì´ìƒ ë‹¨ìˆœížˆ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì´ ì•„ë‹ˆë¼, ìžì—°ì–´ ëª…ë ¹ì„ ì´í•´í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì–‘í•œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìž‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œì„œì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ê³  ìžˆë‹¤ [6, 13]. ì´ëŠ” ì‚¬ìš©ìžê°€ ë³µìž¡í•œ ì½”ë“œë¥¼ ì§ì ‘ ìž‘ì„±í•˜ì§€ ì•Šê³ ë„ ìžì—°ì–´ ëª…ë ¹ì„ í†µí•´ ë‹¤ì–‘í•œ ìž‘ì—…ì„ ìžë™í™”í•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤. Model Context Protocol (MCP)ì™€ ê°™ì€ í‘œì¤€ì´ ë“±ìž¥í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ë„êµ¬ ë° ë°ì´í„° ì†ŒìŠ¤ì— ì ‘ê·¼í•˜ëŠ” ë°©ì‹ì„ í‘œì¤€í™”í•˜ê³  ìžˆë‹¤ [7].
      
      *   **íŠ¹ì • ëª©ì ì— ë§žì¶˜ LLM:** ë²”ìš© LLMì—ì„œ íŠ¹ì • ì‚°ì—… ë° ìž‘ì—…ì— ë§žì¶¤í™”ëœ ëª¨ë¸ë¡œì˜ ì „í™˜ì´ ì´ë£¨ì–´ì§€ê³  ìžˆë‹¤ [10]. ì´ëŠ” íŠ¹ì • ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ì„±ì„ ë†’ì—¬ ë”ìš± íš¨ìœ¨ì ì¸ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. TinyGPT, TinyLlamaì™€ ê°™ì´ ìž‘ì§€ë§Œ ê°•ë ¥í•œ LLMì´ ì£¼ëª©ë°›ê³  ìžˆìœ¼ë©°, ì´ëŠ” ì ‘ê·¼ì„±ê³¼ ë°°í¬ ìš©ì´ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ê¸°ì—¬í•œë‹¤ [11].
      
      **2. ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ ë° ê¸°ëŠ¥:**
      
      *   **í‘œì¤€í™”ëœ ì—ì´ì „íŠ¸ ë£¨í”„:** ì—ì´ì „íŠ¸ ë£¨í”„ëŠ” ì¸ì§€(Perception) -> ê³„íš(Planning) -> í–‰ë™(Action) -> ê¸°ì–µ(Memory)ìœ¼ë¡œ ê³µì‹í™”ë˜ì—ˆìœ¼ë©°, ë„êµ¬ í†µí•© ë° ìžì²´ ê²€ì¦ì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ìžˆë‹¤ [8].  ì´ëŠ” ì—ì´ì „íŠ¸ê°€ í™˜ê²½ì„ ì¸ì‹í•˜ê³ , ê³„íšì„ ìˆ˜ë¦½í•˜ë©°, í–‰ë™ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ê¸°ì–µí•˜ì—¬ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ ì²´ê³„í™”í•œ ê²ƒì´ë‹¤.
      
      *   **ì •êµí•œ ì¸ì§€ ì•„í‚¤í…ì²˜ íƒêµ¬:** ë”ìš± ê°•ë ¥í•œ ì—ì´ì „íŠ¸ ì„¤ê³„ë¥¼ ìœ„í•´ LLM ì—ì´ì „íŠ¸ë¥¼ SOAR, ACT-Rê³¼ ê°™ì€ ì¸ì§€ ì•„í‚¤í…ì²˜ì— ì—°ê²°í•˜ëŠ” ë“± ë”ìš± ì •êµí•œ ì¸ì§€ ì•„í‚¤í…ì²˜ê°€ ì—°êµ¬ë˜ê³  ìžˆë‹¤ [15].
      
      **3. ì‘ìš© ë¶„ì•¼ì˜ í™•ìž¥:**
      
      *   **ë‹¤ì–‘í•œ ë¶„ì•¼ ì ìš©:** LLM ì—ì´ì „íŠ¸ëŠ” ê¹ƒí—ˆë¸Œ ì´ìŠˆ í•´ê²°(MAGIS [4]), ì½˜í…ì¸  ìƒì„±, ì¸í„°ëž™í‹°ë¸Œ ê²½í—˜ [9] ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©ë˜ê³  ìžˆë‹¤.  ì´ëŠ” LLM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì´ ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ìƒì„±ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ë¬¸ì œ í•´ê²° ë° ìžë™í™”ì— í™œìš©ë  ìˆ˜ ìžˆìŒì„ ë³´ì—¬ì¤€ë‹¤.
      
      **4. ê°œë°œ ë„êµ¬ì™€ì˜ í†µí•©:**
      
      *   **AI ê°œë°œ ë„êµ¬ ì„±ìˆ™:** LLM ë° AI ê°œë°œ ë„êµ¬ ì‹œìž¥ì´ ì„±ìˆ™í•˜ë©´ì„œ AIê°€ í•µì‹¬ ê°œë°œ ë„êµ¬ì— í†µí•©ë˜ê³  ìžˆë‹¤ [14]. ì´ëŠ” ê°œë°œìžê°€ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ë³´ë‹¤ ì‰½ê²Œ ê°œë°œí•˜ê³  ë°°í¬í•  ìˆ˜ ìžˆë„ë¡ ì§€ì›í•œë‹¤.
      
      ## ê´€ë ¨ ìžë£Œ ë° ì¶œì²˜
      
      *   [1] https://www.emergentmind.com/topics/llm-based-agent-frameworks
      *   [2] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
      *   [3] https://www.amitysolutions.com/blog/llm-expectations-in-2024
      *   [4] https://dl.acm.org/doi/10.1145/3712003
      *   [5] https://arxiv.org/abs/2402.01680
      *   [6] https://arxiv.org/html/2510.04023v1
      *   [7] https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue
      *   [8] https://www.sciencedirect.com/science/article/pii/S1571064524001386
      
      **ì°¸ê³ :** ì¶œì²˜ [9], [10], [11], [12], [13], [14], [15]ëŠ” ì œê³µë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ìžë£Œ ë¶„ì„ì— ë°˜ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•´ë‹¹ ìžë£Œê°€ ì œê³µëœë‹¤ë©´ ë¶„ì„ì„ ë”ìš± í’ë¶€í•˜ê²Œ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
      
      ## ê²°ë¡  ë° í‰ê°€
      
      2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ í™œìš© ë°©ì‹ ë³€í™”, ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ì˜ ë°œì „, ì‘ìš© ë¶„ì•¼ì˜ í™•ìž¥, ê°œë°œ ë„êµ¬ì™€ì˜ í†µí•©ì´ë¼ëŠ” ëšœë ·í•œ íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì¤€ë‹¤.  LLMì€ ë‹¨ìˆœížˆ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì—ì„œ ë²—ì–´ë‚˜, ìžì—°ì–´ ëª…ë ¹ì„ í†µí•´ ë‹¤ì–‘í•œ ìž‘ì—…ì„ ìžë™í™”í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œì„œì˜ ì—­í• ì„ ê°•í™”í•˜ê³  ìžˆë‹¤. ë˜í•œ, ìž‘ì§€ë§Œ ê°•ë ¥í•œ LLMì˜ ë“±ìž¥ê³¼ íŠ¹ì • ëª©ì ì— ë§žì¶˜ ëª¨ë¸ ê°œë°œì€ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ íš¨ìœ¨ì„±ê³¼ ì ‘ê·¼ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•˜ê³  ìžˆë‹¤. ì•žìœ¼ë¡œ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ë”ìš± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, ê°œë°œ ë„êµ¬ì™€ì˜ í†µí•©ì„ í†µí•´ ê°œë°œ ìƒì‚°ì„±ì´ ë”ìš± í–¥ìƒë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.  ë‹¤ë§Œ, LLM ì—ì´ì „íŠ¸ì˜ ìœ¤ë¦¬ì  ë¬¸ì œ, ë³´ì•ˆ ë¬¸ì œ, ê·¸ë¦¬ê³  ì„¤ëª… ê°€ëŠ¥ì„±(Explainability) ë¬¸ì œëŠ” ì§€ì†ì ìœ¼ë¡œ ì—°êµ¬í•˜ê³  í•´ê²°í•´ì•¼ í•  ê³¼ì œì´ë‹¤.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 3 Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: 2024ë…„ ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ê³  ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•´ì¤˜...
â”‚ Time: 37.24s
â”‚ LLM Calls: 2
â”‚ Search Calls: 3
â”‚ URLs Read: 9
â”‚ Iterations: 3
â”‚ Est. Tokens: 1141
â”‚ Response Length: 2895 chars
â”‚ Has Citations: âœ…
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ðŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½

2024ë…„ì— ë°œí‘œëœ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì€ LLMì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œ í™œìš©í•˜ì—¬ API í˜¸ì¶œì„ ìžì—°ì–´ ëª…ë ¹ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë” ìž‘ì§€ë§Œ ê°•ë ¥í•œ LLMì„ í†µí•´ ì ‘ê·¼ì„±ê³¼ ë°°í¬ ìš©ì´ì„±ì„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•˜ê³  ìžˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ë˜í•œ, í•µì‹¬ ê°œë°œ ë„êµ¬ì— AI í†µí•©ì´ ê°€ì†í™”ë˜ëŠ” ì¶”ì„¸ê°€ ë‚˜íƒ€ë‚œë‹¤.

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   LLM ê¸°ë°˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(LLM-MA)ì€ ë¹ ë¥´ê²Œ ì§„í™”í•˜ëŠ” ë¶„ì•¼ì´ë‹¤ [5].
*   LLMì€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œ í™œìš©ë˜ì–´ ìžì—°ì–´ë¥¼ API í˜¸ì¶œë¡œ ë³€í™˜í•œë‹¤ [6, 13].
*   ì—ì´ì „íŠ¸ ë£¨í”„ëŠ” ì¸ì§€(Perception) -> ê³„íš(Planning) -> í–‰ë™(Action) -> ê¸°ì–µ(Memory)ìœ¼ë¡œ ê³µì‹í™”ë˜ë©°, ë„êµ¬ í†µí•© ë° ìžì²´ ê²€ì¦ì„ í†µí•´ ê°•í™”ëœë‹¤ [8].
*   2024ë…„ì—ëŠ” ë” ìž‘ì§€ë§Œ ê³ ì„±ëŠ¥ LLMìœ¼ë¡œì˜ ì „í™˜ê³¼ í•µì‹¬ ê°œë°œ ë„êµ¬ì— AI í†µí•©ì´ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ë‚˜íƒ€ë‚¬ë‹¤ [11, 14].
*   LLM ì—ì´ì „íŠ¸ëŠ” ê¹ƒí—ˆë¸Œ ì´ìŠˆ í•´ê²°, ì½˜í…ì¸  ìƒì„± ë° ì¸í„°ëž™í‹°ë¸Œ ê²½í—˜ì„ ìœ„í•´ ì‚¬ìš©ë˜ê³  ìžˆë‹¤ [4, 9].

## ìƒì„¸ ë¶„ì„

2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ ë™í–¥ì€ í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì€ ì¸¡ë©´ì—ì„œ ë¶„ì„í•  ìˆ˜ ìžˆë‹¤.

**1. LLMì˜ ì—­í•  ë³€í™”:**

*   **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´:** LLMì€ ë” ì´ìƒ ë‹¨ìˆœížˆ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì´ ì•„ë‹ˆë¼, ìžì—°ì–´ ëª…ë ¹ì„ ì´í•´í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì–‘í•œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìž‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œì„œì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ê³  ìžˆë‹¤ [6, 13]. ì´ëŠ” ì‚¬ìš©ìžê°€ ë³µìž¡í•œ ì½”ë“œë¥¼ ì§ì ‘ ìž‘ì„±í•˜ì§€ ì•Šê³ ë„ ìžì—°ì–´ ëª…ë ¹ì„ í†µí•´ ë‹¤ì–‘í•œ ìž‘ì—…ì„ ìžë™í™”í•  ìˆ˜ ìžˆë„ë¡ í•œë‹¤. Model Context Protocol (MCP)ì™€ ê°™ì€ í‘œì¤€ì´ ë“±ìž¥í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ë„êµ¬ ë° ë°ì´í„° ì†ŒìŠ¤ì— ì ‘ê·¼í•˜ëŠ” ë°©ì‹ì„ í‘œì¤€í™”í•˜ê³  ìžˆë‹¤ [7].

*   **íŠ¹ì • ëª©ì ì— ë§žì¶˜ LLM:** ë²”ìš© LLMì—ì„œ íŠ¹ì • ì‚°ì—… ë° ìž‘ì—…ì— ë§žì¶¤í™”ëœ ëª¨ë¸ë¡œì˜ ì „í™˜ì´ ì´ë£¨ì–´ì§€ê³  ìžˆë‹¤ [10]. ì´ëŠ” íŠ¹ì • ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ì„±ì„ ë†’ì—¬ ë”ìš± íš¨ìœ¨ì ì¸ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. TinyGPT, TinyLlamaì™€ ê°™ì´ ìž‘ì§€ë§Œ ê°•ë ¥í•œ LLMì´ ì£¼ëª©ë°›ê³  ìžˆìœ¼ë©°, ì´ëŠ” ì ‘ê·¼ì„±ê³¼ ë°°í¬ ìš©ì´ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ê¸°ì—¬í•œë‹¤ [11].

**2. ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ ë° ê¸°ëŠ¥:**

*   **í‘œì¤€í™”ëœ ì—ì´ì „íŠ¸ ë£¨í”„:** ì—ì´ì „íŠ¸ ë£¨í”„ëŠ” ì¸ì§€(Perception) -> ê³„íš(Planning) -> í–‰ë™(Action) -> ê¸°ì–µ(Memory)ìœ¼ë¡œ ê³µì‹í™”ë˜ì—ˆìœ¼ë©°, ë„êµ¬ í†µí•© ë° ìžì²´ ê²€ì¦ì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ìžˆë‹¤ [8].  ì´ëŠ” ì—ì´ì „íŠ¸ê°€ í™˜ê²½ì„ ì¸ì‹í•˜ê³ , ê³„íšì„ ìˆ˜ë¦½í•˜ë©°, í–‰ë™ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ê¸°ì–µí•˜ì—¬ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ ì²´ê³„í™”í•œ ê²ƒì´ë‹¤.

*   **ì •êµí•œ ì¸ì§€ ì•„í‚¤í…ì²˜ íƒêµ¬:** ë”ìš± ê°•ë ¥í•œ ì—ì´ì „íŠ¸ ì„¤ê³„ë¥¼ ìœ„í•´ LLM ì—ì´ì „íŠ¸ë¥¼ SOAR, ACT-Rê³¼ ê°™ì€ ì¸ì§€ ì•„í‚¤í…ì²˜ì— ì—°ê²°í•˜ëŠ” ë“± ë”ìš± ì •êµí•œ ì¸ì§€ ì•„í‚¤í…ì²˜ê°€ ì—°êµ¬ë˜ê³  ìžˆë‹¤ [15].

**3. ì‘ìš© ë¶„ì•¼ì˜ í™•ìž¥:**

*   **ë‹¤ì–‘í•œ ë¶„ì•¼ ì ìš©:** LLM ì—ì´ì „íŠ¸ëŠ” ê¹ƒí—ˆë¸Œ ì´ìŠˆ í•´ê²°(MAGIS [4]), ì½˜í…ì¸  ìƒì„±, ì¸í„°ëž™í‹°ë¸Œ ê²½í—˜ [9] ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©ë˜ê³  ìžˆë‹¤.  ì´ëŠ” LLM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì´ ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ìƒì„±ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ë¬¸ì œ í•´ê²° ë° ìžë™í™”ì— í™œìš©ë  ìˆ˜ ìžˆìŒì„ ë³´ì—¬ì¤€ë‹¤.

**4. ê°œë°œ ë„êµ¬ì™€ì˜ í†µí•©:**

*   **AI ê°œë°œ ë„êµ¬ ì„±ìˆ™:** LLM ë° AI ê°œë°œ ë„êµ¬ ì‹œìž¥ì´ ì„±ìˆ™í•˜ë©´ì„œ AIê°€ í•µì‹¬ ê°œë°œ ë„êµ¬ì— í†µí•©ë˜ê³  ìžˆë‹¤ [14]. ì´ëŠ” ê°œë°œìžê°€ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ë³´ë‹¤ ì‰½ê²Œ ê°œë°œí•˜ê³  ë°°í¬í•  ìˆ˜ ìžˆë„ë¡ ì§€ì›í•œë‹¤.

## ê´€ë ¨ ìžë£Œ ë° ì¶œì²˜

*   [1] https://www.emergentmind.com/topics/llm-based-agent-frameworks
*   [2] https://newsletter.victordibia.com/p/ai-agents-2024-rewind-a-year-of-building
*   [3] https://www.amitysolutions.com/blog/llm-expectations-in-2024
*   [4] https://dl.acm.org/doi/10.1145/3712003
*   [5] https://arxiv.org/abs/2402.01680
*   [6] https://arxiv.org/html/2510.04023v1
*   [7] https://www.linkedin.com/pulse/evolving-landscape-large-language-models-2024-2025-zqgue
*   [8] https://www.sciencedirect.com/science/article/pii/S1571064524001386

**ì°¸ê³ :** ì¶œì²˜ [9], [10], [11], [12], [13], [14], [15]ëŠ” ì œê³µë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ìžë£Œ ë¶„ì„ì— ë°˜ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•´ë‹¹ ìžë£Œê°€ ì œê³µëœë‹¤ë©´ ë¶„ì„ì„ ë”ìš± í’ë¶€í•˜ê²Œ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

## ê²°ë¡  ë° í‰ê°€

2024ë…„ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì—°êµ¬ëŠ” LLMì˜ í™œìš© ë°©ì‹ ë³€í™”, ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ì˜ ë°œì „, ì‘ìš© ë¶„ì•¼ì˜ í™•ìž¥, ê°œë°œ ë„êµ¬ì™€ì˜ í†µí•©ì´ë¼ëŠ” ëšœë ·í•œ íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì¤€ë‹¤.  LLMì€ ë‹¨ìˆœížˆ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì—ì„œ ë²—ì–´ë‚˜, ìžì—°ì–´ ëª…ë ¹ì„ í†µí•´ ë‹¤ì–‘í•œ ìž‘ì—…ì„ ìžë™í™”í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ë¡œì„œì˜ ì—­í• ì„ ê°•í™”í•˜ê³  ìžˆë‹¤. ë˜í•œ, ìž‘ì§€ë§Œ ê°•ë ¥í•œ LLMì˜ ë“±ìž¥ê³¼ íŠ¹ì • ëª©ì ì— ë§žì¶˜ ëª¨ë¸ ê°œë°œì€ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ íš¨ìœ¨ì„±ê³¼ ì ‘ê·¼ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•˜ê³  ìžˆë‹¤. ì•žìœ¼ë¡œ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ë”ìš± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, ê°œë°œ ë„êµ¬ì™€ì˜ í†µí•©ì„ í†µí•´ ê°œë°œ ìƒì‚°ì„±ì´ ë”ìš± í–¥ìƒë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.  ë‹¤ë§Œ, LLM ì—ì´ì „íŠ¸ì˜ ìœ¤ë¦¬ì  ë¬¸ì œ, ë³´ì•ˆ ë¬¸ì œ, ê·¸ë¦¬ê³  ì„¤ëª… ê°€ëŠ¥ì„±(Explainability) ë¬¸ì œëŠ” ì§€ì†ì ìœ¼ë¡œ ì—°êµ¬í•˜ê³  í•´ê²°í•´ì•¼ í•  ê³¼ì œì´ë‹¤.
======================================================================


ðŸ“Š Running benchmark: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜...

ðŸ”Ž Clarify: Analyzing query...
   â””â”€ Query: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ê³¼ ê°ê° ì–¸ì œ ì‚¬ìš©í•˜ë©´ ì¢‹ì€ì§€ ì„¤ëª…í•´ì¤˜
   â””â”€ Status: ðŸŸ¢ Clear
   â””â”€ Analysis: The query asks for a comparison between Retrieval-Augmented Generation (RAG) and Agent-based approaches, and guidance on when to use each. The intent is clear: explanation and comparison.
   â””â”€ Topics: Retrieval-Augmented Generation, Agent-based approach
ðŸ“‹ Planner: Creating research plan for: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜

ðŸ“‹ Planner: Generated 4 queries
   â””â”€ Queries:
      [1] RAG vs Agent based approach
      [2] Retrieval-Augmented Generation vs Agent differences
      [3] When to use RAG vs Agent
      [4] Advantages and disadvantages of RAG and Agent based systems
   â””â”€ Focus: RAG architecture, Agent based system architecture, Comparison of RAG and Agent use cases, Trade-offs between RAG and Agent approaches
ðŸ” Searcher [1]: Searching for: RAG vs Agent based approach

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/
      [2] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [3] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [4] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [5] https://medium.com/olarry/understanding-the-difference-between-rag-and-ai-agents-10df56b35e02
   â””â”€ Snippets:
      â€¢ In all fairness, thereâ€™s no single â€œwinnerâ€ across all scenarios. Fine-tuning shines in high-volume, domain-specific workloads; RAG thrives where data changes quickly; and agents unlock new possibilities for orchestrated, multi-step tasks. The key is to align the approach with your business model, growth plans, and tolerance for complexity.  ### Key takeaway [...] A quick reminder: fine-tune for stability, RAG for adaptability, and agents for orchestration. Combining these approaches creates a hybrid AI strategy that balances precision, flexibility, and scalability. Fine-tuned models handle repetitive or compliance-heavy tasks reliably, RAG keeps knowledge up-to-date and transparent, and agents automate multi-step workflows across systems. This layered approach minimizes risks, reduces maintenance overhead, and maximizes business impact, ensuring AI [...] Fine-tuning, RAG, and agents each solve different categories of problems, and no single method is a universal answer. Fine-tuning shines when domain expertise must be baked into the model itself. RAG ensures real-time accuracy by grounding outputs in fresh or proprietary data. Agents excel when tasks demand multi-step reasoning and tool orchestration. The real value comes from knowing when to use each (or how to combine them) so that your AI strategy is efficient, scalable, and aligned with
      â€¢ The table below makes it easy for you to see the trade-offs:   RAG is best for quick wins with static content.  Agentic RAG is a smart bridge when goal-based reasoning is needed.  MCP is for building durable, intelligent systems with real decision-making power. [...] Before diving into comparisons, letâ€™s define each approach in clear, business-relevant terms: what they are, what they do, and where they fit in real-world AI use cases.  ### RAG (Retrieval-Augmented Generation)  RAG enhances large language models (LLMs) by letting them â€œlook things up.â€ Instead of relying only on what the model was trained on, RAG retrieves relevant documents or knowledge from an external source (like a database or vector store) before generating a response.  Use it for: [...] Once weâ€™ve clarified your goals, we design and build using the framework that fits your current business readiness:   RAG â†’ When your priority is fast, accurate answers from internal data.  Example: A knowledge assistant trained on your HR policies or product manuals.   Agentic RAG â†’ When you need goal-driven, step-by-step reasoning with smart retrieval.  Example: A sales research agent that pulls competitive insights and drafts summaries.
      â€¢ RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant, context-aware information. Traditional RAG improves LLMs by connecting them to external data sources, while Agentic RAG goes a step further by adding intelligent agents that handle decisions and complex tasks. If the task is simple and query-based, traditional RAG is enough. However, for more complex, multi-step processes, Agentic RAG offers more flexibility, adaptability, and accuracy. As AI [...] Traditional RAG systems lack decision-making capabilities. They follow a fixed flow â€” retrieve, augment, and generate.  Agentic RAG systems, however, involve agents that make intelligent decisions about what data to retrieve, which tools to use, and how to generate responses. These agents can also adapt their approach based on the userâ€™s query and available data.  ### Multi-Step Reasoning: [...] Traditional RAG systems are great for answering simple queries and retrieving information from static sources. However, they may struggle with multi-step, complex queries.  Agentic RAG systems, on the other hand, excel in handling complex tasks by breaking them down into smaller, manageable steps. They se agents to make decisions at each stage, ensuring that the system adapts to the taskâ€™s complexity.  ### Decision Making:
ðŸ’­ Think: Query: RAG vs Agent based approach | Found 5 results, 5 URLs. Key snippets: In all fairness, thereâ€™s no single â€œwinnerâ€ across all scenarios. Fine-tuning shines in high-volume, | The table below makes it easy for you to see the trade-offs:

 RAG is best for quick wins with stati | RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant. Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
ðŸ“– Read URL: https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-... (8015 chars)
   â””â”€ [https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/]
      Preview: LLM fineâ€‘tuning vs. RAG vs. agents: a practical comparison - MITRIX Technology Home Services AI development for startups AI/ML & generative AI Consulting Cloud development Business intelligence Digital transformation Mobile development Web development Portfolio Dedicated Team Team augmentation Startup development Blog Contacts --> contact us Artificial intelligence Technical debt LLM fineâ€‘tuning vs. RAG vs. agents: a practical comparison September 29, 2025 7 min reading It&#8217;s fair to say that the past few years have reshaped natural language processing (NLP) and AIâ€‘driven applications. Nowadays, businesses face a pivotal question: â€œ Whatâ€™s the best way to harness large language models (LLMs) for their specific needs?â€ Three primary approaches dominate the landscape: LLM fineâ€‘tuning, retrievalâ€‘augmented generation (RAG), and AI agents. Each has unique strengths, tradeâ€‘offs, and implications for cost, scalability, and control. The differences, use cases, and a practical LLM comparison are essential for decision-makers seeking clarity. Key considerations include LLM leaderboard rankings, LLM benchmark performance, and best practices for LLM training, all of which guide informed choices. In this article, youâ€™ll learn: Why LLM fineâ€‘tuning, RAG, and AI agents matter for business AI. How fineâ€‘tuning embeds expertise, ensures consistency, and supports compliance. How RAG delivers fresh, explainable insights without retraining. How agents automate multi-step workflows across systems. Cost, scalability, and hybrid strategies for real-world adoption . Practical steps for piloting, benchmarking, and scaling anything LLM. How Mitrix helps implement tailored LLM solutions with AI agents, fine-tuning, and RAG. Why the comparison matters Naturally, not all AI problems need the same solution. Some demand custom expertise embedded in the model (fineâ€‘tuning). Others rely on realâ€‘time access to fresh or proprietary data (RAG). And increasingly, enterprises deploy multiâ€‘step AI agents that combine reasoning, planning, and tool use. Without a clear framework, teams risk over-engineering or under-delivering. Thatâ€™s where a practical comparison helps. It sharpens decision-making by matching solutions to real business needs. This practice also prevents wasted investment in approaches that donâ€™t scale or align with long-term goals. RAG/CAG/Fine-tuning comparison Key takeaway Fine-tuning, RAG, and agents each solve different categories of problems, and no single method is a universal answer. Fine-tuning shines when domain expertise must be baked into the model itself. RAG ensures real-time accuracy by grounding outputs in fresh or proprietary data. Agents excel when tasks demand multi-step reasoning and tool orchestration. The real value comes from knowing when to use each (or how to combine them) so that your AI strategy is efficient, scalable, and aligned with business objectives. LLM fineâ€‘tuning: embedding expertise into the model Fineâ€‘tuning refers to adjusting a preâ€‘trained model on a narrower dataset so that it better aligns with a companyâ€™s domain, style, or compliance needs. Advantages Custom expertise . Embeds industryâ€‘specific knowledge (e.g., legal, medical, or financial terminology). Consistency . Produces more predictable outputs for repetitive, structured tasks. Data security . Keeps sensitive workflows internal when paired with private LLM training pipelines. Challenges Cost . Training and hosting fineâ€‘tuned models can be expensive. Maintenance . Models can become stale if regulations or data shift. Complexity . Requires understanding of how to finetune LLM effectively. Best practices If youâ€™re exploring how to fineâ€‘tune LLM systems, start with: Curated datasets . Quality beats quantity: clean, representative samples matter most. Instruction tuning . Aligning outputs with human preferences. Benchmarking . Use an LLM leaderboard or LLM benchmark to measure progress against baselines. Use cases Customer service with domainâ€‘specific compliance. Contract analysis in law firms. Clinical decision support in healthcare . Key takeaway In a nutshell, LLM fine-tuning shines when stability, compliance, and domain expertise are non-negotiable. It embeds specialized knowledge directly into the model, delivers consistent outputs, and safeguards sensitive data , though at the cost of higher training and maintenance demands. For industries with strict requirements, itâ€™s the most reliable way to align AI with business realities. Retrievalâ€‘augmented generation (RAG): injecting fresh knowledge Unlike fineâ€‘tuning, RAG doesnâ€™t alter the base model. Instead, it enhances responses by retrieving documents from a knowledge base at query time. Think of it as â€œopenâ€‘book AI.â€ Advantages Dynamic knowledge . Access to realâ€‘time or frequently updated data. Lower cost . No need for repeated LLM training. Explainability . Ability to cite sources for improved trust. Challenges Latency . Retrieval adds overhead. Quality control . Poorly indexed data equals poor results. Limited reasoning . The model still relies on external context stitching. Best practices Use vector databases for efficient semantic search. Regularly update knowledge repositories. Benchmark retrieval quality against domainâ€‘specific LLM comparison tests. Use cases Enterprise search and knowledge management. Product support documentation. Financial research with realâ€‘time market data. Key takeaway RAG excels when access to up-to-date information is critical. It keeps models dynamic, cost-efficient, and explainable, while avoiding repeated LLM training. However, performance depends on high-quality indexing, efficient retrieval, and careful monitoring to ensure accuracy and reliability. AI agents: multiâ€‘step reasoners and doers While fineâ€‘tuning and RAG improve single interactions, agents represent a different paradigm. They are systems that use LLMs as reasoning engines but also interact with tools, APIs , and other agents to complete multiâ€‘step workflows. Advantages Autonomy . Capable of executing complex tasks with minimal supervision. Flexibility . Can combine RAG, fineâ€‘tuning, and external tools. Scalability . Extendable through modular architectures. Challenges Reliability . Prone to â€œ hallucinations â€ without guardrails. Governance . Harder to audit multiâ€‘step reasoning. Engineering complexity . Requires orchestration frameworks. Best practices Define clear boundaries for agent autonomy. Monitor workflows continuously. Leverage LLM benchmarks to evaluate reasoning performance. Use cases Automated research assistants. Supply chain optimization. Customer onboarding journeys that require multiple systems. Key takeaway To cut a long story short, AI agents take LLM capabilities beyond single-turn answers by chaining reasoning with action. They offer autonomy, flexibility, and scalability, but come with reliability and governance challenges that require careful orchestration. Teams that define clear guardrails, monitor workflows, and ground performance with LLM benchmarks can unlock use cases from automated research to end-to-end customer journeys. LLM leaderboards, benchmarks, and reality checks In 2025, the surge of public LLM leaderboards has made it easier to track how different models perform across tasks. But remember: benchmarks are abstractions. They often emphasize math, reasoning, or academic QA tasks, which may not reflect your business context. When running an LLM comparison for your project: Use public LLM benchmarks as a starting point. Create internal benchmarks tied to your data. Test across scenarios like latency, compliance, and user satisfaction. Benchmarks tell you how a model performs in theory, while pilots tell you how it performs in practice. Another limitation is that leaderboard results usually come from controlled test sets and donâ€™t capture operational realities. For example, a model may rank high on reasoning tasks but struggle when integrated into workflows with strict latency requirements. Cost... [truncated]
ðŸ“– Read URL: https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/... (8015 chars)
   â””â”€ [https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/]
      Preview: RAG vs Agentic RAG vs MCP: A 2025 Comparison Guide for Business Leaders Skip to main content Get awesome and let's build together! +1 858-683-3692 Hit enter to search or ESC to close Close Search search Menu Services Web Development Full Stack Development SaaS Development Ruby on Rails Development Node.js Development React Development Angular Development Vue.js Development eCommerce Development PHP Development Firebase Development WordPress Development WooCommerce Development Shopify Development Shopify Apps Development Mobile App Development iOS App Development Android App Development Progressive Web Application React Native App Development Hybrid App Development Flutter App Development Roku App Development Apple tvOS App Development Apple WatchOS App Development Tablet App Development Google Tv App Development UX UI Services Enterprise Digital Transformation Web Data Extraction Scraping Big Data and Business Intelligence AWS Serverless Computing Robotic Process Automation AWS Cloud Computing AI &#038; Machine Learning Development DevOps Services Cloud Computing Services Business Software Development Software Development Partner Contentful Digital Agency Chia Blockchain farming Automation &#038; AI AI Development Services Power Platform Consulting Chatbot Development GenAI Integration Services AI Consulting Services AI Development with v0 &#038; Cursor Healthcare AI Agents AI Agent Development Workflow automation Services CMS &#038; eCommerce Identity &#038; Access Management Modern Data Stack Low Code Development Industries Healthcare Wound Care Software Development EHR/EMR Software Development HMO Automation Software Advance Imaging Software Solutions Telemedicine Software Development Services RPM Software Development Healthcare Mobile App Development Medical Device Software Development Life Sciences Software Development Healthcare Web Design &#038; Development Manufacturing Fitness FinTech Non-Profit eCommerce Retail Startups Our Work Solutions Cloud Solutions Cloud Application Development Custom Solutions Digital SMS/IVR Will Call with Twilio Digital Inspection Platform Digital Lending Platform Custom Software Development Marketplace Platform IoT Development Appointment Scheduling Software HME Software Development Business Software Solutions No-Code Solutions RPA Solution CRM Integrations Integrations Payment Gateway Google Calendar Integration Google Maps Integration OAuth Authentication Twilio API Integration OKTA Integration NetSuite Integration Salesforce API Integration SugarCRM &#038; SuiteCRM Integration VGS Integration Partner Hire Us Hire Mobile App Developer Hire Ruby on Rails Developer Hire Swift Developer Hire Full Stack Developer Hire Xamarin Developer Hire PHP Developer Hire Vue.js Developer Hire Angular JS Developer Hire React Developers Hire Node.js Developer Hire DevOps Engineer Blog Jumpstart My Project search RAG vs Agentic RAG vs MCP: A 2025 Comparison Guide for Business Leaders By Raj Sanghvi June 24, 2025 AI , Automation ChatGPT Perplexity Claude Social Facebook Twitter LinkedIn WhatsApp Email No Comments For business leaders exploring AI-powered solutions, terms like RAG, Agentic RAG, and MCP are now at the center of strategy discussions. But what do they actually mean, and which one is right for your organization? This guide cuts through the technical jargon and gets straight to the point: What are these AI frameworks? How do they differ in capabilities and complexity? Which is best suited for your goals? Whether youâ€™re leading a digital transformation initiative or simply looking to make smarter decisions with AI, this side-by-side comparison of Retrieval-Augmented Generation (RAG), Agentic RAG, and the Model Context Protocol (MCP) will help you confidently choose the right approach. Letâ€™s break it down. Contents hide 1 What Are RAG, Agentic RAG, and MCP? 1.1 RAG (Retrieval-Augmented Generation) 1.2 Agentic RAG 1.3 MCP (Model Context Protocol) 2 How RAG, Agentic RAG, and MCP Differ: Side-by-Side Comparison 3 Which One Should You Use: RAG, Agentic RAG, or MCP? 4 Why Bitcot is the Right Partner No Matter Which AI Framework You Choose 5 Final Thoughts 6 FAQs What Are RAG, Agentic RAG, and MCP? Before diving into comparisons, letâ€™s define each approach in clear, business-relevant terms: what they are, what they do, and where they fit in real-world AI use cases. RAG (Retrieval-Augmented Generation) RAG enhances large language models (LLMs) by letting them â€œlook things up.â€ Instead of relying only on what the model was trained on, RAG retrieves relevant documents or knowledge from an external source (like a database or vector store) before generating a response. Use it for: Chatbots that answer based on company knowledge. Customer service bots with access to FAQs and manuals. Sales reps that summarize case studies or product info on demand. Strength: High-accuracy answers using up-to-date, controlled content. Limitation: Passive; answers only whatâ€™s asked, no autonomy or reasoning. Agentic RAG Agentic RAG adds goal-driven reasoning to traditional RAG. RAG AI agents and Agentic RAG represent two stages of intelligent retrieval systems, starting with basic response generation and evolving into systems with planning and tool-use capabilities. This evolution introduces a layer of autonomy that RAG alone cannot achieve. Instead of just answering questions, the AI becomes an agent that can plan steps, retrieve multiple pieces of information over time, use tools (like web search or APIs), and reflect on progress toward a goal. Use it for: Research agents that proactively gather insights. Internal assistants that answer, verify, and summarize from multiple sources. Complex workflows where context evolves. Strength: Autonomy + search = more useful, more flexible. Limitation: Harder to control, test, or explain compared to simple RAG. RAG AI agents and Agentic RAG represent two stages of intelligent retrieval systems, starting with basic response generation and evolving into systems with planning and tool-use capabilities. This evolution introduces a layer of autonomy that RAG alone cannot achieve. MCP (Model Context Protocol) MCP is a framework for building modular, transparent, and fully autonomous AI agents. It organizes everything an agent needs, its memory, tools, instructions, and roles, into a reusable â€œprotocolâ€ that drives how it reasons, acts, and evolves. Use it for: Building AI agents with MCP that interact seamlessly with tools, data, and people. Agents that learn from feedback and adapt over time. Enterprise AI thatâ€™s structured, auditable, and explainable. Strength: Full agent control, modularity, and long-term memory. Limitation: Requires thoughtful design; best used when agents must act autonomously with accountability. How RAG, Agentic RAG, and MCP Differ: Side-by-Side Comparison The comparison of MCP vs RAG in AI highlights the progression from simple retrieval-based responses (RAG) to more dynamic, goal-oriented systems (Agentic RAG), and ultimately to MCP, offering long-term memory, autonomy, and multi-system integration. The table below makes it easy for you to see the trade-offs: RAG is best for quick wins with static content. Agentic RAG is a smart bridge when goal-based reasoning is needed. MCP is for building durable, intelligent systems with real decision-making power. Feature / Capability RAG Agentic RAG MCP Primary Function Answering questions using retrieved content Multi-step reasoning with goal-driven retrieval Building modular, fully autonomous agents Autonomy None Partial (task-focused) Full autonomy (reasoning + action) Memory Stateless Limited (per session/task) Persistent memory &amp; state tracking Use of Tools None Can use tools/APIs during reasoning Tool-using via structured interface Task Complexity Simple Q&amp;A Medium-complex (e.g., research, synthesis) High-complex (multi-tool, multi-step workflows) Best For Knowledge chatbots, FAQ bots Research agents, assistant-style tasks Enterprise agen... [truncated]
   â””â”€ [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037]
      Preview: Error: HTTP 403 for URL: https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
ðŸ”¬ Analyzer [1]: Analyzing 5 results, 3 contents

ðŸ”¬ Analyzer [1]: Analyzed 5 results, 3 contents
   â””â”€ New findings:
      [1] RAGì€ ì •ì ì¸ ì½˜í…ì¸ ì— ì í•©í•˜ê³  Agentic RAGëŠ” ëª©í‘œ ê¸°ë°˜ ì¶”ë¡ ì´ í•„ìš”í•  ë•Œ ì í•©í•˜ë‹¤.
      [2] RAGëŠ” LLMì— ì¶”ê°€ ì§€ì‹ì„ ì œê³µí•˜ëŠ” ë°˜ë©´, AI ì—ì´ì „íŠ¸ëŠ” ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ê³  ìž‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ ê´€ë¦¬ìžì™€ ê°™ë‹¤.
      [3] RAGëŠ” ê²€ìƒ‰ ê¸°ë°˜ ì¦ê°• ê¸°ìˆ ì´ê³  AI ì—ì´ì „íŠ¸ëŠ” ê²€ìƒ‰ ì´ìƒì˜ êµ¬ì¡°í™”ëœ ì‹¤í–‰ì„ ìˆ˜í–‰í•œë‹¤. RAGëŠ” AI ì—ì´ì „íŠ¸ì˜ ë„êµ¬ë¡œ ì‚¬ìš©ë  ìˆ˜ ìžˆë‹¤.
      [4] RAGëŠ” ë¹ ë¥¸ ìŠ¹ë¦¬ì— ê°€ìž¥ ì í•©í•˜ê³  ì—ì´ì „íŠ¸ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì— ê°€ìž¥ ì í•©í•˜ë‹¤. ë¯¸ì„¸ ì¡°ì •ì€ ì•ˆì •ì„±ì—, RAGëŠ” ì ì‘ì„±ì—, ì—ì´ì „íŠ¸ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì— ì í•©í•˜ë‹¤.
      [5] RAGëŠ” ê°„ë‹¨í•œ ê²€ìƒ‰ ìž‘ì—…ì— ì í•©í•˜ê³  Agentic RAGëŠ” ë³µìž¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ë” ì í•©í•˜ë‹¤.
   â””â”€ Decision: More research needed
   â””â”€ Next query: RAG Agent ì°¨ì´ì  ì˜ˆì‹œ
ðŸ” Searcher [2]: Follow-up search for: RAG Agent ì°¨ì´ì  ì˜ˆì‹œ

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC
      [2] https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/
      [3] https://osckorea.tistory.com/332
      [4] https://www.skelterlabs.com/blog/llm-rag-aiagent
      [5] https://www.zhihu.com/tardis/zm/art/675509396
   â””â”€ Snippets:
      â€¢ RAGì™€ Agentë¥¼ ì„¤ëª…í•˜ëŠ” í•œ ê¸€ì—ì„œëŠ” 'RAGê°€ ê¸°ì–µìž¥ì¹˜(ì •ë³´ í…Œì´ë¸Œ)ë¥¼ ì–¸ì–´ëª¨ë¸ì— ìž¥ì°©í•˜ëŠ” ì¼ì´ë¼ë©´, AgentëŠ” ì–¸ì–´ëª¨ë¸ì— íŒ”ë‹¤ë¦¬ë¥¼ ë¶™ì—¬ì£¼ëŠ” ì¼' ì´ë¼ê³  ì„¤ëª…í•˜ê¸°ë„ í•œë‹¤.  ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒ ë‘ ê°€ì§€ ì¼€ì´ìŠ¤ì˜ RAGê¸°ë°˜ì˜ êµ¬ì¡°ê°€ ìžˆë‹¤ê³  í•˜ìž.    ì™¼ìª½ì˜ ê²½ìš°, ì¼ë°˜ì ì€ RAGêµ¬ì¡°ë¡œ, input queryê°€ ë“¤ì–´ì˜¤ë©´ vectorDBì—ì„œ ì¿¼ë¦¬ë¥¼ í•´ì„œ Modelì—ê²Œ ì°¸ê³ í•  ìˆ˜ ìžˆëŠ” ì •ë³´ë¥¼ ë„˜ê²¨ì£¼ê³ , ìµœì¢… resultëŠ” ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•œë‹¤. ì´ë•Œ VectorDB ë¶€ë¶„ì—ëŠ” Search APIê°€ ë“¤ì–´ê°ˆ ìˆ˜ë„ ìžˆê³ , ê¸°íƒ€ data augmented í”„ë¡œì„¸ìŠ¤ë¡œ êµì²´ë  ìˆ˜ ìžˆë‹¤. ë˜í•œ query rewriteë‚˜ verifierì™€ ê°™ì€ ìµœì í™”, ê²€ì¦ í”„ë¡œì„¸ìŠ¤ê°€ ë“¤ì–´ê°ˆ ìˆ˜ë„ ìžˆë‹¤. [...] ì‚¬ì‹¤ ì´ ë¶€ë¶„ì´ ê°€ìž¥ í˜¼ëž€ìŠ¤ëŸ¬ì› ë‹¤. Agentë¼ëŠ” ê°œë…ì´ ì´ë ‡ê²Œ ëœ¨ê¸° ì „ì—, ë‚˜ë¥¼ í¬í•¨í•´ì„œ ë§Žì€ ì‚¬ëžŒë“¤ì´ Langchainê³¼ Langgraph ê¸°ë°˜ì˜ RAG í”„ë ˆìž„ì›Œí¬ë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ê³  ì‚¬ìš©í•˜ê³  ìžˆì—ˆë‹¤ê³  ìƒê°í•œë‹¤. ê·¸ëŸ¼ ì§€ê¸ˆê¹Œì§€ ë‚´ê°€ ì‚¬ìš©í•œê±´ Agentê°€ ì•„ë‹ˆëž€ ê±¸ê¹Œ?  LangGraphëŠ” ê¸°ë³¸ì ìœ¼ë¡œ Agentsë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ Langchainì˜ í”„ë ˆìž„ì›Œí¬ìž„  ê²°ë¡ ë¶€í„° ì–˜ê¸°í•˜ë©´ ì•„ë‹ˆë‹¤. ì—¬ê¸°ì„œë¶€í„°ëŠ” ê°œì¸ì ì¸ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì—ˆëŠ”ë°, 'ì—¬ëŸ¬ê°€ì§€ Toolsì™€ ì—°ê²°ë˜ëŠ” ë°©ì‹ì— ë”°ë¥¸ ì°¨ì´ë¡œ êµ¬ë¶„' ëœë‹¤ê³  ì •ë¦¬í•  ìˆ˜ ìžˆë‹¤ê³  ìƒê°í•œë‹¤. ì¦‰, inputì´ ë“¤ì–´ì™”ì„ ë•Œ, ì •í•´ì§„ flow(e.g. Inputì´ ë“¤ì–´ì˜¤ë©´ ë°˜ë“œì‹œ VectorDBë¥¼ í†µí•œ ìœ ì‚¬í•œ chunkë¥¼ ê¸°ë°˜ìœ¼ë¡œ data augmentedëœ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” vanilla RAG)ì— ë”°ë¼ì„œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ì§€ í˜¹ì€ Modelì´ ìƒí™©ì— ë§žëŠ” Toolì„ ì§ì ‘ ì„ íƒí•˜ê³  í•„ìš”ì— ë”°ë¼ì„œ flowë¥¼ ì›€ì§ì´ë©° ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ì§€ì˜ ì°¨ì´ë¼ëŠ” ê²ƒì´ë‹¤. [...] ì˜¤ë¥¸ìª½ í”„ë¡œì„¸ìŠ¤ê°€ Agentì˜ ê°œë…ê³¼ í—·ê°ˆë¦¬ëŠ” ë¶€ë¶„ì´ì—ˆë‹¤. ì´ êµ¬ì¡°ì—ëŠ” Routerë¥¼ í†µí•´ì„œ ì–´ë–¤ íˆ´ì„ ì‚¬ìš©í•  ì§€ ë¶„ê¸°í•˜ëŠ” ê³¼ì •ì´ ì¶”ê°€ë˜ì–´ ìžˆëŠ”ê±´ë°, ì´ë•Œì˜ Routerë¥¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì“°ëƒì— ë”°ë¼ì„œ agenticí•˜ë‹¤ê³  ë³¼ ìˆ˜ë„ ìžˆì„ ê²ƒ ê°™ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, LMì„ í™œìš©í•œ Routerë¥¼ ë§Œë“¤ì–´ì„œ ì¼€ì´ìŠ¤ë“¤ì„ ëª¨ë¸ì´ ë¶„ë¥˜í•´ì„œ Toolë¡œ ì—°ê²°ë˜ë„ë¡ í•œë‹¤ë©´, ì´ê±´ Agentì˜ ì¡°ê±´ ì¤‘ 'ìŠ¤ìŠ¤ë¡œ ìž‘ì—…ì„ ì œì–´í•˜ê³  ìž‘ì—…ì˜ ê²½ë¡œ ì„ íƒ'ì´ë¼ëŠ” ê²ƒì— í•´ë‹¹í•œë‹¤ê³  ë³¼ ìˆ˜ ìžˆë‹¤. ë°˜ë©´, Routerë¥¼ if-else ì¡°ê±´ë¬¸ê³¼ ê°™ì´ êµ¬ì„±í•œë‹¤ë©´, ì˜ˆë¥¼ ë“¤ì–´ 'input queryì— "ê²€ìƒ‰"ì´ë¼ëŠ” ë‹¨ì–´ê°€ ë“¤ì–´ê°€ë©´ Search API ë„êµ¬ë¡œ ì—°ê²°í•´ì¤˜'ì™€ ê°™ì´, ì´ë¥¼ AgenticRAGë¼ê³  ë³´ê¸°ëŠ” ì–´ë ¤ìš´ ê²ƒì´ë‹¤.
      â€¢ ì´ëŸ° Agentic RAGëŠ” íŠ¹ížˆ êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ë°©ëŒ€í•œ ë°ì´í„° ì†ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë†’ì€ ì •í™•ë„ì™€ ì‹ ë¢°ì„±ì´ ìš”êµ¬ë˜ëŠ” ì˜ë£Œë¶„ì•¼ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ìƒê°í•´ ë³¼ê¹Œìš”? ì‚¬ìš©ìžê°€ â€œì½”ë¡œë‚˜19 ë°±ì‹ ê³¼ ë…ê° ë°±ì‹ ì„ ë™ì‹œì— ë§žì•„ë„ ë ê¹Œìš”?â€ë¼ëŠ” ì§ˆë¬¸ì„ í–ˆì„ ë•Œ, ì¼ë°˜ì ì¸ RAG ì‹œìŠ¤í…œì€ ë‹¨ìˆœížˆ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•˜ëŠ” ë° ê·¸ì¹˜ì§€ë§Œ, Agentic RAGëŠ” í›¨ì”¬ ë” ë³µìž¡í•œ ê³¼ì •ì„ ê±°ì¹  ê²ƒìž…ë‹ˆë‹¤. [...] ìµœê·¼ ìžì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ í° ì£¼ëª©ì„ ë°›ê³  ìžˆëŠ” RAG ëª¨ë¸ì€ ë°©ëŒ€í•œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ˆì˜ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê°•ë ¥í•œ ìžì—°ì–´ ìƒì„± ê¸°ìˆ ì¸ë°ìš”, ì—¬ê¸°ì— ì—ì´ì „íŠ¸ì˜ ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ì´ ë”í•´ì§€ë©´ì„œ Agentic RAGë¼ëŠ” ìƒˆë¡œìš´ ê°œë…ì´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.  Agentic RAGëŠ” LLMì˜ ì–¸ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ê³¼ ì—ì´ì „íŠ¸ì˜ ìžìœ¨ì  íƒœìŠ¤í¬ ìˆ˜í–‰ ëŠ¥ë ¥ì´ ê²°í•©ëœ í˜•íƒœë¼ê³  ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¼ë°˜ RAGê°€ ë‹¨ìˆœížˆ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©í•œë‹¤ë©´ Agentic RAGëŠ” ì •ë³´ì˜ í•„ìš”ì„±ì„ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ê³ , ì ì ˆí•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ êµ¬ì„±í•˜ë©°, ê²€ìƒ‰ëœ ì •ë³´ë¥¼ í‰ê°€í•˜ê³  í†µí•©í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. [...] ë¨¼ì € ì—¬ëŸ¬ ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ì™€ ìµœì‹  ë³´ê±´ ê°€ì´ë“œë¼ì¸ì„ ê²€ìƒ‰í•˜ê³ , ê²€ìƒ‰ëœ ì •ë³´ì˜ ë°œí–‰ ë‚ ì§œë¥¼ í™•ì¸í•˜ì—¬ ìµœì‹ ì„±ì„ í‰ê°€í•˜ê³ , ë§Œì•½ ì„œë¡œ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ë°œê²¬ë˜ë©´ ì—ì´ì „íŠ¸ëŠ” ì´ëŸ¬í•œ ë¶ˆì¼ì¹˜ë¥¼ ë¶„ì„í•˜ê³  í•„ìš”ì— ë”°ë¼ íŠ¹ì • ì¸êµ¬ ì§‘ë‹¨(ì˜ˆ: ë©´ì—­ ì €í•˜ìž)ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œëŠ” ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìžì—ê²Œ ì œê³µí•˜ë˜, ì´ê²ƒì´ ì „ë¬¸ì ì¸ ì˜í•™ì  ì¡°ì–¸ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŒì„ ëª…í™•ížˆ í•¨ìœ¼ë¡œì¨ ì •ë³´ì˜ ì±…ìž„ ìžˆëŠ” ì‚¬ìš©ì„ ìž¥ë ¤í•  ê²ƒì´ê³  ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ Agentic RAGëŠ” ë‹¨ìˆœí•œ ì •ë³´ ê²€ìƒ‰ì„ ë„˜ì–´ ì§€ëŠ¥ì ì¸ ì˜ë£Œ ì •ë³´ ë³´ì¡° ë„êµ¬ë¡œì„œ ì—­í• ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  ë˜í•œ, ë²•ë¥ ì´ë‚˜ íŠ¹í—ˆì™€ ê°™ì´ ë°©ëŒ€í•œ ë„ë©”ì¸ ì§€ì‹ì´ ìš”êµ¬ë˜ëŠ” ë¶„ì•¼ì—ì„œë„ ì „ë¬¸ê°€ë¥¼ ë³´ì¡°í•˜ëŠ” ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìžˆì„ ê²ƒìž…ë‹ˆë‹¤. ìˆ˜ë§Žì€ íŒë¡€ì™€ ë²•ì¡°ë¬¸ ì†ì—ì„œ ì‚¬ì•ˆì— ì ìš© ê°€ëŠ¥í•œ ì¡°í•­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ê·¼ê±°ë¡œ ë²•ë¥  ìžë¬¸ì„ ì œê³µí•˜ëŠ” ì‹ì´ì£ .
      â€¢ Agentic RAGëŠ” ë§ ê·¸ëŒ€ë¡œ AI â€˜ì—ì´ì „íŠ¸â€™ë¥¼ ê²°í•©í•œ ì—…ê·¸ë ˆì´ë“œ ë²„ì „ìž…ë‹ˆë‹¤. Agentic RAGëŠ” í•˜ë‚˜ì˜ LLMë§Œ í™œìš©í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ì—¬ëŸ¬ íˆ´ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•´ì„œ í›¨ì”¬ ë” ë³µìž¡í•˜ê³  ë©€í‹°ìŠ¤í…ì¸ ë¬¸ì œë„ ì²˜ë¦¬í•  ìˆ˜ ìžˆê²Œ í•©ë‹ˆë‹¤.  |  |  |  |  ---  | íŠ¹ì§• | ë°”ë‹ë¼ RAG | Agentic RAG | | LLM ê¸°ë°˜ | âœ… | âœ… | | ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ë°ì´í„° ê²€ìƒ‰ | âœ… | âœ… | | ë‹¤ì–‘í•œ ë„êµ¬ í™œìš© | âŒ | âœ… | | ë‹¤ë‹¨ê³„ ì¶”ë¡  | âŒ | âœ… | | í’ë¶€í•œ ë©”ëª¨ë¦¬ | ì œí•œì  | âœ… | | ì¿¼ë¦¬ ì •ì œ | âŒ | âœ… |  Agentic RAGì˜ í•µì‹¬ì€ íš¨ìœ¨ì„±ê³¼ í™•ìž¥ì„±ìž…ë‹ˆë‹¤. ì‹œë§¨í‹± ìºì‹±ê³¼ ê³ ë„í™”ëœ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë•ë¶„ì— LLM í˜¸ì¶œ ë¹„ìš©ê³¼ ì§€ì—°ì´ ëŒ€í­ ì¤„ê³ , ë³µìž¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ë„ í›¨ì”¬ ì‰½ê²Œ ìžë™í™”í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  #### ëœ¨ê±°ì›Œì§€ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆ ì‹œìž¥ [...] ëŒ€ìš©ëŸ‰ ë°ì´í„°, ê³ ì„±ëŠ¥ ê´€ë¦¬: Agentic RAGì—ì„œ ì¤‘ìš”í•œ ê±´ ë°©ëŒ€í•œ ì™¸ë¶€ ì§€ì‹ì˜ ì‹¤ì‹œê°„ ê²€ìƒ‰ê³¼ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì¸ë°, RedisëŠ” ëŒ€ê·œëª¨ ë²¡í„° ìž„ë² ë”©ì„ ì €ìž¥, ìƒ‰ì¸(indexing)í•˜ë©°, ëŒ€í™” ížˆìŠ¤í† ë¦¬ ê´€ë¦¬(LLM ì„¸ì…˜ ë§¤ë‹ˆì €)ì—ë„ ìµœì í™”ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.  ì—”í„°í”„ë¼ì´ì¦ˆ ì¸í”„ë¼ì™€ì˜ ì¹œí™”ì„±: RedisëŠ” ê²€ì¦ëœ í™•ìž¥ì„±, ë‚®ì€ ì§€ì—°, ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡° ì§€ì›(ë¬¸ìžì—´, ë¦¬ìŠ¤íŠ¸, í•´ì‹œ, ì§‘í•© ë“±) ë“±ìœ¼ë¡œ ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì— ìœ ì—°í•˜ê²Œ ì ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê¸°ì¡´ ì„œë¹„ìŠ¤ì™€ì˜ ê²°í•©, ë°ì´í„° ë™ê¸°í™” ë“±ë„ ìš©ì´í•˜ë‹¤ëŠ” íŠ¹ì§•ì´ ëª…ì‹œë˜ì–´ ìžˆìŠµë‹ˆë‹¤.  ë¹ ë¥´ê³  ëŠê¹€ ì—†ëŠ” ì‚¬ìš©ìž ê²½í—˜: ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ì¤‘ìš”í•œ AI ì„œë¹„ìŠ¤, ì˜ˆë¥¼ ë“¤ë©´ RAG ê¸°ë°˜ ì±—ë´‡ì´ë‚˜ ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” Redisë¥¼ í†µí•´ '100ms ë£°'(ì‚¬ìš©ìžê°€ ëŠë¼ê¸°ì— ì¦‰ê°ì ì¸ ì‘ë‹µ ì†ë„) ê²½í—˜ì— í•œì¸µ ë” ê·¼ì ‘í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. [...] ê²°ë¡ ì ìœ¼ë¡œ, ì²¨ë¶€ ë¬¸ì„œì—ì„œëŠ” Agentic RAGì˜ ë¹ ë¥¸ ë©”ëª¨ë¦¬, ì‹œë§¨í‹± ìºì‹±, ê³ ì„±ëŠ¥ ë²¡í„° ê²€ìƒ‰, í™•ìž¥ì„±ê³¼ ì‹ ë¢°ì„± ì¸¡ë©´ì—ì„œ Redisê°€ ì—”í„°í”„ë¼ì´ì¦ˆ AI ì•„í‚¤í…ì²˜ì˜ í•„ìˆ˜ ì¸í”„ë¼ìž„ì„ ê°•ì¡°í•˜ê³  ìžˆìŠµë‹ˆë‹¤. Agentic RAGë¥¼ ê³ ë¯¼í•˜ëŠ” ì‹¤ë¬´ì§„ì´ë‚˜ ê°œë°œìžë¼ë©´, Redisì˜ ë„ìž…ì´ ì‹¤ì œë¡œ ì‹œìŠ¤í…œì˜ ì†ë„, ë¹„ìš©, í™•ìž¥ì„± ì¸¡ë©´ì—ì„œ í° ì´ì ì´ ìžˆìŠµë‹ˆë‹¤.  ì›ë¬¸ ì¶œì²˜:  Agentic RAG: How enterprises are surmounting the limits of traditional RAG  10 techniques to improve RAG accuracy  Using Redis for real-time RAG goes beyond a Vector Database  RAG with Redis  ì°¸ê³  ë§í¬:  AI ì—ì´ì „íŠ¸ ì‹œëŒ€, 'ë©”ëª¨ë¦¬'ê°€ í•µì‹¬ì´ë‹¤  ì €ìž‘ìží‘œì‹œ ë¹„ì˜ë¦¬ ë³€ê²½ê¸ˆì§€ (ìƒˆì°½ì—´ë¦¼)  ## íƒœê·¸
ðŸ’­ Think: Query: RAG Agent ì°¨ì´ì  ì˜ˆì‹œ | Found 5 results, 5 URLs. Key snippets: RAGì™€ Agentë¥¼ ì„¤ëª…í•˜ëŠ” í•œ ê¸€ì—ì„œëŠ” 'RAGê°€ ê¸°ì–µìž¥ì¹˜(ì •ë³´ í…Œì´ë¸Œ)ë¥¼ ì–¸ì–´ëª¨ë¸ì— ìž¥ì°©í•˜ëŠ” ì¼ì´ë¼ë©´, AgentëŠ” ì–¸ì–´ëª¨ë¸ì— íŒ”ë‹¤ë¦¬ë¥¼ ë¶™ì—¬ì£¼ëŠ” ì¼' ì´ë¼ê³  ì„¤ëª…í•˜ê¸°ë„ í•œë‹¤. | ì´ëŸ° Agentic RAGëŠ” íŠ¹ížˆ êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ë°©ëŒ€í•œ ë°ì´í„° ì†ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë†’ì€ ì •í™•ë„ì™€ ì‹ ë¢°ì„±ì´ ìš”êµ¬ë˜ëŠ” ì˜ë£Œë¶„ | Agentic RAGëŠ” ë§ ê·¸ëŒ€ë¡œ AI â€˜ì—ì´ì „íŠ¸â€™ë¥¼ ê²°í•©í•œ ì—…ê·¸ë ˆì´ë“œ ë²„ì „ìž…ë‹ˆë‹¤. Agentic RAGëŠ” í•˜ë‚˜ì˜ LLMë§Œ í™œìš©í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ì—¬ëŸ¬ íˆ´ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜. Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
ðŸ“– Read URL: https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B... (5240 chars)
   â””â”€ [https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC]
      Preview: RAG &amp; Agents - 5ë¶„ ì•ˆì— ê°œë… ì •ë¦¬í•˜ê¸° jyun.log ë¡œê·¸ì¸ jyun.log ë¡œê·¸ì¸ RAG &amp; Agents - 5ë¶„ ì•ˆì— ê°œë… ì •ë¦¬í•˜ê¸° JeongYun Lee Â· 2025ë…„ 1ì›” 15ì¼ íŒ”ë¡œìš° 2 Anthropic LLM agent google rag AI ëª©ë¡ ë³´ê¸° 12 / 20 êµ¬ê¸€ì—ì„œ ìž‘ë…„ ë§ ì •ë„ì— Agent ë°±ì„œë¥¼ ë°œí–‰í–ˆê³ , ê°„ë‹¨í•œ ì„¤ëª…ê³¼ ì‹¤ìš©ì ì¸ ë‚´ìš©ì„ ë‹´ê³  ìžˆì–´ì„œ ë§Žì€ ë„ì›€ì´ ëë‹¤. ë°±ì„œì˜ ë‚´ìš©ì„ ì •ë¦¬í•˜ê³  ìš”ì•½í•œ ê¸€ì€ ê²€ìƒ‰í•´ë³´ë©´ êµ‰ìž¥ížˆ ë§Žìœ¼ë¯€ë¡œ ìƒëžµí•˜ê³ , í•´ë‹¹ ê¸€ì—ì„œëŠ” ë°±ì„œë¥¼ ì½ìœ¼ë©´ì„œ ê°œì¸ì ìœ¼ë¡œ ìƒˆë¡œ ì•Œê²Œëœ ë‚´ìš©, ê¶ê¸ˆí•œ ì ë“¤ì„ ì ì–´ë³´ì•˜ë‹¤. Google Agents white paper ì›ë¬¸ ë§í¬ 'ë°±ì„œ'ê°€ ì˜ì–´ë¡œ 'White paper'ì¸ê±¸ ë³´ê³  í™”ë“¤ì§ ë†€ëžë‹¤. ë‚˜ë§Œ ë†€ëžë‚˜? ã…‹ã…‹ã…œ âœ… Agentsì™€ modelsì˜ ì°¨ì´ëŠ”? ì´ ê¸€ì—ì„œëŠ” Agentsì™€ modelsì˜ ê°œë…ì— ëŒ€í•´ì„œ ëª…í™•í•˜ê²Œ ë¹„êµí•˜ê³  ìžˆë‹¤. ì—¬ê¸°ì„œ ë§í•˜ëŠ” modelì€ geminiì™€ ê°™ì€ LM(Large Model)ì„ ì˜ë¯¸í•œë‹¤. í‰ì†Œì— ìµœê·¼ ê°œë°œë˜ëŠ” LMë“¤ì€ ì´ë¯¸ì§€ë‚˜ ì˜ìƒ ë“± Multi-modalityí™” ë˜ê³  ìžˆì–´ì„œ LLM, ì¦‰ Language Modelì´ë¼ê³  í‘œí˜„í•˜ë©´ ê°œë…ì  ì˜¤ë¥˜ê°€ ìžˆì§€ ì•Šë‚˜ë¼ê³  ìƒê°í–ˆëŠ”ë°, ì—­ì‹œ ì´ ê¸€ì—ì„œëŠ” 'Models'ë¼ê³  í‘œí˜„í•œë‹¤ëŠ” ì ì´ ì¸ìƒì ì´ì—ˆë‹¤. ì´ ë¬¸ì„œì˜ ì—¬íŒŒì¸ì§€, ìµœê·¼ LinkedInì„ ë¹„ë¡¯í•œ ê°ì¢… ì»¤ë®¤ë‹ˆí‹°ì—ëŠ” Agentì™€ modelsë¥¼ ë¹„êµí•´ì„œ ì„¤ëª…í•˜ëŠ” ê¸€ì´ ìžì£¼ ë³´ì¸ë‹¤. LLM ëª¨ë¸ê³¼ ì—ì´ì „íŠ¸ì˜ ì°¨ì´ì  AI ì—ì´ì „íŠ¸(AI ì—ì´ì „íŠ¸)ëž€? ì—ì´ì „íŠ¸ì˜ ê°œë…, ëª¨ë¸ê³¼ì˜ ì°¨ì´, ì–¸ì œ ì‚¬ìš©í•´ì•¼ í• ê¹Œ? âœ… ê·¸ëŸ¼ LLMê¸°ë°˜ì˜ RAG frameworkëŠ” Agentsë¼ê³  ë³¼ ìˆ˜ ìžˆì„ê¹Œ? ì‚¬ì‹¤ ì´ ë¶€ë¶„ì´ ê°€ìž¥ í˜¼ëž€ìŠ¤ëŸ¬ì› ë‹¤. Agentë¼ëŠ” ê°œë…ì´ ì´ë ‡ê²Œ ëœ¨ê¸° ì „ì—, ë‚˜ë¥¼ í¬í•¨í•´ì„œ ë§Žì€ ì‚¬ëžŒë“¤ì´ Langchainê³¼ Langgraph ê¸°ë°˜ì˜ RAG í”„ë ˆìž„ì›Œí¬ë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ê³  ì‚¬ìš©í•˜ê³  ìžˆì—ˆë‹¤ê³  ìƒê°í•œë‹¤. ê·¸ëŸ¼ ì§€ê¸ˆê¹Œì§€ ë‚´ê°€ ì‚¬ìš©í•œê±´ Agentê°€ ì•„ë‹ˆëž€ ê±¸ê¹Œ? LangGraphëŠ” ê¸°ë³¸ì ìœ¼ë¡œ Agentsë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ Langchainì˜ í”„ë ˆìž„ì›Œí¬ìž„ ê²°ë¡ ë¶€í„° ì–˜ê¸°í•˜ë©´ ì•„ë‹ˆë‹¤. ì—¬ê¸°ì„œë¶€í„°ëŠ” ê°œì¸ì ì¸ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì—ˆëŠ”ë°, 'ì—¬ëŸ¬ê°€ì§€ Toolsì™€ ì—°ê²°ë˜ëŠ” ë°©ì‹ì— ë”°ë¥¸ ì°¨ì´ë¡œ êµ¬ë¶„' ëœë‹¤ê³  ì •ë¦¬í•  ìˆ˜ ìžˆë‹¤ê³  ìƒê°í•œë‹¤. ì¦‰, inputì´ ë“¤ì–´ì™”ì„ ë•Œ, ì •í•´ì§„ flow(e.g. Inputì´ ë“¤ì–´ì˜¤ë©´ ë°˜ë“œì‹œ VectorDBë¥¼ í†µí•œ ìœ ì‚¬í•œ chunkë¥¼ ê¸°ë°˜ìœ¼ë¡œ data augmentedëœ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” vanilla RAG)ì— ë”°ë¼ì„œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ì§€ í˜¹ì€ Modelì´ ìƒí™©ì— ë§žëŠ” Toolì„ ì§ì ‘ ì„ íƒí•˜ê³  í•„ìš”ì— ë”°ë¼ì„œ flowë¥¼ ì›€ì§ì´ë©° ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ì§€ì˜ ì°¨ì´ë¼ëŠ” ê²ƒì´ë‹¤. RAGì™€ Agentë¥¼ ì„¤ëª…í•˜ëŠ” í•œ ê¸€ ì—ì„œëŠ” 'RAGê°€ ê¸°ì–µìž¥ì¹˜(ì •ë³´ í…Œì´ë¸Œ)ë¥¼ ì–¸ì–´ëª¨ë¸ì— ìž¥ì°©í•˜ëŠ” ì¼ì´ë¼ë©´, AgentëŠ” ì–¸ì–´ëª¨ë¸ì— íŒ”ë‹¤ë¦¬ë¥¼ ë¶™ì—¬ì£¼ëŠ” ì¼' ì´ë¼ê³  ì„¤ëª…í•˜ê¸°ë„ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒ ë‘ ê°€ì§€ ì¼€ì´ìŠ¤ì˜ RAGê¸°ë°˜ì˜ êµ¬ì¡°ê°€ ìžˆë‹¤ê³  í•˜ìž. ì™¼ìª½ì˜ ê²½ìš°, ì¼ë°˜ì ì€ RAGêµ¬ì¡°ë¡œ, input queryê°€ ë“¤ì–´ì˜¤ë©´ vectorDBì—ì„œ ì¿¼ë¦¬ë¥¼ í•´ì„œ Modelì—ê²Œ ì°¸ê³ í•  ìˆ˜ ìžˆëŠ” ì •ë³´ë¥¼ ë„˜ê²¨ì£¼ê³ , ìµœì¢… resultëŠ” ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•œë‹¤. ì´ë•Œ VectorDB ë¶€ë¶„ì—ëŠ” Search APIê°€ ë“¤ì–´ê°ˆ ìˆ˜ë„ ìžˆê³ , ê¸°íƒ€ data augmented í”„ë¡œì„¸ìŠ¤ë¡œ êµì²´ë  ìˆ˜ ìžˆë‹¤. ë˜í•œ query rewriteë‚˜ verifierì™€ ê°™ì€ ìµœì í™”, ê²€ì¦ í”„ë¡œì„¸ìŠ¤ê°€ ë“¤ì–´ê°ˆ ìˆ˜ë„ ìžˆë‹¤. ì˜¤ë¥¸ìª½ í”„ë¡œì„¸ìŠ¤ê°€ Agentì˜ ê°œë…ê³¼ í—·ê°ˆë¦¬ëŠ” ë¶€ë¶„ì´ì—ˆë‹¤. ì´ êµ¬ì¡°ì—ëŠ” Routerë¥¼ í†µí•´ì„œ ì–´ë–¤ íˆ´ì„ ì‚¬ìš©í•  ì§€ ë¶„ê¸°í•˜ëŠ” ê³¼ì •ì´ ì¶”ê°€ë˜ì–´ ìžˆëŠ”ê±´ë°, ì´ë•Œì˜ Routerë¥¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì“°ëƒì— ë”°ë¼ì„œ agenticí•˜ë‹¤ê³  ë³¼ ìˆ˜ë„ ìžˆì„ ê²ƒ ê°™ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, LMì„ í™œìš©í•œ Routerë¥¼ ë§Œë“¤ì–´ì„œ ì¼€ì´ìŠ¤ë“¤ì„ ëª¨ë¸ì´ ë¶„ë¥˜í•´ì„œ Toolë¡œ ì—°ê²°ë˜ë„ë¡ í•œë‹¤ë©´, ì´ê±´ Agentì˜ ì¡°ê±´ ì¤‘ 'ìŠ¤ìŠ¤ë¡œ ìž‘ì—…ì„ ì œì–´í•˜ê³  ìž‘ì—…ì˜ ê²½ë¡œ ì„ íƒ'ì´ë¼ëŠ” ê²ƒì— í•´ë‹¹í•œë‹¤ê³  ë³¼ ìˆ˜ ìžˆë‹¤. ë°˜ë©´, Routerë¥¼ if-else ì¡°ê±´ë¬¸ê³¼ ê°™ì´ êµ¬ì„±í•œë‹¤ë©´, ì˜ˆë¥¼ ë“¤ì–´ 'input queryì— "ê²€ìƒ‰"ì´ë¼ëŠ” ë‹¨ì–´ê°€ ë“¤ì–´ê°€ë©´ Search API ë„êµ¬ë¡œ ì—°ê²°í•´ì¤˜'ì™€ ê°™ì´, ì´ë¥¼ AgenticRAGë¼ê³  ë³´ê¸°ëŠ” ì–´ë ¤ìš´ ê²ƒì´ë‹¤. ì—¬ì „ížˆ ì•Œë“¯ ë§ë“¯í•˜ë‹¤. Anthropicì˜ Building effective agents(2024.12.20) ê¸€ì„ ë³´ë©´ì„œ ì¢€ ë” ì•Œì•„ë³´ê³ ìž í–ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” ë‹¤ìŒ ì„¸ê°€ì§€ë¡œ êµ¬ë¶„í•´ì„œ agentic systemsë¥¼ ì„¤ëª…í•˜ê³  ìžˆë‹¤. (1) Building blocks Building blocksëŠ” LLMì´ ì¿¼ë¦¬ë¥¼ í•˜ê³  ì ì ˆí•œ Toolì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ë©° í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìžˆëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ì˜ë¯¸í•œë‹¤. RAGì— ë² ì´ìŠ¤ë¥¼ ë‘ëŠ”ë°, Toolì„ ì§ì ‘ ì„ íƒí•œë‹¤ëŠ” ì ì—ì„œ agentic systemì— í•´ë‹¹í•˜ëŠ” ê²ƒì´ë‹¤. ì•žì„œ ìœ„ì—ì„œ ì„¤ëª…í•œ RAGêµ¬ì¡° ì¤‘ ì˜¤ë¥¸ìª½ì˜ êµ¬ì¡°ì—ì„œ Routerê°€ LMì„ ì‚¬ìš©í•´ì„œ íŒë‹¨í•˜ë„ë¡ í•œ ê²½ìš°ê°€ ì´ ì¼€ì´ìŠ¤ì— í•´ë‹¹í•œë‹¤ê³  ë³¼ ìˆ˜ ìžˆì„ ê²ƒ ê°™ë‹¤. (2) Workflows WorkflowsëŠ” ë‹¤ì‹œ Prompt chaining, Routing, Parallelization, Orchestrator-workers, Evaluator-optimizerìœ¼ë¡œ ì„¤ëª…í•œë‹¤. ë³µìž¡í•´ë³´ì´ì§€ë§Œ, RAG í”Œë¡œìš°ë¥¼ ì–´ë–»ê²Œ ë§Œë“¤ì–´ì¤„ ê²ƒì¸ì§€ì— ëŒ€í•œ ì¼€ì´ìŠ¤ë³„ ì„¤ëª…ì¼ ë¿ì´ë‹¤. ì´ê²ƒë“¤ì„ ì¡°í•©í•´ì„œ ë¬´ìˆ˜ížˆ ë§Žì€ ê²½ìš°ì˜ ìˆ˜ê°€ ë‚˜ì˜¬ ìˆ˜ ìžˆì„ ê²ƒ ê°™ë‹¤. Prompt Chainingì˜ GateëŠ” Evaluatorì™€ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šë‹¤ê³  ìƒê°í•´ì„œ verification ë¶€ë¶„ì„ ì¶”ê°€í•˜ëŠ” ê²ƒ ì •ë„ë¡œ ì´í•´í–ˆë‹¤. ì•„ëž˜ êµ¬ì¡°ì—ì„œì™€ ê°™ì´ Prompt chainingì€ verifierì—ì„œ Failì¼ ë•Œ Exitë¡œ í‘œí˜„í–ˆê³  EvaluatorëŠ” verifierì—ì„œ ë‹¤ì‹œ Tool ë¶€ë¶„ìœ¼ë¡œ ëŒì•„ê°€ëŠ” ê²ƒìœ¼ë¡œ í‘œí˜„í–ˆë‹¤. RouterëŠ” ë‹¨ìˆœížˆ ë¶„ê¸°ë§Œ í•´ì£¼ëŠ” ì—­í• ì´ê³  Orchestrator-workersëŠ” ë¶„ê¸°í•´ì„œ ìˆ˜í–‰í•˜ë„ë¡ í•œ ë’¤, ê²°ê³¼ë¥¼ ì¢…í•©í•œë‹¤ëŠ” ì°¨ì´ê°€ ìžˆë‹¤ê³  í•˜ëŠ”ë° ì´ì™€ ê´€ë ¨í•´ì„œëŠ” ì•„ëž˜ì—ì„œ ë” ìžì„¸ížˆ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ë‹¤(êµ¬ê¸€ ë°±ì„œì—ëŠ” OrchestratorsëŠ” reasoningì„ ì§„í–‰í•  ìˆ˜ ìžˆë‹¤ëŠ” ì–¸ê¸‰ì´ ë˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„ ë³´ë‹¤ ê³ ë„ì˜ ë‚´ë¶€ ì¶”ë¡  ê³¼ì •ì„ ìˆ˜í–‰í•œë‹¤ê³  ë³¼ ìˆ˜ ìžˆë‹¤). Parallelizationì€ ì—¬ëŸ¬ê°œì˜ Model í˜¸ì¶œì„ ë³‘ë ¬ì ìœ¼ë¡œ ì§„í–‰í•œ ë’¤ ì¢…í•©í•´ì„œ data augmented outputì„ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤. ì•„ëž˜ì™€ ê°™ì€ êµ¬ì¡°ë¡œ ì •ë¦¬í•  ìˆ˜ ìžˆë‹¤. (3) Agents ì—¬ê¸°ì„œ Agentsë¼ëŠ” í‘œí˜„ ë•Œë¬¸ì— ê·¸ëŸ¼ ìœ„ì— ê²ƒë“¤ì€ ëª¨ë‘ Agentsê¸°ë°˜ì´ ì•„ë‹Œê°€..? ì‹¶ì„ ìˆ˜ ìžˆì§€ë§Œ, ì´ ê¸€ì—ì„œë„ ì–¸ê¸‰ë˜ë“¯ Building blocks, workflowsëŠ” ëª¨ë‘ agentic systemì— í•´ë‹¹í•œë‹¤. ì—¬ê¸°ì„œ ë§í•˜ëŠ” AgentsëŠ” ë³´ë‹¤ 'ìžìœ¨í˜•' êµ¬ì¡°ë¥¼ ì˜ë¯¸í•˜ëŠ”ë°, ìœ„ ê·¸ë¦¼ì—ì„œ Enviromentì— ì•žì„œ ìœ„ì˜ ëª¨ë“  Toolsì™€ flowê°€ í¬í•¨ë˜ê³  ì´ë¥¼ ì„ íƒí•˜ëŠ” ê³¼ì •ì´ ìœ ë™ì ì´ë¼ëŠ” ê²ƒì´ë‹¤. ì´ ì˜ë¯¸ëŠ” êµ¬ê¸€ì˜ Agents ë°±ì„œì— ìžˆëŠ” Figure14ë¥¼ í†µí•´ì„œ ë³´ë‹¤ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìžˆë‹¤. ì‚¬ìš©ìžì˜ inputì´ ë“¤ì–´ê°”ì„ ë•Œ, ì´ˆë¡ìƒ‰ ë¶€ë¶„ì˜ ReACT ê¸°ë°˜ì˜ Reasoningì„ í•˜ëŠ”ë°, ì²˜ìŒì— ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ì„ í•´ì•¼ í•˜ëŠ” ë¶€ë¶„ì„ ìºì¹˜í•˜ê³  vector searchë¼ëŠ” actionì„ ì§„í–‰í•œë‹¤. workflowì—ì„œ routerë¥¼ í†µí•´ì„œ ì¡°ê±´ë¶€ë¡œ Toolì„ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ì°¨ì´ê°€ ìžˆëŠ” ê²ƒì´ë‹¤. ì¦‰, '~í•  ë•ŒëŠ” Aë¥¼ ì‚¬ìš©í•˜ê³ , ~í•  ë•ŒëŠ” Bë¥¼ ì‚¬ìš©í•´ì¤˜'ì™€ ê°™ì€ ëª…ë ¹ì´ ì•„ë‹Œ 'AëŠ” ~í•  ë•Œ ì‚¬ìš©í•´', 'BëŠ” ~í•  ë•Œ ì‚¬ìš©í•´'ì™€ ê°™ì€ Toolì´ ìžˆë‹¤ë©´ ê° ìƒí™©ì— ë§žê²Œ A, B, í˜¹ì€ Aì™€Bë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ì‹ìœ¼ë¡œ ì§„í–‰ë˜ëŠ” ê²ƒì´ë©°, ì´ ë¶€ë¶„ì´ ì•žì— workflowì˜ Routerì™€ Operatorì˜ ì°¨ì´ë¼ê³  ë³¼ ìˆ˜ ìžˆë‹¤. ðŸ’¥ ì—¬ê¸°ì„œ ê¶ê¸ˆí•œ ì  ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ íŒë‹¨í•˜ëŠ”ê±´ Toolì— ê¸°ìž…í•œ ì„¤ëª…ê³¼ promptë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìž‘ë™í•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œê³  ìžˆëŠ”ë°, Routerë¥¼ í†µí•´ì„œ ì§„í–‰í•˜ëŠ” ê²ƒë³´ë‹¤ ìžìœ¨ì„±ì€ ë†’ì§€ë§Œ ì •í™•ë„ë„ ë†’ì„ê¹Œ? &gt;&gt; The autonomous nature of agents means higher costs, and the potential for compounding errors. We recommend extensive testing in sandboxed environments, along with the appropriate guardrails. ìžìœ¨ì  íŠ¹ì§•ì€ ë” ë†’ì€ ë¹„ìš©ê³¼ ë³µí•©ì ì¸ ì˜¤ë¥˜ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆë‹¤ëŠ” ì„¤ëª…ìœ¼ë¡œ ë³´ì•„, case by caseì¸ ë“¯... âœ… Summary êµ¬ê¸€ Agents ë°±ì„œì™€ Anthropicì˜ ê¸€ì„ ì¢…í•©í•´ì„œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. WorkflowëŠ” ì‚¬ì „ì— ì •ì˜ëœ ê·œì¹™ì ì¸ ê²½ë¡œë¥¼ ë”°ë¥´ëŠ” ë°˜ë©´, AgentsëŠ” ìŠ¤ìŠ¤ë¡œ ìž‘ì—…ì„ ì œì–´í•˜ì—¬ ë³µìž¡í•˜ê³  ì˜ˆì¸¡í•  ìˆ˜ ì—†ëŠ” ìž‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆìŒ AgentsëŠ” ì—¬ëŸ¬ê°€ì§€ ë„êµ¬(ì—¬ëŸ¬ ëª¨ë¸ í˜¹ì€ API í˜¹ì€ ì‚¬ìš©ìžê°€ ìƒì„±í•œ í•¨ìˆ˜ ë“±)ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì ‘ê·¼í•˜ê³  í™œìš©í•  ìˆ˜ ìžˆìœ¼ë©°, ì´ë¥¼ ìžìœ¨ì ìœ¼ë¡œ ê³„íší•˜ê³  ìˆ˜í–‰í•¨ Orchestration layerëŠ” Agentsì˜ ìžìœ¨ì ì¸ ìˆ˜í–‰ì„ íŒë‹¨í•˜ëŠ” í•µì‹¬(heart) íŒŒíŠ¸ì´ë©°, ReAct, CoTì™€ ê°™ì€ Reasoning íƒœí¬ë‹‰ì„ í™œìš©í•¨ Tools: Extensions(ì™¸ë¶€ API), Functions(ì‚¬ìš©ìžì˜ í•¨ìˆ˜), Data Stores(RDF, VectorDB, GraphDB ë“± ì ‘ê·¼í•  ìˆ˜ ìžˆëŠ” ì €ìž¥ì†Œ) Anthropicì€ Effective Agentsë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ì„¸ ê°€ì§€ ë°©ë²•ì„ ì œì‹œí•˜ê¸°ë„ í•œë‹¤. ë‹¨ìˆœí•œ ë””ìžì¸ìœ¼ë¡œ êµ¬ì„±í•  ê²ƒ Agent êµ¬ì„± ë‹¨ê³„ë¥¼ ëª…í™•í•˜ê²Œ ë³´ì—¬ì¤„ ê²ƒ(transparency ìœ ì§€ë¥¼ ìœ„í•´? for user?) ë°˜ë³µëœ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì‹ ì¤‘í•˜ê²Œ ë§Œë“¤ ê²ƒ ì°¸ê³ ìžë£Œ langchain(langgraph): https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/ huggingface: https://huggingface.co/blog/smolagents í…Œë””ë…¸íŠ¸-í—ˆì •ì¤€ë‹˜ì˜ ì—ì´ì „íŠ¸ ê´€ë ¨ ì˜ìƒ: https://www.youtube.com/watch?v=zb3v45ik9KI JeongYun Lee ê¶ê¸ˆí•œ ê±´ ë§Žì§€ë§Œ, ì²œì²œížˆ ì•Œì•„ê°€ëŠ” ì¤‘ìž…ë‹ˆë‹¤ íŒ”ë¡œìš° ì´ì „ í¬ìŠ¤íŠ¸ í•œê¸€ì´ í¬í•¨ëœ ì‚¬ì§„ì—ì„œ Multimodal modelìœ¼ë¡œ Object Detectionì„ ìž˜ í•˜ëŠ” ë°©ë²• ë‹¤ìŒ í¬ìŠ¤íŠ¸ Sky-T1-32B-Preview, 450$ë¡œ í•™ìŠµí•œ o1ê¸‰ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì•Œì•„ë³´ê¸° 1 ê°œì˜ ëŒ“ê¸€ ëŒ“ê¸€ ìž‘ì„± hamham 2025ë…„ 4ì›” 6ì¼ ì˜¤ agent ê°œë…ì´ í—·ê°ˆë ¸ëŠ”ë° ìž˜ ì •ë¦¬ëœê±° ê°™ì•„ìš©~ ë‹µê¸€ ë‹¬ê¸°
ðŸ“– Read URL: https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%... (5944 chars)
   â””â”€ [https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/]
      Preview: AI Agentì˜ ê°œë…ë¶€í„° Agentic RAG ì‘ìš©ê¹Œì§€ - ìœ ë¼í´ ë¸”ë¡œê·¸ Current Date: 20 December, 2025 AI Insight Mobile Insight Use Case Company AI Insight Mobile Insight Use Case Company AI Agentì˜ ê°œë…ë¶€í„° Agentic RAG ì‘ìš©ê¹Œì§€ ìœ ë¼í´ 2025ë…„ 5ì›” 16ì¼ 0 Comment 1 &nbsp; ê¸€ë¡œë²Œ IT ë¦¬ì„œì¹˜ ê¸°ì—… ê°€íŠ¸ë„ˆ(Gartner)ëŠ” 2025ë…„ ì£¼ëª©í•´ì•¼ í•  10ëŒ€ ì „ëžµ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ AIì˜ í•„ìˆ˜ì„±ê³¼ ìœ„í—˜ì„± , ì»´í“¨íŒ…ì˜ ìƒˆë¡œìš´ ì§€í‰ , ì‚¬ëžŒ-ê¸°ê³„ ì‹œë„ˆì§€ì˜ í™•ìž¥ ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ì´ ì¤‘ ì²« ë²ˆì§¸ ì£¼ì œì¸ AI í•„ìˆ˜ì„±ê³¼ ìœ„í—˜ì„±ì—ì„œ &#8216;ì—ì´ì „í‹± AI&#8217;ë¥¼ ì£¼ìš” ê¸°ìˆ ë¡œ ê±°ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤. &nbsp; &nbsp; ì—ì´ì „í‹± AIëŠ” ê¸°ì¡´ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ëŠ” ìƒˆë¡œìš´ í˜•íƒœì˜ AI ì‹œìŠ¤í…œì„ ì˜ë¯¸í•˜ëŠ”ë°ìš”. ëŒ€í‘œì ì¸ ì˜ˆì‹œ ì¤‘ í•˜ë‚˜ê°€ ìžìœ¨ì£¼í–‰ ìžë™ì°¨ìž…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ AI ì‹œìŠ¤í…œì´ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ”ë° ê·¸ì¹œë‹¤ë©´ ìžìœ¨ì£¼í–‰ ìžë™ì°¨ëŠ” í•œ ê±¸ìŒ ë” ë‚˜ì•„ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ í™˜ê²½ì„ ì¸ì‹í•˜ê³ , ë‹¤ì–‘í•œ ë³€ìˆ˜ë¥¼ ê³ ë ¤í•œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ë©°, ì˜ˆì¸¡í•˜ì§€ ëª»í•œ ìƒí™©ì— ì ì‘í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìžˆìŠµë‹ˆë‹¤. ì´ì²˜ëŸ¼ ëª…í™•í•œ ëª©í‘œë¥¼ ê°€ì§€ê³  í™˜ê²½ê³¼ ìƒí˜¸ìž‘ìš©í•˜ë©° ìžìœ¨ì ìœ¼ë¡œ í–‰ë™í•˜ëŠ” íŠ¹ì„±ì´ ë°”ë¡œ ì—ì´ì „í‹± AIì˜ í•µì‹¬ìž…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì—ì´ì „í‹± AIë¥¼ í˜„ì‹¤ì—ì„œ êµ¬í˜„í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê²ƒì´ ë°”ë¡œ &#8216;AI ì—ì´ì „íŠ¸&#8217;ìž…ë‹ˆë‹¤. ì‰½ê²Œ ë¹„ìœ í•˜ìžë©´, ì—ì´ì „í‹± AIê°€ ìžìœ¨ì£¼í–‰ì´ë¼ëŠ” &#8216;ê°œë…&#8217;ì´ë¼ë©´, AI ì—ì´ì „íŠ¸ëŠ” ì´ë¥¼ ì‹¤ì œë¡œ êµ¬í˜„í•œ &#8216;ìžìœ¨ì£¼í–‰ ì†Œí”„íŠ¸ì›¨ì–´&#8217;ë¼ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤. AI ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ìžì˜ ìš”ì²­ì„ ì´í•´í•˜ê³ , ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì—¬, í•„ìš”í•œ í–‰ë™ì„ ì·¨í•˜ëŠ” ì‹¤ì œ í”„ë¡œê·¸ëž¨ì¸ ì…ˆì´ì£ . ì˜¤ëŠ˜ ê¸€ì—ì„œëŠ” ì´ëŸ¬í•œ AI ì‹œìŠ¤í…œì˜ ê¸°ë°˜ì´ ë˜ëŠ” í•µì‹¬ ê¸°ìˆ ì¸ &#8216;AI ì—ì´ì „íŠ¸&#8217;ì— ëŒ€í•´ ê°œë…ë¶€í„° ì‘ìš© ì‚¬ë¡€ê¹Œì§€ ì‹¬ì¸µì ìœ¼ë¡œ ì‚´íŽ´ë³´ê³ ìž í•©ë‹ˆë‹¤. &nbsp; 1. AI Agent ëž€? AI Agentê°€ ë¬´ì—‡ì¼ê¹Œìš”? ê°„ë‹¨ížˆ ë§í•´, AI ì—ì´ì „íŠ¸ëŠ” ì£¼ì–´ì§„ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ í™˜ê²½ì„ ì¸ì‹í•˜ê³  ìžìœ¨ì ìœ¼ë¡œ í–‰ë™í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì‚¬ìš©ìžì˜ ìš”êµ¬ì‚¬í•­ì„ ì´í•´í•˜ê³  ì´ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì¼ë ¨ì˜ ìž‘ì—…ë“¤ì„ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ì§€ëŠ¥í˜• í”„ë¡œê·¸ëž¨ì´ë¼ê³  í•  ìˆ˜ ìžˆì£ . ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œê°€ ê·œì¹™ ê¸°ë°˜ ë¡œì§ì´ë‚˜ ë‹¨ìˆœ í†µê³„ ëª¨ë¸ì´ì—ˆë‹¤ë©´, AI ì—ì´ì „íŠ¸ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ , íŠ¹ížˆ ìžì—°ì–´ ì²˜ë¦¬ì™€ ê¸°ê³„ í•™ìŠµ ê¸°ìˆ ì„ ê·¼ê°„ìœ¼ë¡œ ë™ìž‘í•©ë‹ˆë‹¤. ì‚¬ìš©ìžì™€ì˜ ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ íƒœìŠ¤í¬ë¥¼ íŒŒì•… í•˜ê³ , ë°©ëŒ€í•œ ë°ì´í„°ì™€ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•´ ìµœì ì˜ ì†”ë£¨ì…˜ì„ ë„ì¶œ í•˜ëŠ” ê²ƒì´ AI ì—ì´ì „íŠ¸ì˜ í•µì‹¬ ì—­ëŸ‰ìž…ë‹ˆë‹¤. &nbsp; 2. AI Agent ì˜ í•µì‹¬ 3ìš”ì†Œ AI AgentëŠ” í¬ê²Œ ì„¸ê°€ì§€ í•µì‹¬ ìš”ì†Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. &nbsp; &nbsp; ì²«ì§¸ëŠ” ì—ì´ì „íŠ¸ì˜ &#8216;ë‘ë‡Œ&#8217; ì—­í• ì„ í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ (Language Model)ìž…ë‹ˆë‹¤. ìµœì‹  ìžì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ í™œìš©í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ì‚¬ìš©ìžì˜ ìžì—°ìŠ¤ëŸ¬ìš´ ë§ì´ë‚˜ í…ìŠ¤íŠ¸ í˜•íƒœì˜ ìš”ì²­ì„ ì´í•´í•˜ê³  ì´ì— ì ì ˆížˆ ì‘ë‹µ í•  ìˆ˜ ìžˆëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìžˆìŠµë‹ˆë‹¤. ë‘˜ì§¸ëŠ” íƒœìŠ¤í¬ ìˆ˜í–‰ì„ ìœ„í•œ ì „ëžµì„ ìˆ˜ë¦½í•˜ê³  ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” &#8216; ì¡°ì • ê³„ì¸µ( Orchestration Layer)&#8217;ìž…ë‹ˆë‹¤. ì‚¬ìš©ìžì˜ ìš”êµ¬ì‚¬í•­ê³¼ ë§¥ë½ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í–‰ë™ ê³„íšì„ ì„¸ìš°ê³ , í•„ìš”í•œ í•˜ìœ„ íƒœìŠ¤í¬ë“¤ì„ ì¡°ìœ¨ í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì—ì´ì „íŠ¸ê°€ ì‹¤ì œ í–‰ë™ì„ ì˜®ê¸°ëŠ” ë° í•„ìš”í•œ &#8216;íŒ”ë‹¤ë¦¬&#8217; ì—­í• ì„ í•˜ëŠ” ê²ƒì´ ë°”ë¡œ ì‹¤í–‰ ë„êµ¬ (Action Tool)ë“¤ìž…ë‹ˆë‹¤. API, ë°ì´í„°ë² ì´ìŠ¤ ë“± ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì¡´ìž¬í•˜ëŠ” ì´ ë„êµ¬ë“¤ì€ ì—ì´ì „íŠ¸ê°€ ì˜ì‚¬ ê²°ì •í•œ ë°”ë¥¼ í˜„ì‹¤ì— êµ¬í˜„í•˜ëŠ” í†µë¡œ ê°€ ë©ë‹ˆë‹¤. ì´ì²˜ëŸ¼ LLM, ì˜ì‚¬ê²°ì • ì—”ì§„, ì‹¤í–‰ ë„êµ¬ ëŠ” ê°ê° ì¸ì§€, íŒë‹¨, í–‰ë™ ì´ë¼ëŠ” ì—ì´ì „íŠ¸ ìž‘ë™ì˜ 3 ìš”ì†Œë¥¼ êµ¬í˜„í•˜ëŠ” ë…ë¦½ì ì´ë©´ì„œë„ ìƒí˜¸ë³´ì™„ì ì¸ ëª¨ë“ˆì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë“¤ì´ ê¸´ë°€í•˜ê³  ìœ ê¸°ì ìœ¼ë¡œ í˜‘ì—…í•  ë•Œ ë¹„ë¡œì†Œ ìžì—°ìŠ¤ëŸ½ê³  íš¨ê³¼ì ì¸ ì—ì´ì „íŠ¸ì˜ íƒœìŠ¤í¬ ìˆ˜í–‰ì´ ê°€ëŠ¥í•´ì§€ëŠ” ê²ƒì´ì£ . íŠ¹ížˆ LLMì€ ì—ì´ì „íŠ¸ì˜ ì‚¬ê³ ì™€ ë¬¸ì œ í•´ê²° ê³¼ì • ì „ë°˜ì„ ê´€í†µí•˜ëŠ” í•µì‹¬ ë™ë ¥ì´ë¼ í•  ìˆ˜ ìžˆëŠ”ë°ìš”. ìµœê·¼ DeepSeekì²˜ëŸ¼ ê°€ì„±ë¹„ ë†’ì€ ëª¨ë¸ë“¤ì´ ê°œë°œë˜ê³  ìžˆëŠ” ìƒí™©ì—ì„œ AI ì—ì´ì „íŠ¸ê°€ ë”ìš± ê°€ë³ê³  íš¨ìœ¨ì ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ìš°ë¦¬ ì‚¶ì˜ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë  ìˆ˜ ìžˆëŠ” ì‹œëŒ€ê°€ ê°€ê¹Œì›Œì§„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ê³  ìžˆìŠµë‹ˆë‹¤. &nbsp; 3. ì—ì´ì „íŠ¸ì˜ ì‚¬ê³ ë°©ì‹ ì§€ê¸ˆê¹Œì§€ ì‚´íŽ´ë³¸ AI ì—ì´ì „íŠ¸ì˜ êµ¬ì„± ìš”ì†Œë“¤ì´ &#8216;ë¬´ì—‡&#8217;ì— í•´ë‹¹í•œë‹¤ë©´, ì´ì œëŠ” ì´ëŸ¬í•œ ìš”ì†Œë“¤ì´ &#8216;ì–´ë–»ê²Œ&#8217; í•¨ê»˜ ìž‘ë™í•˜ëŠ”ì§€ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. AI ì—ì´ì „íŠ¸ê°€ ë¬¸ì œë¥¼ ì¸ì‹í•˜ê³  í•´ê²°ì±…ì„ ëª¨ìƒ‰í•˜ëŠ” ê³¼ì •ì„ êµ¬í˜„í•˜ëŠ” í•µì‹¬ ê°œë…ì´ ë°”ë¡œ &#8216;ì¸ì§€ ì•„í‚¤í…ì²˜(Cognitive Architecture)&#8217;ìž…ë‹ˆë‹¤. ì´ëŠ” ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ìž…ë ¥ì„ ì´í•´í•˜ê³  ìµœì„ ì˜ í–‰ë™ì„ ê²°ì •í•˜ëŠ” ì¼ë ¨ì˜ ë…¼ë¦¬ì  ì‚¬ê³  ê³¼ì •ì„ ì„¤ê³„í•˜ëŠ” ë¼ˆëŒ€ë¼ê³  í•  ìˆ˜ ìžˆëŠ”ë°ìš”. AI Agent ë¶„ì•¼ì—ì„œ íŠ¹ížˆ ëŒ€í‘œì ì¸ ì¸ì§€ ì•„í‚¤í…ì²˜ëŠ” &#8216;Chain-of-Thought&#8217;, &#8216;Tree-of-Thoughts&#8217; ê·¸ë¦¬ê³  &#8216;ReAct&#8217;ìž…ë‹ˆë‹¤. &nbsp; &nbsp; ë¨¼ì € &#8216; Chain-of-Thought &#8216;ëŠ” ì—ì´ì „íŠ¸ê°€ ë³µìž¡í•œ ì§ˆì˜ì— ëŒ€í•´ ë‹¨ê³„ì  ì¶”ë¡ ì„ í†µí•´ ìµœì¢… ë‹µë³€ì„ ë„ì¶œ í•´ ë‚´ëŠ” ì‚¬ê³  ì²´ê³„ìž…ë‹ˆë‹¤. &#8220;Aë¼ëŠ” ì‚¬ì‹¤ê³¼ Bë¼ëŠ” ì‚¬ì‹¤ì´ ìžˆìœ¼ë¯€ë¡œ, Cë¼ëŠ” ê²°ë¡ ì„ ë‚´ë¦´ ìˆ˜ ìžˆë‹¤&#8221;ì™€ ê°™ì´ ì¼ë ¨ì˜ ë…¼ë¦¬ì  íë¦„ì„ ë”°ë¼ ë¬¸ì œë¥¼ í•´ê²°í•´ ë‚˜ê°€ëŠ” ê²ƒì´ì£ . CoTë¥¼ í™•ìž¥í•œ ê°œë…ì¸ &#8216; Tree-of-Thoughts &#8216;ëŠ” í•˜ë‚˜ì˜ ë¬¸ì œì— ëŒ€í•´ ë™ì‹œë‹¤ë°œì ìœ¼ë¡œ ì—¬ëŸ¬ ê°ˆëž˜ì˜ ì‚¬ê³  íë¦„ì„ íƒìƒ‰ í•˜ëŠ” ì¸ì§€ êµ¬ì¡°ìž…ë‹ˆë‹¤. ë§ˆì¹˜ ë‘ë‡Œ ì†ì—ì„œ ìˆ˜ë§Žì€ ë‰´ëŸ°ì´ ë³‘ë ¬ì ìœ¼ë¡œ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê²ƒì²˜ëŸ¼, ì—ì´ì „íŠ¸ê°€ ì£¼ì–´ì§„ ë¬¸ì œì— ëŒ€í•´ ë‹¤ì–‘í•œ ê°€ì„¤ê³¼ í•´ì„ì„ ë™ì‹œì— ê³ ë ¤í•˜ë©° ìµœì ì˜ ì†”ë£¨ì…˜ì„ ëª¨ìƒ‰ í•˜ëŠ” ë°©ì‹ì´ë¼ê³  í•  ìˆ˜ ìžˆê² ì£ . ë§ˆì§€ë§‰ìœ¼ë¡œ &#8216; ReAct &#8216;ëŠ” &#8216; Reason+Act &#8216;ì˜ ì¤„ìž„ ë§ë¡œ, ì—ì´ì „íŠ¸ê°€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¦¬ì  ì¶”ë¡ ì„ ê±°ì³ í–‰ë™ì„ ê²°ì • í•˜ëŠ” êµ¬ì¡°ë¥¼ ê°–ê³  ìžˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìžì˜ ìš”ì²­ì´ë‚˜ ë¬¸ì œ ìƒí™©ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ ë‹¨ê³„ì  í•˜ìœ„ ê³¼ì œë¡œ ìª¼ê°œì–´ ê° ë‹¨ê³„ë¥¼ ì‹¤í–‰í•´ ë‚˜ê°€ëŠ” ë°©ì‹ìœ¼ë¡œ ì „ì²´ íƒœìŠ¤í¬ë¥¼ ì™„ìˆ˜í•˜ëŠ” ê±°ì£ . ì˜ˆë¥¼ ë“¤ì–´, ì´ì»¤ë¨¸ìŠ¤ ê³ ê° ì§€ì› ì—ì´ì „íŠ¸ê°€ &#8220;ì§€ë‚œì£¼ì— ì£¼ë¬¸í•œ ìƒí’ˆì´ ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”&#8221;ë¼ëŠ” ê³ ê° ë¬¸ì˜ë¥¼ ë°›ì•˜ë‹¤ë©´ 1) ì£¼ë¬¸ ë²ˆí˜¸ ì°¾ê¸°, 2) ë°°ì†¡ ìƒíƒœ í™•ì¸, 3) ì§€ì—° ì›ì¸ íŒŒì•…, 4) í•´ê²°ì±… ì œì•ˆì´ë¼ëŠ” ë‹¨ê³„ì  ìž‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë©° ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•´ ë‚˜ê°‘ë‹ˆë‹¤. ì´ë ‡ë“¯ Chain-of-Thought, Tree-of-Thoughts, ReActëŠ” ê°ê¸° ë‹¤ë¥¸ ì² í•™ê³¼ ì ‘ê·¼ë²•ì„ ì·¨í•˜ê³  ìžˆì§€ë§Œ, ê³µí†µì ìœ¼ë¡œ ì—ì´ì „íŠ¸ì˜ ì‚¬ê³  ì²´ê³„ë¥¼ ì„¤ê³„í•˜ëŠ” ì¸ì§€ ì•„í‚¤í…ì²˜ë¡œì„œ ê¸°ëŠ¥í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ìµœê·¼ AI ê¸°ìˆ  ë°œì „ì˜ íë¦„ì€ ì´ëŸ¬í•œ ë‹¤ì–‘í•œ ì‚¬ê³  ëª¨ë¸ë“¤ì„ ë‹¨ì¼ ì—ì´ì „íŠ¸ ë‚´ì—ì„œ ê²°í•©í•˜ê±°ë‚˜, ì„œë¡œ ë‹¤ë¥¸ ì‚¬ê³  ë°©ì‹ì„ ê°€ì§„ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ë ¥í•˜ëŠ” ì‹œìŠ¤í…œì„ ê°œë°œí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í™”í•˜ê³  ìžˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ê¸°ì¡´ë³´ë‹¤ ë” ë³µìž¡í•˜ê³  ë‹¤ì–‘í•œ ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìžˆëŠ” AI ì—ì´ì „íŠ¸ê°€ ë“±ìž¥í•˜ê³  ìžˆìŠµë‹ˆë‹¤. &nbsp; 4. Agentic RAG : AI ì—ì´ì „íŠ¸ì˜ ì‘ìš© ì§€ê¸ˆê¹Œì§€ AI ì—ì´ì „íŠ¸ì˜ ê°œë…ê³¼ í•µì‹¬ êµ¬ì„± ìš”ì†Œ, ê·¸ë¦¬ê³  ì‚¬ê³ ë°©ì‹ì— ëŒ€í•´ ì‚´íŽ´ë³´ì•˜ëŠ”ë°ìš”. ì´ì œ ì—ì´ì „íŠ¸ ê¸°ìˆ ì´ ì‹¤ì œ ì‹œìŠ¤í…œì— ì–´ë–»ê²Œ ì‘ìš©ë˜ê³  ìžˆëŠ”ì§€ RAG(Retrieval-Augmented Generation) ëª¨ë¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ìµœê·¼ ìžì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ í° ì£¼ëª©ì„ ë°›ê³  ìžˆëŠ” RAG ëª¨ë¸ì€ ë°©ëŒ€í•œ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ˆì˜ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê°•ë ¥í•œ ìžì—°ì–´ ìƒì„± ê¸°ìˆ ì¸ë°ìš”, ì—¬ê¸°ì— ì—ì´ì „íŠ¸ì˜ ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ì´ ë”í•´ì§€ë©´ì„œ Agentic RAGë¼ëŠ” ìƒˆë¡œìš´ ê°œë…ì´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. &nbsp; &nbsp; Agentic RAG ëŠ” LLMì˜ ì–¸ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ ê³¼ ì—ì´ì „íŠ¸ì˜ ìžìœ¨ì  íƒœìŠ¤í¬ ìˆ˜í–‰ ëŠ¥ë ¥ ì´ ê²°í•©ëœ í˜•íƒœë¼ê³  ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¼ë°˜ RAGê°€ ë‹¨ìˆœížˆ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©í•œë‹¤ë©´ Agentic RAGëŠ” ì •ë³´ì˜ í•„ìš”ì„±ì„ ìŠ¤ìŠ¤ë¡œ íŒë‹¨ í•˜ê³ , ì ì ˆí•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ êµ¬ì„± í•˜ë©°, ê²€ìƒ‰ëœ ì •ë³´ë¥¼ í‰ê°€í•˜ê³  í†µí•© í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ëŸ° Agentic RAGëŠ” íŠ¹ížˆ êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ë°©ëŒ€í•œ ë°ì´í„° ì†ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì œë¥¼ í•´ê²° í•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë†’ì€ ì •í™•ë„ì™€ ì‹ ë¢°ì„±ì´ ìš”êµ¬ë˜ëŠ” ì˜ë£Œë¶„ì•¼ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ìƒê°í•´ ë³¼ê¹Œìš”? ì‚¬ìš©ìžê°€ &#8220;ì½”ë¡œë‚˜19 ë°±ì‹ ê³¼ ë…ê° ë°±ì‹ ì„ ë™ì‹œì— ë§žì•„ë„ ë ê¹Œìš”?&#8221;ë¼ëŠ” ì§ˆë¬¸ì„ í–ˆì„ ë•Œ, ì¼ë°˜ì ì¸ RAG ì‹œìŠ¤í…œì€ ë‹¨ìˆœížˆ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•˜ëŠ” ë° ê·¸ì¹˜ì§€ë§Œ, Agentic RAGëŠ” í›¨ì”¬ ë” ë³µìž¡í•œ ê³¼ì •ì„ ê±°ì¹  ê²ƒìž…ë‹ˆë‹¤. ë¨¼ì € ì—¬ëŸ¬ ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ì™€ ìµœì‹  ë³´ê±´ ê°€ì´ë“œë¼ì¸ì„ ê²€ìƒ‰í•˜ê³ , ê²€ìƒ‰ëœ ì •ë³´ì˜ ë°œí–‰ ë‚ ì§œë¥¼ í™•ì¸í•˜ì—¬ ìµœì‹ ì„±ì„ í‰ê°€í•˜ê³ , ë§Œì•½ ì„œë¡œ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ìƒì¶©ë˜ëŠ” ì •ë³´ê°€ ë°œê²¬ë˜ë©´ ì—ì´ì „íŠ¸ëŠ” ì´ëŸ¬í•œ ë¶ˆì¼ì¹˜ë¥¼ ë¶„ì„í•˜ê³  í•„ìš”ì— ë”°ë¼ íŠ¹ì • ì¸êµ¬ ì§‘ë‹¨(ì˜ˆ: ë©´ì—­ ì €í•˜ìž)ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œëŠ” ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìžì—ê²Œ ì œê³µí•˜ë˜, ì´ê²ƒì´ ì „ë¬¸ì ì¸ ì˜í•™ì  ì¡°ì–¸ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŒì„ ëª…í™•ížˆ í•¨ìœ¼ë¡œì¨ ì •ë³´ì˜ ì±…ìž„ ìžˆëŠ” ì‚¬ìš©ì„ ìž¥ë ¤í•  ê²ƒì´ê³  ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ Agentic RAGëŠ” ë‹¨ìˆœí•œ ì •ë³´ ê²€ìƒ‰ì„ ë„˜ì–´ ì§€ëŠ¥ì ì¸ ì˜ë£Œ ì •ë³´ ë³´ì¡° ë„êµ¬ë¡œì„œ ì—­í• ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ, ë²•ë¥ ì´ë‚˜ íŠ¹í—ˆì™€ ê°™ì´ ë°©ëŒ€í•œ ë„ë©”ì¸ ì§€ì‹ì´ ìš”êµ¬ë˜ëŠ” ë¶„ì•¼ì—ì„œë„ ì „ë¬¸ê°€ë¥¼ ë³´ì¡°í•˜ëŠ” ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìžˆì„ ê²ƒìž…ë‹ˆë‹¤. ìˆ˜ë§Žì€ íŒë¡€ì™€ ë²•ì¡°ë¬¸ ì†ì—ì„œ ì‚¬ì•ˆì— ì ìš© ê°€ëŠ¥í•œ ì¡°í•­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ê·¼ê±°ë¡œ ë²•ë¥  ìžë¬¸ì„ ì œê³µí•˜ëŠ” ì‹ì´ì£ . ì´ì²˜ëŸ¼ Agentic RAG ê¸°ìˆ ì€ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ ì •ë³´ ê²€ìƒ‰ê³¼ ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œìœ¼ë¡œ í° ìž ìž¬ë ¥ì„ ë³´ì´ê³  ìžˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¸ë Œë“œì— ë°œë§žì¶° ë§Žì€ ê¸°ì—…ë“¤ì´ ìžì²´ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ê²€í† í•˜ê³  ìžˆìœ¼ë©°, ì €í¬ ìœ ë¼í´ë„ ì´ ë¶„ì•¼ì— ì ê·¹ì ìœ¼ë¡œ íˆ¬ìží•˜ê³  ìžˆìŠµë‹ˆë‹¤. &nbsp; 5. ê¸€ì„ ë§ˆë¬´ë¦¬í•˜ë©° AI ì—ì´ì „íŠ¸ ê¸°ìˆ ì€ ê³„ì†í•´ì„œ ë°œì „ ì¤‘ìž…ë‹ˆë‹¤. ë¬¼ë¡  ì•„ì§ AI ì—ì´ì „íŠ¸ê°€ ì‚¬ê³  ëŠ¥ë ¥ì„ êµ¬í˜„í•˜ê¸°ì—ëŠ” ì œì•½ì´ ìžˆëŠ” ê²ƒë„ ì‚¬ì‹¤ìž…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ê°€ ê¸°ì¡´ì— í•™ìŠµí•˜ì§€ ì•Šì€ ì˜ì—­ì˜ ë¬¸ì œì— ë¶€ë”ªížˆê±°ë‚˜, ìœ¤ë¦¬ì  ë”œë ˆë§ˆ ìƒí™©ì— ì§ë©´í–ˆì„ ë•Œ í•©ë¦¬ì ì¸ íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ë° í•œê³„ê°€ ìžˆì£ . ê·¸ëŸ¬ë‚˜ ë¶„ëª…í•œ ê²ƒì€ ì´ ê¸°ìˆ ì´ ë‹¨ìˆœí•œ ì—…ë¬´ ìžë™í™”ë¥¼ ë„˜ì–´ ì¸ê°„ì˜ ì˜ì‚¬ê²°ì •ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ì¦ê°•í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•˜ê³  ìžˆë‹¤ëŠ” ì ìž…ë‹ˆë‹¤. ê°€íŠ¸ë„ˆì˜ ì˜ˆì¸¡ì²˜ëŸ¼ 2028ë…„ê¹Œì§€ ì¼ìƒì ì¸ ì—…ë¬´ì˜ ì•½ 15%ê°€ ì—ì´ì „í‹± AIì— ì˜í•´ ìžìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬ë  ìˆ˜ ìžˆë‹¤ë©´ ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ë” ê°€ì¹˜ ìžˆëŠ” ì—…ë¬´ì— ì§‘ì¤‘í•˜ê³ , AIëŠ” ë°˜ë³µì ì´ê³  ì‹œê°„ ì†Œëª¨ì ì¸ ìž‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ë¯¸ëž˜ë¥¼ ê·¸ë ¤ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. &nbsp; &nbsp; &nbsp; ì¶œì²˜) êµ¬ê¸€ â€“ Newwhitepaper_Agents2(September 2024) ë‰´ìŠ¤ &#8211; https://www.sciencetimes.co.kr/nscvrg/view/menu/249?searchCategory=221&amp;nscvrgSn=259776 &nbsp; &nbsp; &nbsp; Share Related Articles ìœ ë¼í´, ì¸í…”ë¦¬ì•ˆí…Œí¬ ìƒì„±í˜• AI í”Œëž«í¼ êµ¬ì¶• ìˆ˜ì£¼ ìœ ë¼í´ 2025ë…„ 8ì›” 20ì¼ ìœ ë¼í´, ê±´ì„¤ì‚¬ AI ì „í™˜ íŒŒíŠ¸ë„ˆë¡œ &#8216;ë¶€ìƒ&#8217;â€¦ê¸€ë¡œë²Œ ìˆ˜ì¶œê¹Œì§€ ê²¨ëƒ¥ ìœ ë¼í´ 2025ë…„ 8ì›” 18ì¼ ìœ ë¼í´, ê¸°ì—…ìš© AI ì½”ë”© ì†”ë£¨ì…˜ ì¶œì‹œ ìœ ë¼í´ 2025ë…„ 8ì›” 12ì¼ ìœ ë¼í´, GSê±´ì„¤ &#8216;AI ê¸°ë°˜ ëª¨ë°”ì¼ ì›Œí¬í”Œë ˆì´ìŠ¤&#8217; ì‚¬ì—… ìˆ˜ì£¼ ìœ ë¼í´ 2025ë…„ 8ì›” 7ì¼ &nbsp; ëŒ“ê¸€ ë¡œë“œì¤‘... &nbsp; ëŒ“ê¸€ ë‹¬ê¸°... ì´ë©”ì¼ ì´ë¦„ ì›¹ì‚¬ì´íŠ¸
ðŸ“– Read URL: https://osckorea.tistory.com/332... (4525 chars)
   â””â”€ [https://osckorea.tistory.com/332]
      Preview: OSC Korea ë¸”ë¡œê·¸ | í´ë¼ìš°ë“œ, ì˜¤í”ˆì†ŒìŠ¤, AI ì¸ì‚¬ì´íŠ¸ ë³¸ë¬¸ ë°”ë¡œê°€ê¸° OSC Korea Blog ë©”ë‰´ ë¶„ë¥˜ ì „ì²´ë³´ê¸° (332) NEWS (67) POST (219) Tech (111) Insight (70) Video (28) Series Article (10) Event (26) Workshop (4) Seminar (17) OSCer (20) Talk (13) Recruit (6) Facebook POWERED BY TISTORY ë¸”ë¡œê·¸ ë‚´ ê²€ìƒ‰ ê²€ìƒ‰ POST/Tech ì—”í„°í”„ë¼ì´ì¦ˆ AI í˜ì‹ , RAGì™€ Agentic RAG í•œëˆˆì— ë³´ê¸° ìž¥ìˆ˜ì˜2 2025. 8. 12. 06:00 &nbsp; &nbsp; ì˜¤ëŠ˜ì€ ìš”ì¦˜ AI ì—…ê³„ì—ì„œ ê°€ìž¥ í•«í•˜ê²Œ ë– ì˜¤ë¥´ëŠ” ë‘ ê°€ì§€ ê¸°ìˆ , "RAG(Retrieval-Augmented Generation)"ì™€ ê·¸ ì§„í™”íŒì¸ Agentic RAGì— ëŒ€í•´ ê¹Šì´ ìžˆê²Œ í’€ì–´ë“œë¦½ë‹ˆë‹¤. &nbsp; LLMì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ë‹¤: RAGê°€ ë“±ìž¥í•œ ì´ìœ  ì—¬ëŸ¬ë¶„ë„ ChatGPTë‚˜ Claude ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í•œë²ˆì¯¤ ì‚¬ìš©í•´ë³´ì…¨ì„ ê²ë‹ˆë‹¤. êµ‰ìž¥ížˆ ë˜‘ë˜‘í•˜ì§€ë§Œ, ë•Œë¡œëŠ” ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ë‹µì„ ë‚´ë†“ê±°ë‚˜ ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜í•˜ì§€ ëª»í•´ ë‹¹í™©í•œ ì ì´ ìžˆìœ¼ì‹œì£ ? ì´ê²Œ ë°”ë¡œ ìš°ë¦¬ê°€ í”ížˆ ë§í•˜ëŠ” &lsquo;í™˜ê°&rsquo; í˜„ìƒìž…ë‹ˆë‹¤. ì—¬ê¸°ì„œ RAGê°€ ê²Œìž„ì²´ì¸ì €ë¡œ ë“±ìž¥í•©ë‹ˆë‹¤. &nbsp; RAGëŠ” ë‹¨ìˆœížˆ LLMì—ê²Œ ë‹µì„ ì‹œí‚¤ëŠ” ê²Œ ì•„ë‹ˆë¼, ë¨¼ì € í•„ìš”í•œ ì •ë³´ë¥¼ 'ê²€ìƒ‰'í•´ì„œ ê·¸ ê²°ê³¼ë¥¼ LLMì—ê²Œ ê±´ë„¨ ë’¤ ë‹µì„ ìƒì„±í•˜ê²Œ í•˜ëŠ” êµ¬ì¡°ìž…ë‹ˆë‹¤. ì‹œí—˜ ë³¼ ë•Œ ì°¸ê³ ìžë£Œ í—ˆìš©ë˜ëŠ” ì˜¤í”ˆë¶ ì‹œí—˜ê³¼ ë¹„ìŠ·í•˜ë‹¤ê³  ìƒê°í•˜ì‹œë©´ ì´í•´ê°€ ì‰¬ìš¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŠ¹ížˆ ë²•ë¥ , ì˜ë£Œ, ê¸ˆìœµ ê°™ì´ ì •í™•ì„±ì´ ìƒëª…ì¸ ì‚°ì—…ì—ì„œ AI í™œìš©ë„ë¥¼ ë¹„ì•½ì ìœ¼ë¡œ ëŒì–´ì˜¬ë¦¬ëŠ” ë¹„ê²°ìž…ë‹ˆë‹¤. &nbsp; RAG ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” 10ê°€ì§€ í•µì‹¬ í…Œí¬ë‹‰ RAGë¥¼ ì œëŒ€ë¡œ êµ¬í˜„í•˜ë ¤ë©´ ì—¬ëŸ¬ ê°€ì§€ ê¸°ìˆ ì„ ì¡°í•©í•´ì•¼ í•©ë‹ˆë‹¤. ì‹¤ì „ì—ì„œ íŠ¹ížˆ íš¨ê³¼ì ì¸ 10ê°€ì§€ í•µì‹¬ ê¸°ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ : í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ê³¼ ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ì„ ëª¨ë‘ í™œìš©í•´ì„œ, ëª…í™•í•œ ìš©ì–´ë‚˜ ì˜ë¯¸ìƒ ìœ ì‚¬í•œ ì •ë³´ê¹Œì§€ í­ë„“ê²Œ ì°¾ì•„ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. HNSW ì¸ë±ìŠ¤ íŠœë‹ : ë²¡í„° ê²€ìƒ‰ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, ë¯¸ë¬˜í•œ ì°¨ì´ê°€ ìžˆëŠ” ì§ˆë¬¸ë„ ì •í™•ížˆ êµ¬ë¶„í•´ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸í•œ ë¬¸ì„œ ë¶„í• ê³¼ íŒŒì‹± : ê¸´ ë¬¸ì„œë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ìž˜ê²Œ ìª¼ê°œì–´, ë³µìž¡í•œ ë¬¸ì„œì—ì„œë„ ê¼­ í•„ìš”í•œ ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ ë½‘ì•„ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë„ë©”ì¸ íŠ¹í™” ìž„ë² ë”© ë¯¸ì„¸ ì¡°ì • : ë²”ìš© ìž„ë² ë”©ì´ ë†“ì¹  ìˆ˜ ìžˆëŠ” ì„¸ë°€í•œ ì˜ë¯¸ ì°¨ì´ë¥¼ ë„ë©”ì¸ì— ë§žê²Œ ë³´ì™„í•©ë‹ˆë‹¤. LLM ë¯¸ì„¸ ì¡°ì • : ì—…ê³„ë³„ íŠ¹ìˆ˜í•œ ê·œì •ì´ë‚˜ ì–´íˆ¬ ë“±ì— ë§žì¶° LLMì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•´, ë”ìš± ê³µì‹ ë ¥ ìžˆëŠ” ë‹µë³€ì„ ì–»ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‹œë§¨í‹± ìºì‹± : ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸ì˜ ë‹µë³€ì„ ë¯¸ë¦¬ ìºì‹±í•˜ì—¬, ìœ ì‚¬ì§ˆë¬¸ì— ì¦‰ì‹œ ë‹µë³€í•  ìˆ˜ ìžˆê²Œ í•©ë‹ˆë‹¤. ìž¥ê¸° ë©”ëª¨ë¦¬ : ëŒ€í™” ë¬¸ë§¥ì„ ìž¥ê¸°ì ìœ¼ë¡œ ê¸°ì–µí•´, ë” ê°œì¸í™”ë˜ê³  ìžì—°ìŠ¤ëŸ¬ìš´ ìƒí˜¸ìž‘ìš©ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤. ì¿¼ë¦¬ ë³€í™˜ : ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ì§ˆë¬¸ì„ ëª…í™•í•œ ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ìž…ë‹ˆë‹¤. LLM as a Judge : LLMì´ ìŠ¤ìŠ¤ë¡œ ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•´, ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ë‹µë³€ì„ ìš°ì„ ì ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤. ê²°ê³¼ ìž¬ìˆœìœ„í™” : ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•œ ë²ˆ ë” ì •ë ¬í•´, ê°€ìž¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´ê°€ ëŠ˜ ìµœìš°ì„ ìœ¼ë¡œ ì œì‹œë˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ ë‹¤ì–‘í•œ ê¸°ë²•ë“¤ì€ ë„ìž… ì´ˆë°˜ë¶€í„° ì „ë¶€ ì ìš©í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ êµ¬ì¡°ì—ì„œ ì‹œìž‘í•´ ì‹¤ì œ ë°ì´í„°ë¥¼ ê´€ì°°í•˜ë©´ì„œ ì ì§„ì ìœ¼ë¡œ ê³ ë„í™”í•˜ëŠ” ê²ƒì´ ë¦¬ìŠ¤í¬ì™€ ë¹„ìš©ì„ ëª¨ë‘ ì¤„ì—¬ì£¼ëŠ” ì‹¤ì „ ì „ëžµìž…ë‹ˆë‹¤. &nbsp; ë°”ë‹ë¼ RAGì˜ í•œê³„ì™€ ì•„ì‰¬ì›€ ë¬¼ë¡  ê¸°ë³¸í˜• RAG(=ë°”ë‹ë¼ RAG)ë„ ë¬´ìž‘ì • ì™„ë²½í•œ ê¸°ìˆ ì€ ì•„ë‹™ë‹ˆë‹¤. ë‹¨ìˆœ ì§ˆì˜ì‘ë‹µì—ëŠ” ê°•í•˜ì§€ë§Œ, ë³µìž¡í•œ ì¶”ë¡ ì´ í•„ìš”í•œ ë‹¤ë‹¨ê³„ ì—…ë¬´ì—ëŠ” í•œê³„ê°€ ìžˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ê³¼ì •ì„ ê±°ì³ì•¼ í•˜ëŠ” ìžë™í™” ìž‘ì—…ì—ëŠ” íš¨ìœ¨ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤. í•œ ë²ˆì— í•˜ë‚˜ì˜ ë¬¸ì˜ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìžˆì–´ í™•ìž¥ì„±ì—ì„œë„ ì œí•œì ìž…ë‹ˆë‹¤. ë°”ë¡œ ì´ ì§€ì ì—ì„œ ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ì—…ë“¤ì€ í•œ ë‹¨ê³„ ë„ì•½í•œ RAGê°€ í•„ìš”í•¨ì„ ëŠë¼ê²Œ ë˜ì§€ìš”. &nbsp; ì°¨ì„¸ëŒ€ ê¸°ìˆ , Agentic RAGì˜ ë“±ìž¥ Agentic RAGëŠ” ë§ ê·¸ëŒ€ë¡œ AI &lsquo;ì—ì´ì „íŠ¸&rsquo;ë¥¼ ê²°í•©í•œ ì—…ê·¸ë ˆì´ë“œ ë²„ì „ìž…ë‹ˆë‹¤. Agentic RAGëŠ” í•˜ë‚˜ì˜ LLMë§Œ í™œìš©í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ì—¬ëŸ¬ íˆ´ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•´ì„œ í›¨ì”¬ ë” ë³µìž¡í•˜ê³  ë©€í‹°ìŠ¤í…ì¸ ë¬¸ì œë„ ì²˜ë¦¬í•  ìˆ˜ ìžˆê²Œ í•©ë‹ˆë‹¤. &nbsp; íŠ¹ì§• ë°”ë‹ë¼ RAG&nbsp; Agentic RAG LLM ê¸°ë°˜ âœ… âœ… ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ë°ì´í„° ê²€ìƒ‰ âœ… âœ… ë‹¤ì–‘í•œ ë„êµ¬ í™œìš© âŒ âœ… ë‹¤ë‹¨ê³„ ì¶”ë¡  âŒ âœ… í’ë¶€í•œ ë©”ëª¨ë¦¬ ì œí•œì  âœ… ì¿¼ë¦¬ ì •ì œ âŒ âœ… &nbsp; Agentic RAGì˜ í•µì‹¬ì€ íš¨ìœ¨ì„±ê³¼ í™•ìž¥ì„±ìž…ë‹ˆë‹¤. ì‹œë§¨í‹± ìºì‹±ê³¼ ê³ ë„í™”ëœ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë•ë¶„ì— LLM í˜¸ì¶œ ë¹„ìš©ê³¼ ì§€ì—°ì´ ëŒ€í­ ì¤„ê³ , ë³µìž¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ë„ í›¨ì”¬ ì‰½ê²Œ ìžë™í™”í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. &nbsp; ëœ¨ê±°ì›Œì§€ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆ ì‹œìž¥ ì‹œìž¥ ë°ì´í„°ë„ ë¬´ì‹œë¬´ì‹œí•˜ê²Œ ë‚˜ì˜µë‹ˆë‹¤. RAG ê´€ë ¨ ì‹œìž¥ì€ 2025ë…„ ì•½ 20ì–µ ë‹¬ëŸ¬ì—ì„œ 2035ë…„ 400ì–µ ë‹¬ëŸ¬ë¡œ ì„±ìž¥í•  ì „ë§ìž…ë‹ˆë‹¤. ì„±ìž¥ ì¤‘ì‹¬ì—ëŠ” ì‹¤ì œë¡œ ë°”ë‹ë¼ RAGì˜ í•œê³„ë¥¼ ê²½í—˜í•œ ëŒ€ê¸°ì—…ë“¤ì˜ ëŒ€ê·œëª¨ ì „í™˜ì´ ìžë¦¬í•˜ê³  ìžˆìŠµë‹ˆë‹¤. &nbsp; ì´ë“¤ì´ Agentic RAGì—ì„œ ì–»ê³ ìž í•˜ëŠ” ê±´ ë°ì´í„° ì‹ ë¢°ì„± ê°•í™” LLM ë¹„ìš© ì ˆê° ë³µìž¡í•œ ì—…ë¬´ì˜ ìžë™í™”ì™€ ì§€ëŠ¥ì  ì˜ì‚¬ê²°ì • ì§€ì› &nbsp; ê¸°ì—…ë“¤ì€ ì²˜ìŒë¶€í„° ì™„ë²½í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê¸°ë³´ë‹¤ëŠ”, RAG&rarr;Agentic RAGë¡œ ê°€ëŠ” ì ì§„ì  ì§„í™”ë¥¼ ì±„íƒí•˜ëŠ” ê²½ìš°ê°€ ë§ŽìŠµë‹ˆë‹¤. Agentic RAG ë„ìž… ì‹œ Redisì˜ ì—­í• ê³¼ ìž¥ì ì„ ì´í•´í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. RedisëŠ” ë›°ì–´ë‚œ ì†ë„ì™€ í™•ìž¥ì„±ì„ ë°”íƒ•ìœ¼ë¡œ Agentic RAGê°€ ìš”êµ¬í•˜ëŠ” ë³µìž¡í•œ ë©€í‹°ìŠ¤í… ì¶”ë¡ ê³¼ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤. ê·¸ë¿ë§Œ ì•„ë‹ˆë¼, ì‹œë§¨í‹± ìºì‹± ê¸°ëŠ¥ì„ í†µí•´ ìœ ì‚¬í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë¹ ë¥¸ ì‘ë‹µì„ ê°€ëŠ¥í•˜ê²Œ í•¨ìœ¼ë¡œì¨ LLM í˜¸ì¶œ ë¹„ìš©ê³¼ ì§€ì—°ì„ í¬ê²Œ ì¤„ì—¬ ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê°•ì ë“¤ì€ Redisê°€ ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ Agentic RAG êµ¬í˜„ì˜ í•µì‹¬ ì¸í”„ë¼ë¡œ ìžë¦¬ ìž¡ëŠ” ì´ìœ ë¥¼ ëª…í™•ížˆ ë³´ì—¬ì¤ë‹ˆë‹¤. &nbsp; Redisê°€ Agentic RAGì™€ ê²°í•©í–ˆì„ ë•Œ ë‹¤ìŒê³¼ ê°™ì€ ìž¥ì ì´ ìžˆìŠµë‹ˆë‹¤.&nbsp; ê·¹ê°•ì˜ ì†ë„ì™€ í™•ìž¥ì„± : RedisëŠ” ì¸ë©”ëª¨ë¦¬ êµ¬ì¡°ë¡œ ì‹¤ì‹œê°„ ë°ì´í„° ê²€ìƒ‰ê³¼ ë²¡í„° ì—°ì‚°, ì˜ë¯¸ ê¸°ë°˜(semantic) ìºì‹±ì— ë§¤ìš° ë›°ì–´ë‚©ë‹ˆë‹¤. íŠ¹ížˆ Agentic RAGì™€ ê°™ì´ ë³µìž¡í•œ ë©€í‹°ìŠ¤í… ì¶”ë¡ ê³¼ ë°˜ë³µì ì¸ ì»¨í…ìŠ¤íŠ¸ ì „í™˜ì´ ë§Žì€ í™˜ê²½ì—ì„œ, RedisëŠ” ë‹¤ë¥¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ëŒ€ë¹„ ì›”ë“±ížˆ ë¹ ë¥¸ ê²€ìƒ‰/ìž¬ê²€ìƒ‰ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤ . íš¨ìœ¨ì ì¸ ìºì‹±ê³¼ ë¹„ìš© ì ˆê° : Redisì˜ ì‹œë§¨í‹± ìºì‹œëŠ” ì§ˆë¬¸ì´ ì¡°ê¸ˆë§Œ ë‹¬ë¼ì ¸ë„ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ ìºì‹œì—ì„œ ì¦‰ì‹œ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë•ë¶„ì— LLM í˜¸ì¶œ ë¹„ìš©ê³¼ ì§€ì—°(latency)ì´ í¬ê²Œ ì¤„ì–´ë“­ë‹ˆë‹¤. ì‹¤ì œë¡œ FAQ ë“± ìžì£¼ ë°˜ë³µë˜ëŠ” ì—…ë¬´ì—ì„  ì •ë‹µì„ ë¯¸ë¦¬ ìºì‹±í•´ì„œ ê±°ì˜ ì‹¤ì‹œê°„ ì‘ë‹µì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤ . ëŒ€ìš©ëŸ‰ ë°ì´í„°, ê³ ì„±ëŠ¥ ê´€ë¦¬ : Agentic RAGì—ì„œ ì¤‘ìš”í•œ ê±´ ë°©ëŒ€í•œ ì™¸ë¶€ ì§€ì‹ì˜ ì‹¤ì‹œê°„ ê²€ìƒ‰ê³¼ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì¸ë°, RedisëŠ” ëŒ€ê·œëª¨ ë²¡í„° ìž„ë² ë”©ì„ ì €ìž¥, ìƒ‰ì¸(indexing)í•˜ë©°, ëŒ€í™” ížˆìŠ¤í† ë¦¬ ê´€ë¦¬(LLM ì„¸ì…˜ ë§¤ë‹ˆì €)ì—ë„ ìµœì í™”ë˜ì–´ ìžˆìŠµë‹ˆë‹¤ . ì—”í„°í”„ë¼ì´ì¦ˆ ì¸í”„ë¼ì™€ì˜ ì¹œí™”ì„± : RedisëŠ” ê²€ì¦ëœ í™•ìž¥ì„±, ë‚®ì€ ì§€ì—°, ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡° ì§€ì›(ë¬¸ìžì—´, ë¦¬ìŠ¤íŠ¸, í•´ì‹œ, ì§‘í•© ë“±) ë“±ìœ¼ë¡œ ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì— ìœ ì—°í•˜ê²Œ ì ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê¸°ì¡´ ì„œë¹„ìŠ¤ì™€ì˜ ê²°í•©, ë°ì´í„° ë™ê¸°í™” ë“±ë„ ìš©ì´í•˜ë‹¤ëŠ” íŠ¹ì§•ì´ ëª…ì‹œë˜ì–´ ìžˆìŠµë‹ˆë‹¤ . ë¹ ë¥´ê³  ëŠê¹€ ì—†ëŠ” ì‚¬ìš©ìž ê²½í—˜ : ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ì¤‘ìš”í•œ AI ì„œë¹„ìŠ¤, ì˜ˆë¥¼ ë“¤ë©´ RAG ê¸°ë°˜ ì±—ë´‡ì´ë‚˜ ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” Redisë¥¼ í†µí•´ '100ms ë£°'(ì‚¬ìš©ìžê°€ ëŠë¼ê¸°ì— ì¦‰ê°ì ì¸ ì‘ë‹µ ì†ë„) ê²½í—˜ì— í•œì¸µ ë” ê·¼ì ‘í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤ . ê²°ë¡ ì ìœ¼ë¡œ, ì²¨ë¶€ ë¬¸ì„œì—ì„œëŠ” Agentic RAGì˜ ë¹ ë¥¸ ë©”ëª¨ë¦¬, ì‹œë§¨í‹± ìºì‹±, ê³ ì„±ëŠ¥ ë²¡í„° ê²€ìƒ‰, í™•ìž¥ì„±ê³¼ ì‹ ë¢°ì„± ì¸¡ë©´ì—ì„œ Redisê°€ ì—”í„°í”„ë¼ì´ì¦ˆ AI ì•„í‚¤í…ì²˜ì˜ í•„ìˆ˜ ì¸í”„ë¼ìž„ì„ ê°•ì¡°í•˜ê³  ìžˆìŠµë‹ˆë‹¤. Agentic RAGë¥¼ ê³ ë¯¼í•˜ëŠ” ì‹¤ë¬´ì§„ì´ë‚˜ ê°œë°œìžë¼ë©´, Redisì˜ ë„ìž…ì´ ì‹¤ì œë¡œ ì‹œìŠ¤í…œì˜ ì†ë„, ë¹„ìš©, í™•ìž¥ì„± ì¸¡ë©´ì—ì„œ í° ì´ì ì´ ìžˆìŠµë‹ˆë‹¤.&nbsp; &nbsp; &nbsp; &nbsp; ì›ë¬¸ ì¶œì²˜:&nbsp; Agentic RAG: How enterprises are surmounting the limits of traditional RAG 10 techniques to improve RAG accuracy Using Redis for real-time RAG goes beyond a Vector Database RAG with Redis &nbsp; &nbsp; &nbsp; ì°¸ê³  ë§í¬: AI ì—ì´ì „íŠ¸ ì‹œëŒ€, 'ë©”ëª¨ë¦¬'ê°€ í•µì‹¬ì´ë‹¤ ê³µìœ í•˜ê¸° ê²Œì‹œê¸€ ê´€ë¦¬ OSC Korea Blog ì €ìž‘ìží‘œì‹œ ë¹„ì˜ë¦¬ ë³€ê²½ê¸ˆì§€ (ìƒˆì°½ì—´ë¦¼) --> 'POST/Tech' Related Articles ì‹œí¬ë¦¿ ìŠ¤í”„ë¡¤(Sprawl)ì˜ ìˆ¨ì€ ë¹„ìš©: ìƒìƒ ì´ˆì›”ì˜ ì†ì‹¤ ë ˆê±°ì‹œ NASì—ì„œ í˜„ëŒ€ì  ê¸€ë¡œë²Œ íŒŒì¼ ì‹œìŠ¤í…œìœ¼ë¡œ K8s ë¹„ìš© ìµœì í™”ì˜ ì •ì„: íŠ¸ë Œë“œ, ì†”ë£¨ì…˜ ë¹„êµ, ê·¸ë¦¬ê³  í˜ì‹ ì  ìžë™í™” í”Œëž«í¼ í­ì¦í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì•…ì„±ì½”ë“œ - ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ì˜ ìƒˆë¡œìš´ ë³´ì•ˆ ê³¼ì œ DESIGN BY TISTORY ê´€ë¦¬ìž í‹°ìŠ¤í† ë¦¬íˆ´ë°”
ðŸ”¬ Analyzer [2]: Analyzing 5 results, 6 contents

ðŸ”¬ Analyzer [2]: Analyzed 5 results, 6 contents
   â””â”€ New findings:
      [1] RAGëŠ” LLMì— ê¸°ì–µìž¥ì¹˜ë¥¼ ìž¥ì°©í•˜ëŠ” ê²ƒê³¼ ê°™ê³ , AgentëŠ” LLMì— íŒ”ë‹¤ë¦¬ë¥¼ ë¶™ì—¬ì£¼ëŠ” ê²ƒê³¼ ê°™ë‹¤.
      [2] Agentic RAGëŠ” êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ë°©ëŒ€í•œ ë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° íš¨ê³¼ì ì´ë‹¤.
      [3] Agentic RAGëŠ” ì—¬ëŸ¬ íˆ´ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ì—¬ ë³µìž¡í•œ ë¬¸ì œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìžˆê²Œ í•œë‹¤.
      [4] Agentic RAGëŠ” ì‹œë§¨í‹± ìºì‹±ê³¼ ê³ ë„í™”ëœ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í†µí•´ LLM í˜¸ì¶œ ë¹„ìš©ê³¼ ì§€ì—°ì„ ì¤„ì¼ ìˆ˜ ìžˆë‹¤.
      [5] RAGëŠ” ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ì— í•œì •ë˜ë©° ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€í•˜ëŠ” ë°ì´í„°ë‚˜ ë™ì  ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë°ëŠ” í•œê³„ê°€ ìžˆë‹¤.
   â””â”€ Decision: More research needed
   â””â”€ Next query: RAG vs Agent ê¸°ë°˜ RAG ë¹„êµ ë¶„ì„
ðŸ” Searcher [3]: Follow-up search for: RAG vs Agent ê¸°ë°˜ RAG ë¹„êµ ë¶„ì„

ðŸ” Searcher: Found 5 results
   â””â”€ URLs found:
      [1] https://www.slexn.com/agentic-rag-contextual-ai/
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [4] https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
      [5] https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis
   â””â”€ Snippets:
      â€¢ Qodoì˜ ìµœì‹  ë¸”ë¡œê·¸ì—ì„œëŠ” â€œAgentic RAG ì‹œìŠ¤í…œì´ AI ì—ì´ì „íŠ¸ë¥¼ RAG íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ì—¬ ìœ ì—°ì„±ê³¼ ì •í™•ì„±ì„ ê°•í™”í•œë‹¤â€œê³  ì–¸ê¸‰í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œ ë•ë¶„ì— LLMì€ ë‹¨ì¼ ë°ì´í„°ë² ì´ìŠ¤ì— êµ­í•œë˜ì§€ ì•Šê³  ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ì™€ ë„êµ¬ë¥¼ í™œìš©í•  ìˆ˜ ìžˆìœ¼ë©°, ë³µìž¡í•œ ë‹¤ë‹¨ê³„ ìž‘ì—… íë¦„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¦‰, ì „í†µì ì¸ RAGëŠ” ë‹¨ì¼ ë°ì´í„°ì…‹ì— ê¸°ë°˜í•œ ì¼íšŒì„± ê²€ìƒ‰ ë°©ì‹ì— ê°€ê¹ìŠµë‹ˆë‹¤.  ë°˜ë©´ ì—ì´ì „í‹± RAGëŠ” ëª¨ë¸ì„ ëŠ¥ë™ì ì¸ ì—ì´ì „íŠ¸ë¡œ ë°”ë¼ë³´ë©°, ì§ˆì˜ë¥¼ ì§€ì†ì ìœ¼ë¡œ ì¡°ì •í•˜ê³  ì—¬ëŸ¬ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë„êµ¬ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ ì •ë³´ë¥¼ ìž¬ê²€ì¦í•˜ë©° ë³µìž¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì´ˆì ì„ ë§žì¶¥ë‹ˆë‹¤.  ì•„ëž˜ì˜ í‘œëŠ” ë‘ ì ‘ê·¼ë²•ì„ ì£¼ìš” ì¸¡ë©´ì—ì„œ ë¹„êµí•œ ê²ƒìž…ë‹ˆë‹¤. [...] ê¸°ì¡´ì˜ RAG íŒŒì´í”„ë¼ì¸ì€ ì„ í˜•ì ì¸ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. íŠ¹ì • ì§ˆì˜ê°€ ê²€ìƒ‰ê³¼ ìž¬ìˆœìœ„í™” ê³¼ì •ì„ ê±°ì³ ìƒì„± ë‹¨ê³„ë¡œ ì „ë‹¬ë˜ê³  ìµœì¢… ê²°ê³¼ê°€ ìƒì„±ë©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ ì •ì ì´ë©° ë‹¨ì¼ ì‹¤í–‰ ë°©ì‹ì´ë¼ê³  ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  ë°˜ë©´ì— Agentic RAGëŠ” ë£¨í”„ ê¸°ë°˜ì˜ ë™ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì„ íƒí•©ë‹ˆë‹¤. ì´ ê²½ìš° ì—ì´ì „íŠ¸ëŠ” ì²˜ìŒì— ì§ˆì˜ë¥¼ ë¶„ì„í•˜ê³ , ë‚´ë¶€ ë°ì´í„° ë˜ëŠ” ì™¸ë¶€ ì†ŒìŠ¤ ì¤‘ ì–´ëŠ ê³³ì—ì„œ íƒìƒ‰í• ì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ê·¸ í›„ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³ , ë§Œì•½ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨ë˜ë©´ ì§ˆì˜ë¥¼ ìž¬êµ¬ì„±í•˜ì—¬ ë‹¤ì‹œ ê²€ìƒ‰ ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤.  ì´ëŸ¬í•œ ê³¼ì •ì€ ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ë‹µë³€ì— í•„ìš”í•œ ë§¥ë½ì´ í™•ë³´ë  ë•Œê¹Œì§€ ì´ì–´ì§‘ë‹ˆë‹¤.  ## Agentic RAG ì•„í‚¤í…ì²˜ ìœ í˜• [...] ì˜ˆë¥¼ ë“¤ì–´ íŠ¹ì • ì—ì´ì „íŠ¸ëŠ” ë‚´ë¶€ ê¸°ìˆ  ë¬¸ì„œë¥¼ ì‚´íŽ´ë³´ê³ , ë‹¤ë¥¸ ì—ì´ì „íŠ¸ëŠ” ì´ë©”ì¼ì´ë‚˜ ë©”ì‹ ì € ëŒ€í™” ê¸°ë¡ì„ ë¶„ì„í•©ë‹ˆë‹¤. ë˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ëŠ” ì›¹ì—ì„œ ê´€ë ¨ ìžë£Œë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì£¼ ì—ì´ì „íŠ¸ëŠ” ì´ë“¤ ê°ê°ì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ì›ëž˜ì˜ ê³¼ì—… ëª©í‘œì— ë¶€í•©í•˜ëŠ” ë§¥ë½ì„ í˜•ì„±í•©ë‹ˆë‹¤.  ì´ì™€ ê°™ì€ ê³„ì¸µì  êµ¬ì¡°ëŠ” ëª¨ë“ˆì„±, ìœ ì—°ì„±, ê·¸ë¦¬ê³  ìž¥ì•  ê²©ë¦¬ ì¸¡ë©´ì—ì„œ ìœ ë¦¬í•©ë‹ˆë‹¤. íŠ¹ížˆ ê³µìš© ë°ì´í„°, ì‚¬ë‚´ ë°ì´í„°, ë°˜êµ¬ì¡°ì  ë°ì´í„°ê°€ í˜¼ìž¬ëœ ê¸°ì—… ê·œëª¨ì˜ ë³µí•© ì‹œìŠ¤í…œì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ìž‘ë™í•©ë‹ˆë‹¤.  ## Agentic RAGì™€ ì „í†µì  RAGì˜ ë¹„êµ
      â€¢ RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant, context-aware information. Traditional RAG improves LLMs by connecting them to external data sources, while Agentic RAG goes a step further by adding intelligent agents that handle decisions and complex tasks. If the task is simple and query-based, traditional RAG is enough. However, for more complex, multi-step processes, Agentic RAG offers more flexibility, adaptability, and accuracy. As AI [...] Traditional RAG systems are great for answering simple queries and retrieving information from static sources. However, they may struggle with multi-step, complex queries.  Agentic RAG systems, on the other hand, excel in handling complex tasks by breaking them down into smaller, manageable steps. They se agents to make decisions at each stage, ensuring that the system adapts to the taskâ€™s complexity.  ### Decision Making: [...] In e-commerce, RAG can be used to generate product descriptions by retrieving relevant product details and specifications.  Agentic RAG can take it a step further by handling complex queries such as recommending products based on user behavior, pricing analysis, and trends from different sources.  ### Challenges with RAG and Agentic RAG  Despite their advantages, both RAG and Agentic RAG face certain challenges:
      â€¢ generates the final response. A traditional RAG has a simple retrieval, limited adaptability, and relies on static knowledge, making it less flexible for dynamic and real-time information. Agentic RAG improves on this by introducing AI agents that can make decisions, select tools, and even refine queries for more accurate and flexible responses. Hereâ€™s how Agentic RAG works on a high level: 1 - The user query is directed to an AI Agent for processing. 2 - The agent uses short-term and long-term [...] RAG vs Agentic RAG RAG (Retrieval Augmented Generation) is a method that combines information retrieval with large language models to generate answers. Hereâ€™s how RAG works on a high level: 1 - The model retrieves relevant data from data sources and then extracts it to a vector database from the pre-indexed model. 2 - Augment the prompts by retrieving information and merging it with the query prompt. 3 - A Large Language Model (like GPT, Claude, or Gemini) understands the combined query and [...] RAG: fetches facts. Agentic RAG: fetches facts and adds a â€œstrategyâ€ deck. The noise is real. Seen another â€œinnovationâ€ thatâ€™s just more buzzwords for Googling? Tag Pingdin or DM us â€” weâ€™ll translate it into plain English (or memes). #SignalInTheNoise #Pingdin  LikeReply 1 Reaction   Image 14: Kyth Lekhong, graphic  Kyth Lekhong Strategic Planning | Business Development | New Business   4w      Report this comment  Thanks for sharing, Alex  LikeReply 1 Reaction
ðŸ’­ Think: Query: RAG vs Agent ê¸°ë°˜ RAG ë¹„êµ ë¶„ì„ | Found 5 results, 5 URLs. Key snippets: Qodoì˜ ìµœì‹  ë¸”ë¡œê·¸ì—ì„œëŠ” â€œAgentic RAG ì‹œìŠ¤í…œì´ AI ì—ì´ì „íŠ¸ë¥¼ RAG íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ì—¬ ìœ ì—°ì„±ê³¼ ì •í™•ì„±ì„ ê°•í™”í•œë‹¤â€œê³  ì–¸ê¸‰í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œ ë•ë¶„ì— LLM | RAG and Agentic RAG are both key advancements in AI, helping LLMs access and generate relevant, cont | generates the final response. A traditional RAG has a simple retrieval, limited adaptability, . Assessment: Is this sufficient or need more specific search?

ðŸ“– ContentReader: Reading 3 URLs
ðŸ“– Read URL: https://www.slexn.com/agentic-rag-contextual-ai/... (8015 chars)
   â””â”€ [https://www.slexn.com/agentic-rag-contextual-ai/]
      Preview: Agentic RAG : ë” ë˜‘ë˜‘í•´ì§„ ë¬¸ë§¥ ì¤‘ì‹¬ AI ì‹œìŠ¤í…œ - SLEXN Solutions AI &#038; ML Engineeringâ€‹ ALM Engineeringâ€‹ DevOps Testing &amp; Security Work &#038; Collaborationâ€‹â€‹ Experience Platformâ€‹ Products Resources Blog Events Newsletter Contact Support Solutions AI &#038; ML Engineeringâ€‹ ALM Engineeringâ€‹ DevOps Testing &amp; Security Work &#038; Collaborationâ€‹â€‹ Experience Platformâ€‹ Products Resources Blog Events Newsletter Contact Support Blog &gt; Insights Agentic RAG : ë” ë˜‘ë˜‘í•´ì§„ ë¬¸ë§¥ ì¤‘ì‹¬ AI ì‹œìŠ¤í…œ September 16, 2025 12 min Read ìµœê·¼ ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì—ì„œ Retrieval-Augmented Generation(RAG)ì€ ì£¼ëª©ë°›ê³  ìžˆëŠ” ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í•œê³„ë¥¼ ë³´ì™„í•˜ëŠ” í•µì‹¬ ì „ëžµìœ¼ë¡œ ìžë¦¬ìž¡ê³  ìžˆìŠµë‹ˆë‹¤. RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ì‘ë‹µì— í†µí•©í•˜ì—¬ ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ìƒì„±ì„ ë„˜ì–´, ë”ìš± ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ì§€ëŠ¥í˜• ì‘ë‹µì„ ì œê³µí•˜ëŠ” ê¸°ìˆ ë¡œ, ì½”ë“œ ë¶„ì„, ë¬¸ì„œ ì²˜ë¦¬, ê²€ìƒ‰ ê¸°ë°˜ ìžë™í™” ë“± ë‹¤ì–‘í•œ ì‚°ì—… í˜„ìž¥ì— ë¹ ë¥´ê²Œ í™•ì‚°ë˜ê³  ìžˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ë¡ ì ì¸ ê¸°ëŒ€ì™€ëŠ” ë‹¬ë¦¬ ì‹¤ì œ ê¸°ì—… í™˜ê²½ì—ì„œì˜ ì„±ê³¼ëŠ” ê·¸ë¦¬ ë†’ì§€ ì•ŠìŠµë‹ˆë‹¤. í•œ ì‚°ì—… ë¶„ì„ ë³´ê³ ì„œì— ë”°ë¥´ë©´ ê¸°ì—…ì—ì„œ RAGë¥¼ ë„ìž…í–ˆì„ ë•Œ ì•½ 87%ê°€ ê¸°ëŒ€í•œ íˆ¬ìž ëŒ€ë¹„ ìˆ˜ìµ(ROI)ì„ ë‹¬ì„±í•˜ì§€ ëª»í•œ ê²ƒìœ¼ë¡œ ë°í˜€ì¡ŒìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œì˜ ì£¼ëœ ì›ì¸ì€ ë‹¤ì–‘í•œ ì¸ë±ì‹± ë°©ë²•, ê³ ì •ëœ ê²€ìƒ‰ ê²½ë¡œ, ê·¸ë¦¬ê³  ì‹¤ì œ ìž‘ì—… í™˜ê²½ì„ ë°˜ì˜í•˜ì§€ ëª»í•˜ëŠ” í‰ê°€ ë°©ì‹ ë•Œë¬¸ìž…ë‹ˆë‹¤ ì¼ë°˜ì ì¸ RAG ì‹œìŠ¤í…œì€ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•œ í›„ì—ë„ ì—¬ì „ížˆ ê´€ë ¨ì„±ì´ ë‚®ì€ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ì¤‘ìš”í•œ ë¡œê·¸ ì°¸ì¡°ë¥¼ ë†“ì¹˜ê±°ë‚˜, ì˜ì¡´ì„± ì •ë³´ë¥¼ ê°„ê³¼í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‹¤íŒ¨ ì‚¬ë¡€ë“¤ì€ ë°ì´í„°ê°€ í•­ìƒ ê¹”ë”í•˜ê³  ìž˜ ì¡°ì§ë˜ì–´ ìžˆì„ ê²ƒì´ë¼ëŠ” ê°€ì •ì— ì˜ì¡´í•˜ëŠ” ê³ ì •ì ì¸ ê²€ìƒ‰ ë¡œì§ì—ì„œ ê¸°ì¸í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë“±ìž¥í•œ ê°œë…ì´ ë°”ë¡œ Agentic RAG ìž…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¨ìˆœí•œ ê²€ìƒ‰ê¸°ë¥¼ ë‹¨ìˆœ í˜¸ì¶œí•˜ëŠ” ë°©ì‹ì—ì„œ ë²—ì–´ë‚˜, ì—ì´ì „íŠ¸ëŠ” ë¬´ì—‡ì„ ê²€ìƒ‰í• ì§€, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í• ì§€, íƒìƒ‰ì„ ì–¸ì œ ì¢…ë£Œí• ì§€ë¥¼ ìŠ¤ìŠ¤ë¡œ ë™ì ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²€ìƒ‰ì€ ë‹¨ì¼ í˜¸ì¶œì´ ì•„ë‹Œ, ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ ë°˜ë³µì ì´ê³  ì ì§„ì ì¸ ê³¼ì •ìœ¼ë¡œ ë‹¤ì‹œ ì •ì˜ë©ë‹ˆë‹¤. íŠ¹ížˆ Qodoì˜ Agentic RAG ëŠ” ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì„ ì‹¤ì œë¡œ êµ¬í˜„í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ì—ì´ì „íŠ¸ê°€ Git ì €ìž¥ì†Œ, íŒŒì¼, Pull Request, ì‹¬ì§€ì–´ í„°ë¯¸ë„ ë¡œê·¸ì™€ ê°™ì€ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë§¥ë½ì„ íƒìƒ‰í•  ìˆ˜ ìžˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ìƒí™©ì— ë§žê²Œ ì§ˆë¬¸ì„ ìž¬êµ¬ì„±í•˜ê³  í•„ìš”ì— ë”°ë¼ ê²€ìƒ‰ ê²½ë¡œë¥¼ ë³€ê²½í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ê²€ìƒ‰ì€ ë‹¨ìˆœí•œ ì •ë³´ ê²€ìƒ‰ì„ ë„˜ì–´ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì ê·¹ì ì¸ ì˜ì‚¬ê²°ì • ê³¼ì •ìœ¼ë¡œ ë°œì „í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë²ˆ ë¸”ë¡œê·¸ì—ì„œëŠ” Agentic RAGì˜ ìž‘ë™ ë°©ì‹, ê¸°ì¡´ RAGì™€ì˜ ì°¨ì´ì , ê·¸ë¦¬ê³  Qodoì˜ Agentic RAGê°€ ì œê³µí•˜ëŠ” ì‹¤ì œ í™œìš© ë°©ì•ˆì— ëŒ€í•´ ìžì„¸ížˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. Agentic RAGëž€? Agentic RAGëŠ” ê¸°ì¡´ì˜ Retrieval-Augmented Generation(RAG) ë°©ì‹ì— ìžìœ¨ì  ì˜ì‚¬ê²°ì • ê¸°ëŠ¥ì„ ì ‘ëª©í•œ ìƒˆë¡œìš´ êµ¬ì¡°ìž…ë‹ˆë‹¤. ì „í†µì ì¸ RAGê°€ ë¯¸ë¦¬ ì„¤ì •ëœ ê²€ìƒ‰ ê²½ë¡œë¥¼ ë”°ë¼ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ìž‘ë™í•˜ëŠ” ê²ƒê³¼ëŠ” ë‹¬ë¦¬, Agentic RAGëŠ” ê²€ìƒ‰ì„ ëª©í‘œ ì§€í–¥ì ì´ê³  ë°˜ë³µì ì¸ ê³¼ì •ìœ¼ë¡œ ìž¬íŽ¸í•©ë‹ˆë‹¤. ì´ ì—ì´ì „íŠ¸ëŠ” ëª…í™•í•œ ìž„ë¬´ë¥¼ ê°€ì§€ê³  ê²€ìƒ‰ ê³„íšì„ ìˆ˜ë¦½í•˜ë©°, ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ë„ì¶œëœ ê²°ê³¼ë¥¼ í‰ê°€í•˜ì—¬ í•„ìš”í•  ê²½ìš° ì ‘ê·¼ ë°©ì‹ì„ ì¡°ì •í•©ë‹ˆë‹¤. ì¶©ë¶„í•œ ë§¥ë½ì´ í™•ë³´ë  ë•Œê¹Œì§€ ê²€ìƒ‰ì„ ì§€ì†í•˜ê³ , ê·¸ ì´í›„ì— ë‹µë³€ì„ ìƒì„±í•œë‹¤ëŠ” ì ì´ í•µì‹¬ìž…ë‹ˆë‹¤. ì•„ëž˜ì˜ ë„ì‹ì€ ì´ëŸ¬í•œ Agentic RAGì˜ êµ¬ì¡°ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤: Source: www.qodo.ai | How Agentic RAGs formed ê¸°ì¡´ì˜ RAG íŒŒì´í”„ë¼ì¸ì€ ì„ í˜•ì ì¸ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. íŠ¹ì • ì§ˆì˜ê°€ ê²€ìƒ‰ê³¼ ìž¬ìˆœìœ„í™” ê³¼ì •ì„ ê±°ì³ ìƒì„± ë‹¨ê³„ë¡œ ì „ë‹¬ë˜ê³  ìµœì¢… ê²°ê³¼ê°€ ìƒì„±ë©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ ì •ì ì´ë©° ë‹¨ì¼ ì‹¤í–‰ ë°©ì‹ì´ë¼ê³  ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë°˜ë©´ì— Agentic RAGëŠ” ë£¨í”„ ê¸°ë°˜ì˜ ë™ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì„ íƒí•©ë‹ˆë‹¤. ì´ ê²½ìš° ì—ì´ì „íŠ¸ëŠ” ì²˜ìŒì— ì§ˆì˜ë¥¼ ë¶„ì„í•˜ê³ , ë‚´ë¶€ ë°ì´í„° ë˜ëŠ” ì™¸ë¶€ ì†ŒìŠ¤ ì¤‘ ì–´ëŠ ê³³ì—ì„œ íƒìƒ‰í• ì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ê·¸ í›„ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³ , ë§Œì•½ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨ë˜ë©´ ì§ˆì˜ë¥¼ ìž¬êµ¬ì„±í•˜ì—¬ ë‹¤ì‹œ ê²€ìƒ‰ ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê³¼ì •ì€ ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ë‹µë³€ì— í•„ìš”í•œ ë§¥ë½ì´ í™•ë³´ë  ë•Œê¹Œì§€ ì´ì–´ì§‘ë‹ˆë‹¤. Agentic RAG ì•„í‚¤í…ì²˜ ìœ í˜• Agentic RAGì˜ êµ¬ì¡°ëŠ” ê¸°ë³¸ì ì¸ í˜•íƒœë¶€í„° ë§¤ìš° ëª¨ë“ˆí™”ëœ í˜•íƒœê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì˜ í•µì‹¬ì€ ì—ì´ì „íŠ¸ê°€ ê³ ì •ëœ ë‹¨ì¼ ê²€ìƒ‰ ë°©ì‹ì— ì–½ë§¤ì´ì§€ ì•Šìœ¼ë©°, ê³¼ì—…ì˜ ëª©í‘œì™€ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ë„êµ¬ì— ê¸°ë°˜í•˜ì—¬ ìžì‹ ì˜ ê²€ìƒ‰ ì „ëžµì„ ìŠ¤ìŠ¤ë¡œ ì¡°ì •í•œë‹¤ëŠ” ì ìž…ë‹ˆë‹¤. ì´ì™€ ê´€ë ¨í•˜ì—¬ ë‘ ê°€ì§€ ëŒ€í‘œì ì¸ ì•„í‚¤í…ì²˜ íŒ¨í„´ì„ ì†Œê°œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: 1. ë‹¨ì¼ ì—ì´ì „íŠ¸ RAG (Single-Agent RAG, Routing Agent) ì£¼ì–´ì§„ ì§ˆì˜ë¥¼ ë¶„ì„í•œ í›„, ê°€ìž¥ ì•Œë§žì€ ê²€ìƒ‰ ë°©ë²•ì„ ê²°ì •í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¡°íšŒí•˜ê±°ë‚˜ ë¬¸ì„œ ì €ìž¥ì†Œë¥¼ íƒìƒ‰í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ APIë¥¼ í˜¸ì¶œí•˜ëŠ” ë“±ì˜ ìž‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. íŠ¹ížˆ ì£¼ëª©í•  ì ì€ ì´ëŸ¬í•œ ì„ íƒì´ ì‚¬ì „ì— ì •í•´ì§„ ê·œì¹™ì— ë”°ë¼ ì´ë£¨ì–´ì§€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì‹¤í–‰ ì‹œì , ì¦‰ ëŸ°íƒ€ìž„ì— ë™ì ìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤ëŠ” ê²ƒìž…ë‹ˆë‹¤. Source: www.qodo.ai | Single Agent RAG System ì´ ëª¨ë¸ì€ ê²€ìƒ‰ì›ì´ ì†Œìˆ˜ì´ê³  ë¹„êµì  ë‹¨ìˆœí•œ ì¡°ì •ë§Œìœ¼ë¡œ ì¶©ë¶„í•œ ìƒí™©ì—ì„œ ì í•©í•©ë‹ˆë‹¤. ê·œëª¨ê°€ ìž‘ë”ë¼ë„ ê²€ìƒ‰ ì˜ì‚¬ê²°ì •ì„ ì—ì´ì „íŠ¸ê°€ ìžìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì— ì—¬ì „ížˆ Agentic RAGì˜ íŠ¹ì§•ì„ ìœ ì§€í•©ë‹ˆë‹¤. 2. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ RAG (Multi-Agent RAG, Specialized Retrieval Agents) ë³µìž¡í•œ í™˜ê²½ì—ì„œëŠ” ë‹¨ì¼ ì—ì´ì „íŠ¸ë§Œìœ¼ë¡œëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ê²€ìƒ‰ ìš”êµ¬ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° íž˜ë“­ë‹ˆë‹¤. ë”°ë¼ì„œ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ êµ¬ì¡°ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì—…ë¬´ë¥¼ ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì‚°ì‹œí‚µë‹ˆë‹¤. ì´ êµ¬ì¡°ì—ì„œëŠ” ì£¼ ì—ì´ì „íŠ¸(ë¦¬ë” ì—ì´ì „íŠ¸)ê°€ ì „ì²´ì ì¸ ìž‘ì—…ì„ ê´€ë¦¬í•˜ë©°, êµ¬ì²´ì ì¸ ì„¸ë¶€ ìž‘ì—…ì€ ê°ê¸° íŠ¹í™”ëœ í•˜ìœ„ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ìž„ë©ë‹ˆë‹¤. Source: www.qodo.ai | Multi Agent RAG System ì˜ˆë¥¼ ë“¤ì–´ íŠ¹ì • ì—ì´ì „íŠ¸ëŠ” ë‚´ë¶€ ê¸°ìˆ  ë¬¸ì„œë¥¼ ì‚´íŽ´ë³´ê³ , ë‹¤ë¥¸ ì—ì´ì „íŠ¸ëŠ” ì´ë©”ì¼ì´ë‚˜ ë©”ì‹ ì € ëŒ€í™” ê¸°ë¡ì„ ë¶„ì„í•©ë‹ˆë‹¤. ë˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ëŠ” ì›¹ì—ì„œ ê´€ë ¨ ìžë£Œë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì£¼ ì—ì´ì „íŠ¸ëŠ” ì´ë“¤ ê°ê°ì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ì›ëž˜ì˜ ê³¼ì—… ëª©í‘œì— ë¶€í•©í•˜ëŠ” ë§¥ë½ì„ í˜•ì„±í•©ë‹ˆë‹¤. ì´ì™€ ê°™ì€ ê³„ì¸µì  êµ¬ì¡°ëŠ” ëª¨ë“ˆì„±, ìœ ì—°ì„±, ê·¸ë¦¬ê³  ìž¥ì•  ê²©ë¦¬ ì¸¡ë©´ì—ì„œ ìœ ë¦¬í•©ë‹ˆë‹¤. íŠ¹ížˆ ê³µìš© ë°ì´í„°, ì‚¬ë‚´ ë°ì´í„°, ë°˜êµ¬ì¡°ì  ë°ì´í„°ê°€ í˜¼ìž¬ëœ ê¸°ì—… ê·œëª¨ì˜ ë³µí•© ì‹œìŠ¤í…œì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ìž‘ë™í•©ë‹ˆë‹¤. Agentic RAGì™€ ì „í†µì  RAGì˜ ë¹„êµ Qodoì˜ ìµœì‹  ë¸”ë¡œê·¸ ì—ì„œëŠ” &#8220; Agentic RAG ì‹œìŠ¤í…œì´ AI ì—ì´ì „íŠ¸ë¥¼ RAG íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ì—¬ ìœ ì—°ì„±ê³¼ ì •í™•ì„±ì„ ê°•í™”í•œë‹¤ &#8220; ê³  ì–¸ê¸‰í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œ ë•ë¶„ì— LLMì€ ë‹¨ì¼ ë°ì´í„°ë² ì´ìŠ¤ì— êµ­í•œë˜ì§€ ì•Šê³  ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ì™€ ë„êµ¬ë¥¼ í™œìš©í•  ìˆ˜ ìžˆìœ¼ë©°, ë³µìž¡í•œ ë‹¤ë‹¨ê³„ ìž‘ì—… íë¦„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¦‰, ì „í†µì ì¸ RAGëŠ” ë‹¨ì¼ ë°ì´í„°ì…‹ì— ê¸°ë°˜í•œ ì¼íšŒì„± ê²€ìƒ‰ ë°©ì‹ì— ê°€ê¹ìŠµë‹ˆë‹¤. ë°˜ë©´ ì—ì´ì „í‹± RAGëŠ” ëª¨ë¸ì„ ëŠ¥ë™ì ì¸ ì—ì´ì „íŠ¸ë¡œ ë°”ë¼ë³´ë©°, ì§ˆì˜ë¥¼ ì§€ì†ì ìœ¼ë¡œ ì¡°ì •í•˜ê³  ì—¬ëŸ¬ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë„êµ¬ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ ì •ë³´ë¥¼ ìž¬ê²€ì¦í•˜ë©° ë³µìž¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì´ˆì ì„ ë§žì¶¥ë‹ˆë‹¤. ì•„ëž˜ì˜ í‘œëŠ” ë‘ ì ‘ê·¼ë²•ì„ ì£¼ìš” ì¸¡ë©´ì—ì„œ ë¹„êµí•œ ê²ƒìž…ë‹ˆë‹¤. êµ¬ë¶„ (Aspect) ì „í†µì  RAG (Standard RAG) Agentic RAG ë°ì´í„° ì†ŒìŠ¤ ë‹¨ì¼ ì§€ì‹ ë² ì´ìŠ¤ (ë²¡í„° DB ë“±) ë³µìˆ˜ ì†ŒìŠ¤ ë° ë„êµ¬ (ë²¡í„° DB, ì›¹ API ë“±) ê²€ìƒ‰ ê³¼ì • ë‹¨ì¼ ì‹¤í–‰(one-shot): ê²€ìƒ‰ í›„ ìƒì„± ë°˜ë³µì (iterative): ì—ì´ì „íŠ¸ê°€ ê²€ìƒ‰ ì‹œì Â·ë°©ì‹ ê²°ì •, ìž¬ì§ˆì˜ ê°€ëŠ¥ ì™¸ë¶€ ë„êµ¬ í™œìš© ê±°ì˜ ì—†ìŒ ê²€ìƒ‰, ê³„ì‚°ê¸°, ë°ì´í„°ë² ì´ìŠ¤, API ë“± ë‹¤ì–‘í•œ ë„êµ¬ ì‚¬ìš© ê³„íš ë° ë…¼ë¦¬ ì¿¼ë¦¬ ê³„íš ì—†ìŒ, ì •ì  í”„ë¡¬í”„íŠ¸ ì—ì´ì „íŠ¸ê°€ ê³¼ì—…ì„ ë¶„í•´í•˜ê³  ì „ëžµì„ ë™ì ìœ¼ë¡œ ì¡°ì • ë©”ëª¨ë¦¬ ë¹„ìƒíƒœì (stateless), ì§ˆì˜ ê°„ ë§¥ë½ ê³µìœ  ì—†ìŒ ë‹¨ê¸°Â·ìž¥ê¸° ë©”ëª¨ë¦¬ë¥¼ í†µí•´ ë§¥ë½ ë° ê²°ê³¼ ê¸°ì–µ ì ì‘ì„± ë°˜ì‘ì (reactive), ê³ ì •ëœ ê²€ìƒ‰ ë¡œì§ ëŠ¥ë™ì (proactive)ì´ë©° ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ì „ëžµ ë³€ê²½ ê°€ëŠ¥ ë©€í‹°ëª¨ë‹¬ ëŠ¥ë ¥ ì£¼ë¡œ í…ìŠ¤íŠ¸ ê¸°ë°˜ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“± ë©€í‹°ëª¨ë‹¬ LLM ë° ë„êµ¬ í†µí•© ê°€ëŠ¥ ë³µìž¡ì„± ë° ë¹„ìš© ë‹¨ìˆœ, ì—°ì‚° ë¹„ìš© ë‚®ìŒ ë³µìž¡ì„± ë†’ìŒ, í† í°Â·ì—°ì‚° ë¹„ìš© ì¦ê°€ Qodoì—ì„œì˜ Agentic Mode ìž‘ë™ ë°©ì‹ Qodo ì˜ Agentic Mode ëŠ” ê³ ì •ëœ í”„ë¡¬í”„íŠ¸ë‚˜ ìˆ˜ë™ ì œì–´ì— ì˜ì¡´í•˜ì§€ ì•Šê³ , ìžìœ¨ì ìœ¼ë¡œ ê³„íšÂ·ì¶”ë¡ Â·ì‹¤í–‰í•  ìˆ˜ ìžˆëŠ” ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ê° ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ìžê°€ ëª©í‘œ, ì ‘ê·¼ ê°€ëŠ¥í•œ ë„êµ¬, ë°˜ë³µ ê³¼ì •ì—ì„œì˜ ë™ìž‘ ë°©ì‹ì„ ì •ì˜í•  ìˆ˜ ìžˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ê³¼ì—…ì„ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì—ì´ì „íŠ¸ëŠ” MCP(Model Context Protocol) ë„êµ¬ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ìž‘í•©ë‹ˆë‹¤. MCPëŠ” ì½”ë“œë² ì´ìŠ¤, ì™¸ë¶€ API, í”„ë¡œì íŠ¸ íŒŒì¼, ë¬¸ì„œ, ì›¹ ë“± ë‹¤ì–‘í•œ í™˜ê²½ê³¼ ìƒí˜¸ìž‘ìš©í•  ìˆ˜ ìžˆë„ë¡ ì„¤ê³„ëœ ëª¨ë“ˆí˜• êµ¬ì„± ìš”ì†Œìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ /fetch ë„êµ¬ë¥¼ í†µí•´ Pull Requestë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, /review ë„êµ¬ë¡œ ì½”ë“œ í’ˆì§ˆì„ ê²€ì¦í•˜ê³ , /search ë„êµ¬ë¥¼ í†µí•´ ë‚´ë¶€ ë¬¸ì„œë¥¼ ì¡°íšŒí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ì²˜ëŸ¼ ì—ì´ì „íŠ¸ì™€ MCPì˜ ê²°í•©ì€ ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ì´ ì•„ë‹Œ, ë§¥ë½ ê¸°ë°˜ì˜ ë°˜ë³µì  ê²€ìƒ‰ê³¼ ê³„íš ìˆ˜ì •, ìžìœ¨ì  ì˜ì‚¬ê²°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. Source: www.qodo.ai | How Does Agentic Mode Work in Qodo? Qodo Genì€ ë¡œì»¬ MCPì™€ ì›ê²© MCPë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤. QodoëŠ” ê¸°ë³¸ì ìœ¼ë¡œ Git, Code Navigation, File System, Terminal ê³¼ ê°™ì€ MCPë¥¼ ë‚´ìž¥í•˜ê³  ìžˆìœ¼ë©°, í•„ìš”í•  ê²½ìš° ì¶”ê°€ MCPë¥¼ ì§ì ‘ í†µí•©í•˜ê±°ë‚˜ ê³µê°œ MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì—°ê²°í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. MCPëŠ” ì‹¤í–‰ í™˜ê²½ì— ë”°ë¼ Local MCP ì™€ Remote MCP ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. Local MCPëŠ” ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ ì—†ì´ ë¡œì»¬ í™˜ê²½ì—ì„œ ë°”ë¡œ ì‹¤í–‰ë˜ë©°, ì™¸ë¶€ API ì˜ì¡´ì„±ì´ ì—†ëŠ” ë¡œì§ ì²˜ë¦¬ì— ì í•©í•©ë‹ˆë‹¤. Remote MCPëŠ” ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ ì„ í˜¸ë˜ë©°, ì™¸ë¶€ ì„œë²„ì—ì„œ ì‹¤í–‰ë˜ê³  HTTPë¥¼ í†µí•´ Qodoì™€ ìƒí˜¸ìž‘ìš©í•©ë‹ˆë‹¤. Remote MCP ì„¤ì • ì‹œì—ëŠ” ì—”ë“œí¬ì¸íŠ¸ URLê³¼ í•¨ê»˜ ì¸ì¦ì— í•„ìš”í•œ ì»¤ìŠ¤í…€ HTTP í—¤ë”ë¥¼ ì§€ì •í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. Qodoì˜ ë¸”ë¡œê·¸ ì— ë”°ë¥´ë©´, Git MCPë¥¼ í™œìš©í•˜ì—¬ ì›ê²© ì €ìž¥ì†Œì˜ ìµœì‹  ë³€ê²½ ì‚¬í•­ì„ ì§ˆì˜í•˜ëŠ” ê³¼ì •ì´ ì†Œê°œë˜ì–´ ìžˆìŠµë‹ˆë‹¤. Qodoì˜ Agentic RAGëŠ” ë‹¨ìˆœížˆ ì»¤ë°‹ ë¡œê·¸ë§Œ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì½”ë“œë² ì´ìŠ¤ì˜ êµ¬ì¡°, ë³€ê²½ ì§‘í•©, í•„ìš” ì‹œ íŒŒì¼ ê°„ ì¢…ì†ì„±ê¹Œì§€ ë¶„ì„í•©ë‹ˆë‹¤. ë‹¤ì¤‘ ì„œë¹„ìŠ¤ ë ˆí¬ì§€í† ë¦¬ì—ì„œì˜ í™œìš© ìµœì‹  ë³€ê²½ ì‚¬í•­ì„ ìš”ì²­í•˜ë©´ QodoëŠ” ê´€ë ¨ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì»¤ë°‹ ìš”ì•½ì„ ì •ë¦¬í•´ ì œê³µí•©ë‹ˆë‹¤. ê¸°ë³¸ MCP í™˜ê²½ì´ êµ¬ì¶•ë˜ì–´ ì„œë¹„ìŠ¤ê°€ ë™ê¸°í™”ë˜ë©´, QodoëŠ” ë©€í‹° ì„œë¹„ìŠ¤ ë¦¬íŒ©í„°ë§ ì›Œí¬í”Œë¡œìš°ë¥¼ ì—ì´ì „íŠ¸ ì‹¤í–‰ ê³„ì¸µì„ í†µí•´ ìžë™í™”í•  ìˆ˜ ìžˆëŠ” í•œ ë‹¨ê³„ ë” ë‚˜ì•„ê°„ ìž‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë•Œ ëª©í‘œëŠ” auth-serviceì™€ billing-serviceì— ëŒ€í•œ ë¦¬íŒ©í„°ë§ ì»¤ë°‹ì„ ìƒì„±í•˜ê³ , í…ŒìŠ¤íŠ¸ì˜ ë¬´ê²°ì„±ì„ ìœ ì§€í•˜ë©°, ë³€ê²½ ë‚´ì—­ì„ ëª…í™•í•˜ê²Œ í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ Qodo Genì— ë‹¤ìŒê³¼ ê°™ì€ ì§€ì‹œê°€ ë‚´ë ¤ì§‘ë‹ˆë‹¤. â€œauth-service ì™€ billing-service ì „ë°˜ì— ê±¸ì³ ë¦¬íŒ©í„°ë§ ì»¤ë°‹ì„ ìƒì„±í•˜ê³ , ë³€ê²½ ì‚¬í•­ì„ ì„¤ëª…í•˜ë©°, í…ŒìŠ¤íŠ¸ê°€ ëª¨ë‘ í†µê³¼ë˜ë„ë¡ í•˜ë¼.â€ QodoëŠ” ì´ ìš”ì²­ì„ ë‹¤ë‹¨ê³„ ìžìœ¨ í”„ë¡œì„¸ìŠ¤ë¡œ í•´ì„í•©ë‹ˆë‹¤. ë¨¼ì € billing-serviceë¥¼ ìœ„í•œ í…ŒìŠ¤íŠ¸ í™˜ê²½ì„ ìžë™ìœ¼ë¡œ êµ¬ì¶•í•˜ë©°, requirements.txtì™€ test_billing.py íŒŒì¼ì„ ìƒì„±í•˜ì—¬ pytest ê²€ì¦ì´ ê°€ëŠ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ QodoëŠ” refactor_services.pyë¼ëŠ” ì¤‘ì•™ ì œì–´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìž‘ì„±í•©ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” RefactorAgentë¥¼ ë¡œë“œí•˜ì—¬ ì‹¤í–‰í•˜ë©°, Pythonì˜ subprocess ëª¨ë“ˆì„ í™œìš©í•œ run_tests() ë©”ì„œë“œë¥¼ ì •ì˜í•˜ì—¬ ê° ì„œë¹„ìŠ¤ë³„ í…ŒìŠ¤íŠ¸ë¥¼ ìžë™í™”í•  ìˆ˜ ìžˆë„ë¡ ì„¤ê³„ë©ë‹ˆë‹¤. ì´í›„ ë³€ê²½ ì‚¬í•­ì€ ê¸°ëŠ¥ ë¸Œëžœì¹˜ì— ë™ê¸°í™”ë˜ê³ , ë©”ì¸ ë¸Œëžœì¹˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ Pull Request(PR) ê°€ ìžë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤. ì•„ìš¸ëŸ¬ QodoëŠ” ë¦¬ë·°ì–´ë¥¼ ìœ„í•´ PR Reviewer Guide ë¥¼ ì œê³µí•˜ë©°, ì—¬ê¸°ì—ëŠ” ë¦¬ë·° ë‚œì´ë„(ì˜ˆ: 4/5), í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ì¸, ë³´ì•ˆ ì´ìŠˆ íƒì§€ ê²°ê³¼ê°€ í¬í•¨ë©ë‹ˆë‹¤. íŠ¹ížˆ í•˜ë“œì½”ë”©ëœ SECRET_KEY, MD5 í•´ì‹œ ì‚¬ìš©, í‰ë¬¸ ì‹ ìš©ì¹´ë“œ ì €ìž¥ê³¼ ê°™ì€ ë¬¸ì œë¥¼ ì¡°ê¸°ì— ê°ì§€í•˜ë©°, ë™ì  ëª¨ë“ˆ ìž„í¬íŠ¸ ìƒí™©ì—ì„œ ë°œìƒí•  ìˆ˜ ìžˆëŠ” ìž ìž¬ì  ì˜¤íƒì§€ ê°€ëŠ¥ì„±ë„ í•¨ê»˜ ì•ˆë‚´í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ QodoëŠ” ì—ì´ì „íŠ¸ ê¸°ë°˜ ë¦¬íŒ©í„°ë§ íŒŒì´í”„ë¼ì¸ ì„ ë‹¤ì´ì–´ê·¸ëž¨ í˜•íƒœë¡œ ì œê³µí•©ë‹ˆë‹¤. ì´ ë‹¤ì´ì–´ê·¸ëž¨ì€ Demo Script, RefactorAgent, RefactoringEngine ê°„ì˜ ìƒí˜¸ìž‘ìš©ì„ ë‹¨ê³„ë³„ë¡œ ë‚˜íƒ€ë‚´ë©°, API ë²„ì „ ê´€ë¦¬, ë¶ˆí•„ìš”í•œ ì½”ë“œ ì œê±°, ì˜ì¡´ì„± ì£¼ìž…ê³¼ ê°™ì€ í•µì‹¬ ë¦¬íŒ©í„°ë§ ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ QodoëŠ” ë‹¨ìˆœí•œ ì½”ë“œ ìˆ˜ì • ë‹¨ê³„ë¥¼ ë„˜ì–´, ì—ì´ì „íŠ¸ì™€ MCP ê¸°ë°˜ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ê³„íšì ì´ê³  ìžìœ¨ì ì¸ ë¦¬íŒ©í„°ë§ í”„ë¡œì„¸ìŠ¤ ë¥¼ êµ¬í˜„í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ Qodo Agentic RAGì˜ ê°•ì  ì „í†µì ì¸ RAG(ê²€ìƒ‰-ì‘ë‹µ ìƒì„±) ì‹œìŠ¤í…œì€ ì²­í¬ ë°©ì‹ì´ë‚˜ ê²€ìƒ‰ ê²½ë¡œê°€ ê³ ì •ë˜ì–´ ìžˆëŠ” ê²½í–¥ì´ ìžˆìœ¼ë©°, ì¢…ì¢… ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •ëœ í”„ë¡¬í”„íŠ¸ë‚˜ í•„í„°ì— ì˜ì¡´í•˜ëŠ” í•œê³„ê°€ ìžˆìŠµë‹ˆë‹¤. ë°ì´í„°ì˜ í˜•íƒœê°€ ì •í˜•í™”ë˜ì–´ ìžˆì§€ ì•Šê±°ë‚˜ í™œìš© ë²”ìœ„ì™€ ì§€ì‹ ê¸°ë°˜ì´ ë„“ì–´ì§€ëŠ” ê²½ìš°, ì´ëŸ¬í•œ ë°©ì‹ì€ íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘í•˜ì§€ ëª»í•  ë•Œê°€ ë§ŽìŠµë‹ˆë‹¤. Qodoì˜ Agentic RAGëŠ” ê¸°ì¡´ì˜ ê²€ìƒ‰ ë°©ì‹ì´ ê°€ì§€ëŠ” í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ê²€ìƒ‰ ê³¼ì •ì„ ê³ ì •ëœ ë‹¨ê³„ê°€ ì•„ë‹ˆë¼ ì—ì´ì „íŠ¸ì˜ ì¶”ë¡  ê³¼ì • ë‚´ì—ì„œ ìœ ë™ì ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ì–»ì€ ì •ë³´ì™€ ì‹œë„ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ê²€ìƒ‰ ì „ëžµì„ ì¡°ì •í•˜ê³ , í•„ìš”í•˜ë‹¤ë©´ ê²€ìƒ‰ì„ ë°˜ë³µí•´ í™ë³´í•˜ëŠ” ìµœì ì˜ ë§¥ë½ì„ ì°¾ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ ë³µìž¡í•œ ì½”ë“œ ë¦¬ë·°ë‚˜ ë ˆê±°ì‹œ ì‹œìŠ¤í…œì˜ ë””ë²„ê¹…ê³¼ ê°™ì€ ì–´ë ¤ìš´ ìž‘ì—…ì— ì í•©í•©ë‹ˆë‹¤. ë˜í•œ QodoëŠ” ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ ìš”êµ¬ë˜ëŠ” ì œì–´ë ¥ê³¼ ë¬¸ë§¥ ê´€ë¦¬ ëŠ¥ë ¥ ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ RAG ì†ŒìŠ¤(ì˜ˆ: íŒŒì¸íŠœë‹ëœ ìž„ë² ë”©, ì„¤ê³„ ë¬¸ì„œ, ì˜¨ë³´ë”© ìœ„í‚¤ ë“±)ë¥¼ ë™ì‹œì— êµ¬ì„±í•  ìˆ˜ ìžˆìœ¼ë©°, ê° ì†ŒìŠ¤ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì„¤ì •í•˜ì—¬ ìƒí™©ì— ë§žê²Œ í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê¸°ì—… ë‚´ ì£¼ìš” ê¸°ìˆ  ë¦¬ë”ë“¤ì´ ë°˜ë³µì ì¸ ë¦¬ë·° ìž‘ì—…ì— ì†Œëª¨í•˜ëŠ” ì‹œê°„ì„ ì¤„ì´ê³ , MCP ê¸°ë°˜ì˜ ëª¨ë“ˆí˜• ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•´ í‘œì¤€í™”ëœ ê²€ì¦ ë° ë¦¬íŒ©í„°ë§ í”„ë¡œì„¸ìŠ¤ë¥¼ í™•ë¦½í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë§ˆë¬´ë¦¬ Agentic RAGëŠ” ë‹¨ìˆœí•œ ê¸°ëŠ¥ í–¥ìƒì„ ë„˜ì–´ì„œ ë¬¸ë§¥ ì¤‘ì‹¬ì˜ AI ì‹œìŠ¤í…œìœ¼ë¡œì˜ ë³¸ì§ˆì ì¸ ë³€í™”ìž…ë‹ˆë‹¤. ì´ëŠ” ì •ì ì¸ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ë„˜ì–´, ì‹¤ì œ ê¸°ì—… í™˜ê²½ì—ì„œ ë°œìƒí•˜ëŠ” ë³µìž¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìžˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë¶„ì‚°ë˜ì–´ ìžˆê³  ëª©í‘œê°€ ëª…í™•í•˜ì§€ ì•Šì€ ìƒí™©ì—ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘í•  ìˆ˜ ìžˆëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìžˆìŠµë‹ˆë‹¤. Qodoì˜ êµ¬í˜„ ë°©ì‹ì€ ì´ëŸ¬í•œ ë³€í™”ë¥¼ ì‹¤ì§ˆì ìœ¼ë¡œ ì§€ì›í•˜ë©°, ë‹¤ì¤‘ ì„œë¹„ìŠ¤ ë””ë²„ê¹…, ë¦¬íŒ©í„°ë§ ìžë™í™”, í…ŒìŠ¤íŠ¸ ê²€ì¦ì´ í¬í•¨ëœ PR ê°€ì´ë“œ ìƒì„± ë“± ì—¬ëŸ¬ ì—”í„°í”„ë¼ì´ì¦ˆ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë†’ì€ í™œìš©ë„ë¥¼ ë³´ìž…ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ Qodo Agentic RAGëŠ” ëŒ€ê·œëª¨ ì¡°ì§ì´ í•„ìš”ë¡œ í•˜ëŠ” ìœ ì—°ì„±, ì ì‘ì„± ë° ì‹ ë¢°ì„±ì„ ë™ì‹œì— ë§Œì¡±ì‹œí‚¤ëŠ” ìµœì ì˜ ì†”ë£¨ì…˜ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤. ì •ì  RAGë¡œëŠ” í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ê¸°ì—… ë°ì´í„° ê´€ë¦¬ ë¬¸ì œ, Qodo Agentic RAGë¥¼ í†µí•´ ë‹¤ì¤‘ ì†ŒìŠ¤ ê²€ìƒ‰ê³¼ ìžë™í™”ëœ ê²€ì¦ì„ ê²½í—˜í•˜ì„¸ìš”. ìžì„¸ížˆ ì•Œì•„ë³´ê¸° AI &amp; ML Engineering Qodo Tanya Ilieva Latest Posts AIê°€ ì¼í•˜ê²Œ ë§Œë“œëŠ” ê¸°ìˆ , MCP í•œ ë²ˆ... [truncated]
   â””â”€ [https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037]
      Preview: Error: HTTP 403 for URL: https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
ðŸ“– Read URL: https://www.linkedin.com/posts/alexxubyte_systemde... (8015 chars)
   â””â”€ [https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J]
      Preview: RAG vs Agentic RAG: How AI Agents Improve Answers | Alex Xu posted on the topic | LinkedIn Agree & Join LinkedIn By clicking Continue to join or sign in, you agree to LinkedInâ€™s User Agreement , Privacy Policy , and Cookie Policy . Skip to main content LinkedIn Top Content People Learning Jobs Games Join now Sign in RAG vs Agentic RAG: How AI Agents Improve Answers Alex Xu 5mo Report this post RAG vs Agentic RAG RAG (Retrieval Augmented Generation) is a method that combines information retrieval with large language models to generate answers. Hereâ€™s how RAG works on a high level: 1 - The model retrieves relevant data from data sources and then extracts it to a vector database from the pre-indexed model. 2 - Augment the prompts by retrieving information and merging it with the query prompt. 3 - A Large Language Model (like GPT, Claude, or Gemini) understands the combined query and generates the final response. A traditional RAG has a simple retrieval, limited adaptability, and relies on static knowledge, making it less flexible for dynamic and real-time information. Agentic RAG improves on this by introducing AI agents that can make decisions, select tools, and even refine queries for more accurate and flexible responses. Hereâ€™s how Agentic RAG works on a high level: 1 - The user query is directed to an AI Agent for processing. 2 - The agent uses short-term and long-term memory to track query context. It also formulates a retrieval strategy and selects appropriate tools for the job. 3 - The data fetching process can use tools such as vector search, multiple agents, and MCP servers to gather relevant data from the knowledge base. 4 - The agent then combines retrieved data with a query and system prompt. It passes this data to the LLM. 5 - LLM processes the optimized input to answer the userâ€™s query. Over to you: What else will you add to better understand RAG vs Agentic RAG? -- Subscribe to our weekly newsletter to get a Free System Design PDF (158 pages): https://bit.ly/bbg-social #systemdesign #coding #interviewtips . 9,249 377 Comments Like Comment Share Copy LinkedIn Facebook X Ritheesh T 5mo Report this comment Agentic RAG is going to be huge. Traditional RAG was already a game changer, but giving AI agents memory, decision-making, and tool orchestration takes it to the next level. It opens doors to dynamic multi-hop reasoning, real-time adaptability, and truly autonomous data workflows. Like Reply 31&nbsp;Reactions 32&nbsp;Reactions Aishwarya Srinivasan 5mo Report this comment Always great resources! CFBR Like Reply 9&nbsp;Reactions 10&nbsp;Reactions Mohit Anand 5mo Report this comment Fully agree but i think RAG is messy. Fine-tuning is expensive. And both are outdated â€” too slow, too complex, too resource-heavy. TOXO is the new hero. A smart behavior layer that sits on top of any LLM or API and converts them into C.A.L.M. (Context Augmented Language Model) No GPUs. No ML expertise. Just train it with plain English or your own data. It learns how you think â€” and feels fine-tuned without the pain. No infra. No code. Just alignment â€” in minutes. Like Reply 2&nbsp;Reactions 3&nbsp;Reactions Bajer Lin 5mo Report this comment Anyone know how these graphics are created. Its very impressive. Like Reply 1&nbsp;Reaction LEONARDO SANCHEZ NIÃ‘O 5mo Report this comment The approach you describe about RAG vs Agentic RAG is well structured and captures the key differences between both methods. Traditional RAG, while useful, has limitations in adaptability and handling dynamic information. Agentic RAG represents a natural evolution toward more intelligent systems. However, it's worth considering other modern alternatives like the Model Context Protocol (MCP). MCP offers a complementary approach. Instead of relying on static vector databases, MCP allows models to connect directly with applications and services in real-time - accessing APIs, databases, and tools more dynamically. What makes MCP interesting is that it doesn't just retrieve information but can interact with external systems, execute code, and modify data as needed. The future probably isn't about choosing between RAG, Agentic RAG, or MCP, but combining these approaches intelligently in hybrid systems where: MCP handles real-time connections with external services The agentic component makes decisions about tools and query processing Traditional RAG remains useful for well-indexed static knowledge What do you think about this perspective? Have you experimented with any of these approaches? Like Reply 1&nbsp;Reaction Rasheed H. Ali 5mo Report this comment What is ReAct I'll have to search about that one. Like Reply 1&nbsp;Reaction 2&nbsp;Reactions Naresh Sharma 5mo Report this comment The second diagram is not quite accurate â€” it labels the central agent as an "Aggregator Agent", but it should actually be called an "Orchestrator Agent." This is important because, under the Model Context Protocol (MCP), that central agent does far more than aggregate results. It plans, routes, and delegates tasks to the appropriate Task-Agents, then evaluates the outputs, and may pass results forward as inputs to other agents. This flow is orchestrated, not simply aggregated. It's not a minor nuance â€” the difference reflects the actual architecture and intelligence behind MCP systems. The orchestrator is what enables contextual reasoning, chaining, and decision-making across agents and memory modules. Like Reply 1&nbsp;Reaction Aditya Prashant Dawadikar 5mo Report this comment Recently we developed an Agentic RAG with Vapi's voice AI agent, Google's Gemini 2.5 as a summarizer and aggregator for embeddings stored in Pinecone. Idea was simple. Just query the DOM tree, extract text, save into vector database to be used later. We called it SAGE AI, and it can be used as a browser extension to memorize those interesting articles/research papers that you would want to discuss later... Agentic RAGs are simple to understand, and the LLMs do a lot of heavy lifting for you. As an architect and developer, all i had to do was put the peaces together ðŸ¤·â™‚ï¸ Like Reply 1&nbsp;Reaction 2&nbsp;Reactions Gabriel B. 5mo Report this comment discussion of chunking would be another good addition to the flow! Like Reply 1&nbsp;Reaction See more comments To view or add a comment, sign in More Relevant Posts xAIgent 17 followers 2mo Edited Report this post Retrieval augmented generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. " One of AI's most compelling use cases is managing the overwhelming volume of unstructured, poorly tagged data that organizations accumulate. Many companies sit on tens of billions of files - documents, emails, images, logs, - with no effective way to categorize or retrieve them. AI can: - Automate metadata tagging at a scale impossible for humans - Improve findability - Identify redundant or obsolete data " With this in mind we continue the nine-part series on optimizing RAG - here's Part III... Part III. Enhancing the Query Formulation Process One of the challenges in RAG systems is formulating effective queries that retrieve relevant data. xAIgent assists in this process by transforming user input into optimized queries using relevant keyphrases and keywords. This improves the retrieval componentâ€™s performance by generating more specific and contextually relevant queries based on the input. Better-formulated queries ensure that the generation component has access to the most pertinent information, leading to more accurate and informative responses. Making Trusted Content Findable. Full xAIgent details - https://xAIgent.net For an online demo of how you might approach optimizing Large Language Models (LLM's) =... [truncated]
ðŸ”¬ Analyzer [3]: Analyzing 5 results, 9 contents

ðŸ”¬ Analyzer: Max iterations reached, proceeding to Writer

ðŸ”¬ Analyzer [3]: Analyzed 5 results, 9 contents
   â””â”€ New findings:
      [1] RAGì€ ì •ì ì¸ ì½˜í…ì¸ ì— ì í•©í•˜ê³  Agentic RAGëŠ” ëª©í‘œ ê¸°ë°˜ ì¶”ë¡ ì´ í•„ìš”í•  ë•Œ ì í•©í•˜ë‹¤.
      [2] RAGëŠ” LLMì— ì¶”ê°€ ì§€ì‹ì„ ì œê³µí•˜ëŠ” ë°˜ë©´, AI ì—ì´ì „íŠ¸ëŠ” ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ê³  ìž‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ ê´€ë¦¬ìžì™€ ê°™ë‹¤.
      [3] RAGëŠ” ê²€ìƒ‰ ê¸°ë°˜ ì¦ê°• ê¸°ìˆ ì´ê³  AI ì—ì´ì „íŠ¸ëŠ” ê²€ìƒ‰ ì´ìƒì˜ êµ¬ì¡°í™”ëœ ì‹¤í–‰ì„ ìˆ˜í–‰í•œë‹¤. RAGëŠ” AI ì—ì´ì „íŠ¸ì˜ ë„êµ¬ë¡œ ì‚¬ìš©ë  ìˆ˜ ìžˆë‹¤.
      [4] RAGëŠ” ë¹ ë¥¸ ìŠ¹ë¦¬ì— ê°€ìž¥ ì í•©í•˜ê³  ì—ì´ì „íŠ¸ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì— ê°€ìž¥ ì í•©í•˜ë‹¤. ë¯¸ì„¸ ì¡°ì •ì€ ì•ˆì •ì„±ì—, RAGëŠ” ì ì‘ì„±ì—, ì—ì´ì „íŠ¸ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì— ì í•©í•˜ë‹¤.
      [5] RAGëŠ” ê°„ë‹¨í•œ ê²€ìƒ‰ ìž‘ì—…ì— ì í•©í•˜ê³  Agentic RAGëŠ” ë³µìž¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ë” ì í•©í•˜ë‹¤.
   â””â”€ Decision: Research complete (20 total findings)

ðŸ“¦ Compress: Compressing 20 findings, 9 contents
   â””â”€ Compressed to 3679 chars (from ~6056 raw chars)
   â””â”€ Sources cited: 8
   â””â”€ Preview:
      ## Key Findings
      - RAG is suitable for static content, while Agentic RAG is better for goal-oriented reasoning [1, 5].
      - RAG provides LLMs with additional knowledge, whereas AI agents manage decision-making and task execution [2, 12].
      - Agentic RAG excels at extracting information from vast, unstructured data and solving problems [7, 17].
      - Agentic RAG can reduce LLM call costs and latency through semantic caching and advanced memory systems [9, 19].
      - RAG is limited to document-based information and struggles with real-time or dynamic data [10, 20].
      
      ## Detailed Information
      
      **RAG vs. Agentic RAG: Use Cases and Capabilities**
      
      RAG (Retrieval-Augmented Generation) is well-suited for static content [1, 11] and simple search tasks [5, 15]. In contrast, Agentic RAG is more appropriate when goal-based reasoning is required [1, 11] and for complex, multi-stage processes [5, 15]. RAG is optimized for quick wins, while agents are better suited for orchestration [4, 14].
      
      RAG provides LLMs with additional knowledge, acting like equipping an LLM with memory [2, 6, 12, 16]. AI agents, on the other hand, function as project managers, making decisions and performing tasks [2, 12], essentially giving the LLM limbs [6, 16]. RAG is a search-based augmentation technique, while AI agents perform structured execution beyond simple search [3, 13].  RAG can serve as a tool within AI agent workflows [3, 13].
      
      **Agentic RAG: Advanced Problem Solving**
      
      Agentic RAG is effective at extracting desired information and solving problems from large volumes of unstructured data [7, 17]. It can orchestrate multiple tools to handle complex issues [8, 18]. Agentic RAG leverages semantic caching and advanced memory systems to decrease LLM call costs and latency [9, 19].
      
      **Limitations of RAG**
      
      RAG is confined to document-based information and has limitations in providing real-time or dynamically changing data [10, 20].
      
      ## Sources
      [1] https://osckorea.tistory.com/332
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [4] https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/
      [5] https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/
      [6] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [7] https://www.slexn.com/agentic-rag-contextual-ai/
      [8] https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC
      [9] https://osckorea.tistory.com/332
      [10] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [11] https://osckorea.tistory.com/332
      [12] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [13] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [14] https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/
      [15] https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/
      [16] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [17] https://www.slexn.com/agentic-rag-contextual-ai/
      [18] https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC
      [19] https://osckorea.tistory.com/332
      [20] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037

âœï¸ Writer: Composing response from 20 findings
   â””â”€ Using compressed notes (3679 chars)

âœï¸ Writer: Generated response (4506 chars)
   â””â”€ Sources used:
      [1] https://osckorea.tistory.com/332
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
   â””â”€ Response preview:
      ## í•µì‹¬ ìš”ì•½
      
      RAG(Retrieval-Augmented Generation)ëŠ” ì •ì ì¸ ì½˜í…ì¸ ì— ì í•©í•˜ë©°, Agent ê¸°ë°˜ ì ‘ê·¼ë²•(Agentic RAG)ì€ ëª©í‘œ ì§€í–¥ì ì¸ ì¶”ë¡ ì´ í•„ìš”í•œ ë³µìž¡í•œ ë¬¸ì œ í•´ê²°ì— ë” ì í•©í•©ë‹ˆë‹¤. Agentic RAGëŠ” RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  LLMì˜ í™œìš©ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
      
      ## ì£¼ìš” ë°œê²¬ ì‚¬í•­
      
      *   RAGëŠ” ì •ì ì¸ ì½˜í…ì¸ ì™€ ê°„ë‹¨í•œ ê²€ìƒ‰ ìž‘ì—…ì— ì í•©í•œ ë°˜ë©´, Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ëª©í‘œ ê¸°ë°˜ ì¶”ë¡  ë° ë³µìž¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ë” ì í•©í•©ë‹ˆë‹¤ [1, 5].
      *   RAGëŠ” LLMì— ì¶”ê°€ì ì¸ ì§€ì‹ì„ ì œê³µí•˜ëŠ” ë°˜ë©´, AI ì—ì´ì „íŠ¸ëŠ” ì˜ì‚¬ ê²°ì • ë° ìž‘ì—… ì‹¤í–‰ì„ ê´€ë¦¬í•©ë‹ˆë‹¤ [2, 12].
      *   Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ë°©ëŒ€í•œ ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° íƒì›”í•©ë‹ˆë‹¤ [7, 17].
      *   Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ì‹œë§¨í‹± ìºì‹± ë° ê³ ê¸‰ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í†µí•´ LLM í˜¸ì¶œ ë¹„ìš©ê³¼ ì§€ì—° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [9, 19].
      *   RAGëŠ” ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ì— êµ­í•œë˜ì–´ ìžˆìœ¼ë©° ì‹¤ì‹œê°„ ë˜ëŠ” ë™ì  ë°ì´í„° ì²˜ë¦¬ì—ëŠ” ì–´ë ¤ì›€ì´ ìžˆìŠµë‹ˆë‹¤ [10, 20].
      
      ## ìƒì„¸ ë¶„ì„
      
      RAGì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ Large Language Model (LLM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë‘ ê°€ì§€ ì£¼ìš” ë°©ë²•ë¡ ìž…ë‹ˆë‹¤. ê°ê°ì˜ ìž‘ë™ ë°©ì‹ê³¼ ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
      
      **RAG (Retrieval-Augmented Generation):**
      
      *   **ìž‘ë™ ë°©ì‹:** RAGëŠ” LLMì´ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ì „ì— ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•˜ëŠ” ë°©ì‹ìž…ë‹ˆë‹¤. ì¦‰, LLMì€ ì™¸ë¶€ ì§€ì‹ ì €ìž¥ì†Œ(ì˜ˆ: ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤)ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ [2, 6, 12, 16]. LLMì— ê¸°ì–µì„ ì‹¬ì–´ì£¼ëŠ” ê²ƒê³¼ ìœ ì‚¬í•˜ê²Œ ìž‘ë™í•©ë‹ˆë‹¤.
      *   **ìž¥ì :**
          *   êµ¬í˜„ì´ ë¹„êµì  ê°„ë‹¨í•˜ê³  ë¹ ë¦…ë‹ˆë‹¤.
          *   ì •ì  ì½˜í…ì¸ ì— ëŒ€í•œ ì§ˆë¬¸ ì‘ë‹µì— íš¨ê³¼ì ìž…ë‹ˆë‹¤.
          *   ê¸°ì¡´ LLMì˜ ì§€ì‹ ë¶€ì¡± ë¬¸ì œë¥¼ ë³´ì™„í•©ë‹ˆë‹¤.
      *   **ë‹¨ì :**
          *   ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ì— êµ­í•œë©ë‹ˆë‹¤ [10, 20].
          *   ì‹¤ì‹œê°„ ë°ì´í„°ë‚˜ ë™ì ìœ¼ë¡œ ë³€í™”í•˜ëŠ” ì •ë³´ì— ëŒ€í•œ ì²˜ë¦¬ê°€ ì–´ë µìŠµë‹ˆë‹¤ [10, 20].
          *   ë³µìž¡í•œ ì¶”ë¡ ì´ë‚˜ ë‹¤ë‹¨ê³„ ì˜ì‚¬ ê²°ì •ì´ í•„ìš”í•œ ìž‘ì—…ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
          *   ê²€ìƒ‰ëœ ì •ë³´ì˜ í’ˆì§ˆì— ë”°ë¼ ë‹µë³€ì˜ ì •í™•ë„ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
      
      **Agent ê¸°ë°˜ ì ‘ê·¼ë²• (Agentic RAG):**
      
      *   **ìž‘ë™ ë°©ì‹:** AI ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ LLMì´ ìž‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ê´€ë¦¬í•˜ëŠ” ë°©ì‹ìž…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ê³„íšì„ ì„¸ìš°ê³ , í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•˜ë©°, ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤ [2, 12]. RAGëŠ” Agent ì›Œí¬í”Œë¡œìš° ë‚´ì—ì„œ ë„êµ¬ë¡œ ì‚¬ìš©ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [3, 13].  AgentëŠ” í”„ë¡œì íŠ¸ ê´€ë¦¬ìžì™€ ìœ ì‚¬í•˜ê²Œ LLMì—ê²Œ íŒ”ë‹¤ë¦¬ë¥¼ ì œê³µí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤ [6, 16].
      *   **ìž¥ì :**
          *   ë³µìž¡í•œ ì¶”ë¡  ë° ë‹¤ë‹¨ê³„ ì˜ì‚¬ ê²°ì •ì´ í•„ìš”í•œ ë¬¸ì œ í•´ê²°ì— ì í•©í•©ë‹ˆë‹¤ [1, 11].
          *   ë°©ëŒ€í•œ ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤ [7, 17].
          *   ì‹œë§¨í‹± ìºì‹± ë° ê³ ê¸‰ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í†µí•´ LLM í˜¸ì¶œ ë¹„ìš© ë° ì§€ì—° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [9, 19].
          *   ì—¬ëŸ¬ ë„êµ¬ë¥¼ í†µí•©í•˜ì—¬ ë³µìž¡í•œ ìž‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [8, 18].
      *   **ë‹¨ì :**
          *   êµ¬í˜„ì´ ë³µìž¡í•˜ê³  ê°œë°œ ë¹„ìš©ì´ ë†’ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
          *   ì‹œìŠ¤í…œ ì„¤ê³„ ë° ì—ì´ì „íŠ¸ ì •ì˜ì— ëŒ€í•œ ê¹Šì€ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤.
          *   RAGë³´ë‹¤ ë” ë§Žì€ ê³„ì‚° ìžì›ì„ í•„ìš”ë¡œ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
      
      **ì–¸ì œ ì–´ë–¤ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œìš”?**
      
      *   **RAG:**
          *   ì •ì ì¸ ì§€ì‹ ê¸°ë°˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ë•Œ
          *   ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ê°œë°œ ë˜ëŠ” PoC (Proof of Concept)ë¥¼ ìˆ˜í–‰í•  ë•Œ
          *   ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ë‚˜ ë³µìž¡í•œ ì¶”ë¡ ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°
      *   **Agent ê¸°ë°˜ ì ‘ê·¼ë²•:**
          *   ë³µìž¡í•œ ë¬¸ì œ í•´ê²° ë° ë‹¤ë‹¨ê³„ ì˜ì‚¬ ê²°ì • í”„ë¡œì„¸ìŠ¤ë¥¼ ìžë™í™”í•´ì•¼ í•  ë•Œ
          *   ë°©ëŒ€í•œ ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¶„ì„í•´ì•¼ í•  ë•Œ
          *   LLM í˜¸ì¶œ ë¹„ìš© ë° ì§€ì—° ì‹œê°„ì„ ìµœì í™”í•´ì•¼ í•  ë•Œ
          *   ë‹¤ì–‘í•œ ë„êµ¬ì™€ ì„œë¹„ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ LLMì˜ ê¸°ëŠ¥ì„ í™•ìž¥í•´ì•¼ í•  ë•Œ
      
      Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  LLMì˜ ìž ìž¬ë ¥ì„ ìµœëŒ€í•œ ë°œíœ˜í•  ìˆ˜ ìžˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. íŠ¹ížˆ, Agentic RAGëŠ” ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œ, ì²˜ë¦¬ ë° ì‚¬ìš©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìžˆë„ë¡ LLMì„ ì§€ì›í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸ˆìœµ ë³´ê³ ì„œ ë¶„ì„, ê³ ê° ì„œë¹„ìŠ¤ ìžë™í™”, ì—°êµ¬ ë°ì´í„° ë¶„ì„ ë“± ë³µìž¡í•œ ìž‘ì—…ì— ì í•©í•©ë‹ˆë‹¤. RAGê°€ ê°„ë‹¨í•œ ì •ë³´ ê²€ìƒ‰ì— ìœ ìš©í•œ ë°˜ë©´, Agentic RAGëŠ” ë³µìž¡í•œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤ [4, 14].
      
      ## ê´€ë ¨ ìžë£Œ ë° ì¶œì²˜
      
      [1] https://osckorea.tistory.com/332
      [2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [3] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [4] https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/
      [5] https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/
      [6] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [7] https://www.slexn.com/agentic-rag-contextual-ai/
      [8] https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC
      [9] https://osckorea.tistory.com/332
      [10] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [11] https://osckorea.tistory.com/332
      [12] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      [13] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
      [14] https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/
      [15] https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/
      [16] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
      [17] https://www.slexn.com/agentic-rag-contextual-ai/
      [18] https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC
      [19] https://osckorea.tistory.com/332
      [20] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
      
      ## ê²°ë¡  ë° í‰ê°€
      
      RAGì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ê°ê° ê³ ìœ í•œ ìž¥ë‹¨ì ì„ ê°€ì§€ê³  ìžˆìœ¼ë©°, ì‚¬ìš© ì‚¬ë¡€ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ì†”ë£¨ì…˜ì´ í•„ìš”í•˜ë‹¤ë©´ RAGê°€ ì í•©í•˜ì§€ë§Œ, ë³µìž¡í•˜ê³  ì§€ëŠ¥ì ì¸ ìžë™í™”ê°€ í•„ìš”í•˜ë‹¤ë©´ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì´ ë” ë‚˜ì€ ì„ íƒìž…ë‹ˆë‹¤. Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ LLMì˜ í™œìš© ë²”ìœ„ë¥¼ ë„“ížˆê³  ë” ê°•ë ¥í•œ AI ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì•žìœ¼ë¡œ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ë”ìš± ë°œì „í•˜ì—¬ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì´ëŒì–´ë‚¼ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

â”Œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ Phase 3 Benchmark Result
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Query: RAG(Retrieval-Augmented Generation)ì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ê³¼ ê°ê° ì–¸...
â”‚ Time: 48.8s
â”‚ LLM Calls: 2
â”‚ Search Calls: 3
â”‚ URLs Read: 9
â”‚ Iterations: 3
â”‚ Est. Tokens: 1581
â”‚ Response Length: 4506 chars
â”‚ Has Citations: âœ…
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


======================================================================
ðŸ“„ FULL RESPONSE:
======================================================================
## í•µì‹¬ ìš”ì•½

RAG(Retrieval-Augmented Generation)ëŠ” ì •ì ì¸ ì½˜í…ì¸ ì— ì í•©í•˜ë©°, Agent ê¸°ë°˜ ì ‘ê·¼ë²•(Agentic RAG)ì€ ëª©í‘œ ì§€í–¥ì ì¸ ì¶”ë¡ ì´ í•„ìš”í•œ ë³µìž¡í•œ ë¬¸ì œ í•´ê²°ì— ë” ì í•©í•©ë‹ˆë‹¤. Agentic RAGëŠ” RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  LLMì˜ í™œìš©ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

## ì£¼ìš” ë°œê²¬ ì‚¬í•­

*   RAGëŠ” ì •ì ì¸ ì½˜í…ì¸ ì™€ ê°„ë‹¨í•œ ê²€ìƒ‰ ìž‘ì—…ì— ì í•©í•œ ë°˜ë©´, Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ëª©í‘œ ê¸°ë°˜ ì¶”ë¡  ë° ë³µìž¡í•œ ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ì— ë” ì í•©í•©ë‹ˆë‹¤ [1, 5].
*   RAGëŠ” LLMì— ì¶”ê°€ì ì¸ ì§€ì‹ì„ ì œê³µí•˜ëŠ” ë°˜ë©´, AI ì—ì´ì „íŠ¸ëŠ” ì˜ì‚¬ ê²°ì • ë° ìž‘ì—… ì‹¤í–‰ì„ ê´€ë¦¬í•©ë‹ˆë‹¤ [2, 12].
*   Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ë°©ëŒ€í•œ ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° íƒì›”í•©ë‹ˆë‹¤ [7, 17].
*   Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ì‹œë§¨í‹± ìºì‹± ë° ê³ ê¸‰ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í†µí•´ LLM í˜¸ì¶œ ë¹„ìš©ê³¼ ì§€ì—° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [9, 19].
*   RAGëŠ” ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ì— êµ­í•œë˜ì–´ ìžˆìœ¼ë©° ì‹¤ì‹œê°„ ë˜ëŠ” ë™ì  ë°ì´í„° ì²˜ë¦¬ì—ëŠ” ì–´ë ¤ì›€ì´ ìžˆìŠµë‹ˆë‹¤ [10, 20].

## ìƒì„¸ ë¶„ì„

RAGì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ Large Language Model (LLM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë‘ ê°€ì§€ ì£¼ìš” ë°©ë²•ë¡ ìž…ë‹ˆë‹¤. ê°ê°ì˜ ìž‘ë™ ë°©ì‹ê³¼ ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

**RAG (Retrieval-Augmented Generation):**

*   **ìž‘ë™ ë°©ì‹:** RAGëŠ” LLMì´ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ì „ì— ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•˜ëŠ” ë°©ì‹ìž…ë‹ˆë‹¤. ì¦‰, LLMì€ ì™¸ë¶€ ì§€ì‹ ì €ìž¥ì†Œ(ì˜ˆ: ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤)ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ [2, 6, 12, 16]. LLMì— ê¸°ì–µì„ ì‹¬ì–´ì£¼ëŠ” ê²ƒê³¼ ìœ ì‚¬í•˜ê²Œ ìž‘ë™í•©ë‹ˆë‹¤.
*   **ìž¥ì :**
    *   êµ¬í˜„ì´ ë¹„êµì  ê°„ë‹¨í•˜ê³  ë¹ ë¦…ë‹ˆë‹¤.
    *   ì •ì  ì½˜í…ì¸ ì— ëŒ€í•œ ì§ˆë¬¸ ì‘ë‹µì— íš¨ê³¼ì ìž…ë‹ˆë‹¤.
    *   ê¸°ì¡´ LLMì˜ ì§€ì‹ ë¶€ì¡± ë¬¸ì œë¥¼ ë³´ì™„í•©ë‹ˆë‹¤.
*   **ë‹¨ì :**
    *   ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ì— êµ­í•œë©ë‹ˆë‹¤ [10, 20].
    *   ì‹¤ì‹œê°„ ë°ì´í„°ë‚˜ ë™ì ìœ¼ë¡œ ë³€í™”í•˜ëŠ” ì •ë³´ì— ëŒ€í•œ ì²˜ë¦¬ê°€ ì–´ë µìŠµë‹ˆë‹¤ [10, 20].
    *   ë³µìž¡í•œ ì¶”ë¡ ì´ë‚˜ ë‹¤ë‹¨ê³„ ì˜ì‚¬ ê²°ì •ì´ í•„ìš”í•œ ìž‘ì—…ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    *   ê²€ìƒ‰ëœ ì •ë³´ì˜ í’ˆì§ˆì— ë”°ë¼ ë‹µë³€ì˜ ì •í™•ë„ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

**Agent ê¸°ë°˜ ì ‘ê·¼ë²• (Agentic RAG):**

*   **ìž‘ë™ ë°©ì‹:** AI ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ LLMì´ ìž‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ê´€ë¦¬í•˜ëŠ” ë°©ì‹ìž…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ê³„íšì„ ì„¸ìš°ê³ , í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•˜ë©°, ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤ [2, 12]. RAGëŠ” Agent ì›Œí¬í”Œë¡œìš° ë‚´ì—ì„œ ë„êµ¬ë¡œ ì‚¬ìš©ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [3, 13].  AgentëŠ” í”„ë¡œì íŠ¸ ê´€ë¦¬ìžì™€ ìœ ì‚¬í•˜ê²Œ LLMì—ê²Œ íŒ”ë‹¤ë¦¬ë¥¼ ì œê³µí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤ [6, 16].
*   **ìž¥ì :**
    *   ë³µìž¡í•œ ì¶”ë¡  ë° ë‹¤ë‹¨ê³„ ì˜ì‚¬ ê²°ì •ì´ í•„ìš”í•œ ë¬¸ì œ í•´ê²°ì— ì í•©í•©ë‹ˆë‹¤ [1, 11].
    *   ë°©ëŒ€í•œ ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° íš¨ê³¼ì ìž…ë‹ˆë‹¤ [7, 17].
    *   ì‹œë§¨í‹± ìºì‹± ë° ê³ ê¸‰ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í†µí•´ LLM í˜¸ì¶œ ë¹„ìš© ë° ì§€ì—° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [9, 19].
    *   ì—¬ëŸ¬ ë„êµ¬ë¥¼ í†µí•©í•˜ì—¬ ë³µìž¡í•œ ìž‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤ [8, 18].
*   **ë‹¨ì :**
    *   êµ¬í˜„ì´ ë³µìž¡í•˜ê³  ê°œë°œ ë¹„ìš©ì´ ë†’ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
    *   ì‹œìŠ¤í…œ ì„¤ê³„ ë° ì—ì´ì „íŠ¸ ì •ì˜ì— ëŒ€í•œ ê¹Šì€ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    *   RAGë³´ë‹¤ ë” ë§Žì€ ê³„ì‚° ìžì›ì„ í•„ìš”ë¡œ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

**ì–¸ì œ ì–´ë–¤ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œìš”?**

*   **RAG:**
    *   ì •ì ì¸ ì§€ì‹ ê¸°ë°˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ë•Œ
    *   ë¹ ë¥¸ í”„ë¡œí† íƒ€ìž… ê°œë°œ ë˜ëŠ” PoC (Proof of Concept)ë¥¼ ìˆ˜í–‰í•  ë•Œ
    *   ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ë‚˜ ë³µìž¡í•œ ì¶”ë¡ ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°
*   **Agent ê¸°ë°˜ ì ‘ê·¼ë²•:**
    *   ë³µìž¡í•œ ë¬¸ì œ í•´ê²° ë° ë‹¤ë‹¨ê³„ ì˜ì‚¬ ê²°ì • í”„ë¡œì„¸ìŠ¤ë¥¼ ìžë™í™”í•´ì•¼ í•  ë•Œ
    *   ë°©ëŒ€í•œ ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë¶„ì„í•´ì•¼ í•  ë•Œ
    *   LLM í˜¸ì¶œ ë¹„ìš© ë° ì§€ì—° ì‹œê°„ì„ ìµœì í™”í•´ì•¼ í•  ë•Œ
    *   ë‹¤ì–‘í•œ ë„êµ¬ì™€ ì„œë¹„ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ LLMì˜ ê¸°ëŠ¥ì„ í™•ìž¥í•´ì•¼ í•  ë•Œ

Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  LLMì˜ ìž ìž¬ë ¥ì„ ìµœëŒ€í•œ ë°œíœ˜í•  ìˆ˜ ìžˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. íŠ¹ížˆ, Agentic RAGëŠ” ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œ, ì²˜ë¦¬ ë° ì‚¬ìš©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìžˆë„ë¡ LLMì„ ì§€ì›í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸ˆìœµ ë³´ê³ ì„œ ë¶„ì„, ê³ ê° ì„œë¹„ìŠ¤ ìžë™í™”, ì—°êµ¬ ë°ì´í„° ë¶„ì„ ë“± ë³µìž¡í•œ ìž‘ì—…ì— ì í•©í•©ë‹ˆë‹¤. RAGê°€ ê°„ë‹¨í•œ ì •ë³´ ê²€ìƒ‰ì— ìœ ìš©í•œ ë°˜ë©´, Agentic RAGëŠ” ë³µìž¡í•œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤ [4, 14].

## ê´€ë ¨ ìžë£Œ ë° ì¶œì²˜

[1] https://osckorea.tistory.com/332
[2] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
[3] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
[4] https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/
[5] https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/
[6] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
[7] https://www.slexn.com/agentic-rag-contextual-ai/
[8] https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC
[9] https://osckorea.tistory.com/332
[10] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
[11] https://osckorea.tistory.com/332
[12] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037
[13] https://www.linkedin.com/posts/alexxubyte_systemdesign-coding-interviewtips-activity-7344040591753678849-j-6J
[14] https://uracle.blog/2025/05/16/ai-agent-%EA%B0%9C%EB%85%90%EB%B6%80%ED%84%B0-agentic-rag-%EC%9D%91%EC%9A%A9%EA%B9%8C%EC%A7%80/
[15] https://mitrix.io/blog/llm-fine%E2%80%91tuning-vs-rag-vs-agents-a-practical-comparison/
[16] https://www.bitcot.com/rag-vs-agentic-rag-vs-mcp/
[17] https://www.slexn.com/agentic-rag-contextual-ai/
[18] https://velog.io/@cathx618/RAG%EC%99%80-Agent%EA%B0%80-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EC%82%AC%EB%9E%8C%EB%93%A4%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A0%95%EB%A6%AC
[19] https://osckorea.tistory.com/332
[20] https://medium.com/@datajournal/rag-vs-agentic-rag-a-comprehensive-guide-6711cce24037

## ê²°ë¡  ë° í‰ê°€

RAGì™€ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ê°ê° ê³ ìœ í•œ ìž¥ë‹¨ì ì„ ê°€ì§€ê³  ìžˆìœ¼ë©°, ì‚¬ìš© ì‚¬ë¡€ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ì†”ë£¨ì…˜ì´ í•„ìš”í•˜ë‹¤ë©´ RAGê°€ ì í•©í•˜ì§€ë§Œ, ë³µìž¡í•˜ê³  ì§€ëŠ¥ì ì¸ ìžë™í™”ê°€ í•„ìš”í•˜ë‹¤ë©´ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì´ ë” ë‚˜ì€ ì„ íƒìž…ë‹ˆë‹¤. Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ LLMì˜ í™œìš© ë²”ìœ„ë¥¼ ë„“ížˆê³  ë” ê°•ë ¥í•œ AI ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì•žìœ¼ë¡œ Agent ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ë”ìš± ë°œì „í•˜ì—¬ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì´ëŒì–´ë‚¼ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.
======================================================================


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Phase 3 Summary (3 tests)
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘  Average Time: 36.97s
â•‘  Average Tokens: 1272
â•‘  Citation Rate: 100%
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“ Results saved to: benchmark_results/phase_3_20251220_223228.json
