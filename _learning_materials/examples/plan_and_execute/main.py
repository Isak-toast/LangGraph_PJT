
"""
LangGraph: Plan-and-Execute (ê³„íš ë° ì‹¤í–‰)
===========================================
ì´ ì˜ˆì œëŠ” ë³µì¡í•œ ì‘ì—…ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ "ê³„íš(Plan)"ê³¼ "ì‹¤í–‰(Execute)" ë‹¨ê³„ë¥¼ ë¶„ë¦¬í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤.
ReAct ì—ì´ì „íŠ¸ì™€ ë‹¬ë¦¬, ë¨¼ì € ì „ì²´ ê³„íšì„ ì„¸ìš°ê³  í•˜ë‚˜ì”© ì‹¤í–‰í•˜ë©°, í•„ìš” ì‹œ ì¬ê³„íš(Replan)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

í•µì‹¬ íë¦„:
[Planner] -> [Executor] -> [Replanner] --(ë¯¸ì™„ë£Œ)--> [Executor]
                             |
                           (ì™„ë£Œ)
                             â†“
                           [END]

êµ¬ì„± ìš”ì†Œ:
1. Planner: ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ë‹¨ê³„ë³„ ê³„íš(steps)ì„ ìƒì„±í•©ë‹ˆë‹¤.
2. Executor: ê³„íšì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. (ì´ ì˜ˆì œì—ì„  ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜)
3. Replanner: ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ê³ , ë‚¨ì€ ê³„íšì„ ìˆ˜ì •í•˜ê±°ë‚˜ ì¢…ë£Œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
"""

import os
import dotenv
from typing import Annotated, List, TypedDict
import operator
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
script_dir = Path(__file__).parent
project_root = script_dir.parent
env_file = project_root / ".env"
if not env_file.exists():
    env_file = script_dir / ".env"
dotenv.load_dotenv(env_file)

# LangSmith ì¶”ì  ì„¤ì •
if os.getenv("LANGCHAIN_TRACING_V2") == "true":
    print("ğŸ“Š LangSmith ì¶”ì ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   í”„ë¡œì íŠ¸: {os.getenv('LANGCHAIN_PROJECT', 'default')}")


# =============================================================================
# 1. ë°ì´í„° ëª¨ë¸ (Data Models)
# =============================================================================
class Plan(BaseModel):
    """ì‹¤í–‰í•  ê³„íš"""
    steps: List[str] = Field(description="ì‹¤í–‰í•  ë‹¨ê³„ë“¤ì˜ ëª©ë¡ (ìˆœì„œëŒ€ë¡œ)")

class Response(BaseModel):
    """ìµœì¢… ë‹µë³€"""
    response: str
    
class PlanExecuteState(TypedDict):
    """ê·¸ë˜í”„ ìƒíƒœ"""
    input: str
    plan: List[str] # ë‚¨ì€ ë‹¨ê³„ë“¤
    past_steps: Annotated[List[tuple], operator.add] # (ì‹¤í–‰í•œ ë‹¨ê³„, ê²°ê³¼)ì˜ ë¦¬ìŠ¤íŠ¸
    response: str # ìµœì¢… ê²°ê³¼


# =============================================================================
# 2. ë…¸ë“œ (Nodes)
# =============================================================================
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)

def planner(state: PlanExecuteState):
    """
    [Planner] ì´ˆê¸° ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("--- [Planner] ì´ˆê¸° ê³„íš ìˆ˜ë¦½ ì¤‘ ---")
    planner_llm = llm.with_structured_output(Plan)
    plan = planner_llm.invoke(f"For the given objective, come up with a simple step by step plan. \nObjective: {state['input']}")
    return {"plan": plan.steps}

def executor(state: PlanExecuteState):
    """
    [Executor] ê³„íšì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    plan = state["plan"]
    step_to_execute = plan[0] # ì²« ë²ˆì§¸ ë‹¨ê³„
    print(f"--- [Executor] ë‹¨ê³„ ì‹¤í–‰: {step_to_execute} ---")
    
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ ë„êµ¬(Tool)ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” LLMì—ê²Œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤.
    task_llm = llm
    result = task_llm.invoke(f"Execute this task: {step_to_execute}. Provide a concise result.")
    
    return {
        "past_steps": [(step_to_execute, result.content)], # ì‹¤í–‰ ê¸°ë¡ ì¶”ê°€
        "plan": plan[1:] # ì‹¤í–‰í•œ ë‹¨ê³„ ì œê±°
    }

def replanner(state: PlanExecuteState):
    """
    [Replanner] ì¬ê³„íš ë˜ëŠ” ì¢…ë£Œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    # ë‚¨ì€ ë‹¨ê³„ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not state["plan"]:
        print("--- [Replanner] ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ! ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘ ---")
        final_response = llm.invoke(f"Generate a final response to the original input based on these steps: {state['past_steps']}\nOriginal Input: {state['input']}")
        return {"response": final_response.content}
    
    # ë‚¨ì€ ë‹¨ê³„ê°€ ìˆìœ¼ë©´ ê³„ì† ì§„í–‰ (ì—¬ê¸°ì„œ ê³„íšì„ ìˆ˜ì •í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ë„ ìˆìŒ)
    print(f"--- [Replanner] {len(state['plan'])}ê°œ ë‹¨ê³„ ë‚¨ìŒ... ê³„ì† ì§„í–‰ ---")
    return {} # ìƒíƒœ ì—…ë°ì´íŠ¸ëŠ” conditional edgeì—ì„œ ë£¨í”„ ì œì–´ìš©

def should_end(state: PlanExecuteState):
    """
    ì¢…ë£Œ ì¡°ê±´: responseê°€ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì¢…ë£Œ, ì•„ë‹ˆë©´ ê³„ì† ì‹¤í–‰
    """
    if state.get("response"):
        return END
    return "executor"


# =============================================================================
# 3. ê·¸ë˜í”„ (Graph)
# =============================================================================
workflow = StateGraph(PlanExecuteState)

workflow.add_node("planner", planner)
workflow.add_node("executor", executor)
workflow.add_node("replanner", replanner)

workflow.add_edge(START, "planner")
workflow.add_edge("planner", "executor")
workflow.add_edge("executor", "replanner")
workflow.add_conditional_edges("replanner", should_end, ["executor", END])

app = workflow.compile()


# =============================================================================
# 4. ì‹¤í–‰ (Execution)
# =============================================================================
def main():
    print("Initializing Plan-and-Execute Agent...")
    try:
        with open("plan_execute_graph.png", "wb") as f:
            f.write(app.get_graph().draw_mermaid_png())
        print("Graph saved to 'plan_execute_graph.png'")
    except Exception as e:
        print(f"Skipping visualization: {e}")
        
    user_input = "Write a haiku about Python and then explain it."
    print(f"\n--- User Request: {user_input} ---")
    
    config = {"recursion_limit": 50}
    inputs = {"input": user_input}
    
    # ì‹¤í–‰
    for event in app.stream(inputs, config=config):
        for k, v in event.items():
            # replannerê°€ ìµœì¢… ì‘ë‹µì„ ëƒˆì„ ë•Œë§Œ ì¶œë ¥
            if v and k == "replanner" and "response" in v:
                print(f"\n[Final Response]:\n{v['response']}")

if __name__ == "__main__":
    main()
