
"""
LangGraph: LATS (Language Agent Tree Search)
=============================================
ì´ ì˜ˆì œëŠ” LATS(Language Agent Tree Search)ì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•œ
ê°„ì†Œí™”ëœ ë°ëª¨ì…ë‹ˆë‹¤. (ì‹¤ì œ íŠ¸ë¦¬ë¥¼ íƒìƒ‰í•˜ëŠ” ë³µì¡í•œ ë¡œì§ ëŒ€ì‹ , 'Best-of-N' ë°©ì‹ì— ê°€ê¹ìŠµë‹ˆë‹¤)

í•µì‹¬ ê°œë…:
1. Expansion (í™•ì¥): í•˜ë‚˜ì˜ ìƒíƒœì—ì„œ ì—¬ëŸ¬ ê°€ì§€ í•´ê²°ì±…(í›„ë³´)ì„ ìƒì„±í•©ë‹ˆë‹¤.
   - LLM Temperatureë¥¼ ë†’ì—¬ì„œ ë‹¤ì–‘í•œ ì‹œë„ë¥¼ ìœ ë„í•©ë‹ˆë‹¤.

2. Scoring (í‰ê°€): ìƒì„±ëœ í›„ë³´ë“¤ì˜ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
   - LLMì´ ìì‹ ì˜ ìƒì„±ë¬¼ì„ ìŠ¤ìŠ¤ë¡œ í‰ê°€(Self-Correction/Reflection)í•˜ê²Œ ì„­ë‹ˆë‹¤.

3. Selection (ì„ íƒ): ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ í›„ë³´ë¥¼ ì„ íƒí•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°‘ë‹ˆë‹¤.

êµ¬ì¡° (Best-of-N Pipeline):
[Expand] --(Nê°œ í›„ë³´)--> [Score] --(ì ìˆ˜)--> [Select] --> [END]
"""

import os
import dotenv
from typing import Annotated, List, Dict, Literal
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from pydantic import BaseModel, Field
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
script_dir = Path(__file__).parent
project_root = script_dir.parent
env_file = project_root / ".env"
if not env_file.exists():
    env_file = script_dir / ".env"
dotenv.load_dotenv(env_file)

# LangSmith ì¶”ì  ì„¤ì •
if os.getenv("LANGCHAIN_TRACING_V2") == "true":
    print("ğŸ“Š LangSmith ì¶”ì ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   í”„ë¡œì íŠ¸: {os.getenv('LANGCHAIN_PROJECT', 'default')}")


# =============================================================================
# 1. ì„¤ì • ë° ìƒíƒœ (Config & State)
# =============================================================================
# LATSëŠ” í™•ì¥ì„ ìœ„í•´ ë‹¤ì–‘ì„±ì´ í•„ìš”í•˜ë¯€ë¡œ Temperatureë¥¼ ë†’ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=1.0)

class LatsState(BaseModel):
    """LATS ê·¸ë˜í”„ ìƒíƒœ"""
    # í•´ê²°í•´ì•¼ í•  ë¬¸ì œ
    input: str
    # í˜„ì¬ê¹Œì§€ ì°¾ì€ ìµœê³ ì˜ í•´ê²°ì±…
    final_answer: str = None
    # í˜„ì¬ ë‹¨ê³„(ê¹Šì´)ì—ì„œ ìƒì„±ëœ í›„ë³´ë“¤
    candidates: List[str] = []
    # í›„ë³´ë“¤ì— ëŒ€í•œ ì ìˆ˜
    scores: List[float] = []
    # íƒìƒ‰ ê¹Šì´ (ì´ ì˜ˆì œì—ì„  í¬ê²Œ í™œìš© ì•ˆë¨)
    height: int = 0


# =============================================================================
# 2. ë…¸ë“œ (Nodes)
# =============================================================================

def expand_node(state: LatsState):
    """
    [í™•ì¥] Nê°œì˜ í›„ë³´ í•´ê²°ì±…ì„ ìƒì„±í•©ë‹ˆë‹¤.
    (ì‹¤ì œ LATSëŠ” 'ë‹¤ìŒ ë‹¨ê³„'ë¥¼ ìƒì„±í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” 'ì „ì²´ í•´ê²°ì±…'ì„ Në²ˆ ì‹œë„í•©ë‹ˆë‹¤)
    """
    print(f"---[Expand] í›„ë³´ ìƒì„± ì¤‘ (Height: {state.height})---")
    
    n = 3 # ìƒì„±í•  í›„ë³´ ê°œìˆ˜
    candidates = []
    for i in range(n):
        res = llm.invoke(f"Solve this problem: {state.input}. Provide a short candidate solution attempt. Current attempt number {i+1}")
        candidates.append(res.content)
    
    return {"candidates": candidates}

def score_node(state: LatsState):
    """
    [í‰ê°€] ìƒì„±ëœ í›„ë³´ë“¤ì— ì ìˆ˜(0.0 ~ 1.0)ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
    """
    print("---[Score] í›„ë³´ í‰ê°€ ì¤‘---")
    candidates = state.candidates
    scores = []
    
    # LLMì—ê²Œ ì±„ì ì„ ìš”ì²­
    for cand in candidates:
        prompt = f"""Rate the correctness of the following solution to the problem: '{state.input}'.
        Solution: {cand}
        Provide ONLY a float number between 0.0 and 1.0."""
        res = llm.invoke(prompt)
        try:
            score = float(res.content.strip())
        except:
            score = 0.5 # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        scores.append(score)
        print(f"   > Score: {score}")
        
    return {"scores": scores}

def select_node(state: LatsState):
    """
    [ì„ íƒ] ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ í›„ë³´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    """
    print("---[Select] ìµœê³  í›„ë³´ ì„ íƒ ì¤‘---")
    
    # ìµœê³ ì  ì°¾ê¸°
    best_idx = state.scores.index(max(state.scores))
    best_score = state.scores[best_idx]
    best_candidate = state.candidates[best_idx]
    
    print(f"   >>> Best Score: {best_score}")
    
    # (ì„ íƒì  ë¡œì§) ì ìˆ˜ê°€ ì¼ì • ìˆ˜ì¤€ ì´ìƒì´ì–´ì•¼ ì±„íƒí•˜ê±°ë‚˜, ì•„ë‹ˆë©´ ì¬ì‹œë„í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ
    # ì—¬ê¸°ì„œëŠ” ë¬´ì¡°ê±´ ë² ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ê³  ì¢…ë£Œ
    return {"final_answer": best_candidate}


# =============================================================================
# 3. ê·¸ë˜í”„ (Graph)
# =============================================================================
workflow = StateGraph(LatsState)

workflow.add_node("expand", expand_node)
workflow.add_node("score", score_node)
workflow.add_node("select", select_node)

workflow.add_edge(START, "expand")
workflow.add_edge("expand", "score")
workflow.add_edge("score", "select")
workflow.add_edge("select", END) 

app = workflow.compile()


# =============================================================================
# 4. ì‹¤í–‰ (Execution)
# =============================================================================
def main():
    print("Initializing LATS (Best-of-N Demo)...")
    try:
        with open("lats_graph.png", "wb") as f:
            f.write(app.get_graph().draw_mermaid_png())
        print("Graph saved to 'lats_graph.png'")
    except Exception as e:
        print(f"Skipping visualization: {e}")

    # ê²€ì¦ì´ í•„ìš”í•œ ìˆ˜í•™ ë¬¸ì œ
    problem = "What is 24 * 56 + 18?"
    inputs = {"input": problem}
    print(f"\n--- User Problem: {problem} ---\n")
    
    result = app.invoke(inputs)
    
    print("\n--- Final Best Solution ---")
    print(result["final_answer"])

if __name__ == "__main__":
    main()
