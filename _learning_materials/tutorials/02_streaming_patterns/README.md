# ìŠ¤íŠ¸ë¦¬ë° íŒ¨í„´ (Streaming Patterns)

LangGraphì˜ ê°•ë ¥í•œ ê¸°ëŠ¥ì¸ **Streaming API** (`stream_mode="values"`, `stream_mode="updates"`)ì˜ ì°¨ì´ì ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.

## LangGraphë€?

LangGraphëŠ” LangChain íŒ€ì—ì„œ ê°œë°œí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, **ìƒíƒœ ê¸°ë°˜ì˜ ìˆœí™˜ ê·¸ë˜í”„ êµ¬ì¡°**ë¥¼ í†µí•´ ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¬ë°ì€ ì‹¤ì‹œê°„ ì‘ë‹µì„ ìœ„í•œ í•µì‹¬ ê¸°ëŠ¥ì…ë‹ˆë‹¤.

## ì´ ì˜ˆì œì—ì„œ ë°°ìš°ëŠ” ê²ƒ

- **stream_modeì˜ ì¢…ë¥˜**: valuesì™€ updatesì˜ ì°¨ì´ì 
- **ì‹¤ì‹œê°„ í”¼ë“œë°±**: ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë°©ë²•
- **ìƒíƒœ ì¶”ì **: ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ìƒíƒœ ë³€í™”ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ë°©ë²•

## ì‹¤í–‰ ëª¨ë“œ ë¹„êµ

| ëª¨ë“œ | ë°˜í™˜ ê°’ | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|---------|--------------|
| **values** | ê° ë‹¨ê³„ í›„ì˜ **ì „ì²´ ìƒíƒœ** | UIì—ì„œ ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ ë‹¤ì‹œ ê·¸ë¦´ ë•Œ |
| **updates** | ê° ë…¸ë“œê°€ ìˆ˜í–‰í•œ **ë³€ê²½ ì‚¬í•­ë§Œ** | ë¡œê·¸, íŠ¹ì • ì•¡ì…˜ ì¶”ì  |

---

## ğŸ“ ì½”ë“œ ìƒì„¸ ë¶„ì„

### 1. ìƒíƒœ ë° ë…¸ë“œ ì •ì˜

```python
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph.message import add_messages
import time

class State(TypedDict):
    messages: Annotated[list, add_messages]

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0, stream=True)

def chatbot(state: State):
    """LLM ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ"""
    return {"messages": [llm.invoke(state["messages"])]}

def slow_node(state: State):
    """ì‹œê°„ì´ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ë…¸ë“œ"""
    time.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
    return {"messages": [AIMessage(content="[System] Processed data slowly...")]}
```

**ì„¤ëª…**: 
- `slow_node`ëŠ” ì‹œê°„ì´ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ì‹œë®¬ë ˆì´ì…˜
- ìŠ¤íŠ¸ë¦¬ë°ì´ ì—†ë‹¤ë©´ ì‚¬ìš©ìëŠ” ëª¨ë“  ì‘ì—…ì´ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì•¼ í•¨

---

### 2. ê·¸ë˜í”„ êµ¬ì„±

```python
graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("slow_process", slow_node)

graph_builder.add_edge(START, "chatbot")
graph_builder.add_edge("chatbot", "slow_process")
graph_builder.add_edge("slow_process", END)

graph = graph_builder.compile()
```

**íë¦„**: `START` â†’ `chatbot` â†’ `slow_process` â†’ `END`

---

### 3. Mode 1: Stream Values

```python
print("=== Mode 1: Stream Values ===")
for event in graph.stream(inputs, stream_mode="values"):
    # Returns the entire state {'messages': [...]}
    last_msg = event["messages"][-1]
    print(f"State Update: Last message from {last_msg.type}: {last_msg.content[:30]}...")
```

**ì¶œë ¥ í˜•íƒœ**:
```
State Update: Last message from human: Tell me a very short story ab...
State Update: Last message from ai: Once upon a time, in a factory...
State Update: Last message from ai: [System] Processed data slowly...
```

**íŠ¹ì§•**:
- ê° ë‹¨ê³„ë§ˆë‹¤ **ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸**ê°€ ë°˜í™˜ë¨
- UIì—ì„œ ì±„íŒ… í™”ë©´ì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ë Œë”ë§í•  ë•Œ ìœ ìš©

---

### 4. Mode 2: Stream Updates

```python
print("=== Mode 2: Stream Updates ===")
for event in graph.stream(inputs, stream_mode="updates"):
    # Returns {node_name: node_output}
    for node_name, node_output in event.items():
        print(f"Node '{node_name}' finished. Added {len(node_output['messages'])} message(s).")
```

**ì¶œë ¥ í˜•íƒœ**:
```
Node 'chatbot' finished. Added 1 message(s).
Node 'slow_process' finished. Added 1 message(s).
```

**íŠ¹ì§•**:
- ê° ë…¸ë“œê°€ **ì¶”ê°€í•œ ë³€ê²½ ì‚¬í•­ë§Œ** ë°˜í™˜
- ë””ë²„ê¹…, ë¡œê¹…, ì§„í–‰ ìƒí™© ì¶”ì ì— ìœ ìš©

---

### 5. Mode 3: Stream Tokens (ê³ ê¸‰)

```python
# í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì€ astream_events API ì‚¬ìš©
# ê° LLM í† í°ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ ì´ë²¤íŠ¸ ë°œìƒ
# ì‹¤ì‹œê°„ íƒ€ì´í•‘ íš¨ê³¼ êµ¬í˜„ì— ì‚¬ìš©
```

> í† í° ìŠ¤íŠ¸ë¦¬ë°ì€ `astream_events` APIë¥¼ í†µí•´ êµ¬í˜„í•©ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

## ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì„ íƒ ê°€ì´ë“œ

```mermaid
graph TD
    Start[ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì„ íƒ] --> Q1{UI ë Œë”ë§?}
    Q1 -->|Yes| Values["stream_mode='values'"]
    Q1 -->|No| Q2{ì§„í–‰ ì¶”ì ?}
    Q2 -->|Yes| Updates["stream_mode='updates'"]
    Q2 -->|No| Q3{í† í° ë‹¨ìœ„?}
    Q3 -->|Yes| Events["astream_events()"]
    Q3 -->|No| NoStream["stream ì•ˆ í•¨ (invoke)"]
```

---

## í™œìš© ì‚¬ë¡€

1. **ì±„íŒ… UI êµ¬í˜„**: ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ í‘œì‹œí•˜ëŠ” ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
2. **ì§„í–‰ ìƒí™© í‘œì‹œ**: ë³µì¡í•œ ì‘ì—…ì˜ ê° ë‹¨ê³„ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë•Œ
3. **ë””ë²„ê¹…**: ê·¸ë˜í”„ ì‹¤í–‰ ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì í•  ë•Œ

## ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ: ì±„íŒ… UI

```python
# React/Vueì—ì„œ ì‚¬ìš©í•  ë•Œ
async for event in graph.astream(inputs, stream_mode="values"):
    # WebSocketìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
    await websocket.send(json.dumps({
        "messages": serialize_messages(event["messages"])
    }))
```

## ë¹ ë¥¸ ì‹œì‘

1.  í´ë” ì´ë™:
    ```bash
    cd 02_streaming_patterns
    ```
2.  ì‹¤í–‰:
    ```bash
    # (ìµœì´ˆ ì‹¤í–‰ ì‹œ) cp ../multi_agent_supervisor/.env .
    python main.py
    ```

## ì‹¤í–‰ ì˜ˆì‹œ

> "Tell me a very short story about a robot."

**ì˜ˆìƒ ì¶œë ¥**:
```
=== Mode 1: Stream Values ===
State Update: Last message from human: Tell me a very short story...
State Update: Last message from ai: Once upon a time...
State Update: Last message from ai: [System] Processed data slowly...

=== Mode 2: Stream Updates ===
Node 'chatbot' finished. Added 1 message(s).
Node 'slow_process' finished. Added 1 message(s).
```

---

*LangGraph íŠœí† ë¦¬ì–¼ í”„ë¡œì íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.*
