# Agentic RAG

ë‹¨ìˆœ ê²€ìƒ‰ì´ ì•„ë‹ˆë¼, ê²€ìƒ‰ëœ ë¬¸ì„œì˜ **ì—°ê´€ì„±ì„ í‰ê°€(Grade)**í•˜ê³ , í•„ìš”ì‹œ ì¬ìƒì„±í•˜ê±°ë‚˜ ë‹µë³€ì„ ê±°ë¶€í•˜ëŠ” ëŠ¥ë™ì ì¸ RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## LangGraphë€?

LangGraphëŠ” LangChain íŒ€ì—ì„œ ê°œë°œí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, **ìƒíƒœ ê¸°ë°˜ì˜ ìˆœí™˜ ê·¸ë˜í”„ êµ¬ì¡°**ë¥¼ í†µí•´ ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. Agentic RAGëŠ” RAG ì‹œìŠ¤í…œì— ì—ì´ì „íŠ¸ ê¸°ëŠ¥ì„ ê²°í•©í•œ ê³ ê¸‰ íŒ¨í„´ì…ë‹ˆë‹¤.

## ì´ ì˜ˆì œì—ì„œ ë°°ìš°ëŠ” ê²ƒ

- **ë¬¸ì„œ í‰ê°€ (Grading)**: ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ì§€ LLMì´ í‰ê°€
- **êµ¬ì¡°í™”ëœ ì¶œë ¥**: Pydantic ëª¨ë¸ë¡œ LLM ì¶œë ¥ í˜•ì‹ ê°•ì œ
- **ì¡°ê±´ë¶€ íë¦„**: í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì§„í–‰
- **í’ˆì§ˆ ë³´ì¥**: ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œëŠ” ì œì™¸í•˜ê³  ê´€ë ¨ ìˆëŠ” ë¬¸ì„œë§Œ ì‚¬ìš©

## ì•„í‚¤í…ì²˜

```mermaid
graph TD
    Start((Start)) --> Retrieve
    Retrieve[Retrieve Node<br/>ë¬¸ì„œ ê²€ìƒ‰] --> Grade
    Grade[Grade Documents<br/>ë¬¸ì„œ í‰ê°€] --> Decision{Relevant?}
    Decision -->|Yes| Generate[Generate<br/>ë‹µë³€ ìƒì„±]
    Decision -->|No| Generate
    Generate --> End((End))
```

---

## ğŸ“ ì½”ë“œ ìƒì„¸ ë¶„ì„

### 1. ê¸°ë³¸ ì„¤ì •

```python
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools.tavily_search import TavilySearchResults
from pydantic import BaseModel, Field

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
search_tool = TavilySearchResults(k=3)
```

---

### 2. ë¬¸ì„œ í‰ê°€ê¸° (Grader) - í•µì‹¬!

```python
class GradeDocuments(BaseModel):
    """Binary score for relevance check on retrieved documents."""
    binary_score: str = Field(
        description="Documents are relevant to the question, 'yes' or 'no'"
    )

# êµ¬ì¡°í™”ëœ ì¶œë ¥ ì„¤ì •
structured_llm_grader = llm.with_structured_output(GradeDocuments)

system_prompt_grader = """You are a grader assessing relevance of a retrieved document to a user question.
If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.
Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question."""
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- `with_structured_output(GradeDocuments)`: LLMì´ ë°˜ë“œì‹œ `GradeDocuments` í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
- í‰ê°€ ê²°ê³¼ëŠ” `"yes"` ë˜ëŠ” `"no"`

---

### 3. ë¬¸ì„œ í‰ê°€ ë…¸ë“œ

```python
def grade_documents(state):
    """Determines whether the retrieved documents are relevant to the question."""
    print("---CHECK RELEVANCE---")
    question = state["question"]
    documents = state["documents"]
    
    # ì²« ë²ˆì§¸ ë¬¸ì„œë§Œ í‰ê°€ (ë°ëª¨ìš©, ì‹¤ì œë¡œëŠ” ëª¨ë“  ë¬¸ì„œ í‰ê°€)
    score = structured_llm_grader.invoke(
        f"User question: {question}\n\nRetrieved document: {documents[0]['content']}"
    )
    grade = score.binary_score
    
    if grade == "yes":
        print("---DECISION: DOCUMENT RELEVANT---")
        return {"documents": documents}
    else:
        print("---DECISION: DOCUMENT NOT RELEVANT---")
        return {"documents": []}  # ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ í•„í„°ë§
```

---

### 4. ê²€ìƒ‰ ë…¸ë“œ

```python
def retrieve(state):
    """Retrieve documents from web search."""
    print("---RETRIEVE---")
    question = state["question"]
    docs = search_tool.invoke(question)
    # Tavily returns list of dicts with 'content' key
    return {"documents": docs}
```

---

### 5. ìƒì„± ë…¸ë“œ

```python
def generate(state):
    """Generates answer using the retrieved documents."""
    print("---GENERATE---")
    question = state["question"]
    documents = state["documents"]
    
    if not documents:
        return {"generation": "I could not find relevant information to answer your question."}

    # ë¬¸ì„œ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
    context = "\n\n".join([doc['content'] for doc in documents])
    
    prompt = f"""You are an assistant for question-answering tasks. 
    Use the following pieces of retrieved context to answer the question. 
    If you don't know the answer, just say that you don't know. 
    Use three sentences maximum and keep the answer concise.
    
    Question: {question} 
    Context: {context} 
    Answer:"""
    
    generation = llm.invoke(prompt)
    return {"generation": generation.content}
```

---

### 6. ìƒíƒœ ì •ì˜

```python
from typing import List, TypedDict

class GraphState(TypedDict):
    question: str       # ì‚¬ìš©ì ì§ˆë¬¸
    generation: str     # ìƒì„±ëœ ë‹µë³€
    documents: List[dict]  # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
```

---

### 7. ê·¸ë˜í”„ ì¡°ë¦½

```python
workflow = StateGraph(GraphState)

workflow.add_node("retrieve", retrieve)
workflow.add_node("grade_documents", grade_documents)
workflow.add_node("generate", generate)

workflow.add_edge(START, "retrieve")
workflow.add_edge("retrieve", "grade_documents")

def decide_to_generate(state):
    """Determines whether to generate an answer."""
    if not state["documents"]:
        return "generate"  # ë¬¸ì„œ ì—†ì–´ë„ generateë¡œ (I don't know ì‘ë‹µ)
    return "generate"

workflow.add_conditional_edges(
    "grade_documents",
    decide_to_generate,
    {"generate": "generate"}
)
workflow.add_edge("generate", END)

app = workflow.compile()
```

---

## ë™ì‘ íë¦„

```mermaid
sequenceDiagram
    participant User
    participant Retrieve
    participant Grade
    participant Generate

    User->>Retrieve: "What are the key features of LangGraph?"
    Retrieve->>Retrieve: Tavily ì›¹ ê²€ìƒ‰
    Retrieve->>Grade: documents[]
    
    Grade->>Grade: LLMìœ¼ë¡œ ê´€ë ¨ì„± í‰ê°€
    
    alt ê´€ë ¨ ìˆìŒ
        Grade->>Generate: documents[] (ìœ ì§€)
        Generate->>Generate: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±
        Generate-->>User: "LangGraph features are..."
    else ê´€ë ¨ ì—†ìŒ
        Grade->>Generate: documents[] (ë¹ˆ ë°°ì—´)
        Generate-->>User: "I could not find relevant information..."
    end
```

---

## ê³ ê¸‰ Agentic RAG íŒ¨í„´

### ì§ˆë¬¸ ì¬ì‘ì„± ì¶”ê°€

```python
def rewrite_query(state):
    """ê´€ë ¨ ë¬¸ì„œê°€ ì—†ì„ ë•Œ ì§ˆë¬¸ì„ ì¬ì‘ì„±"""
    question = state["question"]
    new_question = llm.invoke(f"Rewrite this question for better search: {question}")
    return {"question": new_question.content}

# ì¡°ê±´ë¶€ ì—£ì§€ì— ì¶”ê°€
workflow.add_conditional_edges(
    "grade_documents",
    decide_to_generate,
    {
        "generate": "generate",
        "rewrite": "rewrite_query"  # ê´€ë ¨ ì—†ìœ¼ë©´ ì¬ì‘ì„±
    }
)
```

### ë‹µë³€ í’ˆì§ˆ í‰ê°€ ì¶”ê°€

```python
def check_hallucination(state):
    """ë‹µë³€ì´ ë¬¸ì„œì— ê·¼ê±°í•˜ëŠ”ì§€ í™•ì¸"""
    # í™˜ê° ê²€ì‚¬ ë¡œì§
    pass
```

---

## í™œìš© ì‚¬ë¡€

1. **ê³ í’ˆì§ˆ QA ì‹œìŠ¤í…œ**: ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ ë³´ì¥í•˜ëŠ” ì§ˆì˜ì‘ë‹µ
2. **ì •í™•í•œ ì •ë³´ ì œê³µ**: ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ í•„í„°ë§í•˜ì—¬ ì •í™•ë„ í–¥ìƒ
3. **ì—”í„°í”„ë¼ì´ì¦ˆ ê²€ìƒ‰**: ê¸°ì—… ë¬¸ì„œì—ì„œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ ì œê³µ
4. **ì—°êµ¬ ë³´ì¡°**: ë…¼ë¬¸ì´ë‚˜ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë§Œ ì¶”ì¶œ

## ì¼ë°˜ RAG vs Agentic RAG

| í•­ëª© | ì¼ë°˜ RAG | Agentic RAG |
|------|----------|-------------|
| ë¬¸ì„œ í‰ê°€ | âŒ ì—†ìŒ | âœ… LLMì´ ê´€ë ¨ì„± í‰ê°€ |
| ì§ˆë¬¸ ì¬ì‘ì„± | âŒ ì—†ìŒ | âœ… í•„ìš”ì‹œ ìë™ ì¬ì‘ì„± |
| í’ˆì§ˆ ë³´ì¥ | âŒ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš© | âœ… ê´€ë ¨ ë¬¸ì„œë§Œ ì‚¬ìš© |
| ë³µì¡ë„ | ë‚®ìŒ | ë†’ìŒ |

## ë¹ ë¥¸ ì‹œì‘

1.  í´ë” ì´ë™:
    ```bash
    cd 06_agentic_rag
    ```
2.  ì‹¤í–‰:
    ```bash
    # (ìµœì´ˆ ì‹¤í–‰ ì‹œ) cp ../multi_agent_supervisor/.env .
    python main.py
    ```

## ì‹¤í–‰ ì˜ˆì‹œ

```
Initializing Agentic RAG...
---RETRIEVE---
---CHECK RELEVANCE---
---DECISION: DOCUMENT RELEVANT---
---GENERATE---

--- Final Result ---
LangGraph is a library for building stateful, multi-actor applications with LLMs. 
It provides tools for creating complex agent workflows with cycles and branching.
```

---

*LangGraph íŠœí† ë¦¬ì–¼ í”„ë¡œì íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.*
